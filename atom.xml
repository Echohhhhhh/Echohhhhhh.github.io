<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Echo&#39;s blog</title>
  
  <subtitle>远方到底有多远</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-07-14T16:35:40.262Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Echo</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>面试之海量数据处理</title>
    <link href="http://yoursite.com/2020/07/15/%E9%9D%A2%E8%AF%95%E4%B9%8B%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    <id>http://yoursite.com/2020/07/15/面试之海量数据处理/</id>
    <published>2020-07-14T16:07:09.000Z</published>
    <updated>2020-07-14T16:35:40.262Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="b树和b树">B树和B+树</span></h1><p>为了减少磁盘I/O，磁盘上的数据通常以树的形式存储。<strong>树中每个节点对应一次磁盘I/O</strong>，为了减少搜索时间，因此需要控制树的高度，像二叉树就不适合了，因为二叉树每个节点只有2个子树，导致树的层数很深。这里使用B树和B+树。<br>B树和B+树是多叉搜索树。</p><p>B树</p><ul><li>所有叶子节点位于同一层</li><li>多叉搜索树</li><li>B树的中间节点和叶子节点都表示实际的数据</li></ul><p><img src="/2020/07/15/面试之海量数据处理/B树.jpg" alt=""></p><p>B树的查找顺序为：</p><ol><li>从根节点开始，如果查找的数据比根节点小，就去左子树中找，否则去右子树找</li><li>和子树的多个关键字比较，找出目标所处的范围，然后去范围对应的子树中继续查找</li><li>以此循环，直到找到</li></ol><p>B+树</p><ul><li>叶子节点都在同一层</li><li>多叉搜索树</li><li>B+数的中间节点不保存数据，只用来索引，所有的数据保存在叶子节点上</li></ul><p><img src="/2020/07/15/面试之海量数据处理/B+树.jpg" alt=""></p><p>从图可以看出，B+树的中间节点和叶子节点有重复的数据，这是因为中间节点保存的只是子树数据中的指针，并不是真正的数据。<br>因为中间节点存储的是指针，而指针占用的空间比较少，所以一个节点可以保存很多个指针，使得B+数比B数矮胖，相对而言，读取I/O次数更少。</p><p><strong>磁盘存储的知识</strong></p><ol><li>磁盘I/O比在内存中操作慢非常非常非常多，因此需要尽量减少磁盘I/O操作，即不要过多的读取磁盘</li><li>磁盘I/O时间=寻道+磁盘旋转+数据传输时间<br>从磁盘中读取数据时，系统会将逻辑地址发给磁盘，磁盘将逻辑地址转换为物理地址（哪个磁道，哪个扇区），然后磁头转到相应的磁道，再找到该磁道对应的扇区。</li><li><p>扇区是磁盘的最小存储单元。一次磁盘I/O会读出一个扇<br>区的数据，因此读1个字节和读4k（一个扇区）需要的时间几乎一样</p><p><img src="/2020/07/15/面试之海量数据处理/磁道.jpg" alt=""></p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;&lt;span id=&quot;b树和b树&quot;&gt;B树和B+树&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;为了减少磁盘I/O，磁盘上的数据通常以树的形式存储。&lt;strong&gt;树中每个节点对应一次磁盘I/O&lt;/strong&gt;，为了减少搜索时间，因此需要控制树的高度，像二叉树就不适合了，因为二叉树每个节点
      
    
    </summary>
    
      <category term="算法" scheme="http://yoursite.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>百面机器学习概述二</title>
    <link href="http://yoursite.com/2020/07/05/%E7%99%BE%E9%9D%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0%E4%BA%8C/"/>
    <id>http://yoursite.com/2020/07/05/百面机器学习概述二/</id>
    <published>2020-07-05T14:34:41.000Z</published>
    <updated>2020-07-15T01:53:47.007Z</updated>
    
    <content type="html"><![CDATA[<p>总结《百面机器学习》有关知识点。</p><a id="more"></a><!-- TOC --><ul><li><a href="#1-损失函数">1. 损失函数</a><ul><li><a href="#11-分类损失函数">1.1. 分类损失函数</a><ul><li><a href="#111-二分类和多分类">1.1.1. 二分类和多分类</a></li></ul></li><li><a href="#12-回归损失函数">1.2. 回归损失函数</a></li></ul></li><li><a href="#2-梯度下降">2. 梯度下降</a></li><li><a href="#3-dropout">3. Dropout</a></li><li><a href="#4-集成学习">4. 集成学习</a><ul><li><a href="#41-boosting和bagging">4.1. Boosting和Bagging</a></li><li><a href="#42-集成学习步骤和例子">4.2. 集成学习步骤和例子</a></li><li><a href="#43-偏差和方差">4.3. 偏差和方差</a></li><li><a href="#44-常见集成学习模型">4.4. 常见集成学习模型</a><ul><li><a href="#441-随机森林">4.4.1. 随机森林</a></li><li><a href="#442-adaboost">4.4.2. AdaBoost</a></li><li><a href="#443-gbdt">4.4.3. GBDT</a></li><li><a href="#444-xgboost">4.4.4. XGBoost</a></li><li><a href="#445-gdbt和xgboost区别">4.4.5. GDBT和XGBoost区别</a></li></ul></li></ul></li><li><a href="#5-cnn">5. CNN</a></li><li><a href="#6-gnn">6. GNN</a><ul><li><a href="#61-deepwalk">6.1. DeepWalk</a></li><li><a href="#62-line">6.2. LINE</a></li><li><a href="#63-图卷积神经网络">6.3. 图卷积神经网络</a><ul><li><a href="#631-谱图卷积">6.3.1. 谱图卷积</a></li><li><a href="#632-空间图卷积">6.3.2. 空间图卷积</a></li></ul></li></ul></li></ul><!-- /TOC --><h1><span id="1-损失函数">1. 损失函数</span></h1><p>损失函数用来评估模型预测值和真实值的差异，损失越小，说明模型的性能越好。<br>损失函数分为经验风险损失、结构风险损失<br>经验风险损失指预测值和真实值的差异<br>结构风险损失=经验风险损失+正则化</p><h2><span id="11-分类损失函数">1.1. 分类损失函数</span></h2><p><strong>1. 0-1损失函数</strong></p><script type="math/tex; mode=display">L(Y, f(X))=\left\{\begin{array}{l}   1, Y \neq f(X) \\   0, Y=f(X)   \end{array}\right.</script><p>   特点：<br>   （1）0-1损失表示分类错误的个数，但是它是一个非凸函数，不太适用<br>   （2）这个损失函数的条件太严格，需要严格等于真实值</p><p><strong>2. 对数损失函数</strong><br>   也称为交叉熵损失函数</p><blockquote><p>熵的定义<br>   $H(X)=-\sum_{i=1}^{i=n}p(x_i)log(p(x_i))$</p></blockquote><script type="math/tex; mode=display">L(Y,\hat{Y})=-log(\hat{Y})</script><p>   其中$\hat{Y}$表示训练样本属于某类的概率</p><p>   特点：<br>   （1）逻辑回归和softmax回归都是采用log损失函数<br>   （2）健壮性不强</p><p><strong>3. Hinge Loss</strong><br>   Hinge Loss通常被用于最大间隔算法，例如SVM中，Hinge Loss的数学表达式为：<br>   $L(\hat{y},y)=max(0,1-\hat{y}y)$<br>   $\hat{y}$表示预测输出，值在[-1,1]之间，$y$表示label值，为-1或1.<br>   如果样本被正确分类，损失为0，否则为$1-\hat{y}y$。<br>   什么时候样本损失为0呢？即$\hat{y}y&gt;=1$，也就是当$y=1$时，此时的$\hat{y}&gt;=1$，当$y=-1$时，此时的$\hat{y}&lt;=-1$，这些样本正好是SVM中分割超平面两边的样本。即SVM中分割超平面两边的样本损失为0，分割超平面中间的样本损失为$1-\hat{y}y$，我们要让这个损失尽可能小，即要让$\hat{y}y$尽可能接近1，那就是让正例的输出尽可能为1，让负例的输出尽可能为-1，即最大化间隔。</p><h3><span id="111-二分类和多分类">1.1.1. 二分类和多分类</span></h3><p>逻辑回归用来解决二分类问题，对于逻辑回归，有</p><script type="math/tex; mode=display">h(x)=g(w^Tx)=\frac{1}{1+e^{-w^Tx}}</script><p>输出的$h(x)$表示样本$x$属于正例的概率</p><p>在求二分类的损失函数时，我们先看对数损失函数：</p><script type="math/tex; mode=display">L(Y,P(Y|X))=-log(P(Y|X))</script><p>逻辑回归的损失函数采用对数损失，则可以将逻辑回归的损失函数写成：</p><script type="math/tex; mode=display">\operatorname{L}\left(\hat{y}, y\right)=\left\{\begin{array}{ll}-\log \left(\hat{y}\right) & \text { if } y=1 \\-\log \left(1-\hat{y}\right) & \text { if } y=0\end{array}\right.</script><p>将上面式子合并成一个式子，下面表示一个样本的损失：</p><script type="math/tex; mode=display">L(\hat{y},y)=-ylog(\hat{y})-(1-y)log(1-\hat{y})</script><p>如果所有样本的损失函数</p><script type="math/tex; mode=display">L(\hat{y},y)=-\frac{1}{m}\sum_{i=1}^{i=m}ylog(\hat{y})+(1-y)log(1-\hat{y})</script><p>softmax层中的softmax函数是logistic函数在多分类任务上的推广，将因为是多任务，所以卒中最终输出的是一个N维的向量，N表示类别的个数，但是这N向量需要满足2个条件：</p><ol><li>N为维向量中的每个值在[0,1]之间</li><li>这N个数加起来等于</li></ol><p>而softmax正好可以满足这2个条件，softmax接收1个N维向量，将这个N为维向量变成1个N个[0,1]之间的数，且和为1的N向量输出。</p><script type="math/tex; mode=display">y^j=\frac{o^j}{\sum_{j=1}^{j=N}o^j}</script><p>经过softmax函数之后输出N个y值，表示样本属于N类的概率</p><p>单个样本的log损失函数为：</p><script type="math/tex; mode=display">L(\hat{y},y)=-\sum_{j=1}^{j=N}y_jlog(\hat{y_j})</script><p>$y_j$表示样本真实情况下是否属于第$j$类，属于的话$y_j=1$，否则为0<br>$\hat{y_j}$表示预测情况下样本属于第$j$类的概率。<br>一共有$N$项相加，其中只有1项不为0，其余的$N-1$项均为0</p><p>所有样本的损失函数为：</p><script type="math/tex; mode=display">L(\hat{y},y)=-\sum_{i=1}^{i=m}\sum_{j=1}^{j=N}y_j^ilog(\hat{y_j^i})</script><h2><span id="12-回归损失函数">1.2. 回归损失函数</span></h2><p><strong>1. 平方绝对值误差（L1损失）</strong></p><script type="math/tex; mode=display">M A E=\sum_{i=1}^{n}\left|y_{i}-\hat{y_i}\right|</script><p><strong>2. MSE误差（L2损失）</strong></p><script type="math/tex; mode=display">M S E=\sum_{i=1}^{n}\left(y_{i}-\hat{y_{i}}\right)^{2}</script><p>MAE对异常值有更好的鲁棒性。因为MSE取了平方，如果数据中存在异常点，就会放大误差，对异常点敏感。如果数据中有异常点，用MAE损失比较好。<br>直观理解：如果用MSE作为损失函数，对所有样本只预测出1个值，预测出来的值一定是所有label的均值。如果用MAE作为损失函数，对所有样本只预测1个值，预测出来的值一定是所有label的中位数。我们知道如果样本中有异常点，中位数比均值更鲁棒，因为用MAE比MSE更稳定。<br>但是MAE也存在问题，就是更新梯度始终相同，即使对于很小的损失值，梯度也很大，不利于模型的学习。解决方案是使用变化的学习率，在损失接近最小值时降低学习率。</p><p>但MSE就没有这个问题，因为MSE的梯度是变化的，随着loss减小，梯度也在变小。</p><p><img src="/2020/07/05/百面机器学习概述二/mse.png" alt=""></p><p>在实际情况中，选择MAE还是MSE视情况而定，如果异常值需要被检测出来，选择MSE，否则选择MAE</p><p>但是以上这2种损失都有个问题：当数据中90%的目标值为150，剩下10%为在<code>0~30</code>之间。如果选择MAE作为损失函数，输出的预测值倾向于150，因为MAE倾向于输出中位数。如果选择MSE作为损失函数，输出的预测值倾向于0~30，因为模型会向异常点偏移。这2种情况都不可取。<br>为了解决这个问题，提出了Huber损失函数</p><p><strong>3. Huber损失</strong><br>   Huber损失函数对异常点没有MSE那么敏感，在0也可微分。Huber结合了MAE和MSE，当误差很大时，变成MAE，当误差很小变成MSE。这里误差的大小分界线有1个阈值控制。</p><script type="math/tex; mode=display">L_{\delta}(y, f(x))=\left\{\begin{array}{ll}   \frac{1}{2}(y-f(x))^{2} & \text { for }|y-f(x)| \leq \delta \\   \delta|y-f(x)|- \frac{1}{2}\delta^{2} & \text { otherwise }   \end{array}\right.</script><p><img src="/2020/07/05/百面机器学习概述二/huber.png" alt=""></p><p>Huber有1个缺点是需要不断的调整超参数$\delta$</p><h1><span id="2-梯度下降">2. 梯度下降</span></h1><p>批量梯度下降：BGD<br>随机梯度下降：SGD<br>小批量梯度下降：MBGD</p><p>那逻辑回归损失函数举例：</p><script type="math/tex; mode=display">Loss(w)=-\frac{1}{m}\sum_{i=1}^{i=m}(y^ilog(h(x^i))+(1-y^i)log(1-h(x^i)))</script><ul><li>批量梯度下降：梯度下降公式中的$m$如果是样本总数，则每次更新参数时需要考虑所有的样本，这种方法容易求得全局最优解，但是由于样本个数太多，训练过程非常慢。</li><li>随机梯度下降：$m=1$，即每次更新参数时只考虑一个样本，这种方法训练速度快，但是准确率下降，并不是全局最优。</li><li>小批量梯度下降：m为所有样本的一小部分时，比如m=32，即每次更新参数时只考虑一小部分样本，它克服了上述两种方法的缺点又兼顾它们的优点，在实际中最常使用。</li></ul><h1><span id="3-dropout">3. Dropout</span></h1><p>Dropout用来应对过拟合。</p><p>当对隐藏层使用dropout时，该层的隐藏单元将有一定的概率被丢弃掉。假设丢弃概率为$p$，那么对于隐藏层的一个神经单元有$p$的概率被丢弃</p><h1><span id="4-集成学习">4. 集成学习</span></h1><p>通俗讲：三个臭皮匠，顶个诸葛亮。<br>将多个分类器的结果统一成最终的决策。<br>每个分类器称为：基分类器</p><h2><span id="41-boosting和bagging">4.1. Boosting和Bagging</span></h2><p>集成学习分为2种：Boosting和Bagging</p><p>Boosting是串行学习，各个基分类器之间有依赖。各个基分类器层层叠加，训练的时候，每个基分类器对前一个分类器分错的样本给予更高的权重。测试的时候将所有基分类器的分类结果加权得到最终结果。<br>概括为2点：（1）Boosting训练得到m个分类器，对哪些错误率小的模型赋予大的权重，对错误率大的模型赋予小的权重，在m个分类器结果整合时，乘上对应的权重。（2）在训练第二个模型时，对前一个模型预测错误的样本在第二个模型中提高权重，使其从错误中学习。<br>总结：从错误中学习</p><p><img src="/2020/07/05/百面机器学习概述二/boosting.jpg" alt=""></p><p>Bagging<br>并行训练，各个基分类器相互独立。将所有的训练样本划分成多个子集（可以相同，也可以不同，或部分相同），然后分配给每个分类器单独学习，由于个体之间存在差异，得到的决策也不会完全相同，在最终决策时，通过投票的方式做出最终的决策。<br>总结：集体投票</p><p><img src="/2020/07/05/百面机器学习概述二/bagging.jpg" alt=""></p><p>Boosting：GBDT<br>Bagging：随机森林，如下图</p><p><img src="/2020/07/05/百面机器学习概述二/随机森林.png" alt=""></p><h2><span id="42-集成学习步骤和例子">4.2. 集成学习步骤和例子</span></h2><p>集成学习分为3步：</p><ol><li>选择基分类器</li><li>训练基分类器</li><li>合并基分类器结果</li></ol><ul><li>选择基分类器</li></ul><p>任何的分类模型都可以作为基分类器，为什么集成学习中通常选择决策树作为基分类器？<br>主要有以下3个原因：</p><ol><li>决策树对输入数据分布敏感，数据的扰动对决策树的分类结果影响很大，这样“不稳定的分类器”更适合作为基分类器。</li><li>决策树的复杂程度和泛化能力，可以通过修改树的层数来折中</li><li>决策树可以方便地将样本的权重整合到训练过程中，而不需要通过过采样调整样本权重。</li></ol><p><strong>集成学习要求基分类器：好而不同（不稳定）</strong></p><ul><li>训练基分类器<br>有Bagging（并行）和Boosting（串行）2种方式</li><li>合并基分类器</li></ul><p>神经网络也可以作为基分类器，也可以通过调节层数和神经单元个数调整模型复杂度。</p><ul><li>是否可以选择SVM和KNN作为基分类器<br>不可以，因为SVM和KNN本身是稳定的分类器，方差不大，如果分别训练后再集成，可能和单独的分类器先比，结果不会更好，反而会使得因为将训练集拆分子集导致基分类器更难收敛。</li></ul><h2><span id="43-偏差和方差">4.3. 偏差和方差</span></h2><p>以前我们经常用过拟合、欠拟合来描述模型的好坏，这里使用偏差和方差来定量描述模型的性能。</p><ul><li><p>偏差(bias)：模型<strong>预测值的平均值和真实值之间</strong>的偏差，偏差通常是由于分类器的表达能力有限，导致系统性错误，在训练误差上就可以体现出来</p></li><li><p>方差(varicance)：<strong>模型预测值之间</strong>的方差。方差通常是由于模型太复杂，导致过拟合，点很分散（方差大容易导致过拟合），方差通常体现在测试误差相对训练误差的增量上</p></li></ul><p><img src="/2020/07/05/百面机器学习概述二/偏差和方差.png" alt=""></p><ul><li><p>如何从减小偏差和方差的角度解释Boosting和Bagging<br>Bagging并行，Boosting串行，这2种集成方法都可以提升基分类器的性能，是因为Bagging降低了方差，Boosting降低了偏差。</p><ul><li>因为Bagging是通过n个训练集，得到n个独立的基分类器，$X_1,X_2,…X_n$，每个模型的方差为$\sigma^2$，则n个模型的平均后的方差为<br>$Var(\frac{1}{n}\sum_{i=1}^{i=n}X_i)=\frac{1}{n^2}Var(\sum_{i=1}^{i=n}X_i)=\frac{\sigma^2}{n}$<br>即平均后的模型方差变成基分类器的$\frac{1}{n}$，但这要求n个基分类器相互独立，所以让方差变成原来的$\frac{1}{n}$，需要让这n个基分类器尽可能相互独立。例如在随机森林中，在对特征进行分裂时，随机选择一个特征，而不是选择最优特征。</li><li>Boosting将上一个基分类器的误差或参加，输入到下一个基分类器中，不断减少模型的损失，使输出更靠近靶心，可以减少偏差，但是这n个基分类器是强相关，并不相互独立，所以并不能显著降低方差。</li></ul></li></ul><p><img src="/2020/07/05/百面机器学习概述二/偏差和方差1.png" alt=""></p><h2><span id="44-常见集成学习模型">4.4. 常见集成学习模型</span></h2><p>Bagging：随机森林（基分类器是CART）</p><p>Boosting：AdaBoost，GBDT（基分类器是CART回归树），XGBoost</p><h3><span id="441-随机森林">4.4.1. 随机森林</span></h3><p>随机森林使用CART作为基分类器。</p><p>随机森林由多个决策树组成，不同决策树之间没有关联。当我们进行分类任务时，输入测试样本，就让森林中的每一棵决策树分别进行预测，每个决策树都会得到一个分类结果，然后采用投票机制，将测试样本分到票数多的那个类别。</p><p>构造随机森林的4个步骤：</p><ol><li>随机抽样，用来训练决策树<br>假设有N个样本，有放回地抽样得到N个样本，将这N个样本用来训练一个决策树</li><li>随机选择属性，作为节点分裂属性<br>假设一个样本有M个属性，在构建决策树时，从这这M个属性中随机选m个属性，然后在这m个属性中采用某种策略（信息增益，信息增益比）选择1个最优属性将节点进行划分</li><li>重复步骤2，直到节点不再分裂<br>当节点所有样本属于同一类，或没有属性可以选择停止划分</li><li>将大量决策树组成森林<br>将多个决策树组成森林</li></ol><p>随机森林的优点：</p><ol><li>不容易过拟合</li><li>可以并行，训练速度快</li><li>可以处理很高维的数据，不用做特征选择</li><li>实现简单</li></ol><p>随机森林缺点：</p><ol><li>在某些噪声大的数据集上容易过拟合</li><li>取值多的特征容易对随机森林的决策产生更大的影响</li></ol><p>随机森林的应用：</p><ol><li>分类</li><li>回归</li><li>无监督学习聚类</li><li>异常点检测</li></ol><h3><span id="442-adaboost">4.4.2. AdaBoost</span></h3><p>Boosting是集成技术，从很多个基分类器中创建一个强分类器。<br>AdaBoost是Adaptive Boosting（自适应增强）的缩写。自适应体现在前一个基分类器分错的样本在下一个分类器中权重会变大。</p><p>AdaBoost分为3个步骤：</p><ol><li>初始化训练集样本的权重，假设有N个样本，则每个样本初始化权重为$\frac{1}{N}$</li><li><p>训练基分类器，对所有的训练样本得到预测结果，计算预测结果的误差率，这里的误差率是所有被分错样本的权重之和。假设有3个样本被分错了，这3个样本的权重分别为0.1,0.2,0.2，则误差率是0.5。然后根据误差率计算这个分类器的融合权重。然后更新每个样本在下一个分类器中的权重。如果一个样本已经被正确分类，则在下一个分类器中，该样本的权重被降低或不变，那些没有被分错的样本在下一个分类器中，样本权重被增大。<br><strong>计算第$m$个基分类器的权重</strong><br>$\alpha_m=\frac{1}{2}ln\frac{1-e_m}{e_m}$<br>$e_m$表示第m个基分类器的误差率，可以看出误差率越大，基分类器的权重越小。</p><p><strong>更新每个样本的权重</strong></p><ul><li>对于上一个分类器分对的样本<br>$w_{m+1}(x)=\frac{w_m(x)}{Z_m}exp(-\alpha_m)$</li><li>对于上一个分类器分错的样本<br>$w_{m+1}(x)=\frac{w_m(x)}{Z_m}exp(\alpha_m)$</li></ul><p>$Z_m=\sum_{N}$是归一化因子，为了保证所有的$w$加起来等于1。<br>可以看到对于分对的样本，$exp(-\alpha_m)$小于1，所以该样本在下一个分类器中权重变小。<br>对于分错的样本，$exp(\alpha_m)$大于1，所以该样本在下一个分类器中权重变大</p></li><li><p>给定一个测试样本，将m个基分类器的预测结果加权融合起来，得到最终的预测结果</p></li></ol><p>AdaBoost优点：</p><ol><li>利用基分类器生成强分类器</li><li>具有很高的精度</li><li>充分考虑每个样本的权重</li></ol><p>AdaBoost的缺点：</p><ol><li>基分类器串行训练，耗时</li><li>基分类器数量不好确定</li><li>数据不平衡导致分类精度下降</li></ol><h3><span id="443-gbdt">4.4.3. GBDT</span></h3><p>梯度提升决策树（Gradient Boosting Decision Tree）属于Boosting，GDBT用来做回归。</p><p>GDBT的损失函数是平方损失</p><script type="math/tex; mode=display">L(y, f(x))=\frac{1}{2}(y-f(x))^{2}</script><p>GBDT基于决策树预测结果的残差进行迭代学习。GBDT属于Boosting，即在训练时 当前基分类器基于上一个基分类器的预测结果，重点关注那些分类错误的样本。<br>GDBT使用决策树作为基分类器，GBDT中的决策树通常被称为CART。每个决策树学的是之前所有树结论和的残差。<br>我们使用用户访问视频时长、时段、观看类型来预测用户的年龄。假设用户A的真实是25岁，第一棵决策树的预测年龄为22岁，残差为3，则第二课树就要去学习3，假设第二棵树预测结果为5，残差为-2，则第三棵树就要去学习-2。即每棵树都是学习残差，所以GBDT中的Gradient Boosting就是这个意思。<br>在预测阶段，给定一个测试样本，GBDT中的多个树可以并行预测，最终的结果为n个树预测结果之和。</p><p><strong>GBDT的优点和缺点</strong></p><p>优点：</p><ol><li>预测阶段快，多个树之间可以并行预测（注意GBDT不可以并行训练，但可以并行预测），最终的结果为$f(最终)=f(初)+f(残差1)+…+f(残差n)$</li><li>GBDT使用决策树作为基分类器，使得GBDT具有较好的解释性</li><li>效果好</li></ol><p>缺点：</p><ol><li>在高维系数的数据集上，表现不如SVM和神经网络</li><li>在处理文本分类时，优势不明显</li><li>训练需要串行，速度慢</li><li>以平方损失作为损失函数，对噪声数据敏感，如果有噪声会过度关注噪声，容易产生过拟合，解决方法是换一种损失函数，例如Huber或绝对值损失</li></ol><h3><span id="444-xgboost">4.4.4. XGBoost</span></h3><p>针对GBDT，陈天奇博士在论文中给出更优的解决方案：XGBoost（Extreme Gradient Boosting），基于GBDT的思想做出各种优化。主要包括以下几方面：</p><ul><li>在损失函数中添加正则项，避免过拟合</li><li>在损失函数上进行二阶泰勒展开，提升模型精度</li><li>在工程层面，并行处理，提高训练效率</li><li>对特征中缺失的特征值处理</li></ul><p>XGBoost和GBDT的预测方式一样，都是将所有树的预测结果加起来</p><script type="math/tex; mode=display">\hat{y}_{i}=\sum_{k=1}^{K} f_{k}\left(x_{i}\right), f_{k} \in \mathcal{F}</script><p>$K$表示基分类器的个数</p><p>但XGBoost的目标函数和GBDT不一样，XGBoost添加了正则化项</p><script type="math/tex; mode=display">\operatorname{obj}(\theta)=\sum_{i}^{n} l\left(y_{i}, \hat{y}_{i}\right)+\sum_{k=1}^{K} \Omega\left(f_{k}\right)</script><p>损失函数中我们需要训练的就是每一棵树$f_k$，一共有$K$棵树。<strong>XGBoost和GBDT采用的都是增量训练的方法</strong>，每一步都在是前一步的基础上增加一棵树，而新增的这棵树是为了修复前一棵树的不足。第$t$棵树的预测结果就是前一棵树的预测结果$\hat{y}^{t-1}$加上当前树的预测结果(残差)$f_t{x}$</p><script type="math/tex; mode=display">\begin{aligned}\hat{y}_{i}^{(0)} &=0 \\\hat{y}_{i}^{(1)} &=f_{1}\left(x_{i}\right)=\hat{y}_{i}^{(0)}+f_{1}\left(x_{i}\right) \\\hat{y}_{i}^{(2)} &=f_{1}\left(x_{i}\right)+f_{2}\left(x_{i}\right)=\hat{y}_{i}^{(1)}+f_{2}\left(x_{i}\right) \\& \ldots \\\hat{y}_{i}^{(t)} &=\sum_{k=1}^{t} f_{k}\left(x_{i}\right)=\hat{y}_{i}^{(t-1)}+f_{t}\left(x_{i}\right)\end{aligned}</script><p>在每一次添加一棵树时，怎么确定添加的这棵树就是我们想要的呢？怎么判断添加了这棵树让我们的模型变得更好呢？答案是：添加了这棵树有助于损失函数。在添加第$t$棵树时，损失函数为：</p><script type="math/tex; mode=display">\begin{aligned}\mathrm{obj}^{(t)} &=\sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}^{(t)}\right)+\sum_{i=1}^{t} \Omega\left(f_{i}\right) \\&=\sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}^{(t-1)}+f_{t}\left(x_{i}\right)\right)+\Omega\left(f_{t}\right)+\text {constant}\end{aligned}</script><p>假设这里使用均方差作为经验损失函数，则整体的损失函数变成：</p><script type="math/tex; mode=display">\begin{aligned}\mathrm{obj}^{(t)} &=\sum_{i=1}^{n}\left(y_{i}-\left(\hat{y}_{i}^{(t-1)}+f_{t}\left(x_{i}\right)\right)\right)^{2}+\sum_{i=1}^{t} \Omega\left(f_{i}\right) \\&=\sum_{i=1}^{n}\left[2\left(\hat{y}_{i}^{(t-1)}-y_{i}\right) f_{t}\left(x_{i}\right)+f_{t}\left(x_{i}\right)^{2}\right]+\Omega\left(f_{t}\right)+\text { constant }\end{aligned}</script><p>对于MSE求出来的损失函数式子比较友好，包含一个一阶项和一个二阶项。但是对于其他形式，就不会有这么好的损失函数了，但是我们可以用泰勒展开进行逼近</p><script type="math/tex; mode=display">\mathrm{obj}^{(t)}=\sum_{i=1}^{n}\left[l\left(y_{i}, \hat{y}_{i}^{(t-1)}\right)+g_{i} f_{t}\left(x_{i}\right)+\frac{1}{2} h_{i} f_{t}^{2}\left(x_{i}\right)\right]+\Omega\left(f_{t}\right)+\text {constant}</script><p>其中$g_i,h_i$分别是损失函数的一阶，二阶梯度。</p><script type="math/tex; mode=display">\begin{array}{l}g_{i}=\partial_{\hat{y}_{i}(t-1)} l\left(y_{i}, \hat{y}_{i}^{(t-1)}\right) \\h_{i}=\partial_{\hat{y}_{i}^{(t-1)}}^{2} l\left(y_{i}, \hat{y}_{i}^{(t-1)}\right)\end{array}</script><p>在计算过程中，我们还可以忽略常数项$l\left(y_{i}, \hat{y}_{i}^{(t-1)}\right)$（因为这个常数项表示目标值和第t-1棵决策树的预测值的差，第t棵决策树并不会优化这一项，因此是个定值），则第t棵树的损失函数可以简化为：</p><script type="math/tex; mode=display">\sum_{i=1}^{n}\left[g_{i} f_{t}\left(x_{i}\right)+\frac{1}{2} h_{i} f_{t}^{2}\left(x_{i}\right)\right]+\Omega\left(f_{t}\right)</script><p>因此在选择第t棵树的时候就按照上面的损失函数来选择。式子中只需要考虑$g_i,h_i$，这就是XGBoost为什么能支持自定义损失函数的原因。</p><p>下面介绍正则化$\Omega(f)$，在XGBoost中</p><script type="math/tex; mode=display">\Omega(f)=\gamma T+\frac{1}{2}\gamma\sum_{j=1}^Tw_j^2</script><p>$T$表示一个基分类器中叶子节点的个数，$w_j$表示第$j$个叶子节点上的分数</p><p>将正则化项带入损失函数中，变成：</p><p><img src="/2020/07/05/百面机器学习概述二/xgboost.jpg" alt=""></p><p>其中$f_t(X_i)=w_q(X_i)$，表示在第t个决策树$f_y$中，样本$X_i$落在某个叶子节点，这个叶子节点的权重。</p><ul><li><p><strong>XGBoost中的每个树怎么选择特征分类的</strong><br>XGBoost的基分类器是CART，误以为和CART的分分裂标准一样。先回顾下CART的分类标准：回归问题以平平方损失进行分类，分类树以基尼指数进行分裂。XGBoost和CART的分裂标准不一样，采用下面的公式来选择最优特征：</p><p><img src="/2020/07/05/百面机器学习概述二/xgboost3.jpg" alt=""></p></li><li><p><strong>XGboost使用的残差相加，怎么处理分类问题</strong><br>XGBoost使用残差相加的方式，这里的值都是连续值，最后每个叶子节点的数也是连续值。如果处理二分类问题，则将叶子叶子节点的值经过<code>sigmoid</code>函数，得到一个概率。如果是多分类，则经过<code>softmax</code>函数</p></li><li><p>XGBoost怎么处理缺失值</p><ol><li>在训练基分类器时，对于那些在特征A缺失的样本，分别把它分到左右子树上，然后计算增益大的方向进行分裂</li><li>如果在训练集上没有缺失值，在预测中出现了缺失，那会自动将缺失值的样本划分到右子树上</li></ol></li></ul><ul><li><p>XGBoost为什么这么快</p><ol><li><p>连续值的处理<br>决策树在训练时需要对特征进行划分，对于连续特征，如果枚举所有的划分点将会十分耗时。一种近似的方法是只枚举分位点，首先将这个特征的所有取值排序，然后只将那些对分类结果产生影响的特征值作为分位点，使用损失降低最大的那个分位点作为划分点。</p><ol><li>利用数据的稀疏性<br>产生稀疏性的3个原因：数据丢失；数据本身中就有大量的0；对离散值进行one-hot。通常利用稀疏性可以提高运算速度。XGBoost做法是：每个划分时，都指定一个默认分支，如果样本在划分特征上值为0，就被分到默认分支上。这样，在训练时不必考虑这些0，大大提高运算速度。将缺失样本划分到左节点和右节点，计算增益，分到增益大的一侧。</li></ol><p><img src="/2020/07/05/百面机器学习概述二/xgboost2.jpg" alt=""></p><ol><li>数据的预排序和分块存储<br>在分叉的时候需要找分位点，需要对每个特征进行排序，排序过程需要做很多遍，所以XGBoost在训练之前就将所有的特征按照特征值进行排序，并将排序后的特征值按列存储在内存中。在分布式环境中， 可以进行分块存储。</li><li>并行处理<br>XGBoost的并行不是树级别的并行，而是特征级别的并行。决策树学习中最耗时的部分是将数据按照特征值进行排序，为了降低排序成本，XGBoost通常在训练之前将特征已经排好序存储在内存单元(block)中，每个block数以压缩列的格式存储，每列按特征值排序。在进行节点分裂时，需要计算每个特征的增益，选择增益大的特征进行分裂，在计算各个特征的增益时可以并行计算。</li></ol></li></ol></li></ul><h3><span id="445-gdbt和xgboost区别">4.4.5. GDBT和XGBoost区别</span></h3><ol><li><p>GDBT使用CART作为基分类器，XGBoost还支持线性分类器，通过指定参数<code>booster:default=gbtree</code>，还可以是<code>gblinear,linear model</code></p></li><li><p>GBDT损失函数只用到一阶导数信息，XGBoost对损失函数进行二阶泰勒展开，同时用到一阶和二阶导数，并且指出自定义代价函数。</p></li><li>XGBoost相比GBDT在损失函数中加入正则化，用于控制模型复杂度</li></ol><h1><span id="5-cnn">5. CNN</span></h1><p>什么是平移不变性</p><p>不变性意味着即使目标的外观发生了某种变化，也依然可以识别出来。例如图像，无论是被平移，旋转，缩放，甚至不同的光照条件都可以被识别出来。所以不变性有各种方面：</p><ul><li>平移不变性</li><li>旋转不变性</li><li>光照不变性</li><li>等</li></ul><p>平移不变性：比如对于图像分类任务，图像中的目标不管被移到图片中的哪个位置，得到的label都是完全一样的。</p><p>卷积神经网络的平移不变性主要依赖于：卷积+池化</p><p><a href="https://www.cnblogs.com/Terrypython/p/11147490.html" target="_blank" rel="noopener">卷积神经网络为什么具有平移不变性？</a></p><h1><span id="6-gnn">6. GNN</span></h1><p>图数据是非欧式数据，不满足平移不变性</p><h2><span id="61-deepwalk">6.1. DeepWalk</span></h2><p>DeepWalk将随机游走和word2vec结合起来该算法能为图中每个节点学习一个节点嵌入。</p><p>DeepWalk利用随机游走算法从图中提取一些序列，借助NLP的思路，将这些序列看成一句话，输入到word2vec中的skip-gram模型（一对多），得到节点嵌入。</p><h2><span id="62-line">6.2. LINE</span></h2><p>LINE将大规模网络中的节点变成低维向量，训练的目标是使得联系紧密的节点学到的节点嵌入更相似。</p><p>LINE使用一阶相似性和二阶相似性来衡量图中2个节点的紧密性。例如下图中的6和7<br>一阶相似性：一阶邻居，直接相连。认定直接相连的节点一般更相似。<br>二阶相似性：这2个节点没有直接相连，但是它们有共同的邻居。例如下图中的5和6，一般也认为这2个节点更相似。</p><p><img src="/2020/07/05/百面机器学习概述二/line.jpg" alt=""></p><h2><span id="63-图卷积神经网络">6.3. 图卷积神经网络</span></h2><p>图卷积神经网络主要包括卷积算子和池化算法的构建。其中卷积算子的目的是刻画节点的局部结构。池化算子的目的是学到网络的层级化表示，降低参数。这里我们主要看如何构建卷积算子。</p><p>卷积算子的构建有2种方法：谱图卷积和空间卷积。</p><ul><li>谱图借助卷积定理在谱域上定义卷积</li><li>空间图卷积从节点域出发，通过定义聚合函数来聚合每个中心节点和邻近节点</li></ul><p>图卷积的本质是如何对邻居节点的特征做有效的聚合。</p><h3><span id="631-谱图卷积">6.3.1. 谱图卷积</span></h3><p>借助卷积定理在谱域上定义卷积</p><p>Spectral GNN(2013Bruna)—&gt;ChebNet—&gt;GCN</p><p>Sepctral GNN具有较高的时空复杂性<br>ChebNet和GCN对谱方法的卷积核进行参数化，降低时空复杂度。</p><p><strong>符号定义</strong><br>单位阵（对角阵）$I_{n} \in R^{n \times n}$<br>邻接矩阵$A \in R^{n \times n}$<br>度矩阵（对角阵）$D \in R^{n \times n}$<br>拉普拉斯矩阵$L \in R^{n \times n}$<br>特征向量矩阵$U \in R^{n \times n}$<br>特征值矩阵（对角阵）$\Lambda \in R^{n \times n}$<br>第$i$个特征向量$u_{i} \in R^{n}$</p><p>归一化后的拉普拉斯矩阵$L=I_{n}-D^{-\frac{1}{2}} A D^{-\frac{1}{2}}$<br>$L$是对称矩阵，对$L$做特征分解得到$L=U \Lambda U^{T}$</p><p><strong>卷积定理</strong></p><p>卷积定理：信息卷积的傅里叶变换等于信号傅里叶变换的乘积</p><script type="math/tex; mode=display">F\left(f^{*} g\right)=F(f) \cdot F(g)</script><p>对等式两边做傅里叶逆变换</p><script type="math/tex; mode=display">f^{*} g=F^{-1}(F(f) \cdot F(g))</script><p>利用卷积定理，可以对谱空间的信息$F(f),F(g)$做乘法，然后再做傅里叶逆变换，就可以得到原先空间的卷积运算。</p><p>上面定义的信号的傅里叶变换，而图上的傅里叶变换依赖于图上的拉普拉斯矩阵。下面定义<strong>图上的傅里叶变换</strong>。</p><script type="math/tex; mode=display">\hat{x}=U^{T} x</script><p>$x$表示节点域的图信号矩阵，$\hat{x}$表示$x$变换到谱域后的表示。<br><strong>图上的傅里叶逆变换</strong></p><script type="math/tex; mode=display">x=U \hat{x}</script><p>根据卷积定理，我们可以得到图卷积算子</p><script type="math/tex; mode=display">x_{G}^{*} y=U\left(\left(U^{T} x\right) \odot\left(U^{T} y\right)\right)</script><p>我们用一个对角阵来$g_{\theta}$来代替$U^Tx$，卷积算子变成:</p><script type="math/tex; mode=display">g_{\theta}{*}x=Ug_{\theta}U^{T} x</script><p>$g_{\theta}$就是我们需要学习的卷积核</p><ol><li><p>Spectral GNN<br>使用<strong>特征值组成的对角阵</strong>来代替卷积核$g_{\theta}$，有n个需要学习的参数，卷积运算变成</p><script type="math/tex; mode=display">g_{\theta} {*} x=U g_{\theta}(\Lambda) U^{T} x</script><p>缺点：</p><ol><li>时间复杂度高</li><li>不具有局部性，即产生信息聚合的节点不一定是邻近节点</li></ol></li><li><p>多项式卷积<br>为了降低时间复杂度，对卷积核进行简化，卷积核只考虑$K$阶，然后带入到卷积操作中，得到新的卷积操作：</p><p><img src="/2020/07/05/百面机器学习概述二/gnn1.jpg" alt=""></p><ol><li>不需要对$L$进行特征值分解</li><li>涉及到$L$的$K$次幂</li></ol></li><li><p>ChebNet<br>对上面$L$的$K$次幂使用切比雪夫多项式进行逼近，将矩阵连乘变成多项式，减少时间复杂度，K表示K阶邻居，这里就有了局部的概念</p><p><img src="/2020/07/05/百面机器学习概述二/gnn2.jpg" alt=""></p></li><li><p>GCN<br>GCN进一步通过指定最大的特征值$\lambda_{\max }=2$和$K=1$进一步简化ChebNet，最终得到一阶图卷积神经网络。</p><p><img src="/2020/07/05/百面机器学习概述二/gnn3.jpg" alt=""></p></li></ol><p>在谱图卷积中的ChebNet和GCN就引入了局部的概念，将拉普拉斯矩阵及其变体作为聚合函数。</p><h3><span id="632-空间图卷积">6.3.2. 空间图卷积</span></h3><p>空间图卷积从节点域出发，通过定义聚合函数来聚合每个中心节点和邻近节点。<br>空间图卷积受谱图卷积中局部聚合函数的启发，通过注意力机制或其他网络直接从节点域学习聚合函数，这些方法不再依赖拉普拉斯矩阵，而是设计神经网络来学习聚合函数。</p><ol><li><p>GAT</p><p><img src="/2020/07/05/百面机器学习概述二/gat.jpg" alt=""></p><p>这里的参数有$W,a$,$W$用来节点的特征维度变换，$a$用来计算注意力分数。<br>步骤：</p><ol><li>现将每个节点的特征从$F$维变成$F’$维</li><li>对每个节点计算它对所有邻居的注意力分数，即将$Wh_i$和$Wh_j$拼接起来，输入到一个FCN中，输出一个实数，表示这2个节点的注意力分数</li><li>计算出一个节点对所有邻居的注意力分数后，将这些分数加起来作为综合，对每个注意力分数使用softmax函数进行归一化到[0,1]之间，且和为1</li><li>对所有的邻居特征进行聚合<br>从GAT开始，节点之间的权重计算开始从依赖于网络的结构信息转移到依赖于节点的特征表达。</li></ol><p>缺点：GAT在处理时需要加载整个网络的节点特征，不适用于大规模网络</p></li><li><p>GraphSAGE<br>为了解决大规模图的问题，提出图采样聚合网络GraphSAGE，不同于以前模型考虑所有邻近节点，GraphSAGE对邻近节点做随机采样，利用采样得到的节点进行聚合。</p><p><img src="/2020/07/05/百面机器学习概述二/graphsage.jpg" alt=""></p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;总结《百面机器学习》有关知识点。&lt;/p&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://yoursite.com/categories/Machine-Learning/"/>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>python输入怎么写</title>
    <link href="http://yoursite.com/2020/06/21/python%E8%BE%93%E5%85%A5%E6%80%8E%E4%B9%88%E5%86%99/"/>
    <id>http://yoursite.com/2020/06/21/python输入怎么写/</id>
    <published>2020-06-21T09:35:43.000Z</published>
    <updated>2020-06-21T09:47:14.170Z</updated>
    
    <content type="html"><![CDATA[<p>Leetcode刷多了不太记得python的输入怎么写了。在实际笔试或面试时，需要自己写输入和输出函数，所以在此记录下怎么使用Python读取数据。<br><a id="more"></a></p><p>在面试的时候，面试官只给你一个白板，最多给你定义好的函数名，其余都要自己写。给定的题目一般先读取数据，然后使用<code>print</code>输出最终的结果。</p><ul><li><code>print</code>可以写在<code>test</code>函数中</li><li>也可以将要输出的内容保存下来，作为<code>test</code>的<code>return</code>，然后在<code>main</code>中输出<br>下面是写程序的模板：</li><li><code>main</code>只关注输入和输出</li><li>其余的功能单独封装成函数，在<code>main</code>中调用</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(param1,param2)</span>:</span></span><br><span class="line">    <span class="comment">#do something</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">"xx"</span>)</span><br><span class="line">    <span class="comment">#或者return</span></span><br><span class="line">    <span class="keyword">return</span> xx</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment">#使用input读取数据</span></span><br><span class="line">    m = input()</span><br><span class="line">    n = list(map(int,input.split()))</span><br><span class="line"></span><br><span class="line">    test(m,n)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"xx"</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Leetcode刷多了不太记得python的输入怎么写了。在实际笔试或面试时，需要自己写输入和输出函数，所以在此记录下怎么使用Python读取数据。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="算法" scheme="http://yoursite.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>百面机器学习概述一</title>
    <link href="http://yoursite.com/2020/06/19/%E7%99%BE%E9%9D%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0/"/>
    <id>http://yoursite.com/2020/06/19/百面机器学习概述/</id>
    <published>2020-06-19T15:12:34.000Z</published>
    <updated>2020-07-15T01:26:36.490Z</updated>
    
    <content type="html"><![CDATA[<p>总结《百面机器学习》有关知识点。</p><a id="more"></a><!-- TOC --><ul><li><a href="#1-特征工程">1. 特征工程</a><ul><li><a href="#11-特征归一化">1.1. 特征归一化</a></li><li><a href="#12-类别型特征">1.2. 类别型特征</a></li><li><a href="#13-文本表示模型">1.3. 文本表示模型</a></li><li><a href="#14-word2vec">1.4. Word2Vec</a></li><li><a href="#15-图像不足时处理方法">1.5. 图像不足时处理方法</a></li></ul></li><li><a href="#2-模型评估">2. 模型评估</a><ul><li><a href="#21-常见评估指标">2.1. 常见评估指标</a></li><li><a href="#22-p-r曲线和roc曲线">2.2. P-R曲线和ROC曲线</a></li><li><a href="#23-余弦距离">2.3. 余弦距离</a></li><li><a href="#24-ab测试">2.4. A/B测试</a></li><li><a href="#25-模型评估方法">2.5. 模型评估方法</a></li><li><a href="#26-过拟合和欠拟合">2.6. 过拟合和欠拟合</a></li><li><a href="#27-正则化">2.7. 正则化</a></li><li><a href="#梯度消失和梯度爆炸">梯度消失和梯度爆炸</a></li></ul></li><li><a href="#3-经典算法">3. 经典算法</a><ul><li><a href="#31-回归模型">3.1. 回归模型</a><ul><li><a href="#311-单变量线性回归">3.1.1. 单变量线性回归</a></li><li><a href="#312-多变量线性回归">3.1.2. 多变量线性回归</a></li><li><a href="#313-带有激活函数的反向传播">3.1.3. 带有激活函数的反向传播</a></li><li><a href="#314-l1正则和l2正则">3.1.4. L1正则和L2正则</a></li><li><a href="#315-面试问题">3.1.5. 面试问题</a></li></ul></li><li><a href="#32-逻辑回归">3.2. 逻辑回归</a><ul><li><a href="#321-逻辑回归推导">3.2.1. 逻辑回归推导</a></li><li><a href="#322-逻辑回归常见问题">3.2.2. 逻辑回归常见问题</a></li></ul></li><li><a href="#33-softmax回归">3.3. Softmax回归</a></li><li><a href="#34-回归和分类总结">3.4. 回归和分类总结</a></li><li><a href="#35-数据不平衡问题">3.5. 数据不平衡问题</a><ul><li><a href="#351-smote算法">3.5.1. SMOTE算法</a></li></ul></li><li><a href="#36-svm">3.6. SVM</a><ul><li><a href="#361-线性可分svm">3.6.1. 线性可分SVM</a></li><li><a href="#362-近似线性svm">3.6.2. 近似线性SVM</a></li><li><a href="#363-核函数">3.6.3. 核函数</a></li><li><a href="#364-面试问题">3.6.4. 面试问题</a></li></ul></li><li><a href="#37-决策树">3.7. 决策树</a><ul><li><a href="#371-基础树id3c45cart">3.7.1. 基础树(ID3/C4.5/CART)</a><ul><li><a href="#3711-id3">3.7.1.1. ID3</a></li><li><a href="#3712-c45">3.7.1.2. C4.5</a></li><li><a href="#3713-cart分类回归树">3.7.1.3. CART(分类回归树)</a></li><li><a href="#3714-总结">3.7.1.4. 总结</a></li></ul></li><li><a href="#372-树的剪枝">3.7.2. 树的剪枝</a></li></ul></li><li><a href="#38-k近邻knn">3.8. K近邻(KNN)</a><ul><li><a href="#381-knn原理">3.8.1. KNN原理</a></li><li><a href="#382-kd树">3.8.2. KD树</a></li></ul></li></ul></li><li><a href="#4-聚类">4. 聚类</a><ul><li><a href="#41-k-means聚类">4.1. K-Means聚类</a></li><li><a href="#42-k-means的优化">4.2. K-Means的优化</a><ul><li><a href="#421-k-means">4.2.1. K-Means++</a></li><li><a href="#422-isodata">4.2.2. ISODATA</a></li></ul></li><li><a href="#43-聚类评价指标">4.3. 聚类评价指标</a></li></ul></li><li><a href="#5-贝叶斯分类">5. 贝叶斯分类</a><ul><li><a href="#51-朴素贝叶斯分类器">5.1. 朴素贝叶斯分类器</a></li><li><a href="#52-半朴素贝叶斯分类器">5.2. 半朴素贝叶斯分类器</a></li></ul></li><li><a href="#6-生成模型和判别模型">6. 生成模型和判别模型</a></li></ul><!-- /TOC --><h1><span id="1-特征工程">1. 特征工程</span></h1><h2><span id="11-特征归一化">1.1. 特征归一化</span></h2><ul><li>目的：消除特征之间量纲的影响，防止学习到的结果向数值大的特征倾斜。</li><li>Max-Min归一化：将数据归一化到[0,1]之间，等比缩放。</li><li>Z-Score归一化（零均值归一化）：将数据归一化到均值为0，标准差为1的分布上。</li><li>需要归一化：线性回归、逻辑回归、SVM、深度神经网络。不需要归一化：基于决策树模型。</li></ul><h2><span id="12-类别型特征">1.2. 类别型特征</span></h2><p>将类别特征—&gt;数值特征，有以下方法</p><ul><li>序号编码：有大小关系的，比如低中高，可以编码成1,2,3</li><li>one-hot编码：没有大小关系，问题：高维稀疏，需要将其嵌入成低维稠密向量</li><li>二进制编码：先编码再转换成二进制</li></ul><h2><span id="13-文本表示模型">1.3. 文本表示模型</span></h2><ul><li>词袋模型：将文章按照词分割，使用每个词的权重来表示文章</li><li>TF-IDF：用来计算一个词的权重，TF=一个词w在文章d中出现的频率，IDF：特属词的特征，逆文档频率</li><li>N-gram模型：将连续的n个词作为一个特征放在向量中。</li><li>词嵌入模型：将词映射成低维稠密向量(50~300维度)，Word2Vec是最常用的词嵌入模型。</li></ul><h2><span id="14-word2vec">1.4. Word2Vec</span></h2><p>Word2Vec有2种网络结构：CBOW，skip-gram</p><ul><li>CBOW：多预测一</li><li>skip-gram：一预测多</li></ul><h2><span id="15-图像不足时处理方法">1.5. 图像不足时处理方法</span></h2><p>图像不足易出现过拟合问题。解决图像不足有2种方法：</p><ul><li>基于模型：采用一些措施降低过拟合。例如简化模型，L1L2正则化、Dropout，集成学习。</li><li>基于数据：通过一些方法增加数据。平移、旋转、裁剪、修改图片亮度，锐度、添加噪声等方法。</li></ul><h1><span id="2-模型评估">2. 模型评估</span></h1><h2><span id="21-常见评估指标">2.1. 常见评估指标</span></h2><ul><li>准确率(Accuracy)</li><li>精确率(Precision)</li><li>召回率(Recall)</li></ul><p>其中这些指标都有一定的局限性。对于一个排序模型，怎么评估排序模型的好坏：</p><ul><li>设置不同的N，计算P@N,R@N</li><li>设置更综合的评价指标，PR曲线，ROC曲线，F1值</li></ul><p>RMSE：回归问题的评价指标。如果在一个问题上，RMSE非常高，但是观察预测值和真实值，发现90%的预测值都很接近真实值，为什么RMSE还是这么高。分析由于剩下的10%存在非常大的异常值，即使90%预测很准，但是这10%导致最终的RMSE差别很大。解决方案：</p><ul><li>如果10%是噪声数据，提前去除噪声</li><li>如果10%不是噪声数据，需要对异常数据进行建模</li><li>换一个对异常值不敏感的指标，例如MAPE</li></ul><h2><span id="22-p-r曲线和roc曲线">2.2. P-R曲线和ROC曲线</span></h2><ul><li><p>P-R曲线<br>P-R曲线横坐标是召回率，纵坐标是准确率。<br>为什么要有P-R曲线？因为精确率precision和召回率recall指标都有一定的局限性，所以使用P-R曲线可以综合地评估一个模型的效果。<br>在P-R曲线中，通过改变正负样本间的阈值来改变precision和recall。当判定为正样本的阈值很大时，说明选出的正样本都是很有把握的，precision较大，recall较小。当判定为正样本的阈值很小时，即尽可能不漏掉正样本，导致precision降低，recall变大。</p></li><li><p>ROC曲线<br>横坐标是假阳率FPR，纵坐标是真阳率TPR。</p></li></ul><script type="math/tex; mode=display">假阳率=\frac{负例被判为正例}{真正的负例}\quad真阳率=\frac{正例被判为正例}{真正的正例}</script><p>可以看出真阳率也就是召回率。<br>同P-R曲线类似，ROC曲线也是通过不断改变正负样本的阈值生成的。</p><ul><li>P-R曲线和ROC曲线有什么不同</li></ul><p>当测试集中的负样本数量增加10倍时，P-R曲线发生了明显的变化，ROC曲线几乎不变。ROC曲线能够尽量降低测试集带来的干扰，适用于正负样本不均衡的数据集中。ROC适用的场景更多，被广泛应用在排序，推荐，广告等领域。</p><p><a href="https://blog.csdn.net/songyunli1111/article/details/82285266" target="_blank" rel="noopener">为什么ROC曲线不受样本不均衡问题的影响</a></p><p>AUC是概率值，表示正样本排在负样本前面的概率。AUC越大，说明中正样越有可能排在负样本前面，常用在推荐，排序领域。</p><p>ROC有真阳率和假阳率，所以ROC同时关注正负样本。而PR曲线更关注正样本。</p><ul><li>如果你更关注正例，使用P-R曲线，例如检测癌症，电信诈骗等。如果你同时关注正例和负例，则使用ROC曲线。</li><li>如果你不想让训练集的正负比例过度的影响模型效果，用ROC</li></ul><p><img src="/2020/06/19/百面机器学习概述/PR曲线和ROC曲线.png" alt=""></p><h2><span id="23-余弦距离">2.3. 余弦距离</span></h2><p>余弦相似度：</p><script type="math/tex; mode=display">\cos (A, B)=\frac{A \cdot B}{\|A\|_{2}\|B\|_{2}}</script><p>余弦距离体现方向上的相对差异，欧式距离体现数值上的绝对差异。</p><h2><span id="24-ab测试">2.4. A/B测试</span></h2><p>划分实验组和对照组<br>实验组和对照组：选取样本时要求独立性和无偏性。</p><h2><span id="25-模型评估方法">2.5. 模型评估方法</span></h2><p>通常将数据划分为训练集和测试集，但在<strong>样本划分</strong>和<strong>模型验证</strong>的过程中，存在着不同的方法。</p><ol><li>Holdout验证<br>随机将数据划分为训练集和测试集，在测试集上进行模型验证。<br>缺点：模型的效果取决于样本划分，具有随机性</li><li>k折交叉验证<br>将样本划分为k个大小相等的子集，一个子集作为测试集，k-1个子集作为训练集。将k次评估结果平均作为该模型最终的结果。<br>优点：（1）解决当数据量较小时，模型评估不准确的问题（2）消除数据对评估结果的随机性影响（3）可以用来选择超参数<br>缺点：耗时，需要训练多个模型求评估结果的平均值</li><li>自助法<br>如果数据比较小，holdout和k折交叉验证都需要划分数据集，导致训练集变小。自助发采用随机抽样，在全部样本中进行n次有放回的抽样，得到大小为n的训练集。这n个样本中有的样本是重复的，有的样本没有被抽到，这些没有抽到的样本作为测试集。</li></ol><h2><span id="26-过拟合和欠拟合">2.6. 过拟合和欠拟合</span></h2><ul><li>过拟合<br>模型在训练数据上loss很小，在测试集上loss大</li><li>欠拟合<br>模型在训练集和测试集上loss都很大，效果都不好</li><li><p>降低过拟合的方法</p><ol><li>增加数据集，减少噪声的影响。如果没有这么多数据，可以生成一些数据。例如图像可以通过平移，旋转等生成数据</li><li>正则化，在loss中添加L1或L2正则，防止参数过大</li><li>集成学习，将多个模型集成在一起，降低单一模型的过拟合风险</li><li>降低模型复杂度，例如减少网络参数，神经元个数等。</li><li>早停，当模型在验证机上的loss连续N次没有提升时，停止训练</li><li>Dropout，在训练过程中按照给定的概率随机删除隐藏层的一些神经单元。由于模型训练的随机性，减轻了不同特征之间的协同效应。<strong>Dropout只能在训练时使用，在测试集上不能使用</strong></li></ol></li><li><p>降低欠拟合的方法</p><ol><li>添加新的特征，当特征少时容易出现欠拟合，模型对训练数据的拟合程度不好。</li><li>增加模型复杂度</li><li>减少正则化系数</li></ol></li></ul><h2><span id="27-正则化">2.7. 正则化</span></h2><p>正则化为了避免过拟合，即在损失函数后加上一个正则项（惩罚项），模型越复杂，正则化值就越大。</p><script type="math/tex; mode=display">\min _{f \in \mathcal{F}} \frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)+\lambda J(f)</script><p>第一项是损失值，第二项是正则化项，$\lambda$调整两者的权重。下面拿回归问题举例，损失值为平方损失。</p><ul><li>L1正则<br>惩罚项为权重绝对值的和</li></ul><script type="math/tex; mode=display">L(w)=\frac{1}{N} \sum_{i=1}^{N}\left(f\left(x_{i} ; w\right)-y_{i}\right)^{2}+\lambda\|w\|_{1}</script><ul><li>L2正则</li></ul><p>惩罚项为权重的平方和</p><script type="math/tex; mode=display">L(w)=\frac{1}{N} \sum_{i=1}^{N}\left(f\left(x_{i} ; w\right)-y_{i}\right)^{2}+\frac{\lambda}{2}\|w\|^{2}</script><h2><span id="梯度消失和梯度爆炸">梯度消失和梯度爆炸</span></h2><p>梯度消失和梯度爆炸经常出现在较深的网络中。反向传播用到链式法则，导数连乘。如果激活函数求导后与权重相乘的积大于1，层数增多时，求出的梯度将以指数增加，发生梯度爆炸。如果小于1，梯度将以指数衰减，发生梯度消失。<br>sigmoid的导数最大为0.25，易发生梯度消失问题</p><p>如何解决梯度消失和梯度爆炸：</p><ol><li>使用ReLU代替sigmoid解决梯度消失问题。Relu的正数部分导数为1，不存在梯度消失和梯度爆炸的问题</li><li>梯度裁剪解决梯度爆炸，设置一个梯度裁剪阈值，如果梯度大于这个阈值使，将其强制限制在这个范围内。</li><li>残差网络，解决梯度消失的问题</li><li>BN批归一化层，BN主要是对x进行归一化到均值为0，方差为1。在L对w反向求到时，结果中肯定有x的存在，所以x的大小也会影响梯度消失和梯度爆炸，BN通过将输出进行归一化来消除x带的放大缩小的影响。</li></ol><h1><span id="3-经典算法">3. 经典算法</span></h1><h2><span id="31-回归模型">3.1. 回归模型</span></h2><p>回归模型分为线性回归和非线性回归。</p><p>线性回归又分为单变量线性回归和多变量线性回归。</p><h3><span id="311-单变量线性回归">3.1.1. 单变量线性回归</span></h3><p>使用房子面积和房价举例。训练集中x表示房子面积，y表示房价。使用$(x,y)$表示一个训练样，其中$(x^{(i)},y^{(i)})$表示第$i$个训练样本。。</p><ul><li>$h(x)=w_0+w_1x$，通过训练集学习$w_0,w_1$，使得$x$可以得到对应的$y$。因为这里没有激活函数，$x和y$是线性关系，所以成为单变量线性回归模型，因为输入的特征$x$只有1个特征（房子面积）</li><li>损失函数：$Loss = \frac{1}{2m}\sum_{i=1}^{i=m}(h(x^{i})-y^{i})^2$<br>求得是平均损失，有m个样本，所以前面损失除以m，这里的1/2是为了求导简化添加的。</li></ul><p><img src="/2020/06/19/百面机器学习概述/百面机器学习/../百面机器学习概述/linear.jpg" alt=""></p><h3><span id="312-多变量线性回归">3.1.2. 多变量线性回归</span></h3><p>输入的x有多个特征，上面单变量回归问题中，x只表示房子面积，在多变量线性回归中，x1=房子面积，x2=卧室个数，x3=房子楼层，x4=房子年龄</p><ul><li>$h(x)=w_0+w_1x_1+w_2x_2+w_3x_3+w_4x_4$<br>令$x=[x_1,x_2,x_3,x_4]$为列向量，$w=[w_1,w_2,w_3,w_4]$为列向量，则$h(x)=w^Tx$</li></ul><p><img src="/2020/06/19/百面机器学习概述/百面机器学习/../百面机器学习概述/linear1.jpg" alt=""></p><h3><span id="313-带有激活函数的反向传播">3.1.3. 带有激活函数的反向传播</span></h3><p>上面介绍的单变量和多变量回归都是线性的，没有激活函数，这里介绍带有激活函数的回归问题。</p><p>首先定义损失函数</p><script type="math/tex; mode=display">L=\frac{1}{2m}\sum_{i=1}^{i=m}(h(x^i),y^i)^2\\h(x)=f(xW+b)</script><p>这里的$f$表示激活函数，可以是Sigmoid，Tanh，ReLU</p><p><img src="/2020/06/19/百面机器学习概述/BP1.jpg" alt=""></p><p><img src="/2020/06/19/百面机器学习概述/BP2.jpg" alt=""></p><p><strong>不同激活函数的导数</strong></p><p><img src="/2020/06/19/百面机器学习概述/BP3.jpg" alt=""></p><h3><span id="314-l1正则和l2正则">3.1.4. L1正则和L2正则</span></h3><p>正则就是给参数添加限制，缩小参数的解空间，降低结构风险。<br>L1正则和L2正则都是为了避免过拟合设计的。使用L1正则化的叫做Lasso回归，使用L2正则化的叫做岭回归。<br>这两种回归为了<strong>解决线性回归出现过拟合</strong>的问题。通过<strong>在损失函数中引入正则化项</strong>来解决</p><ul><li><p>Lasso回归损失函数<br> 添加L1正则项</p><script type="math/tex; mode=display">J(w)=\frac{1}{2m}\sum_{i=1}^{i=m}(h(x^i)-y^i)^2+\lambda\sum_{j=1}^{j=n}|w_j|</script></li><li><p>岭回归损失函数<br> 添加L2正则项</p><script type="math/tex; mode=display">J(w)=\frac{1}{2m}\sum_{i=1}^{i=m}(h(x^i)-y^i)^2+\lambda\sum_{j=1}^{j=n}w_j^2</script></li></ul><p>我们从梯度下降的角度分析下为什么加入正则化可以避免过拟合。下面以L2正则化为例。L2正则化的梯度下降公式为</p><script type="math/tex; mode=display">w_j = w_j - \alpha * \frac{1}{m}\sum_{i=1}^{i=m}(h(x^i)-y^i)x^i_j-2\lambda w_j</script><p>当惩罚项越大，即$\lambda$越大时，更新后得到的$w_j$也就越小，模型复杂度变小，模型更简单。</p><p>下面以线性回归为例，模型只包含2个参数。下面等高线图表示$w_1,w_2$和损失的关系。当$w_1,w_2$取值为图像中最里面紫色圆圈上的点时，损失最小。</p><p><img src="/2020/06/19/百面机器学习概述/L1_1.png" alt=""></p><p>当加上L1正则化后，目标函数图像为</p><p><img src="/2020/06/19/百面机器学习概述/L1_2.png" alt=""></p><p>原先损失函数的第一项就是等高线，L1正则化损失函数的第二项就是菱形上的点。图中的菱形函数为$\sum_{j=1}^{j=2}w_j=F$。我们现在求解的目标是不仅要让第一项小，即$w_1,w_2$的值靠近紫色的圆圈，还要让第二项小，即$|w_1|+|w_2|=F$小，即$F$比较小。如下图所示，如果让菱形靠近紫色的圆圈，虽然损失函数第一项小了，但是第二项会变大。因此我们要取到一个恰好的值，让第一项的值+第二项的值最小。<br>我们发现对于同一个等高线来说，即损失函数的第一项相同，当菱形和等高线相切（只有一个交点）时，菱形的边长最小，即$w_1+w_2$最小，也就是相加得到的损失最小。</p><p>由上面的说明可以看出，L1正则化后的解一定是某个菱形和某个等高线的切点。经过观察发现，对于图中的每条等高线，与这个等高线相切的菱形的切点一般出现在坐标轴上(x轴或y轴)，例如上面的解为$(0,y)$，这也是说L1正则化更容易得到稀疏解(解向量中0比较多)的原因。</p><p><img src="/2020/06/19/百面机器学习概述/L1_3.png" alt=""></p><p>当加入L2正则化后，目标函数图像为</p><p><img src="/2020/06/19/百面机器学习概述/L2.png" alt=""></p><p>菱形变成了圆，同样求等高线和圆的切点作为最终的解。与L1正则化相比，切点不容易出现在坐标轴上，然后仍然比较靠近坐标轴。因此L2正则化得到的解比较小（靠近0），但是比较平滑（不等于0）。所以通过添加L2正则化向，模型不会得到特别大的权重，偏向于学习比较小的权重。因此L2正则化又叫做权重衰减。</p><p><strong>总结</strong></p><p>L1正则化使权重稀疏，L2正则化使权重平滑。</p><ul><li>L1正则化趋向于使用更少的特征，没用的特征权重为0，</li><li>L2正则化趋向于使用更多的特征，但这些特征的权重都接近0。这样可以避免模型严重依赖与其中的少数特征，而是倾向于使用所有的特征。</li><li>如果不是进行特征选择，最常用L2正则化。</li></ul><p>问题：</p><ol><li>什么时候用L1正则化，什么时候用L2正则化？<br>如果想让参数变得稀疏，即很多参数都为0，意味着模型使用的特征没有那么多，就用L1正则。<br>如果想用所有的特征，同时特征的参数又不这么大，用L2正则。</li><li>L1正则中实现参数稀疏有什么好处？<br>参数稀疏，说明有些参数为0，这样就可以实现特征的选择，参数为0的那些特征不会参与到模型计算中。一般而言，大部分特征对模型是没有贡献的，有些无用的特征虽然可以减少训练集的误差，但是在测试集上，反而会产生干扰。通过引入稀疏参数，可以将无用特征的权重设置为0.</li><li>L2正则中为什么参数越小表示模型越简单<br>越是复杂的模型，越想要对训练集中所有的点都要拟合，包括异常点，这就会造成在较小的区间中产生较大的波动，这个较大的波动也会反映在这个区间的导数比较大。而只有较大的参数才会有较大的导数，因此参数越小，模型越简单。</li></ol><h3><span id="315-面试问题">3.1.5. 面试问题</span></h3><p><strong>1. 简单介绍以下线性回归</strong></p><ul><li>线性：输入x和输出y的关系是线性的，即图像是直线</li><li>非线性：输入x和输出y的关系不是一次函数，图像不是直线</li><li>线性回归就是利用已有的样本，通过监督学习，学习由x到y的映射，然后利用学到的映射函数对未知的x进行预测。由于预测的值是连续值，所以是回归问题。</li></ul><p><strong>2. 线性回归的损失函数</strong></p><script type="math/tex; mode=display">J(w)=\frac{1}{2m}\sum_{i=1}^{i=m}(h(x^i)-y^i)^2</script><ol><li><p>简述岭回归和Lasso回归<br>这两种回归为了<strong>解决线性回归出现过拟合</strong>的问题。通过<strong>在损失函数中引入正则化项</strong>来解决</p><ul><li>Lasso回归损失函数<br>添加L1正则项<script type="math/tex; mode=display">J(w)=\frac{1}{2m}\sum_{i=1}^{i=m}(h(x^i)-y^i)^2+\lambda\sum_{j=1}^{j=n}|w_j|</script></li><li>岭回归损失函数<br>添加L2正则项<script type="math/tex; mode=display">J(w)=\frac{1}{2m}\sum_{i=1}^{i=m}(h(x^i)-y^i)^2+\lambda\sum_{j=1}^{j=n}w_j^2</script></li></ul></li></ol><p><strong>4. 线性回归的假设</strong><br>   线性回归假设因变量y符合正态分布   </p><h2><span id="32-逻辑回归">3.2. 逻辑回归</span></h2><p>逻辑回归是分类模型，虽然名字中有回归二字，但却是分类模型，用来二分类任务。<br>二分类的y有正负样本，即$y\in{(0,1)}$，$y$只有2个取值，一般将我们想要找的样本作为正样本。例如垃圾邮件分类中，想要找垃圾邮件，所以将垃圾邮件划分为正样本，非垃圾邮件为负样本。肿瘤良性判断中将恶性肿瘤设置为正样本，良性肿瘤设置为负样本。</p><ul><li><p>如何用连续的数组预测离散的y</p><p>线性回归输出的是连续值，而分类问题的标签y是离散值，属于{0,1}。怎么用回归模型预测离散的标签呢？<br>一个直观的办法是设定一个阈值，比如0，如果预测的值&gt;0，则属于正样本，否则属于负样本。<br>另一种方法是不去直接预测标签，而是预测样本属于正样本的概率。概率是连续值，并且在[0,1]之间。但是回归问题的输出值并不是在[0,1]之间，为了限制回归问题的值域，使用sigmoid函数，又成为logistic函数。因为sigmoid函数可以将输入$x\in[-\infty,\infty]$映射到$[0,1]$之间，输出的$h(x)$正好可以作为样本属于正例的概率。这种方法成为<strong>逻辑回归模型=logistic函数+回归模型</strong></p></li></ul><h3><span id="321-逻辑回归推导">3.2.1. 逻辑回归推导</span></h3><p>sigmoid函数：</p><script type="math/tex; mode=display">g(x)=\frac{1}{1+e^{-x}}</script><p><img src="/2020/06/19/百面机器学习概述/sigmoid.png" alt=""></p><p>输出值在<code>0~1</code>之间。原先的回归问题的假设函数简化为$h(x)=w^Tx$，为了让$h(x)$的输出在0~1之间，在外面套上sigmoid函数。</p><script type="math/tex; mode=display">h(x)=\frac{1}{1+e^{-w^{T}x}}</script><p>求得的$h(x)$表示样本$x$被判为正样本的概率，例如$h(x)=0.7$表示邮件是垃圾邮件的概率是0.7。因为真实标签值$y$只能为0和1，所以需要将$h(x)$和$y$对应起来。<br>如果$h(x)&gt;=0.5$，也就是$w^Tx&gt;=0$，则预测$y=1$<br>如果$h(x)&lt;0.5$，也就是$w^Tx&lt;0$，则预测$y=0$</p><ul><li>逻辑回归损失函数</li></ul><p><img src="/2020/06/19/百面机器学习概述/logistic.png" alt=""></p><ol><li><p>求单个样本预测正确的概率<br>$h(x)$表示样本为正例$(y=1)$的概率$P(y=1|x,w)=h(x)$<br>则样本为负例的概率为$P(y=0|x,w)=1-h(x)$</p></li><li><p>将上述公式整合</p><script type="math/tex; mode=display">P(y \mid {x})=\left\{\begin{array}{r}h(x), y=1 \\1-h(x), y=0\end{array}\right.</script><p>将上述2种情况整合成一个公式为</p><script type="math/tex; mode=display">P(y^i|x^i)=h(x^i)^{y_i}*(1-h(x^i))^{1-y^i}</script><p>对于样本$(x^i,y^i)$，如果$y^i=1$，则概率为$h(x^i)$，如果$y^i=0$，则概率为$1-h(x^i)$</p></li><li><p>求$m$个样本的似然函数</p><blockquote><p>极大似然估计：利用已知的样本结果，反推最有可能（最大概率）导致这些样本结果出现的模型参数，即在模型已知的情况下，求参数。</p></blockquote><p>如果有$m$个样本，分别为$(x^1,y^1),(x^2,y^2),…,(x^m,y^m)$，这m个样本假设相互独立，组合概率为每个样本概率的乘积，即最大似然估计为：</p><script type="math/tex; mode=display">P_总=P(y^1|x^1)P(y^2|x^2)...P(y^m|x^m)=\prod_{i=1}^{i=m}h(x^i)^{y_i}*(1-h(x^i))^{1-y^i}</script><p>其中<script type="math/tex">h(x)=\frac{1}{1+e^{-w^Tx}}</script></p></li><li><p>求对数似然<br>模型需要做的就是该概率最大，即连乘的乘积最大，但是连乘很复杂，通过<strong>对两边取对数将连乘变成累加的形式</strong></p></li></ol><script type="math/tex; mode=display">\begin{array}{l}log(P_总)=log(\prod_{i=1}^{i=m}h(x^i)^{y_i}*(1-h(x^i))^{1-y^i})\\   =\sum_{i=1}^{i=m}log(h(x^i)^{y_i}*(1-h(x^i))^{1-y^i})\\=\sum_{i=1}^{i=m}(y^ilog(h(x^i))+(1-y^i)log(1-h(x^i)))\end{array}</script><ol><li><p>求逻辑回归损失函数<br>上面的最大化$P_总$其实是我们的目标函数，但是如果在最大化目标函数时，对参数$w$进行求导时，非常复杂，所以就先取对数，将连乘换成累加。然后为了迎合一般都是最小化损失函数，所以加上一个符号。<br>模型最好的效果是让$log(P_总)$越大越好，但是损失函数却是越小越好，所以我们将其取负数作为损失函数，应为损失函数求的是平均误差，所以需要除以样本个数$m$,即逻辑回归的损失函数为交叉熵损失函数</p><script type="math/tex; mode=display">Loss(w)=-\frac{1}{m}\sum_{i=1}^{i=m}(y^ilog(h(x^i))+(1-y^i)log(1-h(x^i)))</script><ul><li><p>为什么可以用似然函数<br>因为逻辑回归的目标是让预测为正的概率最大，且预测为负的概率最大，即每个样本都要保证得到最大的概率，将所有样本预测后的概率相乘就最大，即得到似然函数。</p></li><li><p>为什么损失函数要取对数</p><ul><li>线性回归模型的平方损失函数对sigmoid函数求导无法保证是凸函数，在优化求$w$的过程中，求得的解有可能是局部最优，而不是全局最优</li><li>取对数后，方便后续的求导</li></ul></li></ul></li></ol><ul><li><p>梯度下降</p><p>首先先看sigmoid的导数</p><script type="math/tex; mode=display">g(x)=\frac{1}{1+e^{-x}}</script><p><img src="/2020/06/19/百面机器学习概述/sigmoid.jpg" alt=""></p><p><img src="/2020/06/19/百面机器学习概述/sigmoid1.jpg" alt=""></p><p>得到导数之后，更新参数$w_j$<br><img src="/2020/06/19/百面机器学习概述/sigmoid2.jpg" alt=""></p><ol><li>梯度下降公式中的$m$如果是样本总数，则每次更新参数时需要考虑所有的样本，称为批量梯度下降(BGD)。这种方法容易求得全局最优解，但是由于样本个数太多，训练过程非常慢。</li><li>如果$m=1$，即每次更新参数时只考虑一个样本，称为随机梯度下降(SGD)。这种方法训练速度快，但是准确率下降，并不是全局最优。</li><li>综上所述，当m为所有样本的一小部分时，比如m=32，即每次更新参数时只考虑一小部分样本，称为小批量梯度下降(MBGD)。它克服了上述两种方法的缺点又兼顾它们的优点，在实际中最常使用。</li></ol></li></ul><h3><span id="322-逻辑回归常见问题">3.2.2. 逻辑回归常见问题</span></h3><p><strong>1. 用一句话概括逻辑回归</strong><br>   逻辑回归假设数据服从伯努利分布，通过极大化似然函数，使用梯度下降求解参数，达到二分类的目的。</p><p><strong>2. 逻辑回归的目的</strong><br>   进行二分类<br>   逻辑回归作为回归，输出值是连续的，怎么应用在分类上呢？这里的y确实是一个连续的值，但是它的输出值在[0,1]之间，可以选定一个阈值来进行划分，如果输出值大于0.5，则判定为正样本，否则判定为负样本。</p><p><strong>3. 逻辑回归的基本假设</strong></p><ul><li><p>逻辑回归假设数据服从伯努利分布。伯努利分布就是抛硬币，正面的概率为$p$，反面的概率为$1-p$<br>在逻辑回归中，样本被判定为正例的概率为$h(x)$，则被判为负例的概率为$1-h(x)$</p></li><li><p>第二个假设是样本为正的概率是</p><script type="math/tex; mode=display">p=\frac{1}{1+e^{-w^Tx}}</script></li></ul><p><strong>4. 逻辑回归的损失函数</strong><br>   逻辑回归的损失函数是它的极大对数似然函数的相反数</p><script type="math/tex; mode=display">Loss(w)=-\frac{1}{m}\sum_{i=1}^{i=m}(y^ilog(h(x^i))+(1-y^i)log(1-h(x^i)))</script><p><strong>5. 随机梯度下降、批量梯度下降、小批量梯度下降的优缺点</strong></p><ul><li>梯度下降公式中的$m$如果是样本总数，则每次更新参数时需要考虑所有的样本，称为批量梯度下降(BGD)。这种方法容易求得全局最优解，但是由于样本个数太多，训练过程非常慢。</li><li>如果$m=1$，即每次更新参数时只考虑一个样本，称为随机梯度下降(SGD)。这种方法训练速度快，但是准确率下降，并不是全局最优。</li><li>综上所述，当m为所有样本的一小部分时，比如m=32，即每次更新参数时只考虑一小部分样本，称为小批量梯度下降(MBGD)。它克服了上述两种方法的缺点又兼顾它们的优点，在实际中最常使用。</li></ul><p><strong>6. 逻辑回归的优缺点</strong><br>   优点：</p><ul><li>形式简单，模型可解释性好。模型的权重$w$表示不同特征对最终结果的影响，如果$w_j$大，说明第$j$个特征的权重比较高，对最终的结果影响较大</li><li>模型效果不错。在工程上可以接受，如果特征工作做的好，效果不会太差。</li><li>训练速度快。在分类时，计算两仅仅和特征的数目有关</li><li>资源占用小，尤其是内存。因为只需要存储各个维度的特征值</li><li><p>方便输出结果。逻辑回归可以很方便的得到最后的分类结果，因为输出的结果表示每个样本属于正例的概率，可以很容易的对概率进行划分阈值。<br>缺点</p></li><li><p>准确率不是很高，因为形式简单</p></li><li>很难处理不平衡的数据。距离：如果正负样本比例1:1000，则将所有的样本都预测为负样本，模型的损失值就很小，但是这样的模型对于正样本的召回率并不高</li><li>处理非线性数据较麻烦。逻辑回归一般只处理线性可分的数据，一般用于二分类</li><li>无法筛选特征，需要提前做特征工程。</li></ul><p><strong>7. 逻辑回归的输出是真实概率吗</strong><br>  如果数据满足以上的2个假设，则输出的数据表示样本属于正例的概率。但是这2个假设并不是那么容易满足，所以很多情况下，逻辑回归的输出值无法作为真实的概率，只能看做置信度。</p><p><strong>8. 使用逻辑回归怎么进行多分类</strong><br>  可以将多分类问题转换成二分类问题</p><p><strong>9. 逻辑回归和线性回归的区别</strong></p><ol><li>线性回归阈值$[-\infty,\infty]$,逻辑回归的阈值$[0,1]$</li><li>拟合函数不同，线性回归$h(x)=w^Tx$，逻辑回归$h(x)=\frac{1}{1+e^{-w^Tx}}$</li><li>损失函数形式不同。线性回归是最小二乘法（平方损失），逻辑回归是极大似然估计</li></ol><p><strong>10. 逻辑回归是分类问题，为什么叫回归？逻辑回归也叫做“对数几率回归”，这里的“对数几率”如何理解？</strong><br>  逻辑回归的前面部分和线性回归一样，都是$W^Tx+b$，只是最后输出层加了sigmoid函数，将输出转换到[0,1]之间，所以逻辑回归的可以写成</p><p>  $y=\frac{1}{1+e^{-z}}$<br>  $z=W^Tx+b$</p><p>  上式可以转换成</p><script type="math/tex; mode=display">ln\frac{y}{1-y}=W^Tx+b</script><p>  $y$表示样本属于正例的概率，$1-y$表示样本属于负例的概率，而两者的比$\frac{y}{1-y}$称为“几率”，取对数$ln\frac{y}{1-y}$叫做“对数几率”。<br>  由此可以式子$y=\frac{1}{1+e^{-W^Tx+b}}$是在用线性回归模型的预测结果$W^Tx+b$去逼近真实的对数几率，因此也叫做“对数几率回归”</p><p><strong>11.  分类为什么不用平方损失MSE</strong></p><ol><li><p>因为在逻辑回归中，输出层使用的sigmoid激活函数，如果使用MSE作为损失函数，权重和损失函数的的曲线是非凸的，有很多局部最优点。</p><p><img src="/2020/06/19/百面机器学习概述/逻辑回归.jpg" alt=""> </p></li><li><p>在分类问题中，例如样本的真实标签是第3类，我们预测出来的值不需要知道对于每类的预测概率，比如预测出属于第三类的概率为0.6，那另外2类的概率为多少我们并不在意，我们只需要让第三类的预测值大于另外2类就可以了。如果用MSE损失就太严格了</p></li></ol><h2><span id="33-softmax回归">3.3. Softmax回归</span></h2><p>逻辑回归用来解决二分类问题，softmax回归用来解决多分类问题。</p><p>假设对一个2*2的图像进行分类，判断图像是狗、猫、鸡的哪一种。即输入x有4个特征$x_1,x_2,x_3,x_4$，真实标签$y=1,2,3$。</p><p>softmax回归和线性回归一样，也是一个单层全连接层。输入有4个，输出有3个，所以参数有12个。</p><p><img src="/2020/06/19/百面机器学习概述/softmax.png" alt=""></p><p>像上面的线性回归，输出的y值是连续的，我们可以把输出的y值看做样本属于某一类值置信度。例如$o_1=o_3=10,o_2=1000$，则图片被预测为猫。但是由于输出的值不稳定，并且连续的预测值和真实的离散值误差难以衡量。<br>为了解决这个问题，这里用到softmax运算。softmax将原先输出的连续值$o$转换为概率。</p><p><img src="/2020/06/19/百面机器学习概述/softmax1.png" alt=""></p><p>最终softmax回归模型函数为</p><p>$o^i=W^Tx+b$<br>$y^i=softmax(o^i)$</p><p>逻辑回归和softmax回归的不同</p><ol><li>逻辑回归最后的输出层只有1个神经元，输出的结果表示样本属于正例的概率。softmax回归最后的输出层有n个神经元(n为类别数)，输出样本属于每个类别的概率。即sigmoid输出的是一个数，softmax输出的是一个向量。</li><li>逻辑回归最后输出用sigmoid将连续值转换为属于正例的概率。softmax回归最后输出用softmax将连续值转换为属于各类的概率。都是将连续值转换为概率。</li></ol><ul><li>softmax回归是逻辑回归在多分类的拓展</li></ul><p><img src="/2020/06/19/百面机器学习概述/softmax.jpg" alt=""></p><ul><li><p>逻辑回归怎么用来解决多分类问题<br>将多分类问题拆分成多个二分类问题。具体怎么拆分有3种方法：</p><ol><li>一对一。假设多分类中一共有k类，则将任意2类进行组合，一共形成k(k-1)/2个组合。将一个样本输入到这k(k-1)/2个分类器中，得到k(k-1)/2个分类结果，然后取个数最多的类别作为这个样本最终预测类别</li></ol><p><img src="/2020/06/19/百面机器学习概述/多分类1.png" alt=""> </p><ol><li>一对多。假设多分类中共有k类，一共形成k个分类器，第一个分类器将k1作为正例，其余类作为负例。第二个分类器将k2作为正例，其余类作为负例，以此类推。一个样本输入到这k个分类器中，输出k个分类结果，如果只有一个正例，则该样本属于这个类，如果输出多个正例，则看置信度。</li></ol><p><img src="/2020/06/19/百面机器学习概述/多分类2.png" alt=""></p><ol><li>多对多。每次将多个类作为正例，多个类作为负例。</li></ol></li></ul><p>  <img src="/2020/06/19/百面机器学习概述/多分类.png" alt=""></p><ul><li><p>如果一个样本有多个类别标签，怎么办？</p><p>这就不是一个多分类问题了，而是多标签学习。假设一共有k类，训练k个分类器。第$i$个分类器判断每个样本是否归为第$i$类。训练分类器时，需要将标签重新整理为属于第$i$类和不属于第$i$类。</p></li></ul><h2><span id="34-回归和分类总结">3.4. 回归和分类总结</span></h2><p><img src="/2020/06/19/百面机器学习概述/前向1.png" alt=""></p><p>回归问题和分类问题在前半部分都是一样的，输入$X$乘以权重$W$，然后再经过激活函数$f$，堆叠多层，得到输出$out$</p><p>回归问题和分类问题只是最后的输出层不一样。回归问题经过前面的堆叠得到最后的输出$y$</p><p>分类问题（多分类）还需要将$y$经过一个softmax层，将输出值归一化到[0,1]之间，且和为1。</p><p><img src="/2020/06/19/百面机器学习概述/前向2.png" alt=""></p><h2><span id="35-数据不平衡问题">3.5. 数据不平衡问题</span></h2><p>在分类问题中可能会遇到类别不平衡问题。例如1000个样本中，2个正例，998个负例。这样模型在预测值偏向于将样本预测为负例，但是在实际中却没有价值，因为它检测不到正例。</p><p>解决正负样本不均衡问题，有以下3个方法</p><ol><li><p>欠采样<br>对负样本进行负采样，使得正负样本均衡。欠采样需要丢弃一些负样本，但也不能随意丢弃，否则会丢失一些重要信息。代表算法为EasyEnsemble利用集成学习，将负样本划分为若干个集合进行训练，这样每个模型的数据都进行了欠采样。</p><p>欠采样方法有：<br>(1) Easy Ensemble算法：每次从样本多的那个类别中抽出一个子集E，子集E的样本个数等于少数类别的样本数，然后让E和少数样本训练得到一个分类器。多次抽取形成不同的子集E，就会训练得到不同的分类器，给定一个测试样本，测试样本的分类结果是多个分类器结果的融合。</p></li><li><p>过采样<br>生成一些正样本，使得正负样本均衡。但是过采样不能将原先的正样本复制n份，这样会造成严重的过拟合。过采样代表算法为SMOTE通过对训练集中的正样本进行插值生成一些正样本。<br>SMOTE算法对少数类别的样本点x，选择同类别的k个邻居，然后这K个邻居中随机选择1个邻居y，然后在x和y的连线上随机选择1个点作为新生成的样本。</p><p><img src="/2020/06/19/百面机器学习概述/smote.png" alt=""></p></li></ol><ol><li><p>调整阈值<br>在逻辑回归中，我们通常将$h(x)&gt;0.5$判定为正例，否则为负例。这说明正例和负例出现的可能性相同。但是如果正负样本不平衡，正样本出现非常小，可能阈值就需要变小。假设正样本:负样本=2:10，则将阈值变成0.2，例$h(x)&gt;0.2$我们就判定为正例，否则为负例。</p></li><li><p>转换问题角度<br>当样本数目极其不平衡时，可以将问题转化为单类学习，异常检测等问题。</p></li></ol><h3><span id="351-smote算法">3.5.1. SMOTE算法</span></h3><p>SMOTE是一种合成少数类过采样技术。SMOTE算法的基本思想是对少数样本进行分析和模拟，并将人工模拟的新样本添加到数据集中，该算法的模型过程采用KNN技术，步骤如下：</p><ol><li>对每个少数样本x，计算x到其他少数样本的欧式距离，为x找到K个最近邻居</li><li><p>从K个近邻中随机挑选1个样本，在x和这1个样本之间的连线上，线性差值生成新样本。</p><script type="math/tex; mode=display">x_{\text {new}}=x+\operatorname{rand}(0,1) \times(\tilde{x}-x)</script></li><li><p>重复步骤2进行N次，则少数样本数变成原来的N倍</p></li></ol><h2><span id="36-svm">3.6. SVM</span></h2><p>SVM用来做二分类，主要分为三部分</p><ol><li>数据线性可分：最优划分超平面/硬间隔SVM/线性可分SVM</li><li>数据近似线性可分：软间隔SVM/近似线性可分SVM</li><li>数据线性不可分：核方法</li></ol><h3><span id="361-线性可分svm">3.6.1. 线性可分SVM</span></h3><p>SVM就是解决二分类问题，分类学习最基本的想法就是找到一个划分超平面，将不同类别的数据集分开。目的就是找到一个最优的分割线将两类分开。</p><p>分类问题有线性可分和线性不可分。线性可分就是在二维空间中能找到一条直线将2类样本划分开。线性不可分就是不能找到一条直线。对于线性不可分的样本通常是通过高斯核函数将样本映射到高维空间，然后转换为高维空间线性可分的问题。<br>下图中的直线都可以将2类样本分开，但是哪个才是好的分割线呢？分类器的价值不在于它多么擅长分割训练样本，而是对于哪些未知的样本它的分类效果怎么样。下图中中间较粗的那条线，在正确划分训练样本的前提下，尽可能地同时远离两个聚类。而其他的线都是有些“倾斜”，一头远离一类，另一头靠近另一类。</p><p><img src="/2020/06/19/百面机器学习概述/SVM1.png" alt=""></p><p>假设划分超平面的公式为</p><script type="math/tex; mode=display">w^Tx+b=0</script><p>这就是我们初中学的直线公式$ax+b=0$</p><p>理想中超平面进行划分时，如果结果大于0就划分为正例，否则划分为负例。下面就是逻辑回归的划分方式：</p><script type="math/tex; mode=display">\left\{\begin{array}{ll}\omega^{T} x_{i}+b>0, & y_{i}=+1 \\\omega^{T} x_{i}+b<0, & y_{i}=-1\end{array}\right.</script><p>而SVM是逻辑回归的强化，SVM设置更严格的划分条件，变成：</p><script type="math/tex; mode=display">\left\{\begin{array}{l}w^{T} x+b \geq 1 \quad y=1 \\w^{T} x+b \leq-1 \quad y=-1\end{array}\right.</script><p>上面我们简单的介绍下SVM和逻辑回归的不同，下面我们将详细介绍SVM</p><p>假设SVM中的分割超平面为<script type="math/tex">w^Tx+b=0</script></p><p>$w=(w_1,w_2,…w_d)$是有个列向量，拆分开就是$w_1x_1+w_2x_2+…+w_dx_d+b=0$</p><p>超平面有以下几个性质</p><p><strong>性质1</strong>：等比例缩放$w,b$，超平面不变，仍然是同一条直线或超平面<br><strong>性质2</strong>：点$x=(x_1,x_2,…,x_d)$到超平面的距离为</p><script type="math/tex; mode=display">\frac{|w_1x_1+w_2x_2+...+w_dx_d+b|}{\sqrt{w_1^2+w_2^2+...+w_d^2}}=\frac{|w^Tx+b|}{||w||}</script><p>下面介绍2个概念：<strong>函数间隔、几何间隔</strong></p><blockquote><p>二维平面中点$(x,y)$到$AX+By+c=0$的距离为$\frac{|Ax+By+c|}{\sqrt{A^2+B^2}}$</p></blockquote><p>  <strong>超平面</strong>：$w^Tx+b=0$<br>  <strong>函数间隔</strong>：$\hat{\gamma}=y(w^Tx+b)=yf(x)=|f(x)|$<br>  函数间隔就是标签$y$乘上$f(x)$的值，函数间隔永远为正。但是由于SVM中$y$的取值只能为1和-1，所以函数间隔的值就是$|f(x)|$<br>  几何间隔表示点到超平面的距离，在SVM中点到超平面的距离为$\frac{|w^Tx+b|}{||w||}=\frac{|f(x)|}{||w||}=\frac{\hat{\gamma}}{||w||}$<br>  <strong>几何间隔</strong>：$\gamma=\frac{|w^Tx+b|}{||w||}=\frac{y(w^Tx+b)}{||w||}=\frac{\hat{\gamma}}{||w||}$</p><p>  函数间隔$y(w^Tx+b)$可以表示分类预测的准确性和置信度，值越大越好，说明模型将样本分正确的概率越大，但函数间隔并不表示点到超平面的距离，因为假如将$w,b$成比例变成$2w,2b$，超平面的位置没有变，但是$f(x)$却变成原来的2倍，即函数间隔变成原来的2倍。在实际中，定义点到直线的距离时，用的是几何间隔。$w,b$成倍数增加时，几何间隔不变。函数间隔是几何间隔没有除以$||w||$的表示，几何间隔是函数间隔归一化的结果。函数间隔是我们自己定义的，而几何间隔是客观存在的，无论$w,b$扩大几倍，对几何间隔没有影响。</p><p><strong>SVM的目标</strong></p><p>SVM的目标是找到一个最优的划分超平面。那怎么定义最优呢？在SVM中评价指标就是几何间隔。在下图中，我们直观的感觉图a的分类效果比b和c好，因为在图a中，与分割线最近的样本点相比b和c来说，这个样本点距离分割线最远。SVM正是遵循这一思想，在众多分割超平面中，找样本点（超平面附近的点）与分割超平面距离最大的那个超平面，即最小几何间隔中，最大的那个。</p><p><img src="/2020/06/19/百面机器学习概述/SVM3.png" alt=""></p><p>SVM的最佳划分超平面需要满足2个条件：（1）能够将所有的正负样本划分正确，即函数间隔大于0，（2）离超平面最近的样本点与超平面的几何距离最大</p><p>第一个条件公式为$\hat{\gamma}=y(w^Tx+b)&gt;0$<br>第二个条件为首先找到最近的样本点，即最小的函数间距，然后再最大化函数间距。</p><script type="math/tex; mode=display">\begin{array}{l}\min\tilde{\gamma}^{i}=\min \frac{y^{i}\left(w^{T} \mathbf{x}^{i}+b\right)}{\| w \mid}=\frac{1}{\|w\|} \min y^{i}\left(w^{T} \mathbf{x}^{i}+b\right), i=1,2, \ldots, m \\\max _{w, b} \frac{1}{\|w\|} \min y^{i}\left(w^{T} \mathbf{x}^{i}+b\right), i=1,2, \ldots, m\end{array}</script><p>结合上面的2个条件，求解最优划分超平面的公式为</p><script type="math/tex; mode=display">\begin{aligned}\max _{w, b} \frac{1}{\|w\|} \min y^{i}\left(w^{T} \mathbf{x}^{i}+b\right), i=1,2, \ldots, m \\\text { subject to } y^{i}\left(w^{T} \mathbf{x}^{i}+b\right)>0\end{aligned}</script><p>但是上面这个目标函数太复杂了，需要对其进行简化。这里就需要用到超平面的性质1：对$w,b$进行缩放，超平面不变。如果在求解的过程中，继续保持这个性质的话，就算上面的公式可以求得最优的划分超平面，但是$w,b$的取值却有无数个，即解不唯一。但是我们要求一个固定的超平面，对应的$w,b$是唯一的，就需要添加限制条件。限制条件可以有多种选择：</p><p>选择1：限制$||w||=1$，即超平面的法向量模长为1，这样就消除了等比缩放的影响。但是添加了这个限制对上面公式的简化没有什么帮助<br>选择2：$miny^i(w^Tx^i+b)=1$，限制最小的函数间隔等于1，这也是SVM所采取的方式。如果$\hat{\gamma}=1$，假设将$w,b$放大为$kw,kb$，理论上来说缩放后的函数间隔$\hat{\gamma}_{i+1}=k\hat{\gamma}$，但是我们限制了函数间隔只能为1，即$\hat{\gamma}_{i+1}=\hat{\gamma}=1$，那$k$也只能为1，即不存在等比缩放的问题。</p><blockquote><p>注意：SVM中将$miny^i(w^Tx^i+b)=1$，其实将值限制为2,3,4…，限制为多少都没关系，都可以消除等比缩放带来的影响，但是不可以不限制。</p></blockquote><p>有了这个限制条件，原先的目标就需要变了</p><p><strong>原先的目标函数</strong>：</p><script type="math/tex; mode=display">\begin{aligned}\max _{w, b} \frac{1}{\|w\|} \min y^{i}\left(w^{T} \mathbf{x}^{i}+b\right), i=1,2, \ldots, m \\\text { subject to } y^{i}\left(w^{T} \mathbf{x}^{i}+b\right)>0\end{aligned}</script><p>增加了$min y^i(w^Tx^i+b)=1$的限制，也就是说$y^i(w^Tx^i+b)&gt;=1$，第一个限制条件变成$\max _{w, b} \frac{1}{|w|}$，最大化$\frac{1}{||w||}$其实就是最小化$||w||$，也就是$min \frac{1}{2}||w||^2$，</p><p><strong>最终SVM的目标函数</strong></p><script type="math/tex; mode=display">\begin{aligned}\min _{w, b} \frac{1}{2}||w||^2 , i=1,2, \ldots, m \\\text { subject to } y^{i}\left(w^{T} \mathbf{x}^{i}+b\right)>=1\end{aligned}</script><p>于是我们得到了3个平面：最优划分超平面$w^Tx+b=0$，与划分超平面间隔平行的2个超平面$w^Tx+b=1$和$w^Tx+b=-1$</p><p><img src="/2020/06/19/百面机器学习概述/SVM2.png" alt=""></p><p>这是一个凸二次规划的问题，对于一个优化问题，通常可以从2个角度考虑：主问题和对偶问题。常常利用拉格朗日对偶性将主问题转换为对偶问题，通过求解对偶问题的解来得到原始问题的解，这是因为对偶问题的复杂度往往低于原始问题。</p><blockquote><p>拉格朗日乘子法知识点<br>拉格朗日乘子法将原问题转换为对偶问题进行求解，主问题有等式约束和不等式约束<br>主问题：</p><script type="math/tex; mode=display">\begin{array}{c}\min _{x} f(x)\\s . t . h_{i}(x)=0(i=1, \ldots, m)\\g_{j}(x) \leq 0(j=1, \ldots, n)\end{array}</script><p>拉格朗日函数为</p><script type="math/tex; mode=display">L(x, \lambda, \mu)=f(x)+\sum_{i=1}^{m} \lambda_{i} h_{i}(x)+\sum_{j=1}^{n} \mu_{j} g_{j}(x)</script><p>由不等式约束引入的KKT条件</p><script type="math/tex; mode=display">\left\{\begin{array}{l}g_{j}(x) \leq 0 \\\mu_{j} \geq 0 \\\mu_{j} g_{j}(x)=0\end{array}\right.</script><p>其中$\lambda=\left(\lambda_{1}, \lambda_{2}, \ldots, \lambda_{m}\right)^{T} \text { 和 } \mu=\left(\mu_{1}, \mu_{2}, \ldots, \mu_{n}\right)^{T}$是拉格朗日乘子</p></blockquote><p>根据上面的知识，我们得到<strong>SVM的拉格朗日函数</strong></p><p>[<br>L(\omega, b, \alpha)=\frac{1}{2}|\omega|^{2}+\sum_{i=1}^{m} \alpha_{i}\left(1-y_{i}\left(\omega^{T} x_{i}+b\right)\right)<br>]</p><script type="math/tex; mode=display">L(w, b, \alpha)=\frac{1}{2}\|w\|^{2}-\sum_{i=1}^{m} \alpha_{i} y_{i}\left(\omega^{T} x_{i}+b\right)+\sum_{i=1}^{N} \alpha_{i}</script><p>其中 $\alpha=\left(\alpha_{1} ; \alpha_{2} ; \ldots ; \alpha_{m}\right)$,拉格朗日乘子 $\alpha_{i} \geq 0$</p><p>一个优化问题可以从两个角度考虑：主问题和对偶问题。在约束最优化问题中，常常利用拉格朗日对偶性将原问题转化为对偶问题，通过对偶问题来得到原始问题的解。<br>根据拉格朗日对偶性，原始问题的对偶问题是极大极小问题：</p><script type="math/tex; mode=display">\max _{\alpha} \min _{w, b} L(w, b, \alpha)</script><p>所以为了求得对偶问题的解，需要先求$L(w,b,\alpha)$对$w,b$的极小，再求对$\alpha$的极大。</p><p>（1）求$\min _{w, b} L(w, b, \alpha)$<br>将拉格朗日函数$L(w,b,\alpha)$分别对$w,b$求偏导，并令其为0</p><script type="math/tex; mode=display">\begin{array}{l}\nabla_{w} L(w, b, \alpha)=w-\sum_{i=1}^{m} \alpha_{i} y_{i} x_{i}=0 \\\nabla_{b} L(w, b, \alpha)=-\sum_{i=1}^{m} \alpha_{i} y_{i}=0\end{array}</script><p>得到：</p><script type="math/tex; mode=display">\begin{array}{l}w=\sum_{j=1}^{m} \alpha_{i} y_{i} x_{i} \\\sum_{i=1}^{m} \alpha_{i} y_{i}=0\end{array}</script><p>将求得$w$带入到拉格朗日函数中</p><script type="math/tex; mode=display">\begin{aligned}L(w, b, \alpha) &=\frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_{i} \alpha_{j} y_{i} y_{j}x_{i}^T x_{j}-\sum_{i=1}^{m} \alpha_{i} y_{i}\left(\left(\sum_{j=1}^{m} \alpha_{j} y_{j} x_{j}^T\right) x_{i}+b\right)+\sum_{i=1}^{m} \alpha_{i} \\&=\frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_{i} \alpha_{j} y_{i} y_{j}x_{i}^T x_{j}-\sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_{i} \alpha_{j} y_{i} y_{j}x_{i}^T x_{j}-\sum_{i=1}^{m} \alpha_{i} y_{i}b+\sum_{i=1}^{m} \alpha_{i} \\&=-\frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_{i} \alpha_{j} y_{i} y_{j}\left(x_{i} \cdot x_{j}\right)+\sum_{i=1}^{m} \alpha_{i}\end{aligned}</script><p>即</p><script type="math/tex; mode=display">\min _{w, b} L(w, b, \alpha)=-\frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_{i} \alpha_{j} y_{i} y_{j}x_{i}^T x_{j}+\sum_{i=1}^{m} \alpha_{i}</script><p>（2）求$\min _{w, b} L(w, b, \alpha)$关于$\alpha$的极大，即是对偶问题</p><script type="math/tex; mode=display">\begin{array}{ll}\max _{\alpha} & -\frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_{i} \alpha_{j} y_{i} y_{j}x_{i}^T x_{j}+\sum_{i=1}^{m} \alpha_{i} \\\text { s.t. } & \sum_{i=1}^{m} \alpha_{i} y_{i}=0 \\& \alpha_{i} \geqslant 0, \quad i=1,2, \cdots, m\end{array}</script><p>将上面的求极大变成下面的求极小问题</p><script type="math/tex; mode=display">\begin{array}{ll}\min _{\alpha} & \frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_{i} \alpha_{j} y_{i} y_{j}x_{i}^T x_{j}-\sum_{i=1}^{m} \alpha_{i} \\\text { s.t. } & \sum_{i=1}^{m} \alpha_{i} y_{i}=0 \\& \alpha_{i} \geqslant 0, \quad i=1,2, \cdots, m\end{array}</script><p>最终求得的$w,b$只和支持向量有关。因此SVM的一个重要性质是：SVM训练完之后，大部分的训练样本不需要保留，最终模型只和支持向量有关。</p><h3><span id="362-近似线性svm">3.6.2. 近似线性SVM</span></h3><p>在实际应用中，完全线性可分是很少的，例如下图中，没有一条直线可以将2类完全分开。</p><p><img src="/2020/06/19/百面机器学习概述/SVM4.png" alt=""></p><p>于是就有了软间隔，与线性可分的硬间隔相比，条件没有那么苛刻，我们允许个别样本点出现在隔离带里面，例如下</p><p><img src="/2020/06/19/百面机器学习概述/SVM5.png" alt=""></p><p>硬间隔要求所有样本点都满足</p><script type="math/tex; mode=display">y^i(w^Tx^i+b)>=1</script><p>软间隔引入松弛变量，允许部分样本点满足</p><script type="math/tex; mode=display">y^i(w^Tx^i+b)+\xi_{i}>=1</script><p>当$\xi_{i}=0$时，样本分类正确<br>当0&lt;$\xi_{i}<1$时，样本分类正确 当$\xi_{i}="">=1$时，样本分类正确</1$时，样本分类正确></p><p>增加松弛变量后，SVM的目标变成：</p><script type="math/tex; mode=display">\begin{aligned}&\min _{w} \frac{1}{2}\|w\|^{2}+C \sum_{i=1}^{m} \xi_{i}\\&\text {s.t.} \quad y_{i}\left(w^{T} x_{i}+b\right)\geq 1-\xi_{i}, \quad \xi_{i} \geq 0, \quad i=1,2, \ldots, n\end{aligned}</script><p>松弛变量通过学习得到，且要惩罚大的松弛变量。<br>$C$是一个大于0的数，表示错误样本的惩罚程度，当$C$无穷大时，表示对错误样本的惩罚无穷大，不允许分错样本，这样$\xi_i$就无穷小，就是线性可分SVM。当$C$为有限值时，才会允许部分样本分错。</p><p>注意：在间隔内的那部分样本点是不是支持向量？是</p><p>上述原问题的拉格朗日函数是</p><script type="math/tex; mode=display">L(w, b, \xi, \alpha, \mu)=\frac{1}{2}\|w\|^{2}+C \sum_{i=1}^{m} \xi_{i}-\sum_{i=1}^{m} \alpha_{i}\left(y_{i}\left(w^T x_{i}+b\right)-1+\xi_{i}\right)-\sum_{i=1}^{m} \mu_{i} \xi_{i}</script><script type="math/tex; mode=display">\alpha_{i} \geqslant 0, \mu_{i} \geqslant 0</script><p>对偶问题是拉格朗日的极大极小问题，所以对偶问题为</p><script type="math/tex; mode=display">\max _{\alpha,\mu} \min _{w, b,\xi} L(w, b, \xi, \alpha, \mu)</script><p>（1）极小化$\min _{w, b,\xi} L(w, b, \xi, \alpha, \mu)$，对$w, b,\xi$求导使其为0</p><script type="math/tex; mode=display">\begin{array}{l}\nabla_{w} L(w, b, \xi, \alpha, \mu)=w-\sum_{i=1}^{m} \alpha_{i} y_{i} x_{i}=0 \\\nabla_{b} L(w, b, \xi, \alpha, \mu)=-\sum_{i=1}^{m} \alpha_{i} y_{i}=0 \\\nabla_{\xi_{i}} L(w, b, \xi, \alpha, \mu)=C-\alpha_{i}-\mu_{i}=0\end{array}</script><p>得到</p><script type="math/tex; mode=display">\begin{array}{c}w=\sum_{i=1}^{m} \alpha_{i} y_{i} x_{i} \\\sum_{i=1}^{m} \alpha_{i} y_{i}=0 \\C-\alpha_{i}-\mu_{i}=0\end{array}</script><p>将上述公式带入到拉格朗日函数中，得到</p><script type="math/tex; mode=display">\min _{w, b, \xi} L(w, b, \xi, \alpha, \mu)=-\frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_{i} \alpha_{j} y_{i} y_{j}x_{i}^T x_{j}+\sum_{i=1}^{m} \alpha_{i}</script><p>（2）对$\min _{w, b, \xi} L(w, b, \xi, \alpha, \mu)$求$\alpha$的极大，得到对偶问题</p><script type="math/tex; mode=display">\max _{\alpha}-\frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_{i} \alpha_{j} y_{i} y_{j}x_{i}^T  x_{j}+\sum_{i=1}^{m} \alpha_{i}</script><script type="math/tex; mode=display">\begin{aligned}&\text { s.t. } \quad \sum_{i=1}^{m} \alpha_{i} y_{i}=0\\&\begin{array}{l}C-\alpha_{i}-\mu_{i}=0 \\\alpha_{i} \geqslant 0 \\\mu_{i} \geqslant 0, \quad i=1,2, \cdots, m\end{array}\end{aligned}</script><p>将上述极大变成极小为：</p><script type="math/tex; mode=display">\min _{\alpha}\frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_{i} \alpha_{j} y_{i} y_{j}x_{i}^T  x_{j}-\sum_{i=1}^{m} \alpha_{i}</script><p>SVM中的2个重要参数：惩罚系数$C$和$\gamma$<br>C和gamma都起到了正则化的作用<br>惩罚系数C表示对误差的惩罚程度，C越大，说明越不能容忍误差，容易出现过拟合；C越小，容易欠拟合<br>gamma是选择RBF函数（高斯核函数）作为核函数后，该函数自带的一个参数，隐含地决定了数据映射到新的特征空间后的分布，gamma越大，支持向量越少,容易过拟合；gamma越小，支持向量越多，容易欠拟合。支持向量的个数影响训练和预测的速度。</p><p><img src="/2020/06/19/百面机器学习概述/SVM4.jpg" alt=""></p><h3><span id="363-核函数">3.6.3. 核函数</span></h3><p>上面讨论的硬间隔和软间隔都是样本完全线性可分或者近似线性可分的，但是也会遇到样本不是线性可分的，例如下图：</p><p><img src="/2020/06/19/百面机器学习概述/SVM6.png" alt=""></p><p>解决方案：将样本使用核函数，向高维空间转化，使得在高维空间中线性可分。</p><p><img src="/2020/06/19/百面机器学习概述/SVM7.png" alt=""></p><p>核函数的好坏对SVM至关重要。若核函数选择不合适，将样本映射到一个不合适的特征空间，很有可能分类效果不佳。</p><p><img src="/2020/06/19/百面机器学习概述/SVM8.png" alt=""></p><h3><span id="364-面试问题">3.6.4. 面试问题</span></h3><ul><li><p><strong>介绍函数间隔和几何间隔</strong></p><blockquote><p>二维平面中点$(x,y)$到$AX+By+c=0$的距离为$\frac{|Ax+By+c|}{\sqrt{A^2+B^2}}$</p></blockquote><p><strong>超平面</strong>：$w^Tx+b=0$<br><strong>函数间隔</strong>：$\hat{\gamma}=y(w^Tx+b)=yf(x)=|f(x)|$<br>函数间隔就是标签$y$乘上$f(x)$的值，函数间隔永远为正。但是由于SVM中$y$的取值只能为1和-1，所以函数间隔的值就是$|f(x)|$<br>几何间隔表示点到超平面的距离，在SVM中点到超平面的距离为$\frac{|w^Tx+b|}{||w||}=\frac{|f(x)|}{||w||}=\frac{\hat{\gamma}}{||w||}$<br><strong>几何间隔</strong>：$\gamma=\frac{|w^Tx+b|}{||w||}=\frac{y(w^Tx+b)}{||w||}=\frac{\hat{\gamma}}{||w||}$</p><p>函数间隔$y(w^Tx+b)$可以表示分类预测的准确性和置信度，值越大越好，说明模型将样本分正确的概率越大，但函数间隔并不表示点到超平面的距离，因为假如将$w,b$成比例变成$2w,2b$，超平面的位置没有变，但是$f(x)$却变成原来的2倍，即函数间隔变成原来的2倍。在实际中，定义点到直线的距离时，用的是几何间隔。$w,b$成倍数增加时，几何间隔不变。函数间隔是几何间隔没有除以$||w||$的表示，几何间隔是函数间隔归一化的结果。函数间隔是我们自己定义的，而几何间隔是客观存在的，无论$w,b$扩大几倍，对几何间隔没有影响。</p></li><li><p><strong>SVM中$w^Tx+b&gt;1$，$w^Tx+b&lt;-1$设置为正负样本的阈值，为什么是正负1</strong><br>SVM最终学习到的是一个超平面，至于系数是$(w^T,b)$还是$(2w^T,2b)$都不重要，所以需要对$w,b$进行限制，这SVM对函数间隔进行限制为$y(w^Tx+b)=1$，这样在求得的解中$w,b$就是唯一的。当然$y(w^Tx+b)$也不一定为1，也可以为2，3或其他值</p></li><li><p><strong>SVM什么时候选择线性核函数，什么时候选择高斯核函数</strong><br>当样本量比较小，特征量比较大时使用线性核函数。因为此时特征空间已经很高维了，只是数据量不够，线性核函数足够了。如果用高斯核函数投影到高维容易出现过拟合。<br>当数据量比较大而特征量比较小时，使用高斯核函数，需要投影到高维特征空间。</p></li><li><p><strong>使用高斯核函数之前需要对数据进行处理吗</strong><br>需要对特征进行缩放，因为高斯核函数需要计算两个点之间的欧式距离，如果不特征缩放的话那些值特别大的特征将会对核函数的结果有决定性影响，而数据量小的特征将被忽略。</p></li><li><p><strong>SVM如何解决数据不均衡问题</strong><br>数据不均衡在SVM中导致的主要问题是数据量少的样本分布空间不如数据量多的样本。为了能够让分割超平面向数据量少的样本偏移，可以给样本少的分类更大的惩罚因为$C$,表示如果数据少的样本分错了将会有很大的惩罚，使模型更重视数量少的样本。</p></li><li><strong>SVM原始问题为什么要转化为对偶问题求解？</strong><ol><li>改变算法复杂度，对偶问题更容易求解。因为算法的复杂度与样本维度有关，在对偶问题下，算法复杂度和样本数量有关。如果是线性回归，样本维度小于样本数量，在原问题上求解就可以了。但如果是非线性回归，就涉及到升维，例如使用高斯核函数，将样本升到很高维，升维后的样本维度远远大于样本数量，这是显然在对偶问题下更好求解。</li><li>转化为对偶问题才能得到内积形式，引入核函数，进而推广到非线性分类问题中。</li></ol></li><li><strong>SVM为什么采用间隔最大化</strong><br>当数据线性可分时，有无穷多个超平面可以将样本划分开，利用间隔最大化可以求得最优的划分超平面。此时的划分超平面的分类结果是最鲁棒的，对未知数据的泛化能力最强。</li><li><strong>为什么SVM引入核函数</strong><br>当样本在原始空间中线性不可分时，通过核函数将样本映射到更高维的特征空间中，样本在这个特征空间中线性可分或近似线性可分。</li><li><strong>核函数也可以应用在别的分类模型中，为什么在逻辑回归中不用核函数呢？</strong><br>因为核函数将样本维度映射到很高维。在SVM中只有支持向量决定了划分超平面，只有少数样本参与核计算，在计算核函数时优势很大。但是逻辑回归是所有的样本都决定了划分超平面，如果采用核函数，那每个样本都参数核运算，则非常耗时。</li><li><p><strong>SVM为什么对缺失值敏感</strong><br>这里说的缺失数据是指缺失某些特征数据，向量数据不完整。SVM没有处理缺失值的策略（决策树有）。而SVM希望样本在特征空间中线性可分，所以特征空间的好坏对SVM的性能很重要。缺失特征数据将影响训练结果的好坏。</p></li><li><p><strong>SVM和逻辑回归的不同</strong></p><ol><li>SVM只有支持向量对模型有影响，即只有支持向量决定划分超平面。逻辑回归是所有点都影响划分超平面</li><li>损失函数不同。SVM采用hinge损失，逻辑回归采用对数损失<br>逻辑回归的目标函数 <script type="math/tex; mode=display">J(\theta)=-\frac{1}{m}\left[\sum_{i=1}^{m} y^{(i)} \log h_{\theta}\left(x^{(i)}\right)+\left(1-y^{(i)}\right) \log \left(1-h_{\theta}\left(x^{(i)}\right)\right)\right]</script>SVM的目标函数<script type="math/tex; mode=display">\mathcal{L}(w, b, \alpha)=\frac{1}{2}\|w\|^{2}-\sum_{i=1}^{n} \alpha_{i}\left(y_{i}\left(w^{T} x_{i}+b\right)-1\right)</script>逻辑回归是最大化似然，求得参数的值<br>SVM是最大化几何间隔，求得参数的值</li><li>输出不同。SVM输出0/1，逻辑回归输出样本属于正例的概率</li><li>处理非线性问题的能力不同。SVM通过核函数将非线性问题转化为线性问题。逻辑回归需要活动特征转换。</li><li>LR对异常值敏感；SVM相对不敏感，泛化能力好</li></ol></li><li><p>SVM的优缺点<br>优点：</p><ol><li>可以高效地解决高维特征的分类和回归</li><li>只依赖支持向量，无需全部样本</li><li>通过核函数可以处理线性不可分问题<br>缺点：</li><li>样本量巨大时，不适合用</li><li>SVM对缺失值敏感</li><li>对核函数没有选择的标准</li></ol></li></ul><h2><span id="37-决策树">3.7. 决策树</span></h2><p>决策树是一个非常见的机器学习算法，易于理解，可解释强，可以作为分类算法和回归算法。</p><p>决策树通常是递归的选择最优特征，并根据该特征对训练集进行划分，对训练即进行分类。</p><p>现将所有数据都放在根节点，然后选择一个最优特征，按照这一个特征将训练数据集分割成子集，分配到各个子节点上，如果子集中有些节点没有被正确分类，那在这个子集中再选择最优特征，继续分割，直到所有的训练数据集都被正确分类，或者没有合适的特征未知，最后每个子集都被分到叶子节点上，就变成了一棵决策树。</p><p>但如果决策树对训练数据集有非常好的分类能力，在测试数据集上可能会出现过拟合，就需要对已经生成的决策树进行由下而上的剪枝，使树变得简单。</p><p>决策树算法主要包括3个步骤：</p><ol><li>特征选择，选择哪个特征进行划分才能使数据能够很好的分类。</li><li>决策树的生成</li><li>决策树的剪枝</li></ol><p>决策树学习常用的算法有：ID3，C4.5，CART</p><p>在特征选择上，ID3使用信息增益，C4.5使用信息增益比，CART使用基尼指数</p><p>首先了解一个概念：<strong>信息熵</strong></p><p>一个事情发生的概率越大，这个事情所携带的信息熵越小，熵表示随机变量不确定的程度。假设$X$是一个随机变量，它的取值有$x_1,…x_n$，每个取值的概率为$p_i$，也就是$P(X=x_i)=p_i$<br>那么随机变量$X$的熵为：</p><script type="math/tex; mode=display">H(X)=-\sum_{i=1}^{i=n}p_ilogp_i</script><p>这里的$log$可以以2为底，也可以以$e$为底<br>熵越大，随机变量的不确定性越大。</p><p>例如一个人告诉你明天太阳从东方升起，那这个人相当于说了句废话，这个话的信息熵为0。</p><p><strong>条件熵</strong></p><p>有2个随机变量$X,Y$，条件熵就是在$X$给定的情况下随机变量$Y$的熵</p><script type="math/tex; mode=display">P(Y|X)=\sum_{i=1}^{i=n}p_iH(Y|X=x_i)</script><p>$p_i表示X为x_i$的概率</p><h3><span id="371-基础树id3c45cart">3.7.1. 基础树(ID3/C4.5/CART)</span></h3><h4><span id="3711-id3">3.7.1.1. ID3</span></h4><p>ID3根据信息增益进行划分，信息增益表示得知$X$时使得类$Y$的不确定性减少的程度。</p><p>信息增益是用来选择特征的一个指标，信息增益越大，说明这个特征带的信息越多，即已知这个特征的值让类$Y$的不确定性减少的越多，该特征越重要。</p><p>信息增益=信息熵-条件熵</p><p>特征$A$对训练数据集$D$的信息增益为$g(D,A)$<br>$g(D,A)=H(D)-H(D|A)$<br>原来数据集的信息熵为$H(D)$，知道特征$A$后数据集的信息熵为$H(D|A)$，信息熵减少了$H(D)-H(D|A)$就是信息增益</p><p>例如相亲问题中，女生根据男生会不会写代码这个条件下，来决定见或者不见。<br>如果男方会写代码，女方就见。不会写代码，女方就不见。说明这个特征对结果很重要，让分类结果变得确定，因此“会不会写代码”这个特征的信息增益很大。0&lt;=信息增益的取值&lt;=1</p><p>不同的特征有不同的信息增益<br>对数据集（整个数据集/子集）计算每个特征的信息增益，选择信息增益最大的特征进行划分数据集。</p><p>ID3算法步骤：</p><ol><li>从根节点开始，计算所有特征的信息增益，选择信息增益最大的特征作为划分特征，将根节点数据集划分成n类，n为特征的取值数</li><li>对n个子树再次计算所有特征的信息增益，再次划分子树</li><li>直到该节点上所有样本都为同一类时，或没有特征可以选，或信息增益都很小时结束划分。</li></ol><p>注意：当根节点选择特征1作为划分特征时，在子树中计算所有特征的信息增益不包括特征</p><p>缺点：</p><ul><li>信息增益对取值数据较多的特征有多偏好。例如编号，每个人的编号都不一样，编号的取值很多，则编号的信息增益接近1，形成只有2层的决策树。虽然信息增益很大，但是对于数据集的分割却没有意义。</li><li>信息增益只能处理离散的特征，不能处理连续特征</li><li>只能处理分类问题，不能处理回归问题</li><li>对缺失值敏感</li></ul><h4><span id="3712-c45">3.7.1.2. C4.5</span></h4><p>C4.5根据信息增益比进行划分</p><p>为了解决ID3对取值多的特征偏好这一缺点，引入信息增益比。</p><p>特征$A$对训练数据集$D$的信息增益比$g_R(D,A)$<br>为信息增益$g(D,A)$与特征$A$的熵$H_A(D)$之比</p><script type="math/tex; mode=display">g_R(D,A)=\frac{g(D,A)}{H_A(D)}</script><p>信息增益比就是对取值很多的特征进行惩罚。举个例子，假设有100个样本，对这100个样本进行均分。如果特征1的取值有2个，则将样本分成50,50的子集。如果特征2的取值有4个，则将样本分成25,25,25,25的子集。可以看出特征的取值越多，就会生成越多的小子集。但是如果小子集越多的话，就会出现过拟合的问题。所以需要对这样的特征添加个惩罚项。这个特征的取值个数越多，惩罚越大。</p><script type="math/tex; mode=display">信息增益比=\frac{信息增益}{惩罚项}</script><p>ID3中如果一个特征取值取值越多，则信息增益越大，但是在C4.5中这个特征的惩罚项也就越大，就可以让信息增益比平衡。</p><ul><li><p>C4.5怎么处理特征的缺失值<br>分两步实现：<br>第一步，计算所有特征的信息增益或者信息增益率的时候，假设数据集一共10000个样本，特征A中缺失了5000个，则无视缺失值，在剩下的5000个特征中计算信息增益（或者信息增益率），最后乘以0.5，思想就是缺失值多的特征通过这种降低权重的方式来体现信息的缺失；</p><p>第二步，如果运气不好，正好这个A特征乘0.5之后得到的信息增益或者增益率还是最大的，那么就像西瓜书中提到的那样，存在缺失值的样板按照比例进入分裂之后的新的分支，假设根据特征A分裂得到两个新的分支，一个分支有2000个样本有2000个样本，一个分支有3000个样本，则按照比例2000个缺失值和3000个缺失值样本分别进入两个分支。<br>缺点：<br>虽然解决了特征取值多的问题，但是仍然有以下问题</p></li><li><p>需要计算信息增益，计算量大</p></li><li>只能处理分类问题，不能处理回归问题</li><li>对缺失值有处理</li></ul><h4><span id="3713-cart分类回归树">3.7.1.3. CART(分类回归树)</span></h4><p>Classification And Regression Tree</p><p>CART可以用来做回归和分类。如果用来做<strong>回归，需要生成回归树，用平方损失选择最优特征</strong>。如果用来做分类，需要生成<strong>分类树，根据基尼指数来选择最优特征</strong>。</p><p>训练数据集$D$的基尼指数为：<br>$Gini(D)=1-\sum_{k=1}^{K}(\frac{|C_k|}{|D|})^2$<br>$C_k$是$D$中属于第$k$类的样本子集<br>若是二分类，则可以简写为$Gini(D)=2p(1-p)$</p><p>如果要按照特征$A$来划分子集的话，需要先计算在特征$A$的条件下，集合$D$的基尼指数为：<br>$Gini(D,A)=\frac{|D_1|}{|D|}Gini(D_1)+\frac{|D_2|}{|D|}Gini(D_2)$<br>特征$A=a$将数据集$D$划分为$D_1和D_2$<br>基尼指数$Gini(D)$表示集合$D$的不确定性。基尼指数$Gini(D,A)$表示特征$A$分割后集合$D$的不确定性。基尼指数越大，集合的不确定性也越大。划分时选择基尼指数小的特征进行划分。</p><ul><li><p>分类树建立<br>如果数据集有4个特征，每个特征有3个取值，则需要计算每个特征每个取值的基尼指数，即$Gini(D,A1=1),Gini(D,A1=2),Gini(D,A1=3)$，在特征1的3个基尼指数中找一个最小的，然后再分别计算特征2,3,4的3个基尼指数，分别找到一个最小的，然后再比较这4个最小的基尼指数，再次找到一个最小的，假设为$Gini(D,A3=2)$，则将根节点按照特征3=2进行划分成2个子集，等于2的划分到一个子集中，不等于2的划分到一个子集中。</p></li><li><p>回归树建立<br><strong>与分类树使用Gini指数分割特征不同，分类树使用平方和误差来分割特征</strong>。比如特征A的按照阈值a1和按照阈值a2，分别将数据集D划分成D1和D2，计算D1的平方和误差、D2的平方和误差、D1+D2的平方和误差，让这3个值同时最小，然后选择使用a1还是a2</p></li><li><p>回归树和分类树的区别：<br>当CART建立好之后，在给定测试集做预测时，CART分类树采用叶子节点里概率最大的类别作为当前节点的预测类别。回归树输出不是类别，采用叶子节点的均值或者中位数来预测输出结果。</p></li><li><p>CART划分的树是二叉树，因此CART每次分类时会将这个特征的特征值分成两堆，划分成左子树和右子树。然后在子树中还会用到这个特征计算基尼指数，因此CART中特征会被重复利用。但是在ID3和C4.5中，选中一个特征后，会划分为多个子树，例如这个特征有5个取值，就会划分成5个子树，在下一层中就不会计算这个特征的信息增益和信息增益比，因此特征只计算一次。</p></li><li><p><strong>CART怎么处理缺失值</strong><br>首先计算所有特征的Gini，对于有缺失值的特征，只用有值的部分计算Gini，然后再乘上非缺失值占的比重。如果最终选择的最优特征恰好有缺失值，则选择其他代理特征，有2种情况：</p><p>1、首先，如果某个存在缺失值的特征恰好是当前的分裂增益最大的特征，那么我们需要遍历剩余的特征，剩余的特征中如果有也存在缺失值的特征，那么这些特征忽略，仅仅在完全没有缺失值的特征上进行选择，我们选择其中能够与最佳增益的缺失特征分裂之后增益最接近的特征进行分裂。</p><p>2、如果我们事先设置了一定的标准仅仅选择差异性在一定范围内的特征作为代理特征进行分裂而导致了没有特征和最佳缺失特征的差异性满足要求，或者所有特征都存在缺失值的情况下，缺失样本默认进入个数最大的叶子节点。</p><p>显然这种缺失值的处理方式的计算量是非常大的，我们需要遍历其它的特征来进行代理特征选择，这个在数据量很大的情况下开销太大，而带来的性能提升确很有限，所以后来就不怎么用这种处理方式，xgb和lgb中就是直接将缺失值划分到增益大的节点里，这样在处理上要快速的多，而且在gbm的框架下一点点的误差其实影响不大。</p></li><li><p>可以处理连续值，因此既可以分类，也可以回归。</p></li><li>对缺失值有处理</li></ul><h4><span id="3714-总结">3.7.1.4. 总结</span></h4><p>ID3：信息增益<br>C4.5：信息增益比<br>CART：最小基尼指数</p><p>以上3个指标都是描述特征的。</p><p>以上三种方法都是对数据划分的方法，通过选择特征将数据划分为更小的子集。</p><p>ID3选择信息增益大的特征来划分，但是会偏好特征取值多的特征，引入C4.5，使用信息增益比，对取值多的特征添加惩罚项。但是以上2种方法都只能处理分类问题，后来引入CART，计算基尼指数，选择基尼指数最小的特征进行划分。</p><p><img src="/2020/06/19/百面机器学习概述/决策树.jpg" alt=""></p><h3><span id="372-树的剪枝">3.7.2. 树的剪枝</span></h3><p>一棵完全生长的决策树会出现过拟合的问题。例如如果按照“编号”进行划分树，则每个节点只包含1个样本，在测试集上的效果将会很差，出现过拟合现象。为了解决这个问题，对决策树进行剪枝，减掉一些枝叶。剪枝方法有2种方式：预剪枝、后剪枝</p><p>决策树的剪枝往往通过极小化决策树损失函数来实现。设决策树$T$中叶子节点个数为$|T|$，$t$为树$T$的叶子节点，每个叶子节点上有$N_t$个样本，这$N_t$个样本中，真实属于第$k$类样本有$N_{tk}$个</p><p>$C(T)=\sum_{t=1}^{t=T}N_tH_t(T)+\alpha|T|$<br>$H_t(T)=\sum_{k}\frac{N_{tk}}{N_t}log\frac{N_{tk}}{N_t}$<br>即所有叶子节点的样本数*该节点的信息熵+正则化</p><p>$\alpha|T|$是正则项，用来控制决策树的复杂程度，防止过拟合。</p><p>剪枝就是在$\alpha$确定时，最小化损失函数。可以看出决策树生成只考虑了提高信息增益或信息增益比来对训练数据更好的拟合，而决策树剪枝通过优化损失函数还考虑了树的复杂程度。决策树生成只考虑局部信息，决策树剪枝考虑全局信息。</p><ul><li><p>预剪枝<br>在生成决策树的时候进行剪枝。在按照某个特征划分之前，先计算当前的划分是否能够带来模型泛化性能的提升，如果不能，则不再生成子树。此时该节点中包含的样本可能属于不同的类别，按照多数投票的原则，将该节点判为多数类别。怎么判断不再划分树：</p><ol><li>当树的深度达到一定深度</li><li>当节点样本个数小于某个阈值</li><li><p>计算每次分裂对测试集的准确率是否提升，当提升小于某个阈值时，停止划分</p><p>缺点：<br>可能会出现欠拟合的问题，应为当前划分可能造成准确率变小，但是可能后续会让准确率变大，但是树的划分已经止步于此了。</p></li></ol></li><li><p>后剪枝<br>先生成一个完整的决策树，然后自底向上的进行剪枝。通过比较在损失函数，如果剪枝后损失函数更小，则剪枝该子树。<br>后剪枝的欠拟合风险很小，泛化能力优于预剪枝，但是开销比较大。</p></li></ul><h2><span id="38-k近邻knn">3.8. K近邻(KNN)</span></h2><h3><span id="381-knn原理">3.8.1. KNN原理</span></h3><p>KNN是一种监督学习方法，一种基本的分类和回归模型。<br>KNN思想：给定一个训练集，其中的样本类别已确定，然后给定<strong>测试样本</strong>，基于某种距离度量在训练集中找出与其最靠近的k个样本，然后基于这k个训练集邻居，对测试集进行预测。通常在决策时：</p><ul><li>分类问题：k个邻居中出现最多的类别作为测试样本的类别</li><li>回归问题中，使用k个邻居的平均作为训练样本的值</li></ul><p>K近邻学习的特点是：没有显示的训练过程，属于懒惰学习。在训练阶段仅仅将样本保存起来，训练时间为0，等到有测试样本时才开始处理。</p><p>KNN的三个主要问题：</p><ul><li>K的选择</li><li>选择哪种距离度量方式</li><li>使用哪种决策手段：（1）多数投票，（2）加权投票，即距离近的样本权重大</li></ul><p><strong>K的选择</strong></p><p>如果选择较小的k，就相当于用较少的邻居来预测，如果邻居是噪声，预测就会出错。较小的k会让模型变得复杂，容易出现过拟合。</p><p>如果选择较大的k，邻居变多，与测试集较远的样本也会影响预测效果，使预测发生UC哦呜。较大的k会让模型变得简单。</p><p>在应用中，k一般取比较小的数值，通常采用交叉验证来选择最优的k</p><p><strong>距离度量方式</strong></p><ol><li>欧氏距离</li><li>曼哈顿距离</li></ol><p><strong>分类决策</strong></p><ol><li>多数投票</li><li>加权投票</li></ol><p><img src="/2020/06/19/百面机器学习概述/knn1.png" alt=""></p><p>KNN的优点：</p><ol><li>思想简单</li><li>可分类，也可回归</li><li>可用于非线性分类</li><li>训练时间段，仅为O(n)</li><li>对异常点不敏感</li><li></li></ol><p>KNN的缺点：</p><ol><li>计算量大</li><li>样本不均衡时，对稀有类别的预测准确率低</li><li>相比决策树，KNN解释性不强</li></ol><h3><span id="382-kd树">3.8.2. KD树</span></h3><p>当训练样本特别大或样本维度特别大时，测试样本需要计算与每个训练样本的距离，然后排序找出前k个样本，时间复杂度大。</p><p>为了提高k近邻搜索的效率，可以通过减少N值，即在计算距离时，不用计算与所有训练样本的距离，只计算一部分，其中一个应用就是KD树。</p><p>KD树算法分为2步：构造KD树、搜索KD树</p><ol><li>构造KD树<br>KD树是对训练集进行存储，以便快速查询。假设训练样本有k维，KD数是二叉树，对k维空间的一个划分，KD树相当于不断地用垂直于坐标轴的超平面将k维空间切分。样本有k维特征，先找出第1维的特征值，找出其中的中位数，超平面经过该样本点将空间划分为左右2部分，然后在左右区域中，再根据第2维特征的中位数划分。然后再根据第3维特征的中位数划分。重复以上操作，知道空间中只包含1个样本点。如果有6个样本，中位数取右中位数。</li></ol><p><strong>常见问题</strong></p><ol><li><p>不平衡的样本给KNN造成什么影响，怎么解决</p><p><img src="/2020/06/19/百面机器学习概述/knn2.png" alt=""><br>l<br>例如上图中样本点y直观上看属于红色类别。但是使用KNN预测时，由于蓝色样本比较多，所以在k个邻居中蓝色点也占多数，导致y分类错误。<br>为了解决以上问题，可以采用加权投票的方式，与测试样本点距离小的样本权重大。</p></li><li>为了解决KNN算法计算量过大的问题，可以使用分组的方式进行计算，简述一下原理<br>先将样本按照距离分组，获得每个组的中心。给定一个测试样本，找出与其最近的那个簇，在这个簇上进行KNN。</li><li><p>KD树在对维度进行划分时，划分顺序是否可以优化？<br>可以先求每一维的方差，方差大说明数据越分散，可以获得比较好的划分效果。</p></li><li><p>KD树在划分时，需要找某个特征上的中位数，计算量大，怎么优化<br>在构建KD树之前，对每一维进行排序，在之后的划分中，直接使用。</p></li></ol><h1><span id="4-聚类">4. 聚类</span></h1><p>聚类是无监督学习，即不知道样本的标签。</p><h2><span id="41-k-means聚类">4.1. K-Means聚类</span></h2><p>K-Means聚类的目标函数为：最小化平方误差和，即SSE</p><script type="math/tex; mode=display">SSE=\sum_{i=1}^{k}\sum_{p \in C_i}|p-m_i|^2</script><p>$m_i$表示第$i$个簇的中心，使得每个样本点到中心的距离之间最小</p><p><strong>算法步骤:</strong></p><ol><li>数据预处理，如归一化，离群点处理等</li><li>随机选k个点，作为聚类中心。这k个点不一定是样本点，可以是任意一点</li><li>计算每个点到k个聚类中心的距离，然后将这个点分到最近的类中</li><li>重新计算每个簇的中心（簇中心为所有点的均值）</li><li>重复2~4，直到聚类中心不再发生改变或达到迭代次数</li></ol><ol><li><p><strong>K-Means常用的距离度量有哪些</strong></p><ul><li>曼哈顿距离<br>$d12=|x_1-x_2|+|y_1-y_2|$ </li><li>欧式距离<br>$d12=\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}$<br>欧式距离体现2个向量距离上的绝对差异</li><li>余弦相似度<br>$con(A,B)=\frac{AB}{||A||*||B||}$<br>相比欧式距离，余弦距离更关注2个向量在方向上的相对差异。2个向量方向越接近，越可能被聚为一类。</li></ul></li><li><p><strong>K-Means中k如何选择</strong></p><ul><li>根据场景选择</li><li>手肘法<br>计算指标SSE（误差平方和）<script type="math/tex; mode=display">SSE=\sum_{i=1}^{k}\sum_{p \in C_i}|p-m_i|^2</script>一共有k个簇，$C_i$为第$i$个簇，$p$是第$i$个簇的样本，$m_i$是第$i$第个簇的中心。$SSE$表示所有样本的误差平方和，表示聚类结果的好坏。核心思想：随着$k$的增大，每个簇中的样本越来越小，那每个簇越聚集，所有样本点的误差平方和$SSE$逐渐变小。假设理想情况下聚成$k’$类。我们从小到大遍历$k$，当$k&lt;k’$时，随着$k$的增加每个簇的聚合程度会迅速增加，那$SSE$会大幅度下降。当$k=k’$时，接下来再增加$k$，$SSE$下降的幅度会变小，此时不同的$k$和$SSE$的关系图就像手肘的形状。例如下图所示，手肘位置所对应的$k$就是最佳的$k$值。</li></ul><p><img src="/2020/06/19/百面机器学习概述/kmeans1.png" alt=""></p><ul><li>轮廓系数法<br>首先求一个样本点的轮廓系数，然后将所有点的轮廓系数求平均得到整个样本的轮廓系数。<br>怎么求一个样本的轮廓系数？<br>$S_i=\frac{b-a}{max(a,b)}$<br>$a$表示样本$x_i$与相同簇的样本的平均距离。$b$为样本$x_i$与最近簇中样本的平均距离。 因此$a$表示簇内的聚合程度，$b$表示簇间的分离程度。下图中显示了$x_i$的轮廓系数计算方法。平均轮廓系数范围[-1,1]，轮廓系数越大，聚类效果越好，说明簇内越紧密(a越小)，簇间越分离(b越大)。</li></ul><p><img src="/2020/06/19/百面机器学习概述/kmeans2.png" alt=""></p><p> 从小到大遍历$k$，然后计算所有样本的平均轮廓系数，找出最大轮廓系数对应的$k$.下图给出$k$与轮廓系数的关系：</p><p> <img src="/2020/06/19/百面机器学习概述/kmeans3.png" alt=""></p><p> 可以看出$k=2$时聚类效果最好。但是$K=2$时SSE却不是最小的，SSE依然很大。猜测是因为：SSE大说明样本间的误差很大。轮廓系数大说明不一定是$a$小，也有可能是$a$很大，但是$b$更大，导致SSE就很大。所以在选择$k$时需要同时看轮廓法和SSE法。</p></li></ol><ul><li><strong>确定了k，k个初始点怎么选</strong><br>（1）则k个初始点要尽可能远<br>（2）可以先对数据进行层次聚类，将层次聚类得到的k个聚类中心作为k-means的初始聚类中心</li><li><strong>K-Means怎么处理超大数据量的聚类</strong><br>K-Means在大数据量时，因为需要计算每个点到质心的距离，非常耗时。一种解决方案是Mini Batch K-Means小批量K-Means，即在计算距离时不必计算所有的样本点，而是从不同类别的样本中抽出一部分计算。这种方法会减少运行时间，但是会造成准确度下降。<br>步骤：<br>（1）给出k个初始质心<br>（2）从每个簇中选出一部分样本计算与k个质心的距离，分到最近的那个簇中<br>（3）根据小批量样本计算新的质心<br>（4）重复2~4，直到质心不再变化或迭代达到上界</li><li><p><strong>K-Means之前需要对数据标准化吗</strong><br>需要，K-Means是建立在距离度量上，如果维度之间的数据量差别太大，则在计算距离时会造成数值大的特征影响特别大。</p></li><li><p>优点<br>（1）原理简单，易于实现<br>（2）可解释强<br>缺点：<br>（1）容易受初始中心的影响，可能会陷入局部最优<br>（2）由于随机初始化中心点，聚类的结果不稳定<br>（3）k的选取会影响聚类结果<br>（4）对噪声和异常点敏感<br>（5）不适合环形数据，适用与球状数据<br>（6）时间复杂度大O(Nkt),N是样本个数，k是簇个数，t是迭代次数，不适用于大数据量</p></li></ul><p>K-Means手写代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randomCenter</span><span class="params">(samples,k)</span>:</span></span><br><span class="line">    <span class="string">"""根据samples随机生成k个簇中心</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        samples (array): 待分类数据集</span></span><br><span class="line"><span class="string">        k (int): 聚类个数</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        [array]: shape (K,n)随机生成的簇中心</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment">#将随机范围控制在样本的分布范围内</span></span><br><span class="line">    m,n = samples.shape</span><br><span class="line">    centers = np.mat(np.zeros((k,n)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):<span class="comment">#遍历每一个特征</span></span><br><span class="line">        max_i = np.max(samples[:,i])</span><br><span class="line">        min_i = np.min(samples[:,i])</span><br><span class="line">        range_i = max_i - min_i</span><br><span class="line">        <span class="comment">#生成K行1列的特征值，random 返回随机的浮点数，在半开区间 [0.0, 1.0)</span></span><br><span class="line">        centers[:,i] = np.mat(min_i+range_i*np.random((k,<span class="number">1</span>)))</span><br><span class="line">    <span class="keyword">return</span> centers</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calDistance</span><span class="params">(vecA,vecB)</span>:</span></span><br><span class="line">    <span class="string">"""计算2个向量的欧式距离</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        vecA (array): shape:(n,)</span></span><br><span class="line"><span class="string">        vecB (array): shape:(n,)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        [float]: 2个向量的欧式距离</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> np.sqrt(np.sum(np.square(vecA-vecB)))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">KMeans</span><span class="params">(dataset,K)</span>:</span></span><br><span class="line">    <span class="string">"""对dataset聚成K类</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dataset (np.array): 待聚类数据集</span></span><br><span class="line"><span class="string">        K (int): 聚类个数</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        [tupe]: 输出K个簇中心，输出(m个样本属于哪个簇，m个样本到簇重新的距离)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment">#m：样本个数，n：特征个数</span></span><br><span class="line">    m,n = dataset.shape</span><br><span class="line">    <span class="comment">#返回结果一共2维，表示样本所属类别、到簇中心的距离</span></span><br><span class="line">    res = np.zeros((m,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">    centers = randomCenter(dataset,K)</span><br><span class="line">    clusterChange = <span class="keyword">True</span><span class="comment">#当簇中心不再变化时，停止迭代</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> clusterChange:</span><br><span class="line">        clusterChange = <span class="keyword">False</span></span><br><span class="line">        <span class="comment">#遍历所有样本</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            min_distance = float(<span class="string">'inf'</span>)<span class="comment">#当前样本距离簇的最小欧式距离</span></span><br><span class="line">            min_cluster = <span class="number">-1</span><span class="comment">#当前样本所属的簇下标</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(k):<span class="comment">#遍历K个簇</span></span><br><span class="line">                <span class="comment">#计算当前样本到K个簇中心的距离</span></span><br><span class="line">                dis = calDistance(dataset[i,:],centers[j,:])</span><br><span class="line">                <span class="keyword">if</span> dis &lt; min_distance:</span><br><span class="line">                    min_distance = dis</span><br><span class="line">                    min_cluster = j</span><br><span class="line">            <span class="keyword">if</span> res[i,<span class="number">0</span>] != min_cluster:<span class="comment">#如果样本i所属类别改变</span></span><br><span class="line">                clusterChange = <span class="keyword">True</span></span><br><span class="line">            <span class="comment">#更新样本i的聚类结果</span></span><br><span class="line">            res[i,:] = min_cluster,min_distance</span><br><span class="line"></span><br><span class="line">        <span class="comment">#更新簇中心</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(K):</span><br><span class="line">            <span class="comment">#找出属于第i个簇的样本,(z,n)</span></span><br><span class="line">            i_samples = dataset[np.nonzero(res[:,<span class="number">0</span>]==i)[<span class="number">0</span>]]</span><br><span class="line">            centers[i,:]=np.mean(i_samples,axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> centers,res</span><br></pre></td></tr></table></figure><h2><span id="42-k-means的优化">4.2. K-Means的优化</span></h2><p>K-Means的优化有以下几方面：</p><ol><li>数据归一化和离群点处理<br>K-Means是基于距离度量的，聚类之前如果没有归一化，则距离由那些数值大的特征控制，所以需要将数据集归一化到统一量纲。同时离群点和噪声也会对均值产生较大的影响，导致质心偏离，因此需要对数据做预处理。</li><li>选择合适K值<br>手肘法画出不同的K和SSE的关系图，但是这种方法不够自动化，可以采用Gap Statistic法</li><li>采用核函数<br>K-Means要求数据是球状数据，但是实际情况中并不常见。面对非凸的数据分布，需要适用核函数优化，将样本映射到高维空间，在高维空间进行聚类。</li></ol><h3><span id="421-k-means">4.2.1. K-Means++</span></h3><p>K-Means++是K-Means的优化模型，用来改进初始化中心的选择。原始K-Means随机选择k个点作为聚类中心。K-Means++的核心思想是：初始的聚类中心之间的相互距离要尽可能的远。K-Means++采用如下方式选取K个中心点：首先随机选第1个中心点，然后选择和第1个中心点距离最远的点作为2个中心点。在选择第3个中心时，计算每个样本点和最近的中心的距离（中心1或中心2），然后选择距离最大的点作为第3个中心点。以此类推，直到找到k个中心点。</p><h3><span id="422-isodata">4.2.2. ISODATA</span></h3><p>用来确定K值。ISODATA思想很简单：当属于某个类别的样本过少时，删除该类别。当属于某个类别的样本过多时，将该类别分成2个子类别。ISODATA的缺点是指定参数比较多。下面介绍什么时候分裂，什么时候合并</p><ul><li>当2个簇的中心距离小于某个阈值时，合并这2个簇</li><li>当1个簇的方差大于某个阈值时，说明这个簇已经很分散了，将这个簇分成2个簇</li><li>当一个簇中样本个数少于某个阈值时，不再分裂该簇。</li></ul><h2><span id="43-聚类评价指标">4.3. 聚类评价指标</span></h2><ol><li>SSE误差平方和<script type="math/tex; mode=display">SSE=\sum_{i=1}^{k}\sum_{p \in C_i}|p-m_i|^2</script>计算每个样本点与簇中心的距离，SSE越小，聚类效果越好。但是SSE值考虑簇内的紧密程度，没有考虑簇间的分离程度</li><li>轮廓系数<br>描述簇内的聚合程度和簇间的分离程度。<br>$s_i=\frac{b-a}{max(b,a)}$<br>表示样本$x_i$的轮廓系数，每个样本点都计算一次轮廓系数。$a$表示样本$x_i$与本簇其他样本的平均距离，表示簇内聚合程度；$b$是$x_i$与最近的簇中所有样本点的平均距离，表示簇间分离程度。$a$越小，$b$越大，说明聚类效果越好。所有样本点都有一个轮廓系数，将其求平均，得到当前聚类的平均轮廓系数。</li><li>R方<script type="math/tex; mode=display">RS=\frac{\sum_{x \in D}||x-c||^2-\sum_{i}\sum_{x \in C_i}||x-c_i||^2}{\sum_{x \in D}||x-c||^2}</script>其中$D$表示所有样本，$c$表示所有样本的中心点。$\sum_{x \in D}||x-c||^2$表示将所有样本作为1个簇，计算所有样本点与中心点的平方误差和，然后对样本进行聚类，$\sum_{i}\sum_{x \in C_i}||x-c_i||^2$表示聚类之后的样本误差和。$RS$表示聚类之后的结果和聚类之前的结果相比，平方误差和的改进幅度。</li></ol><h1><span id="5-贝叶斯分类">5. 贝叶斯分类</span></h1><h2><span id="51-朴素贝叶斯分类器">5.1. 朴素贝叶斯分类器</span></h2><p>先明确几个概念：<br><strong>先验概率</strong>：P(瓜熟)<br><strong>似然</strong>：P(瓜蒂脱落|瓜熟)<br><strong>后验概率</strong>：P(瓜熟|瓜蒂脱落)<br><strong>联合概率</strong>：P(瓜熟，瓜蒂脱落)<br><strong>全概率公式</strong>：P(瓜蒂脱落)=P(瓜蒂脱落|瓜熟)P(瓜熟)+P(瓜蒂脱落|瓜生)P(瓜生)</p><p><strong>贝叶斯定理</strong></p><script type="math/tex; mode=display">P(A|B)=\frac{P(AB)}{P(B)}=\frac{P(B|A)P(A)}{P(B)}</script><p>贝叶斯定理打通了从$P(B|A)$到$P(A|B)$的道路。</p><p>如果有多个特征，并且多个特征之间相互独立，就是朴素贝叶斯分类器。<br>例如瓜蒂：脱落/未脱，形状：圆尖，颜色：深绿/浅绿/青。已知10个样本如下图所示，现在有一个瓜瓜蒂脱落，形状圆，颜色青色，判断这个瓜是生还是熟。</p><p><img src="/2020/06/19/百面机器学习概述/贝叶斯1.png" alt=""></p><p><strong>这个问题就是朴素贝叶斯分类器：有一些已知样本，样本有n个特征，这n个特征之间相互独立，现在给一个测试样本，知道测试样本这n个特征的值，判断这个测试样本属于哪一类。就需要计算这个样本属于每一类的概率，然后取概率最大的那一类作为测试样本最终的类别。朴素贝叶斯是基于贝叶斯定理和特征条件独立的分类方法。</strong></p><p>问题的关键是：怎么计算测试样本属于每一类的概率？</p><script type="math/tex; mode=display">P(y_i|x)=\frac{P(x|y_i)P(y_i)}{P(x)}</script><p>对于每一类来说分母是一样的，只需要在不同的$y_i$中比较分子哪个大就可以了。由于所有的特征相互独立，所以有下式成立：</p><p>$P(x|y_i)P(y_i)=P(x_1|y_i)P(x_2|y_i)…P(x_n|y_i)P(y_i)$</p><p>由于$P(x_i|y)$也称为“似然”，所以朴素贝叶斯分类器常常和最大化似然联系在一起。</p><p>朴素贝叶斯分类的流程如下图所示：</p><p><img src="/2020/06/19/百面机器学习概述/贝叶斯2.png" alt=""></p><p>朴素贝叶斯分类器有3个阶段：</p><ol><li>准备工作阶段：获取训练数据</li><li>分类器训练阶段：这里并不是真正的训练，只是求先验概率和条件概率，为后续的分类做准备</li><li>分类阶段：给定测试样本，对其进行分类。</li></ol><p>朴素贝叶斯的优点</p><ol><li>算法简单，坚实的数学基础</li><li>在小规模数据上表现好</li><li>能处理多分类任务</li><li>适用于文本分类任务</li></ol><p>朴素贝叶斯的缺点：</p><ol><li>实际应用中，特征往往不是相互独立</li><li>对输入数据的格式很敏感（离散、连续）</li><li>需要知道先验概率，但先验概率很多时候是基于假设的，会造成分类错误</li></ol><p>常见问题</p><ol><li><strong>为什么要引入特征条件独立假设</strong><br>为了避免贝叶斯定理求解时面临的组合爆炸的问题。<br>$P(x|y_i)=P(x_1,x_2,…x_n|y_i)$<br>$x_1,…x_n$表示n个特征，每个特征$s_i$个，$y$的取值有$k$个，则参数个数有$k\prod s_i$，导致条件概率分布的参数数量为指数级别。</li></ol><ul><li><strong>在估计条件概率$P(X|Y)$时出现概率为0怎么办？</strong><br>例如在计算<script type="math/tex; mode=display">P(瓜熟|脱落，圆形，浅绿)=\frac{P(脱落|瓜熟)P(圆形|瓜熟)P(浅绿|瓜熟)P(瓜熟)}{P(脱落，圆形，浅绿)}</script>的概率时，如果$P(浅绿|瓜熟)=0$,这样会造成分子为0，即使其他属性看起来是瓜熟，分类结果都是瓜熟的概率为0。为了避免这一情况，通常使用拉普拉斯修正，在分子分母上加上一个值，避免出现为0的情况<br>修改先验概率公式为：<br>$P(瓜熟)=\frac{瓜熟个数+1}{所有样本+N}$<br>$N$表示类别个数，这里只有2个类别：瓜熟和瓜生，所以N=2<br>修改条件概率公式为：<br>$P(浅绿|瓜熟)=\frac{浅绿且瓜熟个数+1}{瓜熟个数+N_i}$<br>$N_i$表示属性颜色的取值个数，例如这里颜色一共有三个取值：浅绿，深绿，青色，所以$N_i=3$<br>总结一下就是不管是先验概率还是条件概率在分子上都是加1，分母上，先验概率加类别个数，条件概率加属性取值个数。拉普拉斯平滑作用在所有的先验概率和条件概率上，并不是只有为0的概率上。</li><li><strong>朴素贝叶斯分类器和逻辑回归的区别</strong><ol><li>朴素贝叶斯分类器是生成模型，需要先计算出先验概率和联合概率。逻辑回归是判别式模型，直接求出条件概率。</li><li>朴素贝叶斯分类器基于条件独立假设，逻辑回归没有此要求</li><li>朴素贝叶斯适用于数据量少的情景，逻辑回归适用于大规模数据集。</li></ol></li><li><p><strong>在贝叶斯定理中，由于特征相互独立，所以会出现连乘的情况，由于概率值很小，连乘之后趋向于0，怎么解决？</strong><br>对乘积取对数，将连乘变成连加：对每个条件概率取对数$P(x_i|y)$，然后再把所有的对数相加</p></li><li><p><strong>朴素贝叶斯要求特征相互独立，但很多时候并不满足，为什么朴素贝叶斯仍然取得不错的效果？</strong><br>对于分类任务来说，只要各个条件概率的大小排序相对正确，就可以通过比较大小找到正确的类别，并不需要准确的概率值，因为朴素贝叶斯是找后验概率最大的类，不需要知道精确概率值。</p></li><li><p><strong>朴素贝叶斯有没有超参数</strong><br>没有</p></li><li><strong>朴素贝叶斯分类器的应用</strong><br>朴素贝叶斯分类器广泛应用在文本分类上，例如垃圾邮件分类，情感分类等</li><li><strong>朴素贝叶斯分类器对异常值敏感吗</strong><br>对异常值不敏感。所以在数据处理时，不用去除异常值。</li></ul><h2><span id="52-半朴素贝叶斯分类器">5.2. 半朴素贝叶斯分类器</span></h2><p>朴素贝叶斯分类器假设属性条件相互独立，但在实际情况中往往不满足这个假设，于是尝试对这个假设进行放松，生成“半朴素贝叶斯分类器”。<br>在贝叶斯定理中，朴素贝叶斯分类器计算分子公式为</p><script type="math/tex; mode=display">P(x|y)=P(y)P(x_1|y)P(x_2|y)...P(x_n|y)</script><p>半朴素分类器的基本思想是考虑一部分属性之间的关系，并不是完全独立的。半朴素贝叶斯分类器采用“独依赖估计”策略，即每个属性除了类别之外，最多依赖1个其他属性，因此在计算分子时，变成:</p><script type="math/tex; mode=display">P(x|y)=P(y)P(x_1|y,x_j)P(x_2|y,x_j)...P(x_n|y,x_j)</script><p>这里将每个属性依赖的那个属性称为”父属性”。如果知道每个属性的父属性，可以直接计算上述公式，但如果不知道，问题就转化为怎么确定每个属性的父属性，不同的做法产生不同的独依赖分类器（One-Dependent Estimator ODE）。</p><p>最直接的做法是所有的属性都依赖同一个父属性，叫做超父ODE（SPODE）</p><p>还有一种是计算任意2个属性的相关性，为每个属性选择最大相关性的那个属性作为父属性（TAN ODE）</p><h1><span id="6-生成模型和判别模型">6. 生成模型和判别模型</span></h1><p>生成模型是由训练数据学习联合概率$P(X,Y)$，然后求得后验 概率分布$P(Y|X)$，选择后验概率大的那个类作为$X$所属的类。因为对于生成模型，必然要考虑</p><script type="math/tex; mode=display">P(Y|X)=\frac{P(X,Y)}{P(X)}</script><p>判别模式是直接求$P(Y|X)$。</p><p>生成模型：朴素贝叶斯分类器、贝叶斯网络、隐马尔科夫模型</p><p>判别模型：决策树、SVM、神经网络</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;总结《百面机器学习》有关知识点。&lt;/p&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://yoursite.com/categories/Machine-Learning/"/>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>How to Build a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey</title>
    <link href="http://yoursite.com/2020/06/02/How-to-Build-a-Graph-Based-Deep-Learning-Architecture-in-Traffic-Domain-A-Survey/"/>
    <id>http://yoursite.com/2020/06/02/How-to-Build-a-Graph-Based-Deep-Learning-Architecture-in-Traffic-Domain-A-Survey/</id>
    <published>2020-06-02T01:41:59.000Z</published>
    <updated>2020-06-18T02:33:30.602Z</updated>
    
    <content type="html"><![CDATA[<p>这篇综述性论文介绍图神经网络在交通领域的应用。</p><a id="more"></a><!-- TOC --><ul><li><a href="#1-摘要">1. 摘要</a></li><li><a href="#2-前言">2. 前言</a></li><li><a href="#3-研究方向">3. 研究方向</a></li><li><a href="#4-问题定义">4. 问题定义</a><ul><li><a href="#41-构建图">4.1. 构建图</a></li><li><a href="#42-构造邻接矩阵">4.2. 构造邻接矩阵</a></li></ul></li><li><a href="#5-前人的模型">5. 前人的模型</a><ul><li><a href="#51-gnn">5.1. GNN</a></li><li><a href="#52-rnn">5.2. RNN</a></li><li><a href="#53-tcn">5.3. TCN</a></li><li><a href="#54-seq2seq">5.4. Seq2Seq</a></li><li><a href="#55-gan">5.5. GAN</a></li></ul></li><li><a href="#6-挑战">6. 挑战</a><ul><li><a href="#61-空间依赖">6.1. 空间依赖</a></li><li><a href="#62-时间依赖">6.2. 时间依赖</a></li><li><a href="#63-时空依赖">6.3. 时空依赖</a></li><li><a href="#64-外部因素">6.4. 外部因素</a></li></ul></li><li><a href="#7-未来方向">7. 未来方向</a></li></ul><!-- /TOC --><h1><span id="1-摘要">1. 摘要</span></h1><p>在交通数据中，有很多数据以图的形式存在，为了充分利用其中的空间信息，很多模型使用图神经网络来处理交通图数据。本文针对交通领域的图网络模型进行总结。</p><h1><span id="2-前言">2. 前言</span></h1><p>在交通预测领域，（1）早期采用的方法有：ARIMA,VAR,Kalman过滤器等，然而，这些方法通常需要一些前提假设，例如数据是静态且线性相关，不能应用在实际数据中。（2）机器学习方法例如SVM，K近邻可以建模交通数据中的非线性相关性，但是模型结构较浅，且需要人工构造和选择特征，不能满足大量交通数据的应用需求。（3）深度学习方法，例如RNN无法捕获空间相关性，CNN无法应用在图数据中，并且CNN更关注local相关性，忽略了global相关性。（4）图神经网络，使用图神经网络来解决交通领域的预测问题。<br>贡献总结如下：</p><ul><li>第一篇介绍图神经网络在交通领域应用的综述</li><li>系统地列出交通领域的研究方向和挑战</li><li>针对4种交通领域数据，介绍如何构建图</li><li>分析了5种应用在图交通领域的技术，介绍了它们的优缺点，以及变体</li><li>讨论了基于图网络的交通任务中4种常见的挑战，并总结对应的解决方案</li><li>收集数据集，开源代码</li></ul><h1><span id="3-研究方向">3. 研究方向</span></h1><p>给出了交通领域的一些研究问题<br><img src="/2020/06/02/How-to-Build-a-Graph-Based-Deep-Learning-Architecture-in-Traffic-Domain-A-Survey/1.png" alt=""></p><ol><li>交通拥堵</li><li>交通需求<br>出租车、自行车、公共交通的需求预测，像滴滴，Uber等线上打车平台经常做这一类问题。</li><li>交通安全<br>预测交通事故的风险，严重程度</li><li>交通监控<br>主要通过监控的图像和视频检测车辆，行人检测。</li><li>自动驾驶<br>自动驾驶要求检测树木，道路，行人，一般和CV领域相关。</li></ol><p>图神经网络在交通领域的应用</p><ol><li>交通状态预测<br>交通状态：交通流量、速度、时间ETA、密度等。</li><li>交通需求预测<br>预测将来用户对出租车、自行车的需求</li><li>交通信号预测<br>减低用户在交叉路口的等待时间，避免交通拥堵</li><li>司机行为分类</li></ol><p>交通事故预测还没有用到图模型。</p><h1><span id="4-问题定义">4. 问题定义</span></h1><p>基于图的交通预测问题，首先需要构件图G。</p><ul><li>图：无权图，有权图，无向图，有向图，取决于具体的任务。</li><li>节点：传感器sensor，路段，道路交叉口，GPS交叉点。</li><li>邻接矩阵A：非0即1，浮点数（表示2个节点的关系，例如相似性，距离）</li></ul><p>给定历史P个时间段所有节点的信息，维度是$\left[\mathcal{X}_{1}, \cdots, \mathcal{X}_{i}, \cdots, \mathcal{X}_{\mathbf{P}}\right] \in \mathbb{R}^{\mathbf{P} \times \mathbf{N} \times \mathbf{F}_{1}}$预测未来Q个时间段的$\mathcal{Y}=\left[\mathcal{Y}_{1}, \cdots, \mathcal{Y}_{j}, \cdots, \mathcal{Y}_{\mathrm{Q}}\right] \in \mathbb{R}^{\mathbf{Q} \times \mathbf{N} \times \mathrm{F}_{\mathrm{O}}}$</p><ul><li>预测的特征只有1个，即$F_O=1$，预测特征有多个，即$F_O&gt;1$</li><li>预测未来时间段只有1个，单步预测，即$Q=1$，预测未来时间段有多个，多步预测，即$Q&gt;1$</li><li>多步预测问题中，一般使用FC（将输出reshape成需要的维度，ASTGCN,T-GCN,），Seq2Seq（使用RNN循环输出预测结果,DCRNN,GMAN），空洞技术（WaveNet）</li></ul><h2><span id="41-构建图">4.1. 构建图</span></h2><p>在构建图时，一般使用3类数据：传感器，GPS轨迹，打车订单数据，</p><ol><li>传感器数据<br>最常用的加州PEMS数据，图中的每个节点表示一个传感器，同一条路上的传感器有边相连。</li><li>GPS数据<br>GPS轨迹数据，需要将GPS匹配到最近的路段上，以路段为节点创建图，或者以交叉路口为节点创建图。这里的图可以是有向，也可以无向。</li></ol><p><img src="/2020/06/02/How-to-Build-a-Graph-Based-Deep-Learning-Architecture-in-Traffic-Domain-A-Survey/3.png" alt="">  </p><ol><li>订单数据<br>将城市划分为网格，每个节点表示一个网格，边表示连通性。可以根据不同的特征来构件图，例如下图使用邻近区域、道路连通性、功能相似区域分别构建3个图。</li></ol><p><img src="/2020/06/02/How-to-Build-a-Graph-Based-Deep-Learning-Architecture-in-Traffic-Domain-A-Survey/4.png" alt="">  </p><ol><li>公共交通数据<ul><li>地铁图：每个地铁站表示一个节点，如果一条线上的2个地铁站相邻则有边。图信号矩阵是inflow和outflow</li><li>公交车图：每个公交站是一个节点，如果一条线上的2个公交站相邻则有边。图信号矩阵进站记录</li></ul></li></ol><h2><span id="42-构造邻接矩阵">4.2. 构造邻接矩阵</span></h2><ol><li>静态邻接矩阵<br>邻接矩阵不会随着时间变化。可以根据节点之间的特征构建多个邻接矩阵，例如功能相似，道路相通，时间相似。邻接矩阵中的值可以是非0即1，也可以表示节点间距离或者相似性。一般通过阈值来定义邻接矩阵，通过调整阈值来控制邻接矩阵的稀疏性。<script type="math/tex; mode=display">\mathbf{a}_{i j}=\left\{\begin{array}{l}\exp \left(-\frac{\mathbf{d}_{i j}^{2}}{\sigma^{2}}\right), i \neq j \text { and } \mathbf{d}_{i j} \geq \epsilon \\0 \quad, i=j \text { or } \mathbf{d}_{i j}<\epsilon\end{array}\right.</script></li></ol><ol><li>动态邻接矩阵<br>有2种情况：1. 邻接矩阵不随着时间变化，但是邻接矩阵不是预先定义好的，而是模型先动态学习节点嵌入，然后根据学习到的节点嵌入构造邻接矩阵。2. 邻接矩阵随着时间变化。</li></ol><h1><span id="5-前人的模型">5. 前人的模型</span></h1><p>分析图神经网络在交通领域的应用，发现GNN通常和其他组件一起用，类似RNN,Seq2Seq，TCN等。</p><h2><span id="51-gnn">5.1. GNN</span></h2><p>GNN在交通领域的应用主要有3个：谱图卷积for无向图，扩散卷积for有向图。</p><ol><li><p>谱图卷积</p><script type="math/tex; mode=display">\begin{aligned}Y_{j} &=\rho\left(\Theta_{j} *_{\mathcal{G}} X\right) \\&=\rho\left(\sum_{i=1}^{\mathbf{F}_{\mathrm{I}}} \theta_{i, j} \tilde{\mathbf{D}}^{-\frac{1}{2}} \tilde{\mathbf{A}} \tilde{\mathbf{D}}^{-\frac{1}{2}} X_{i}\right), 1 \leq j \leq \mathbf{F}_{\mathbf{O}} \\Y &=\rho\left(\tilde{\mathbf{D}}^{-\frac{1}{2}} \tilde{\mathbf{A}} \tilde{\mathbf{D}}^{-\frac{1}{2}} X W\right)\end{aligned}</script><p>谱图卷积要求对称的拉普拉斯矩阵，来实现特征值分解。</p></li><li><p>扩散卷积<br>谱图卷积要求对称的拉普拉斯矩阵，来实现特征值分解。但是对于有向图来说，拉普拉斯矩阵不是对称的。扩散卷积对图的结构，邻接矩阵，拉普拉斯矩阵没有任何限制。扩散卷积可以看做是转移矩阵的幂次，表示从节点i到节点j的转移概率。</p><script type="math/tex; mode=display">y=\Theta *_{\mathcal{G}} x=\sum_{k=0}^{\mathrm{K}-1}\left(\theta_{k, 1}\left(\mathrm{D}_{\mathrm{O}}^{-1} \mathrm{A}\right)^{k}+\theta_{k, 2}\left(\mathrm{D}_{\mathrm{I}}^{-1} \mathrm{A}^{T}\right)^{k}\right) x</script></li></ol><p>总结：谱图卷积和扩散卷积的不同：谱图卷积的邻接矩阵揭示中心节点和它直接邻近的节点更相关。而扩散卷积揭示空间依赖是随机且动态的。扩散卷积比谱图卷积更复杂。扩散卷积可以适用在任何交通网络上，而谱图卷积只能用在对称的图上，即无向图中。</p><p>有些工作在使用SGC和DGC使用以下tricks</p><ul><li>使用SGC时，引入attention机制<br>S表示图信号矩阵，使用切比雪夫多项式计算图卷积时，对S求attention，计算节点之间的影响程度。</li></ul><script type="math/tex; mode=display">\Theta *_{\mathcal{G}} x \approx \sum_{k=0}^{K-1} \theta_{k}\left(T_{k}(\tilde{\mathbf{L}}) \odot \mathbf{S}\right) x$$ $$\mathbf{S} = W_{1} \odot \rho\left(\left(X W_{2}\right) W_{3}(W_{4} X)^{T}+b\right) \in \mathbb{R}^{N \times N}</script><ul><li><p>直接使用邻接矩阵，FFR表示道路特征</p><script type="math/tex; mode=display">\Theta *_{\mathcal{G}} x=\left(W \odot \tilde{\mathbf{A}}^{\mathrm{K}} \odot \mathcal{F} \mathcal{F} \mathcal{R}\right) x</script></li><li><p>在邻接矩阵中引入地理位置信息</p><script type="math/tex; mode=display">\mathbf{S}=\mathbf{A} \odot \omega$$$$Y=\rho\left(\tilde{\mathbf{Q}}^{-\frac{1}{2}} \tilde{\mathbf{S}} \tilde{\mathbf{Q}}^{-\frac{1}{2}} X W\right)</script></li></ul><h2><span id="52-rnn">5.2. RNN</span></h2><p>交通任务预测中很多都是时间序列数据，适用RNN来捕获时间相关性。这里包括三类：RNN,LSTM,GRU</p><ul><li>RNN：输入层，隐藏层，输出层</li><li>LSTM：为了解决RNN的梯度消失和梯度爆炸问题，引入输入门，遗忘门，输出门。</li><li>GRU：LSTM结构复杂，参数更多，用更简单的GRU来代替，只有2个门：重置门</li></ul><p>在交通预测领域中，很少用RNN，大部分都是用GRU，少数用LSTM。在用GRU或LSTM时，有很多小tricks，例如attention，门控机制，残差机制。<br>在使用RNN所用到的tricks</p><ul><li>在RNN中引入空间信息<script type="math/tex; mode=display">\mathbf{H}_{t} = R N N\left(\left[\mathbf{H}_{t-1}, \mathbf{X}_{t}\right] \odot S\right)</script></li><li>引入外部因素<script type="math/tex; mode=display">\mathbf{H}_{t}=G R U\left(\left[\mathbf{H}_{t-1}, \mathbf{X}_{t}\right], \mathbf{E}_{t}\right)+\mathbf{H}_{t-1} W</script></li><li>使用空洞RNN<script type="math/tex; mode=display">\mathbf{H}_{t}=G R U\left(\mathbf{H}_{t-s}, \mathbf{X}_{t}\right)</script></li><li>RNN和图卷积结合<script type="math/tex; mode=display">\begin{aligned}r_{t} &=\sigma\left(\left[\mathbf{H}_{t-1}, \mathbf{X}_{t}\right] *_{\mathcal{G}} W_{r}+b_{r}\right) \\u_{t} &=\boldsymbol{\sigma}\left(\left[\mathbf{H}_{t-1}, \mathbf{X}_{t}\right] *_{\mathcal{G}} W_{u}+b_{u}\right) \\\tilde{\mathbf{H}}_{t} &=\tanh \left(r_{t} \odot\left[\mathbf{H}_{t-1}, \mathbf{X}_{t}\right] *_{\mathcal{G}} W_{h}+b_{h}\right) \\\mathbf{H}_{t} &=u_{t} \odot \mathbf{H}_{t-1}+\left(1-u_{t}\right) \odot \tilde{\mathbf{H}}_{t}\end{aligned}</script></li></ul><h2><span id="53-tcn">5.3. TCN</span></h2><p>虽然RNN可以捕获时间的相关性，但是其不能并行计算，耗时。与之对比，1D卷积运行更快，同样也可以捕获时间相关性。然后1D卷积与RNN相比应用更少，由于1D卷积缺少长期建模的memory机制。后来提出空洞卷积，在长期时间建模上，比RNN效果更好。之后，TCN被广泛应用在时间建模上。</p><p><img src="/2020/06/02/How-to-Build-a-Graph-Based-Deep-Learning-Architecture-in-Traffic-Domain-A-Survey/5.png" alt=""> </p><p>在使用TCN时，有一些小traick</p><ul><li><p>堆叠不同的TCN层，每层使用不同的dilation rate</p><script type="math/tex; mode=display">\mathcal{Y}^{(l+1)}=\sigma\left(\Theta^{l} *_{\mathcal{T} \mathrm{d}^{l}} \mathcal{Y}^{(l)}\right)</script></li><li><p>残差，原始输入+TCN的输出</p><script type="math/tex; mode=display">\mathcal{Y}^{(l+1)}=\mathcal{Y}^{(l)}+\boldsymbol{\operatorname { R e }} \boldsymbol{L} \boldsymbol{U}\left(\Theta_{1}^{l} *_{\mathcal{T}^{\mathrm{d}}}\left(\boldsymbol{\operatorname { R e }} \boldsymbol{L} \boldsymbol{U}\left(\Theta_{0}^{l} *_{\mathcal{T}^{\mathrm{d}}} \mathcal{Y}^{(l)}\right)\right)\right)</script></li><li><p>使用门控机制</p><script type="math/tex; mode=display">\mathcal{Y}=\rho\left(\Theta_{1} *_{\mathcal{T}^{\mathrm{d}}} \mathcal{X}+b_{1}\right) \odot \sigma\left(\Theta_{2} *_{\mathcal{T}^{\mathrm{d}}} \mathcal{X}+b_{2}\right)</script></li></ul><h2><span id="54-seq2seq">5.4. Seq2Seq</span></h2><p>原始的Seq2Seq模型为对输入进行建模，得到一个隐变量$C$,然后将$C$输入到解码器中，进行预测。</p><p><img src="/2020/06/02/How-to-Build-a-Graph-Based-Deep-Learning-Architecture-in-Traffic-Domain-A-Survey/6.png" alt=""> </p><p>对Seq2Seq的改进主要有2点：</p><ul><li><p>改变隐变量C<br>原先输入到decoder的C是固定的，对decoder中所有的时间步来说都一样，然后输入中的值对不同的输出影响程度不同，这里引入attention机制，动态改变C</p><script type="math/tex; mode=display">\begin{array}{l}\mathbf{H}_{i}=\operatorname{Encoder}\left(\mathbf{X}_{i}, \mathbf{H}_{i-1}\right) \\\mathbf{C}_{j}=\sum_{i=1}^{\mathbf{P}}\left(\theta_{j i} \mathbf{H}_{i}\right), \mathbf{S}_{0}=\mathbf{H}_{\mathbf{P}} \\\mathbf{S}_{j}=\operatorname{Decoder}\left(\mathbf{C}_{j}, \mathbf{Y}_{j-1}, \mathbf{S}_{j-1}\right) \\\mathbf{Y}_{j}=\mathbf{S}_{j} W\end{array}</script></li><li><p>采样<br>在decoder在训练阶段和测试阶段的输入是不同的。在训练阶段，decoder的不同时间步输入的真实的label，而在测试阶段，因为不知道label，输入的是上一个时间步预测的结果，这样可能会造成错误累积的问题。为了解决这个问题，可以在训练阶段进行采样，即并不总是输入真实的label，以$\epsilon_{j}$输入真实babel，以$1-\epsilon_{j}$输入上个时间步的预测结果。</p></li></ul><p>交通领域中的多步预测通常采用Seq2Seq架构。Seq2Seq中的encoder和decoder架构通常采用RNN，但是也不一定相同。</p><h2><span id="55-gan">5.5. GAN</span></h2><p>这一模块看的论文较少，以后补充</p><h1><span id="6-挑战">6. 挑战</span></h1><p>尽管交通领域有很多研究方向，但它们都有一些共同的挑战，如下所示，主要分为三类：空间依赖，时间依赖，外部因素。</p><p><img src="/2020/06/02/How-to-Build-a-Graph-Based-Deep-Learning-Architecture-in-Traffic-Domain-A-Survey/2.png" alt=""> </p><h2><span id="61-空间依赖">6.1. 空间依赖</span></h2><p>在一个双向的道路中，R1只受R2的影响，R3对R1的影响较小。如果采用网格的形式，R3和R2对R1的影响相同，这不符合实际。如果采用图的形式，R2对R1的影响较大，R3对R1的影响较小，符合实际。</p><p><img src="/2020/06/02/How-to-Build-a-Graph-Based-Deep-Learning-Architecture-in-Traffic-Domain-A-Survey/7.png" alt=""> </p><p>交通网络中空间依赖十分复杂，可以分成三类：空间局部性，多元关系，全局连通性。</p><ol><li>空间局部性<br>空间局部性表示邻近区域比较远的区域更相关。K阶局部谱图卷积SGCN可以聚合0~K-1跳的邻居信息。还有一些其他工作可以捕获空间局部相关性。比如动态计算邻接矩阵</li><li>多元关系<br>目标区域也可能与距离较远的区域相关。例如功能相似的区域，交通连通的区域。根据这些不同的相似性来创建不同的图。</li><li>全局连通性<br>以上2点更关注网络部分，而忽略了整体的结构。全局连通性表示不同区域的交通情况在整个网络上互相影响。使用扩散卷积、pooling层、self-adaptive邻接矩阵可以捕获到这种全局连通性。</li></ol><h2><span id="62-时间依赖">6.2. 时间依赖</span></h2><p>使用RNN或TCN来捕获时间依赖</p><ol><li>多粒度<br>时间有不同的周期性，例如recent，daily，weekly。</li><li>不同的权重<br>历史信息对目标时间段的影响权重不同。使用Attention机制计算权重分数。</li></ol><h2><span id="63-时空依赖">6.3. 时空依赖</span></h2><p>以上对时间和空间依赖分别建模，如果对时空依赖同时建模，预测效果可能会更好。例如STSGCN</p><h2><span id="64-外部因素">6.4. 外部因素</span></h2><p>天气（雨/温度/空气质量），时间（节假日/周几/几点），特殊时间，POI等信息都会影响交通预测。<br>对于外部因素的处理通常有2种方法：</p><ol><li>和其他因素拼接，输入到模型中</li><li>设计外部因素处理模块，对外部因素单独处理。通常是2个FCN，第一个FCN提取重要信息，第二个FCN从低维特征映射到高维特征</li></ol><h1><span id="7-未来方向">7. 未来方向</span></h1><ol><li>在司机行为分类，车辆/人们轨迹预测，交通事故预测使用图模型。</li><li>大多使用SGCN和DGCN，很少使用GAT,GAE,RNN+GCN，可以使用以上模型解决交通问题</li><li>交通问题大多是回归问题，很少有分类问题，可以使用图模型研究分类问题</li><li>现有模型对外部因素处理比较简单，可以设计更复杂的模型捕获外部因素信息。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇综述性论文介绍图神经网络在交通领域的应用。&lt;/p&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="时空领域" scheme="http://yoursite.com/tags/%E6%97%B6%E7%A9%BA%E9%A2%86%E5%9F%9F/"/>
    
  </entry>
  
  <entry>
    <title>图神经网络研讨会</title>
    <link href="http://yoursite.com/2020/03/29/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%A0%94%E8%AE%A8%E4%BC%9A/"/>
    <id>http://yoursite.com/2020/03/29/图神经网络研讨会/</id>
    <published>2020-03-29T05:40:52.000Z</published>
    <updated>2020-03-31T15:15:44.158Z</updated>
    
    <content type="html"><![CDATA[<p>在线图神经网络研讨会<br><a id="more"></a><br><img src="/2020/03/29/图神经网络研讨会/intro.png" alt=""></p><h1><span id="网络表示学习">网络表示学习</span></h1><ul><li>网络表示的关键问题：<br>如何定义图中节点的相似性</li></ul><h1><span id="图神经网络及认知推理">图神经网络及认知推理</span></h1><p><strong>网络上的学习任务：</strong></p><ul><li>节点分类：给定一个点，预测其类别</li><li>链接预测：给2个点，预测这2个点是否相连</li><li>community detection：找子图</li><li>网络相似度：2个网络或子网络的相似度</li></ul><h2><span id="回顾网络表示学习">回顾网络表示学习</span></h2><p>给定一个网络，学习节点的低维表示，如果2个节点距离很近，那这2个节点的表示也要相似。<br><strong>挑战：</strong></p><ol><li>CNN只适用于网格(二维)，但是网络是一个拓扑机构</li><li>RNN适用于文本/序列，这种都有先后关系，但是网络没有先后关系</li><li>网络是动态的，节点有属性，并且网络还有结构属性</li></ol><p><strong>网络表示学习发展：</strong></p><ol><li>使用word2vec来做网络表示学习，即DeepWalk</li><li>根据DeepWalk进行扩展：<ul><li>LINE：一阶和二阶相似性</li><li>PTE：异构网络</li><li>Node2vec：biased random walk</li></ul></li></ol><p><strong>网络表示学习的本质：</strong><br>都是在做矩阵分解，SVD分解，只是分解的形式不一样。<br>图表示学习结合的是context信息，用上下文信息来做网络表示学习。</p><p><img src="/2020/03/29/图神经网络研讨会/1.png" alt=""></p><p><strong>问题：</strong></p><h2><span id="gnn">GNN</span></h2><p><img src="/2020/03/29/图神经网络研讨会/2.png" alt=""></p><p><img src="/2020/03/29/图神经网络研讨会/3.png" alt=""></p><h2><span id="异质图">异质图</span></h2><p>同质网络：网络中只有一种类型的节点或边<br>异质网络：网络中有多类节点或边</p><p>首先分解出网络中的对象，以及对象之间的关系。<br>例如：作者-论文-会议，一个网络中有3类节点。<br>其中对象之间的关系（Meta path）有：</p><ul><li>作者1-论文-作者2（2个作者共同合作一篇论文）</li><li>作者1-论文-引用论文1，作者1写论文，引用了其他论文</li><li>……</li></ul><h3><span id="模型">模型</span></h3><ol><li>Metapath2Vec<br>基于meta path的随机游走，</li><li>HERec<br>解决异质图中节点的表示，将异质图变成同质图，在同质图中用DeepWalk或LINE学习节点表示</li><li>HIN2Vec<br>随机游走抽取出点边序列</li><li>MCRec</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在线图神经网络研讨会&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Deep Learning" scheme="http://yoursite.com/categories/Deep-Learning/"/>
    
    
      <category term="Graph" scheme="http://yoursite.com/tags/Graph/"/>
    
  </entry>
  
  <entry>
    <title>argparse不支持bool类型</title>
    <link href="http://yoursite.com/2020/03/09/argparse%E4%B8%8D%E6%94%AF%E6%8C%81bool%E7%B1%BB%E5%9E%8B/"/>
    <id>http://yoursite.com/2020/03/09/argparse不支持bool类型/</id>
    <published>2020-03-09T08:28:29.000Z</published>
    <updated>2020-03-09T08:57:46.605Z</updated>
    
    <content type="html"><![CDATA[<p>在Python中通过下列方式向程序传递bool参数时，其中<code>neg</code>参数指定类型为bool，但是无论传入的值是什么，<code>neg</code>始终为<code>True</code></p><p>解决方法：<br><a href="https://blog.csdn.net/yaokai_assultmaster/article/details/77928629" target="_blank" rel="noopener">使用Python中的argparse从命令行接收boolean类型的参数</a><br><a id="more"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">"--config"</span>, type=str, help=<span class="string">'configuration file'</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--gpus"</span>, type=str,help=<span class="string">"test program"</span>)<span class="comment">#如果</span></span><br><span class="line">parser.add_argument(<span class="string">"--neg"</span>, type=bool, help=<span class="string">"test program"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--test"</span>, action=<span class="string">"store_true"</span>, help=<span class="string">"test program"</span>)</span><br></pre></td></tr></table></figure><p>【注意】类似于上文中<code>gpus</code>这种参数，指定也可以，不指定也可以</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在Python中通过下列方式向程序传递bool参数时，其中&lt;code&gt;neg&lt;/code&gt;参数指定类型为bool，但是无论传入的值是什么，&lt;code&gt;neg&lt;/code&gt;始终为&lt;code&gt;True&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;解决方法：&lt;br&gt;&lt;a href=&quot;https://blog.csdn.net/yaokai_assultmaster/article/details/77928629&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;使用Python中的argparse从命令行接收boolean类型的参数&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="http://yoursite.com/categories/Python/"/>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>深度学习优秀代码示例</title>
    <link href="http://yoursite.com/2020/03/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BC%98%E7%A7%80%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B/"/>
    <id>http://yoursite.com/2020/03/03/深度学习优秀代码示例/</id>
    <published>2020-03-03T03:30:18.000Z</published>
    <updated>2020-03-07T05:14:24.731Z</updated>
    
    <content type="html"><![CDATA[<p>&ensp;&ensp;&ensp;&ensp;曾经一段时间很苦恼，对于深度学习算法不知道怎么上手，看了很多深度学习教程，依然不会写。后来就看论文公开的源代码，对照着论文模型，一点点看，多看几篇代码，逐渐有种开窍的感觉。其次是看Mxnet和Pytorch的源代码(我主要用这2个框架)，Mxnet和Pytorch的Github上给了很多示例代码，写的非常规范，从中可以学到用法，从而也可以规范自己的代码。<br>&ensp;&ensp;&ensp;&ensp;下面整理一下，在我学习过程中，对我帮助很大的教程和代码。</p><a id="more"></a><ol><li><a href="http://zh.gluon.ai/" target="_blank" rel="noopener">《动手学深度学习》Mxnet版</a><br>Mxnet的入门教程，沐神写的，来来回回看了2~3遍，每次看都有新的收货</li><li><a href="https://tangshusen.me/Dive-into-DL-PyTorch/#/" target="_blank" rel="noopener">《动手学深度学习》Pytorch版</a><br>将Mxnet改写为Pytorch版本，非常好的Pytorch入门教程</li><li><a href="https://github.com/Davidham3/ASTGCN" target="_blank" rel="noopener">ASTGCN</a><br>AAAI2019论文公开代码，用Mxnet写的</li><li><a href="https://yjucho1.github.io/spatio-temporal%20data/deep%20learning%20paper/ST-resnet/" target="_blank" rel="noopener">ST-ResNet</a><br>AAAI2017论文公开代码，用Keras，看这篇代码主要是学习模型架构，然后自己用mxnet复现了一下</li><li><a href="https://github.com/panzheyi/ST-MetaNet" target="_blank" rel="noopener">ST-MetaNet</a><br>KDD2019论文公开代码，用Mxnet写的，学到了很多高级用法，例如EarlyStopping，Encoder和Decoder，getattr，DGL</li><li><p><a href="https://github.com/pytorch/examples/tree/master/word_language_model" target="_blank" rel="noopener">Pytorch Transformer</a><br>学习怎么使用Transformer，Dropout和BN在训练和测试的不同，PositionEmbedding，getattr等用法。学习Transformer最好去看Pytorch关于Tranformer的源代码。</p></li><li><p><a href="https://github.com/pytorch/examples" target="_blank" rel="noopener">Pytorch示例代码</a><br>Pytorch Github中的示例代码</p></li><li><a href="https://github.com/apache/incubator-mxnet/tree/master/example" target="_blank" rel="noopener">Mxnet示例代码</a><br>Mxnet Github中的示例代码</li></ol><p>觉得自己最大的变化是喜欢去读源代码了，遇到问题去官网看教程，读源码，帮助很大。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;曾经一段时间很苦恼，对于深度学习算法不知道怎么上手，看了很多深度学习教程，依然不会写。后来就看论文公开的源代码，对照着论文模型，一点点看，多看几篇代码，逐渐有种开窍的感觉。其次是看Mxnet和Pytorch的源代码(我主要用这2个框架)，Mxnet和Pytorch的Github上给了很多示例代码，写的非常规范，从中可以学到用法，从而也可以规范自己的代码。&lt;br&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;下面整理一下，在我学习过程中，对我帮助很大的教程和代码。&lt;/p&gt;
    
    </summary>
    
      <category term="Deep Learning" scheme="http://yoursite.com/categories/Deep-Learning/"/>
    
    
      <category term="Mxnet" scheme="http://yoursite.com/tags/Mxnet/"/>
    
      <category term="Pyotrch" scheme="http://yoursite.com/tags/Pyotrch/"/>
    
  </entry>
  
  <entry>
    <title>时空论文阅读笔记</title>
    <link href="http://yoursite.com/2020/02/27/%E6%97%B6%E7%A9%BA%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2020/02/27/时空论文阅读笔记/</id>
    <published>2020-02-27T12:03:53.000Z</published>
    <updated>2020-06-18T02:36:57.665Z</updated>
    
    <content type="html"><![CDATA[<p>因为疫情推迟开学，在家把以前看的论文又看了一遍，每重新看一次都有新的收获，在此整理下。</p><a id="more"></a><!-- TOC --><ul><li><a href="#1-流量速度预测">1. 流量/速度预测</a><ul><li><a href="#11-deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-predictionaaai2017">1.1. Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction(AAAI2017)</a></li><li><a href="#12-deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolisaaai2019">1.2. DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis(AAAI2019)</a></li><li><a href="#13-urbanfm-inferring-fine-grained-urban-flowskdd2019">1.3. UrbanFM: Inferring Fine-Grained Urban Flows(KDD2019)</a></li><li><a href="#14-attention-based-spatial-temporal-graph-convolutional-networks-for-traffic-flow-forecastingaaai2019">1.4. Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting(AAAI2019)</a></li><li><a href="#15-spatial-temporal-synchronous-graph-convolutional-networks-a-new-framework-for-spatial-temporal-network-data-forecastingaaai2020">1.5. Spatial-Temporal Synchronous Graph Convolutional Networks: A New Framework for Spatial-Temporal Network Data Forecasting(AAAI2020)</a></li><li><a href="#16-hyperst-net-hypernetworks-for-spatio-temporal-forecasting2019aaai">1.6. HyperST-Net: Hypernetworks for Spatio-Temporal Forecasting(2019AAAI)</a></li><li><a href="#17-urban-traffic-prediction-from-spatio-temporal-data-using-deep-meta-learning2019kdd">1.7. Urban Traffic Prediction from Spatio-Temporal Data Using Deep Meta Learning(2019KDD)</a></li><li><a href="#18-stepdeep-a-novel-spatial-temporal-mobility-event-prediction-framework-based-on-deep-neural-networkkdd2018">1.8. StepDeep: A Novel Spatial-temporal Mobility Event Prediction Framework based on Deep Neural Network(KDD2018)</a></li><li><a href="#19-stgrat-a-spatio-temporal-graph-attention-network-for-traffic-forecastingaaai2020">1.9. STGRAT: A Spatio-Temporal Graph Attention Network for Traffic Forecasting(AAAI2020)</a></li><li><a href="#110-connecting-the-dots-multivariate-time-series-forecasting-with-graph-neural-networks">1.10. Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks</a></li></ul></li><li><a href="#2-eta预测">2. ETA预测</a><ul><li><a href="#21-when-will-you-arrive-estimating-travel-time-based-on-deep-neural-networksaaai20">2.1. When Will You Arrive? Estimating Travel Time Based on Deep Neural Networks(AAAI20)</a></li></ul></li><li><a href="#3-出租车需求预测">3. 出租车需求预测</a><ul><li><a href="#31-deep-multi-view-spatial-temporal-network-for-taxi-demand-predictionaaai2018">3.1. Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction(AAAI2018)</a></li><li><a href="#32-revisiting-spatial-temporal-similarity-a-deep-learning-framework-for-traffic-predictionaaai2019">3.2. Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction(AAAI2019)</a></li><li><a href="#33-spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecastingaaai2019">3.3. Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting(AAAI2019)</a></li><li><a href="#34-passenger-demand-forecasting-with-multi-task-convolutional-recurrent-neural-networkspakdd2019">3.4. Passenger Demand Forecasting with Multi-Task Convolutional Recurrent Neural Networks(PAKDD2019)</a></li><li><a href="#35-stg2seq-spatial-temporal-graph-to-sequence-model-for-multi-step-passenger-demand-forecasting2019ijcai">3.5. STG2Seq: Spatial-temporal Graph to Sequence Model for Multi-step Passenger Demand Forecasting(2019IJCAI)</a></li></ul></li><li><a href="#4-时间序列预测">4. 时间序列预测</a><ul><li><a href="#41-restful-resolution-aware-forecasting-of-behavioral-time-series-data2018cikm">4.1. RESTFul: Resolution-Aware Forecasting of Behavioral Time Series Data(2018CIKM)</a></li><li><a href="#42-multi-horizon-time-series-forecasting-with-temporal-attention-learningkdd2019">4.2. Multi-Horizon Time Series Forecasting with Temporal Attention Learning(KDD2019)</a></li></ul></li><li><a href="#5-总结">5. 总结</a><ul><li><a href="#51-网格--图">5.1. 网格—&gt;图</a></li><li><a href="#52-动态图">5.2. 动态图</a></li><li><a href="#53-计算2个区域的相似性">5.3. 计算2个区域的相似性</a></li><li><a href="#54-poi">5.4. POI</a></li><li><a href="#55-时间相关性">5.5. 时间相关性</a></li><li><a href="#56-lstm共t个隐藏状态整合">5.6. LSTM共T个隐藏状态整合</a></li><li><a href="#57-外部因素嵌入">5.7. 外部因素嵌入</a></li><li><a href="#58-mask">5.8. mask</a></li><li><a href="#59-max-min归一化">5.9. Max-min归一化</a></li></ul></li></ul><!-- /TOC --><h1><span id="1-流量速度预测">1. 流量/速度预测</span></h1><h2><span id="11-deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-predictionaaai2017">1.1. Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction(AAAI2017)</span></h2><blockquote><p>张钧波(京东)<br>郑宇(京东)<br><a href="https://github.com/lucktroy/DeepST" target="_blank" rel="noopener">https://github.com/lucktroy/DeepST</a> Keras</p></blockquote><ul><li>给定所有区域历史T个时间段的inflow和outflow，预测下一个时间段所有区域的inflow和outflow</li></ul><p><img src="/2020/02/27/时空论文阅读笔记/ST-ResNet.png" alt=""></p><ul><li>每个时间段所有区域的输入是$I<em>J</em>2$,将输入分为recent，daily，weekly周期，预测第t个时间段的infow和outflow：<ul><li>recent：当天前r个时间段</li><li>daily：前d天该时间段</li><li>weekly：前w周该天该时间段</li></ul></li><li>外部特征包括：天气，节假日，dayOfWeek。用2层FCN对外部特征进行嵌入，第一层FCN作为嵌入层，第二层FCN转换维度和$X_{Res}$一致。</li><li>在融合阶段，先将3个时间周期的输出融合，再和外部因素拼接。</li><li>数据集：北京出租车和NYC自行车流量</li><li>将flow使用Max-Min归一化到[-1,1]，FCN最后一层使用tanh激活函数</li></ul><h2><span id="12-deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolisaaai2019">1.2. DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis(AAAI2019)</span></h2><blockquote><p>Ziqian Lin(清华大学)<br>Jie Feng(清华大学)<br>Ziyang Lu(清华大学)<br>Yong Li(清华大学)<br>Depeng Jin(清华大学)<br><a href="https://github.com/FIBLAB/DeepSTN" target="_blank" rel="noopener">https://github.com/FIBLAB/DeepSTN</a>  Keras</p></blockquote><ul><li>crowd flow预测是给定历史T个时间段，预测区域的inflow和outflow</li><li>现有研究的缺点：<ul><li>不能捕获长距离空间依赖</li><li>忽略区域功能对人流的影响(POI)</li></ul></li><li>提出DeeoSTN+，有3个组件<ul><li>ConvPlus：解决长距离区域的空间依赖</li><li>SemanticPlus：解决区域POI对人流的影响</li><li>early-fusuion模块</li></ul></li></ul><p><img src="/2020/02/27/时空论文阅读笔记/DeepSTN+.png" alt=""></p><ul><li><p>假设预测周四第5个时间段的flow，输入的数据有：</p><ul><li>recent：周四2,3,4个时间段</li><li>day：周一，周二，周三第5个时间段</li><li>week：上上上周四，上上周四，上周四第5个时间段</li><li>time：周四第5个时间段的时间向量</li><li>poi：(C,W,H)所有区域的poi信息</li></ul></li><li>【<strong>ConvPlus</strong>】传统的Conv中kernel的大小远小于网格大小，通常是$3 \times 3$,然后在人流量预测中通常有一些长距离的依赖，例如人们去很远的地方上班。在ConvPlus中，假设原始输入维度是(C,W,H),其中plus维用来捕获长距离依赖<ul><li>正常Conv2D：将原始输入(C,W,H)输入到正常Conv2D中,卷积核有C-plus个，输出维度(C-plus,W,H)，</li><li>ConvPlus：再将原始(C,W,H)输入到ConvPlus中，卷积核有plus<em>W\</em>H个，卷积大小为W*H,则输出维度(plus*W*H,1,1),reshape为(plus,W,H)</li><li>将上面2个卷积的输出拼接成(C,W,H)</li></ul></li><li><strong>计算POI在时间上的分布权重</strong><ul><li>POI维度$C \times W \times H$,表示每个网格有C类POI</li><li>时间维度$T \times W \times H$，T=24+7, 首先对时间进行嵌入，通过2D卷积，将31个数变成一个数$1 \times W \times H$，然后将时间repeat成$C \times W \times H$</li><li>时间和POI逐元素相乘，得到$C \times W \times H$</li><li>如果需要，还可以再通过K个2D卷积，变成$K \times W \times H$</li><li>将该张量和3个周期的输出在通道维上拼接。</li></ul></li><li>crowd flow使用Max-Min归一化到[-1,1]，最后一层使用Tanh，范围[-1,1]</li><li>POI使用Max-Min归一化到[0,1]</li></ul><h2><span id="13-urbanfm-inferring-fine-grained-urban-flowskdd2019">1.3. UrbanFM: Inferring Fine-Grained Urban Flows(KDD2019)</span></h2><blockquote><p>Yuxuan Liang(XiDian)<br>Kun Ouyang(新加坡国立)<br>张钧波(京东)<br>郑宇(京东)<br><a href="https://github.com/yoshall/UrbanFM" target="_blank" rel="noopener">https://github.com/yoshall/UrbanFM</a></p></blockquote><ul><li>基于粗粒度级的flow，实时推测整个城市细粒度级的flow，提出模型<strong>Urban</strong> <strong>F</strong>low <strong>M</strong>agnifier (<strong>UrbanFM</strong>)</li><li>有2个挑战：粗粒度和细粒度的flow在空间上的相关性、复杂的外部因素。</li></ul><p><img src="/2020/02/27/时空论文阅读笔记/UrbanFM1.png" alt=""></p><p><img src="/2020/02/27/时空论文阅读笔记/UrbanFM.png" alt=""></p><h2><span id="14-attention-based-spatial-temporal-graph-convolutional-networks-for-traffic-flow-forecastingaaai2019">1.4. Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting(AAAI2019)</span></h2><blockquote><p>郭晟楠(北京交通大学)<br>冯宁(北京交通大学)<br>宋超(北京交通大学)<br>万怀宇(北京交通大学)<br><a href="https://github.com/Davidham3/ASTGCN" target="_blank" rel="noopener">https://github.com/Davidham3/ASTGCN</a> Mxnet</p></blockquote><p>根据所有节点历史T个时间段traffic flow，occupy，speed，预测所有节点未来T_p个时间段的traffic flow。</p><p><img src="/2020/02/27/时空论文阅读笔记/ASTGCN.png" alt=""></p><ul><li>三个独立的组件，分别对recent，daily，weekly周期进行建模</li><li>比如说预测6.14 8:00-8:55的flow，传入的样本是<br>时：6.14号6:00~7:55（前2个小时）的数据，<br>天：6.13和6.12（前2天）的8:00-8:55，<br>周：上周6.17，上上周5.31（前2周）的8:00-8:55</li></ul><h2><span id="15-spatial-temporal-synchronous-graph-convolutional-networks-a-new-framework-for-spatial-temporal-network-data-forecastingaaai2020">1.5. Spatial-Temporal Synchronous Graph Convolutional Networks: A New Framework for Spatial-Temporal Network Data Forecasting(AAAI2020)</span></h2><blockquote><p>宋超(北京交通大学)<br>郭晟楠(北京交通大学)<br>万怀宇(北京交通大学)<br><a href="https://github.com/Davidham3/STSGCN" target="_blank" rel="noopener">https://github.com/Davidham3/STSGCN</a> Mxnet</p></blockquote><ul><li>给定所有节点历史T个时间段的车流量，预测所有节点未来$T’$个时间段的车流量，</li><li>原先的研究通常使用分开的组件捕获时间和空间的相关性，并且忽略了时空数据的异构性。</li><li>提出<strong>S</strong>patial-<strong>T</strong>emporal <strong>S</strong>ynchronous <strong>G</strong>raph <strong>C</strong>onvolutional <strong>N</strong>etworks (<strong>STSGCN</strong>)</li><li><strong>对于图中的每个节点，它的影响范围有3种</strong>，这是该文章提出的一个新观点，以前的研究中通常只考虑前2种。</li></ul><p><img src="/2020/02/27/时空论文阅读笔记/STSGCN1.png" alt=""></p><ul><li>本文强调的内容有2点：<ul><li>局部的时空关系，称作localized spatial-temporal correlations</li><li>时空数据的异质性，居住区和商业区，早上和晚上</li></ul></li><li><strong>使用连续3个时间步的图数据来构建localized spatial-temporal graph，local指的是在时间上局部</strong><br>假设原先一个图中有N个节点，图信号矩阵为$N \times C$,邻接矩阵为$N \times N$，现在3个图来构建一个局部时空图，图信号矩阵为$3N \times C$,邻接矩阵为$3N \times 3N$,邻接矩阵中非0即1</li></ul><p><img src="/2020/02/27/时空论文阅读笔记/STSGCN2.png" alt=""></p><ul><li>但是把3个图构成1个图失去了图之间的时间关系，模型可能会认为这是一个有3N个节点在一个时间步的信息，为了区域这3个图的时间关系，受ConvS2S启发，为时空网络序列$N \times C \times T$添加位置嵌入，增加时间嵌入矩阵$C \times T$,空间嵌入矩阵$N \times C$,这2个矩阵是通过模型学习的，当模型训练好之后，这2个矩阵可以包含图的时间和空间信息。然后把这2个嵌入矩阵和原始的图信号矩阵相加，这样图中就包含了时间和位置信息。</li></ul><p><img src="/2020/02/27/时空论文阅读笔记/STSGCN.png" alt=""></p><ul><li>图中模型框架：多个STSGCM构成STSGCL，多个STSGCL构成STSGCN。STSGCN就是多层图卷积，从局部时空图中捕获邻居信息。STSGCL一层中有多个STSGCM，一个样本中每个时间段的局部时空图都用一个STSGCM来建模。</li><li><strong>第一个FCN成将输入转换到高维空间，提高模型的表示能力</strong></li><li>【<strong>STSGCM</strong>】中包含多层图卷积，使用GLU作为激活函数，其中sigmoid作为门控机制，控制哪个节点的信息可以流入到下一层。<strong>图卷积计算定义在顶点域，意味着不需要计算图的拉普拉斯矩阵</strong><br><img src="/2020/02/27/时空论文阅读笔记/STSGCN3.png" alt=""><br>STSGCM的架构如下：参考JK-net，一共有L个图卷积层，每一层的输出都输入到AGG层中，AGG层将接收到的L个输出进行max聚合，最终得到一个输出$3N \times C_{out}$,然后进行裁剪，将前中后3个时间步的数据只保留中间时间步，即$N \times C_out$<br><img src="/2020/02/27/时空论文阅读笔记/STSGCN4.png" alt=""></li><li>【<strong>STSGCL</strong>】多个STSGCM组成一个STSGCL层，其输入维度$T \times N \times C$,使用滑动窗口每次取3个时间段段的图构成$3N \times C$,一共构成$T-2$个局部时空图，然后需要$T-2$个STSGCM，最终输出$T-2个N \times C_{out}$，将其拼接为$(T-2) \times N \times C_{out}$，再输入到下一个STSGCL中。<strong>【注意】每个局部时空图是通过滑动窗口获得，每个时空局部图的邻接矩阵是不变的，而不是提前处理好局部图输入到模型中，这样会省空间</strong></li><li>上面使用的邻接矩阵$3N \times 3N$中的值非0即1，每个邻居聚合的权重相等，聚合能力会受到限制，这里对此做出改进，将邻接矩阵乘上一个Mask矩阵，对每个邻居赋予不同的权重，其中Mask矩阵是可学习参数，维度$3N \times 3N$<script type="math/tex; mode=display">A_{\text {adjusted}}^{\prime}=W_{\text {mask}} \otimes A^{\prime} \in \mathbb{R}^{3 N \times 3 N}</script></li><li>最后的FCN将STSGCL的输出转换成预测的格式。STSGCL的输出格式为$T \times N \times C$,reshape成$N \times TC$,然后使用$T’$个2层全连接，每个全连接输出维度为$(N,1)$,然后将$T’$个全连接的输出拼接成$N \times T’$</li><li><strong>损失函数使用Huber Loss，对异常值不敏感</strong><script type="math/tex; mode=display">L(Y, \hat{Y})=\left\{\begin{array}{ll}\frac{1}{2}(Y-\hat{Y})^{2} & |Y-\hat{Y}| \leq \delta \\\delta|Y-\hat{Y}|-\frac{1}{2} \delta^{2} & \text { otherwise }\end{array}\right.</script></li><li>使用mean-std归一化，训练集:验证集:测试集=6:2:2，模型包含4个STSGCL，每个STSGCM包含3个图卷积</li></ul><h2><span id="16-hyperst-net-hypernetworks-for-spatio-temporal-forecasting2019aaai">1.6. HyperST-Net: Hypernetworks for Spatio-Temporal Forecasting(2019AAAI)</span></h2><blockquote><p>潘哲逸(上海交通大学)<br>梁宇轩(西安电子科技大学)<br>张钧波(京东)<br>易修文(京东)<br>郑宇(京东)</p></blockquote><p>论文声称第一个考虑<strong>空间和时间内在因果关系</strong>的深度框架。</p><p><img src="/2020/02/27/时空论文阅读笔记/HyperST_Net.png" alt=""></p><ul><li>该论文提出的只是一个HyperNetwork框架，并不是一个具体的模型。</li><li><strong>HyperNetwork</strong>：和以往不同，以前都是一个网络的输出，输入到下一个网络中，<strong>超网络是一个网络的输出作为另一个网络的参数</strong>。</li><li>该模型有3个模块：空间模块，时间模块，推理模块。将空间模块的输出经过推理模块，得到的输出作为时间模块的权重参数，以此捕获时间和空间的内在因果关系。</li><li>这只是一个框架，可以变换成多种模型。在空间模块中如果使用全连接就是HyperST-Dense，使用卷积就是HyperST-Conv。</li></ul><h2><span id="17-urban-traffic-prediction-from-spatio-temporal-data-using-deep-meta-learning2019kdd">1.7. Urban Traffic Prediction from Spatio-Temporal Data Using Deep Meta Learning(2019KDD)</span></h2><blockquote><p>潘哲逸(上海交通大学)<br>梁宇轩(西安电子科技大学)<br>张钧波(京东)<br>郑宇(京东)<br><a href="https://github.com/panzheyi/ST-MetaNet" target="_blank" rel="noopener">https://github.com/panzheyi/ST-MetaNet</a> Mxnet</p></blockquote><ul><li>使用图中所有节点历史T个时间段的flow或speed，预测所有节点未来</li></ul><p><img src="/2020/02/27/时空论文阅读笔记/ST-MetaNet.png" alt=""></p><p><img src="/2020/02/27/时空论文阅读笔记/ST-MetaNet1.png" alt=""></p><p><img src="/2020/02/27/时空论文阅读笔记/ST-MetaNet2.png" alt=""></p><ul><li>本论文用的图，但是实验中有一个$I \times J$的网格数据，将网格数据构建成图</li><li>本论文来表示1张图有2个矩阵：图信号矩阵(N,D)和边特征矩阵(N,N,C)。对于网格数据来说，图信号矩阵表示每个网格POI个数，道路个数。边特征表示2个两个网格的道路个数。这都是静态数据，不随着时间变化。</li></ul><p>【总结】发现上面这2个论文都是一个网络生成另一个网络的参数，查阅资料发现这叫做<code>meta-learning</code>，先记录一下以后再自己看<br><img src="/2020/02/27/时空论文阅读笔记/Meta-learning.png" alt=""></p><h2><span id="18-stepdeep-a-novel-spatial-temporal-mobility-event-prediction-framework-based-on-deep-neural-networkkdd2018">1.8. StepDeep: A Novel Spatial-temporal Mobility Event Prediction Framework based on Deep Neural Network(KDD2018)</span></h2><blockquote><p>Bilong Shen(清华大学)<br>梁晓丹(卡耐基梅隆)</p></blockquote><ul><li><strong>S</strong>patial-<strong>T</strong>emporal mobility <strong>E</strong>vent <strong>P</strong>rediction framework based on <strong>Deep</strong> neural network (<strong>StepDeep</strong>)同时考虑时间和空间模式，给定所有区域历史T个时间段的出租车流量和外部因素，预测所有区域在下一个时间段出租车的inflow和outflow。</li><li>网格区域中的flow随时间变化，可以看做一个视频(T,C,W,H)，进而看做是视频预测任务</li><li>数据集NYC出租车轨迹数据，将NYC网格划分，计算每个区域的inflow和outflow，</li></ul><p><img src="/2020/02/27/时空论文阅读笔记/StepDeep.png" alt=""></p><p><img src="/2020/02/27/时空论文阅读笔记/StepDeep1.png" alt=""></p><ul><li>提出3种卷积：时间卷积，空间卷积，时空卷积。将输入(T,C,H,W)输入到以上7层卷积中，最终输出(C,H,W)表示下一个时间段所有区域的inflow和outflow，</li></ul><h2><span id="19-stgrat-a-spatio-temporal-graph-attention-network-for-traffic-forecastingaaai2020">1.9. STGRAT: A Spatio-Temporal Graph Attention Network for Traffic Forecasting(AAAI2020)</span></h2><blockquote><p>Cheonbok Park(韩国大学)<br>Chunggi Lee(韩国大学)<br>Hyojin Bahng(韩国大学)</p></blockquote><ul><li>根据所有节点历史T个时间段的交通速度，预测所有节点未来T个时间段的交通速度(T=12)，时间多预测多，Seq2Seq架构</li></ul><p><img src="/2020/02/27/时空论文阅读笔记/STGRAT.png" alt=""></p><ul><li>Encoder layer中有3个sublayer：空间Attention层，时间Attention层和point-wise FCN。<ul><li>空间Attention：关注每个时间步上空间邻近的节点</li><li>时间Attention：关注单个节点，输入时间序列的不同时间步</li></ul></li><li>整个Encoder = 1个嵌入层 + 4个Encoder layer，使用LINE对图节点进行嵌入</li></ul><p><img src="/2020/02/27/时空论文阅读笔记/STGRAT1.png" alt=""></p><ul><li>空间Attention层：参考Transformer，中心结点作为query，其邻居作为key和value，计算每个节点新的表示。</li><li>时间Attention==Transformer，输入维度(batch_size,T,N,D),计算时间步之间的attention分数，输出维度(batch_size,T,N,D)</li><li>Point-wise FFN和Transformer中一样，使用2层FCN，中间使用GELU激活函数，Transformer使用的是ReLU激活函数。</li><li>Decoder layer有4个sublayer：空间Attention层，mask时间Attention层，Encoder-Decoder Attention层，point-wise FFN层。整个Decoder层=1个嵌入层+4个Decoder层。</li><li><strong>本模型比Transformer多了一个空间Attention层，其余都一样，因为时间Attention层、FFN和Transformer的一样</strong></li></ul><h2><span id="110-connecting-the-dots-multivariate-time-series-forecasting-with-graph-neural-networks">1.10. Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks</span></h2><p>该模型使用图网络模型捕获交通数据或其他领域数据中的时间和空间相关性。</p><p><img src="/2020/02/27/时空论文阅读笔记/论文总结/MTGNN-1.png" alt=""></p><p>该模型有2个模块，图卷积模块和时间模块。其中图卷积模块主要解决4个问题：</p><ol><li>节点间的空间相关性</li><li>如何构造图</li><li>如何解决图卷积过度平滑问题</li><li>大图如何训练问题</li></ol><p><img src="/2020/02/27/时空论文阅读笔记/论文总结/MTGNN-2.png" alt=""></p><p>首先图信号矩阵，输入到图结构学习模块，构造图的邻接矩阵。注意这里的邻接矩阵不是预先定义好的，而是根据网络模块学习得到，据此构建图，然后输入到GCN中捕获时间相关性，然后输入到时间卷积捕获时间相关性，最后预测结果。</p><p><img src="/2020/02/27/时空论文阅读笔记/论文总结/MTGNN-3.png" alt=""></p><p>在构造图时，通过模型学习节点的嵌入矩阵，然后根据嵌入矩阵计算节点的相似性，为每个节点选取相似性前k的节点作为其一阶邻居。邻接矩阵不随着时间变化。</p><script type="math/tex; mode=display">\begin{array}{l}\mathbf{M}_{1}=\tanh \left(\alpha \mathrm{E}_{1} \Theta_{1}\right) \\ \mathbf{M}_{2}=\tanh \left(\alpha \mathrm{E}_{2} \mathbf{\Theta}_{2}\right) \\ \mathbf{A}=\operatorname{ReL} U\left(\tanh \left(\alpha\left(\mathbf{M}_{1} \mathbf{M}_{2}^{T}-\mathbf{M}_{2} \mathbf{M}_{1}^{T}\right)\right)\right) \\ \text { for } i=1,2, \cdots, N \\ \text { idx }=\operatorname{argtop} k(\mathrm{A}[i,:]) \\ \quad \mathrm{A}[i,-\mathrm{idx}]=0\end{array}</script><p>在图卷积模块，参考Min-hop架构，每个GCN层的输入会加上原始的图信号矩阵，避免图过度平滑问题，然后再将所有GCN层的输出加起来，进行融合。为了解决大图训练的问题，在进行GCN时，每次随机选取几个节点进行GCN运算，而不是使用所有的节点。</p><script type="math/tex; mode=display">\mathbf{H}^{(k)}=\beta \mathbf{H}_{i n}+(1-\beta) \tilde{\mathbf{A}} \mathbf{H}^{(k-1)}</script><script type="math/tex; mode=display">\mathbf{H}_{o u t}=\sum_{i=0}^{K} \mathbf{H}^{(k)} \mathbf{W}^{(k)}</script><p><img src="/2020/02/27/时空论文阅读笔记/论文总结/MTGNN-4.png" alt=""></p><p>在时间模块，使用一维空洞卷积，捕获长期的时间依赖，同时参照Inception结构，设置不同的卷积核，来捕获不同力度的周期性，例如小时周期，天周期，周周期。</p><p>总结：</p><ol><li>根据模型学习节点嵌入，由此构建邻接矩阵，构建相似性图</li><li>使用一维空洞卷积捕获时间相似性，使用不同的卷积核捕获不同粒度的周期性。</li></ol><h1><span id="2-eta预测">2. ETA预测</span></h1><h2><span id="21-when-will-you-arrive-estimating-travel-time-based-on-deep-neural-networksaaai20">2.1. When Will You Arrive? Estimating Travel Time Based on Deep Neural Networks(AAAI20)</span></h2><blockquote><p>王东(杜克大学)<br>张钧波(京东)<br>郑宇(京东)<br><a href="https://github.com/UrbComp/DeepTTE" target="_blank" rel="noopener">https://github.com/UrbComp/DeepTTE</a> Pytorch</p><ul><li>端到端<strong>Deep</strong> learning framework for <strong>T</strong>ravel <strong>T</strong>ime <strong>E</strong>stimation(<strong>DeepTTE</strong>)，给定路径P和外部因素(weather，day of week，开始时间)预测整个path的时间</li><li>原先的工作都是预测travel中单个路段的耗时，然后再把每个路段的时间加起来，缺点是没有考虑到道路交叉口，红绿灯等影响，错误累积</li></ul></blockquote><p><img src="/2020/02/27/时空论文阅读笔记/DeepTTE.png" alt=""></p><ul><li>DeepTTE提出geo-convolution，将地理信息加入到传统Conv中，捕获空间相关性</li><li>多任务学习，同时预测local path和entir path的时间，在loss中限制2者的权重</li><li><strong>在生成测试数据时，将历史轨迹点中的时间戳都去掉</strong>(因为要预测出行时间，所以测试数据不能带有事件信息)，从轨迹中抽样等距离的点组成路径P</li><li><p>DeepTTE一共有3个组件</p><ul><li>Attribute组件：外部因素：天气(one-hot)，司机ID(one-hot)，weekID和timeID(one-hot)，都是类别值，不能直接输入到网络中，需要先嵌入层低维向量，参考<a href="https://arxiv.org/abs/1512.05287" target="_blank" rel="noopener">(2016NIPS)A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</a>,然后再和整个path的距离拼接作为该组件的输出</li><li>Geo-Conv层，历史轨迹是一个GPS序列，为了捕获空间依赖使用1D卷积，将历史轨迹序列先经过FCN变成一个矩阵$T \times V$,T个轨迹点，每个轨迹点有V个特征，然后使用C个k*V的1D卷积，卷积输出的时间维度变成$T-k+1$,将C个卷积核输出的结果拼接，然后再拼接上local path的距离,输出结果为$T-k+1 \times D$</li></ul><p><img src="/2020/02/27/时空论文阅读笔记/DeepTTE2.png" alt=""></p><ul><li>然后将$T-k+1 \times D$的序列拼接外部因素输入到LSTM中，每个时间步表示一个local path，将<strong>隐藏状态用来预测每个local path的时间作为辅助任务</strong></li><li>LTSM输出$T-k+1$个时间步，将其整合成1个向量，通过和外部因素做Attention，对每个local path赋予不同的权重，然后再和外部因素拼接，用来预测entir path的时间</li></ul></li><li><p><strong>训练阶段预测local path和entir path的时间，在测试阶段只预测entir path的时间</strong></p></li><li><p>在训练时，使用MAPE作为loss，包含辅助任务和主任务的loss<br><img src="/2020/02/27/时空论文阅读笔记/DeepTTE-loss.png" alt=""></p></li><li><p>这篇文章也是经典的CNN+LSTM的架构，只是这里的CNN是1D卷积。在融合外部因素上也是CNN的输出和外部因素拼接，送入到LSTM中。</p></li></ul><h1><span id="3-出租车需求预测">3. 出租车需求预测</span></h1><h2><span id="31-deep-multi-view-spatial-temporal-network-for-taxi-demand-predictionaaai2018">3.1. Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction(AAAI2018)</span></h2><blockquote><p>姚骅修(Pennsylvania State University)<br>吴飞(Pennsylvania State University)<br>柯金涛(香港科技大学)<br>Xianfeng Tang(Pennsylvania State University)<br>叶杰平(滴滴出行)<br><a href="https://github.com/huaxiuyao/DMVST-Net" target="_blank" rel="noopener">https://github.com/huaxiuyao/DMVST-Net</a> Keras</p></blockquote><ul><li><strong>出租车需求预测</strong>，根据S<em>S的小区域，历史T个时间段的出租车订单数据，预测下一个时间段中心区域的订单。<em>*空间和时间都是多预测一</em></em></li></ul><p><img src="/2020/02/27/时空论文阅读笔记/DMVST_Net.png" alt=""></p><ul><li>现有的研究都是使用CNN对空间建模，LSTM对时间建模，时间和空间分开建模，本文的模型是对时间和空间同时建模</li><li>本文提出DMVST-Net，有3个view：<strong>时间view</strong>（通过LSTM建模时间关系），<strong>空间view</strong>（使用local CNN建模邻近空间关系），<strong>语义view</strong>（建模功能相似的区域）</li><li>local CNN只考虑空间邻近的区域，但是不能考虑离得较远，但出租车需求模型相似的区域，所以又加了语义view</li><li><img src="/2020/02/27/时空论文阅读笔记/DMVST_Net-1.jpg" alt=""></li><li><strong>输入是S*S的邻居区域，如果是边界区域，其邻居用0填充</strong></li><li>在LSTM每个时间步的特征中拼接天气等外部因素</li><li>local CNN和LSTM对时间和空间建模，然后再构建图，表示区域之间需求相似性(功能相似性)。求出2个区域每周的需求量，形成一个时间序列，使用DTW计算2个序列的相似性，即<strong>2个区域的相似性，作为图中的边，创建一个全连接图(任意2个区域都相连)</strong>,使用LINE对图中节点进行嵌入。</li><li><img src="/2020/02/27/时空论文阅读笔记/DMVST_Net-2.png" alt=""><br>损失函数由MSE和MAPE组成，MSE更关注大值，为了避免模型偏向大值的方向训练，又添加了MAPE，但是使用MAPE时，真实值中不能有0</li><li>Max-Min激活，最终输出值在[0,1]之间，反归一化</li><li>最后一层FCN用sigmoid激活，其余的FCN用ReLU激活</li></ul><h2><span id="32-revisiting-spatial-temporal-similarity-a-deep-learning-framework-for-traffic-predictionaaai2019">3.2. Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction(AAAI2019)</span></h2><blockquote><p>姚骅修(Pennsylvania State University)<br>Xianfeng Tang(Pennsylvania State University)<br><a href="https://github.com/tangxianfeng/STDN" target="_blank" rel="noopener">https://github.com/tangxianfeng/STDN</a> Keras</p></blockquote><ul><li>主要问题是：原先研究中的空间相关性都是静态的，本次建模<strong>动态的空间相关性</strong>。<strong>时间有天和周周期，且有时间偏移</strong>。</li><li>提出模型<strong>S</strong>patial-<strong>T</strong>emporal <strong>D</strong>ynamic <strong>N</strong>etwork(<strong>STDN</strong>)来traffic prediction</li><li>根据S<em>S小区域历史T个时间段的volume和flow，预测下一个时间段中心区域的volume，<em>*空间和时间都是多预测一</em></em></li></ul><p><img src="/2020/02/27/时空论文阅读笔记/STDN.png" alt=""></p><ul><li>将交通量分为2种<ul><li>traffic volume：无方向，一个区域进来和出去的流量。</li><li>traffic flow：有方向，从区域i到区域j的流量</li></ul></li><li>flow-gated local CNN每次输入S*S区域的volume和flow，其中flow起到门控作用，值在[0,1]之间，如果2个区域之间flow大，即门控的值大，2个区域的相关性强。每个时间段经过local CNN输出的值，再拼接上该时间段的天气等外部因素送入LSTM中</li><li><strong>时间偏移Attention</strong>：比如预测第t+1个时间段的volume，用到当天前t=7个时间段的数据(短期依赖)，前P=3天(长期依赖)，每天Q=3个时间段(解决时间偏移问题)。</li><li>先将短期的t个时间段数据输入LSTM中，得到隐藏状态h做Attention。前P天，每天Q个时间段输入到LSTM中，每天得到Q个隐藏状态，和h做attention，将Q个整合成1个，最终生成P个隐藏状态，再输入到LSTM，得到长期依赖的隐藏状态，然后再和短期的隐藏状态h拼接，输入到FCN中。</li><li><strong>短期的隐藏状态和长期的隐藏状态做Attention</strong></li><li><strong>短期的隐藏状态和长期的隐藏状态拼接</strong></li><li>数据集：出租车流量和自行车流量</li></ul><blockquote><ul><li>STDN和DMVST-Net是同一作者发的</li><li>两者都是：空间和时间<strong>多预测一</strong></li><li><strong>STDN</strong>：local CNN + LSTM</li><li><strong>DMVST-Net</strong>：flow-gated local CNN + Periodically Shifted Attention LSTM</li></ul></blockquote><h2><span id="33-spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecastingaaai2019">3.3. Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting(AAAI2019)</span></h2><blockquote><p>Xu Geng(香港大学)<br>Yaguang Li(南加利福尼亚)<br>Lingyu Zhang(滴滴AI)<br>杨强(香港大学)<br>叶杰平(滴滴)</p></blockquote><p><img src="/2020/02/27/时空论文阅读笔记/ST_MGCN.png" alt=""></p><ul><li>问题：根据所有区域历史T个时间段的订单数，预测所有区域下一个时间段的订单数</li><li>将研究区域划分为网格，根据网格构建3个图，这3个图的图信号矩阵一样，只是邻接矩阵不一样。分别<ul><li><strong>邻居图</strong>（3*3网格，每个区域有8个邻居，2个区域是邻居，邻接矩阵为1，否则为0）；</li><li><strong>区域功能相似图</strong>（根据每个区域的POI，计算相似性，值在0&lt;=sim&lt;=1）；</li><li><strong>交通连通图</strong>（看2个区域是否在高速公路，公共交通等方式相连，相连为1，否则为0）</li></ul></li><li><strong>Channel-wise attention</strong>参考CV领域，图像输入$X \in \mathbb{R}^{W\times H \times C}$，计算每一个通道的权重$s$,然后再把输入和通道权重相乘$\tilde{\boldsymbol{X}}_{:,:,c}=\boldsymbol{X}_{:,:, c} \circ s_{c} \quad for \quad c=1,2, \cdots C$</li><li>一共有3类图，每类图的邻接矩阵不一样，图信号矩阵一样，表示该区域的订单数，图信号矩阵是动态的，每个时间段的图信号矩阵都不一样，一共有T个时间段。拿一个图距离，输入为(T,V,P),根据通道维的attention，<strong>这里将时间维作为通道维，对T个时间段做Attention</strong>，最终得到attention后的输入(T,V,P),然后输入到RNN中，因为RNN一次只能输入一个节点T个时间段的数据，但是这里有V个节点，这里V个节点共享一个RNN，最终得到隐藏状态，然后在把3个图的输出融合，得到最终的预测结果(所有区域下一个时间段的订单数)</li><li>T为5，根据ST_ResNet，其中3个邻近，1个天周期，1个周周期。</li></ul><h2><span id="34-passenger-demand-forecasting-with-multi-task-convolutional-recurrent-neural-networkspakdd2019">3.4. Passenger Demand Forecasting with Multi-Task Convolutional Recurrent Neural Networks(PAKDD2019)</span></h2><blockquote><p>Lei Bai1(University of New South Wales)<br>Lina Yao(University of New South Wales)<br>Salil S. Kanhere(University of New South Wales)</p></blockquote><ul><li>根据历史T个时间段<strong>相似区域</strong>出租车demand和人流量，预测下一个时间段中心区域的出租车demand。<strong>时间和空间都是多预测一</strong></li></ul><p><img src="/2020/02/27/时空论文阅读笔记/MT-CRNN.png" alt=""></p><ul><li>根据路网来划分区域</li><li>多任务预测：<ul><li><strong>主任务(回归)</strong>：预测中心区域的订单需求数</li><li><strong>辅助任务(分类)</strong>：预测中心区域的订单需求等级(高、中、低)</li></ul></li><li>主任务输入的是相似区域的订单数据和人流量数据，其中<strong>根据POI和taxi demand来计算2个区域的相似性</strong>，为中心区域选择m=3个最相似区域</li><li>使用外部信息(天气等)来预测订单需求等级(辅助任务)</li></ul><h2><span id="35-stg2seq-spatial-temporal-graph-to-sequence-model-for-multi-step-passenger-demand-forecasting2019ijcai">3.5. STG2Seq: Spatial-temporal Graph to Sequence Model for Multi-step Passenger Demand Forecasting(2019IJCAI)</span></h2><blockquote><p>Lei Bai1(University of New South Wales)<br>Lina Yao(University of New South Wales)<br>Salil S. Kanhere(University of New South Wales)</p></blockquote><ul><li>基于GCN，提出<strong>Seq2Seq的模型</strong>，来进行<strong>多步预测</strong>。本文说这是第一篇使用GCN来进行多步预测</li><li><p>大部分的研究只预测下一个时间段，本文预测多个时间段。以前的研究预测多个时间段使用seq2seq架构，里面是RNN或者其变体(ConvLSTM)，有个问题是：在decoder中，将前一个时间步的预测结果作为输入，会出现错误累积</p></li><li><p>将城市划分为N个小区域，基于网格或道路划分都可以</p></li><li><p>给定历史h个时间段的D(需求量，维度$N \times D_{in}$)和所有时间段的时间信息E，预测未来$\tau$个时间段的需求量<br><img src="/2020/02/27/时空论文阅读笔记/STG2Seq1.png" alt=""></p></li><li><p>图中每个节点表示一个小区域，图的邻接矩阵A中非0即1，根据区域demand的模式，计算2个区域的皮尔森相似度，如果相似度大于某个阈值，邻接矩阵为1，否则设置为0</p></li><li><p>模型主要有3个模块，假设预测时间段为$t+1,t+1,…,t+\tau$</p><ul><li>长期encoder：历史长期h个时间段，(h,N,D)</li><li>短期encoder：最近的q个时间段，(q,N,D)</li><li>Attention模块：在历史时间段中，找出对预测时间段的重要性</li></ul></li><li><p>长期encoder和短期encoder都是由GGCM组成，一个GGCM中有多个GCN。拿长期encoder举例，输入维度(h,N,D),每k个时间段(k,N,D)输入到GCN中，h个时间段一共有h-k+1个GCN，即经过一个GGCM，输入维度变成(h-k+1,N,D1)，每经过一个GGCM，时间维度都会变小，为了防止时间维度变小，会拼接上一个(k-1,N,D1)的全0padding，让其变成(h,N,D1)的维度，然后再输入到下一个GGCM中。<br>  <img src="/2020/02/27/时空论文阅读笔记/STG2Seq3.png" alt=""><br>  <img src="/2020/02/27/时空论文阅读笔记/STG2Seq4.png" alt=""></p></li><li>对于一个GCN中，输入维度是(k,N,D),reshape成(N,k*D),然后使用下面的公式。下面这个公式用到了残差连接，在经过GCN后，加上原来的$X^l$，同时和后面的sigmoid逐元素相乘，控制线性转换的哪部分可以通过门。<br><img src="/2020/02/27/时空论文阅读笔记/STG2Seq2.png" alt=""></li><li>在经过长期encoder和短期encoder后，将输出拼接，得到$(h+q,N,d_{out})$</li><li><strong>时间Attention</strong>：历史h+q个时间段对target时间段的影响不同，为了求出不同的影响程度，使用Attention机制。将$Y_{h+q}$reshape成$(h+q) \times (N \times d_{out})$<script type="math/tex; mode=display">\boldsymbol{\alpha}=\operatorname{softmax}\left(\tanh \left(Y_{h+q} W_{3}^{Y}+E_{T} W_{4}^{E}+b_{1}\right)\right)</script>其中$W_{3}^{Y} \in \mathbb{R}^{(h+q) \times\left(N \times d_{\text {out }}\right) \times 1}, W_{4}^{E} \in \mathbb{R}^{d_{e} \times(h+q)}$，$b_{1} \in \mathbb{R}^{(h+q)}$ 得到的Attention分数$\boldsymbol{\alpha} \in \mathbb{R}^{(h+q)}$<script type="math/tex; mode=display">Y_{\alpha}=\sum_{i=1}^{h+q} \alpha^{i} y_{i} \quad \in \mathbb{R}^{N \times d_{o u t}}</script></li><li><strong>通道Attention</strong>：经过上一步的时间Attention，得到的结果$Y_{\alpha}$维度为$N \times d_{out}$，然后再经过通道Attention，将$Y_{\alpha}$reshape成$N \times d_{out}$<script type="math/tex; mode=display">\boldsymbol{\beta}=\operatorname{softmax}\left(\tanh \left(Y_{\alpha} W_{5}^{Y}+E_{T} W_{6}^{E}+b_{2}\right)\right)</script>其中$W_{5}^{Y} \in \mathbb{R}^{d_{\text {out}} \times N \times 1}, W_{6}^{E} \in \mathbb{R}^{d_{e} \times d_{\text {out}}}, b_{2} \in \mathbb{R}^{d_{out}}$，$\boldsymbol{\beta} \in \mathbb{R}^{d_{\text {out }}}$<script type="math/tex; mode=display">Y_{\beta}=\sum_{i=1}^{d_{\text {out}}} \beta^{i} \mathscr{Y}_{i} \in \mathbb{R}^{N}</script></li><li>经过通道Attention，求得$Y_{\beta}$就是一个时间段的预测值</li></ul><p><strong>- 总结：</strong></p><ul><li>图的邻接矩阵非0即1，计算2个区域的相似度，大于阈值为1，否则为0</li><li>将历史时间段分为<strong>长期和短期</strong>，在历史时间段上设置一个<strong>长度为k的滑动窗口</strong>，每k个时间段都用不同的GCN来<strong>捕获空间关系</strong></li><li><strong>时间Attention</strong>：经过encoder后，将长期和短期的输出拼接，形成h+q个时间段，计算对target的时间段的时间Attention</li><li><strong>通道Attention</strong>：借鉴CV领域的思想《(CVPR2017)-Spatial and channel-wise attention in convolutional networks for image captioning》</li><li>使用GCN捕获空间相关性，然后分别使用时间Attention和通道Attention</li></ul><h1><span id="4-时间序列预测">4. 时间序列预测</span></h1><h2><span id="41-restful-resolution-aware-forecasting-of-behavioral-time-series-data2018cikm">4.1. RESTFul: Resolution-Aware Forecasting of Behavioral Time Series Data(2018CIKM)</span></h2><blockquote><p>吴宪(University of Notre Dame)<br>史宝旭(University of Notre Dame)<br>Yuxiao Dong(微软)<br>黄超(University of Notre Dame)</p></blockquote><p>本文使用<strong>多种时间粒度</strong>的<strong>时间序列数据</strong>来预测。<br>模型为<strong>RES</strong>olution-aware <strong>T</strong>ime <strong>S</strong>eries Forecasting (RESTFul)<br>第一个使用多种时间粒度来进行行为时间序列预测</p><p><img src="/2020/02/27/时空论文阅读笔记/RESTFul.png" alt=""></p><ul><li>有2个参数$\alpha和\beta$，取值{day,week}，限制α&gt;=β，<br>$\alpha$=1week,$\beta$=1day,表示1周测量1次，1次测1天。<br>$\alpha$=1week,$\beta$=1week,表示1周测量1次，1次测1周。<br>有一个完整的时间序列，要从中隔抽取不同时间粒度的时间序列。$X=\left[x_{1}, \ldots, x_{t}, \ldots, x_{T-1}, x_{T}\right]$，不同的$\alpha和\beta$就构成不同时间粒度的序列，序列长度为k，这里设置为5。</li><li>对于每一个时间序列都用GRU来捕获时间相关性，得到一个隐藏状态，那么n个时间序列就有n个隐藏状态</li><li>将所有的隐藏状态reshape成$\alpha <em> \beta </em> d$的张量，然后使用卷积融合不同粒度。</li><li>使用数据集：销售数据，311投诉数据</li></ul><h2><span id="42-multi-horizon-time-series-forecasting-with-temporal-attention-learningkdd2019">4.2. Multi-Horizon Time Series Forecasting with Temporal Attention Learning(KDD2019)</span></h2><blockquote><p>Chenyou Fan(京东金融)<br>Yuze Zhang(京东金融)<br>Yi Pan(京东金融)</p></blockquote><ul><li>使用前T个时间段的销售数据，预测未来<code>T&#39;</code>个时间段的销售数据</li><li>传统的encoder-decoder架构使用rnn,本文的一个改进是在decoder中使用BiLSTM</li></ul><p><img src="/2020/02/27/时空论文阅读笔记/BiLSTM-Enc-Dec.png" alt=""></p><p><img src="/2020/02/27/时空论文阅读笔记/BiLSTM-Enc-Dec1.png" alt=""></p><ul><li><strong>时间Attention</strong>:在decoder中第$t+1$个时间步生成的隐藏状态，对encoder中的隐藏状态进行attention，这里并不是对所有的历史时间段做attention，而是对历史$T_h$个时间段(可划分为M个period)做attention。例如上图中M=2，然后形成M个$c$向量，再经过FCN转换成$d$，然后再将M个$d$向量融合，这里使用attention融合，通过decoder的隐藏状态$h_{t+1}$对M个向量d做attention，将其融合成1个向量，然后再和$h_{t+1}$拼接，输入到FCN中预测第$t+1$个时间步的$y_{t+1}$，decoder中每个时间步都输出该时间步的预测值$y$。</li><li>本文的创新点就是：BILSTM和时间local Attention(只和局部时间段做Attention)</li></ul><h1><span id="5-总结">5. 总结</span></h1><h2><span id="51-网格gt图">5.1. 网格—&gt;图</span></h2><p>图用2个矩阵表示：图信号矩阵和邻接矩阵。由网格构建图时，节点表示区域，图信号矩阵就是区域的特征。重点是怎么构建邻接矩阵。</p><ul><li>《Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting》(AAAI2019)这篇文章构建了3个图：邻居图，POI功能相似图，交通连通图</li><li>《RiskOracle: A Minute-level Citywide Traffic Accident Forecasting Framework》(AAAI2020)有27*27个网格，但只有354个网格有道路，所以构建图中有354个节点。根据区域之间的道路静态信息和交通动态信息(flow和speed)来计算区域之间的相似性，构建邻接矩阵。由于动态交通信息随时间变化，所有每个时间段的相似性都不同，即每个时间段的邻接矩阵都不一样。<ul><li>图信号矩阵：区域的flow，speed、和前一个时间段的差值</li><li>邻接矩阵：区域之间的相似性，在[0,1]之间</li></ul></li></ul><p><strong>邻接矩阵的构造</strong></p><ul><li><p>邻接矩阵，非0即1，如果2个区域相邻，为1，否则为0<br>《Spatial-Temporal Synchronous Graph Convolutional Networks: A New Framework for Spatial-Temporal Network Data Forecasting》（AAAI2020）</p></li><li><p>计算2个区域的相似性，如果2个区域的相似度大于某个阈值，设置为1，否则为0<br>《STG2Seq: Spatial-temporal Graph to Sequence Model for Multi-step Passenger Demand Forecasting》（2019IJCAI）</p></li><li>计算2个区域的相似性，使用相似性作为邻接矩阵的值<br>《RiskOracle: A Minute-level Citywide Traffic Accident Forecasting Framework》（AAAI2020）</li><li>计算2个节点的相似性，为每个节点选取相似性前k的节点作为其一阶邻居，其余节点的相似性设置为0，例如《Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks》2020KDD</li></ul><h2><span id="52-动态图">5.2. 动态图</span></h2><p>一般的图卷积的输入维度是<code>(batch_size,N,C)</code>，即只有一个时间段，但如果输入的是动态图即<code>(batch_size,T,N,C)</code>，该怎么办？</p><script type="math/tex; mode=display">h^{(l)}=\left(\hat{A} h^{(l-1)} W_{1}+b_{1}\right)</script><ul><li><code>(batch_size,T,N,C)--&gt;(batch_size,T*N,C)--&gt;(T*N,batch_size,C)</code>,例如《Spatial-Temporal Synchronous Graph Convolutional Networks: A New Framework for Spatial-Temporal Network Data Forecasting》（AAAI2020）,将时间T乘到节点N上，需要对邻接矩阵进行变换成<code>(TN,TN)</code>的形式，才可以和h相乘。不常用，除非对邻接矩阵A进行变换</li><li><code>(batch_size,T,N,C)--&gt;(batch_size,N,T*C)</code>，可以先经过一个FCN，将其转换为<code>(batch_size,N,D)</code>,然后再输出到GCN中，也可以不经过FCN，直接输入到GCN中。较常用，例如：<br>《RiskOracle: A Minute-level Citywide Traffic Accident Forecasting Framework》（AAAI2020）<br>《STG2Seq: Spatial-temporal Graph to Sequence Model for Multi-step Passenger Demand Forecasting》（2019IJCAI）</li></ul><h2><span id="53-计算2个区域的相似性">5.3. 计算2个区域的相似性</span></h2><ul><li><p>用<strong>出租车需求量</strong>计算2个区域的<strong>相似性</strong>，用2个区域<strong>训练集</strong>中出租车需求量组成时间序列</p><ul><li>使用DTW计算2个序列的相似性，2个时间序列越相似，说明2个区域越相似。例如：《Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction》(AAAI2018)</li><li>使用皮尔森度量函数Pearson Correlation Coefficient，<br>《Passenger Demand Forecasting with Multi-Task Convolutional Recurrent Neural Networks》(2019PAKDD)<br>《STG2Seq: Spatial-temporal Graph to Sequence Model for Multi-step Passenger Demand Forecasting》（2019IJCAI）</li></ul></li><li><p>计算2个区域之间的<strong>相关性</strong>，使用<strong>区域间带有方向的traffic flow</strong>，如果2个区域之间的traffic flow越大，说明这2个区域越相关。但是《R evisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction》(AAAI2019)说这种相关性也是相似性。我觉得有问题，例如工作区和住宅区，2个区域的traffic flow很大，有很强的相关性，但是相似性并不强。</p></li><li>根据<strong>POI</strong>计算2个区域的相似性<ul><li>例如《Passenger Demand Forecasting with Multi-Task Convolutional Recurrent Neural Networks》(2019PAKDD)</li><li>《Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting》(2019AAAI)但是这篇文章没有提到使用什么函数来计算相似度</li></ul></li><li>《RiskOracle: A Minute-level Citywide Traffic Accident Forecasting Framework》(AAAI2020)根据区域的道路静态信息和交通动态信息(flow和speed)计算2个区域的相似性。使用JS散度</li></ul><h2><span id="54-poi">5.4. POI</span></h2><p>很多论文中都习惯将POI成为Semantic</p><ul><li>《Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction》(AAAI2018)</li><li>《DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis》(AAAI2019)</li></ul><h2><span id="55-时间相关性">5.5. 时间相关性</span></h2><p>像dayOfWeek，monthOfYear等时间信息，在论文中称作<strong>time meta feature</strong></p><ul><li>使用RNN来捕获时间相关性</li><li>使用1D卷积来捕获时间相关性，或者使用1D空洞卷积，来捕获长期的时间相关性。或者参照Inception结构，使用不同大小的卷积核来捕获不同粒度的周期性，例如WaveNet，MTGNN</li><li>使用不同的模块捕获不同粒度的周期性，例如ST-ResNet，DeepSTN，ASTGCN</li></ul><h2><span id="56-lstm共t个隐藏状态整合">5.6. LSTM共T个隐藏状态整合</span></h2><p>LSTM一共有T个时间步，将输出T个隐藏状态，怎么将其整合成1个，有3种方法：</p><ul><li>只取最后一个时间步的隐藏状态，例如<br>《Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction》(AAAI2018)</li><li>将T个时间步的隐藏状态拼接或平均或加和</li><li>将T个时间步的隐藏状态和被预测时间步的某个向量(e.g.外部因素)做Attention，对每个时间步赋予不同的权重，整合成1个向量。例如<br>《Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction》(AAAI2019)<br>《When Will You Arrive? Estimating Travel Time Based on Deep Neural Networks》(AAAI20)</li></ul><h2><span id="57-外部因素嵌入">5.7. 外部因素嵌入</span></h2><p>外部因素包括：天气，时间，holiday等信息，</p><ul><li>外部因素中<strong>类别值</strong>(dayOfWeek，weather等)用one-hot表示，<strong>连续值</strong>(温度，风速)等用float表示，将这些外部因素拼接在一起，送入FCN中做嵌入。<br>例如《 Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction(AAAI2017)》</li><li>外部因素中<strong>类别值</strong>(dayOfWeek，weather等)直接用数字表示，例如周一用0表示，周日用6表示。<strong>连续值</strong>(温度，风速)等用float表示，然后将每个类别值用对应的Embedding嵌入，然后再把嵌入的结果拼接<br>例如《When Will You Arrive? Estimating Travel Time Based on Deep Neural Networks(AAAI20)》<br><code>Embedding</code>相关知识参考<a href="https://echohhhhhh.github.io/2020/02/24/Pytorch%E4%B9%8B%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/#12-embedding" target="_blank" rel="noopener">Pytorhc之Embedding</a></li></ul><h2><span id="58-mask">5.8. mask</span></h2><p>有时候mask是舍弃一些不想关注的值，比如预测车流量时，真实车流量小于5的值则舍弃，即不关注那些车流量小的值预测结果，只关注大约5的值的预测结果。一般在评价指标中mask</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mask_mae_np</span><span class="params">(y_true,y_pred,region_mask,null_val=None)</span>:</span></span><br><span class="line">    <span class="string">"""计算MAE</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">        y_true &#123;np.ndarray&#125; -- 真实值,维度(samples,pre_len,W,H)</span></span><br><span class="line"><span class="string">        y_pred &#123;np.ndarray&#125; -- 预测值,维度(samples,pre_len,W,H)</span></span><br><span class="line"><span class="string">        region_mask &#123;np.ndarray&#125; -- mask矩阵,维度(W,H)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        np.float64 -- MAE值</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    y_true,y_pred = transfer_dtype(y_true,y_pred)</span><br><span class="line">    <span class="keyword">if</span> null_val <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">        label_mask = np.where(y_true &gt; <span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>).astype(<span class="string">'float32'</span>)</span><br><span class="line">        <span class="comment"># label_mask = np.not_equal(y_true, null_val).astype('float32')</span></span><br><span class="line">        mask = region_mask * label_mask</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        mask = region_mask</span><br><span class="line">    mask /= mask.mean()</span><br><span class="line">    <span class="keyword">return</span> np.mean(np.abs(y_true-y_pred)*mask)</span><br></pre></td></tr></table></figure><h2><span id="59-max-min归一化">5.9. Max-min归一化</span></h2><p>使用Max-Min将数据归一化到[0,1]，但是也有论文归一化成[-1,1]，如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MinMaxNormalization</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">'''MinMax Normalization --&gt; [-1, 1]</span></span><br><span class="line"><span class="string">       x = (x - min) / (max - min).</span></span><br><span class="line"><span class="string">       x = x * 2 - 1</span></span><br></pre></td></tr></table></figure><p>【注意】对特征和y归一化有2种方式：</p><ol><li><strong>只对特征进行归一化，y不进行归一化</strong>，模型预测的结果和真实y是同一量纲，模型的loss会偏大，计算评价指标时，不需要反归一化</li><li><strong>对特征和y都归一化</strong>，y归一化到[0,1]之间，在计算loss时，不需要反归一化，loss相对方法1会偏小，在计算评价指标时，需要对真实y和预测y进行反归一化，再计算MAE等指标</li><li><p>关于上面是否需要对y进行归一化。如果模型收敛(loss一直在下降)，可以不对y进行归一化。如果模型不收敛(数值过大)，则需要对y进行归一化。</p><p><img src="/2020/02/27/时空论文阅读笔记/神经网络踩坑/y-norm.png" alt=""><br>如果对y进行归一化，loss初始值很小，模型训练时很快就会收敛loss不再下降。不对y归一化，loss初始值很大，在训练过程中，训练很多轮loss才开始收敛，可能还会造成训练过程不稳定，loss上下震荡。</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;因为疫情推迟开学，在家把以前看的论文又看了一遍，每重新看一次都有新的收获，在此整理下。&lt;/p&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="时空领域" scheme="http://yoursite.com/tags/%E6%97%B6%E7%A9%BA%E9%A2%86%E5%9F%9F/"/>
    
  </entry>
  
  <entry>
    <title>VSCode连接服务器太慢</title>
    <link href="http://yoursite.com/2020/02/26/VSCode%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%A4%AA%E6%85%A2/"/>
    <id>http://yoursite.com/2020/02/26/VSCode连接服务器太慢/</id>
    <published>2020-02-26T09:59:55.000Z</published>
    <updated>2020-02-26T12:26:38.519Z</updated>
    
    <content type="html"><![CDATA[<p>使用VSCode远程连接服务器太慢，是因为需要远程下载vscode-server-linux-x64.tar.gz，下载太慢，下面是解决方案</p><a id="more"></a><p><img src="/2020/02/26/VSCode连接服务器太慢/vscode.png" alt=""></p><p><a href="https://blog.csdn.net/bcfd_yundou/article/details/96135456" target="_blank" rel="noopener">vscode搭建远程开发</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">先将vscode-server-linux-x64.tar.gz拷贝到/data/WangBeibei/.vscode-server/bin/xxx下面，并解压</span></span><br><span class="line">tar -xzvf vscode-server-linux-x64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">删掉压缩包</span></span><br><span class="line">rm -r vscode-server-linux-x64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">将vscode-server-linux-x64目录中所有内容移到/data/WangBeibei/.vscode-server/bin/xxx下面</span></span><br><span class="line">mv /data/WangBeibei/.vscode-server/bin/xxx/vscode-server-linux-x64/* /data/WangBeibei/.vscode-server/bin/xxx</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">删掉vscode-server-linux-x64</span></span><br><span class="line">rm -r vscode-server-linux-x64</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用VSCode远程连接服务器太慢，是因为需要远程下载vscode-server-linux-x64.tar.gz，下载太慢，下面是解决方案&lt;/p&gt;
    
    </summary>
    
      <category term="工具" scheme="http://yoursite.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="VSCode" scheme="http://yoursite.com/tags/VSCode/"/>
    
  </entry>
  
  <entry>
    <title>对loss进行mask</title>
    <link href="http://yoursite.com/2020/02/25/%E5%AF%B9loss%E8%BF%9B%E8%A1%8Cmask/"/>
    <id>http://yoursite.com/2020/02/25/对loss进行mask/</id>
    <published>2020-02-25T05:37:12.000Z</published>
    <updated>2020-03-06T16:32:42.950Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="简介">简介</span></h1><p>在计算loss和评价指标时，对一些不关注的值进行mask。下面介绍mask的使用。</p><a id="more"></a><h1><span id="对loss进行mask">对loss进行mask</span></h1><p>在NLP中的Seq2Seq中经常会对loss进行mask，因为一个batch中句子的长度通常不一样，一个batch中不足长度的位置用0填充，最后生成句子计算loss时需要忽略掉原先那些padding的值，即只保留mask中值为1的位置，忽略值为0的位置。在计算loss时，将那些本不应该计算的mask掉，使其loss为0，这样就不会反向传播了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">masked_predicts = torch.masked_select(predicts, mask)</span><br><span class="line">masked_targets = torch.masked_select(targets, mask)</span><br><span class="line">loss = my_criterion(masked_predicts, masked_targets)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">diff2 = (torch.flatten(input) - torch.flatten(target)) ** <span class="number">2.0</span> * torch.flatten(mask)</span><br><span class="line">loss = torch.sum(diff2) / torch.sum(mask)</span><br><span class="line">out.backward()</span><br></pre></td></tr></table></figure><p>有时候mask是舍弃一些不想关注的值，比如预测车流量时，真实车流量小于5的值则舍弃，即不关注那些车流量小的值预测结果，只关注大约5的值的预测结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">masked_mean_squared_error</span><span class="params">(y_true, y_pred)</span>:</span></span><br><span class="line">    idx = (y_true &gt; <span class="number">5</span>).nonzero()</span><br><span class="line">    <span class="keyword">return</span> K.mean(K.square(y_pred[idx] - y_true[idx]))</span><br></pre></td></tr></table></figure><h1><span id="pytorch的mask_select函数">Pytorch的mask_select函数</span></h1><p><code>torch.masked_select(input, mask, out=None) → Tensor</code><br>返回1-D的Tensor</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">tensor([[ <span class="number">0.3552</span>, <span class="number">-2.3825</span>, <span class="number">-0.8297</span>,  <span class="number">0.3477</span>],</span><br><span class="line">        [<span class="number">-1.2035</span>,  <span class="number">1.2252</span>,  <span class="number">0.5002</span>,  <span class="number">0.6248</span>],</span><br><span class="line">        [ <span class="number">0.1307</span>, <span class="number">-2.0608</span>,  <span class="number">0.1244</span>,  <span class="number">2.0139</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mask = x.ge(<span class="number">0.5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mask</span><br><span class="line">tensor([[<span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">False</span>],</span><br><span class="line">        [<span class="keyword">False</span>, <span class="keyword">True</span>, <span class="keyword">True</span>, <span class="keyword">True</span>],</span><br><span class="line">        [<span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">True</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.masked_select(x, mask)</span><br><span class="line">tensor([ <span class="number">1.2252</span>,  <span class="number">0.5002</span>,  <span class="number">0.6248</span>,  <span class="number">2.0139</span>])</span><br></pre></td></tr></table></figure><p>【参考资料】</p><p><a href="http://www.linzehui.me/2018/10/12/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%B5%85%E8%B0%88mask%E7%9F%A9%E9%98%B5/" target="_blank" rel="noopener">浅谈mask矩阵</a><br><a href="https://github.com/xlwang233/pytorch-DCRNN/blob/master/lib/metrics.py" target="_blank" rel="noopener">pytorch-DCRNN</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;p&gt;在计算loss和评价指标时，对一些不关注的值进行mask。下面介绍mask的使用。&lt;/p&gt;
    
    </summary>
    
      <category term="Deep Learning" scheme="http://yoursite.com/categories/Deep-Learning/"/>
    
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch之知识点汇总</title>
    <link href="http://yoursite.com/2020/02/24/Pytorch%E4%B9%8B%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/"/>
    <id>http://yoursite.com/2020/02/24/Pytorch之知识点汇总/</id>
    <published>2020-02-24T09:08:12.000Z</published>
    <updated>2020-07-08T03:23:00.354Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="1-简介">1. 简介</span></h1><p>汇总Pytorch的一些知识点</p><a id="more"></a><!-- TOC --><ul><li><a href="#1-简介">1. 简介</a></li><li><a href="#2-查看网络参数">2. 查看网络参数</a></li><li><a href="#3-分类问题">3. 分类问题</a></li><li><a href="#4-crossentropyloss和nllloss-区别">4. CrossEntropyLoss()和NLLLoss() 区别</a></li><li><a href="#5-模型训练示例">5. 模型训练示例</a></li><li><a href="#6-关闭梯度">6. 关闭梯度</a></li><li><a href="#7-gpu">7. GPU</a></li><li><a href="#8-多gpu运行程序">8. 多GPU运行程序</a></li><li><a href="#9-tensor">9. Tensor</a></li><li><a href="#10-bn和dropout在训练和测试的不同">10. BN和Dropout在训练和测试的不同</a></li><li><a href="#11-linear">11. Linear</a></li><li><a href="#12-embedding">12. Embedding</a></li><li><a href="#13-linear参数维度">13. Linear参数维度</a></li></ul><!-- /TOC --><h1><span id="2-查看网络参数">2. 查看网络参数</span></h1><ul><li><p>方法1</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> network.parameters():</span><br><span class="line">  print(param.shape)</span><br></pre></td></tr></table></figure></li><li><p>方法2<br>可以查看参数的名称</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> network.named_parameters():</span><br><span class="line">  print(name, <span class="string">'\t\t'</span>, param.shape)</span><br></pre></td></tr></table></figure></li></ul><h1><span id="3-分类问题">3. 分类问题</span></h1><p>例如Fashion-MNIST分类任务中，一共有10类。假设batch_size=16,每个batch的feature维度为(16,1,28,28)，label的维度(16,)，经过模型最终输出的预测结果维度(16,10)，然后我们使用<code>argmax()</code>来得出最终的预测类别。然后可以和真实label比较，看预测结果的正确性,计算预测正确的个数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&gt; preds.argmax(dim=<span class="number">1</span>)</span><br><span class="line">tensor([<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">&gt; labels</span><br><span class="line">tensor([<span class="number">9</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">7</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">&gt; preds.argmax(dim=<span class="number">1</span>).eq(labels)</span><br><span class="line">tensor([<span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">True</span>, <span class="keyword">False</span>], dtype=torch.bool)</span><br><span class="line"></span><br><span class="line">&gt; preds.argmax(dim=<span class="number">1</span>).eq(labels).sum()</span><br><span class="line">tensor(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">&gt; preds.argmax(dim=<span class="number">1</span>).eq(labels).sum().item()</span><br><span class="line"><span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#得到每个batch预测正确的样本</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_num_correct</span><span class="params">(preds, labels)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> preds.argmax(dim=<span class="number">1</span>).eq(labels).sum().item()</span><br></pre></td></tr></table></figure><h1><span id="4-crossentropyloss和nllloss-区别">4. CrossEntropyLoss()和NLLLoss() 区别</span></h1><p><code>CrossEntropyLoss()=log_softmax() + NLLLoss()</code></p><p><a href="https://blog.csdn.net/zwqjoy/article/details/96282788" target="_blank" rel="noopener">Pytorch nn.CrossEntropyLoss()和nn.NLLLoss() 区别</a></p><p><a href="https://www.cnblogs.com/marsggbo/p/10401215.html" target="_blank" rel="noopener">Pytorch里的CrossEntropyLoss详解</a>  </p><p><a href="https://www.zhihu.com/question/66782101" target="_blank" rel="noopener">PyTorch 中，nn 与 nn.functional 有什么区别</a></p><h1><span id="5-模型训练示例">5. 模型训练示例</span></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">network = Network()</span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_set, batch_size=<span class="number">100</span>)</span><br><span class="line">optimizer = optim.Adam(network.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    </span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    total_correct = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> train_loader: <span class="comment"># Get Batch</span></span><br><span class="line">        images, labels = batch </span><br><span class="line"></span><br><span class="line">        preds = network(images) <span class="comment"># Pass Batch</span></span><br><span class="line">        loss = F.cross_entropy(preds, labels) <span class="comment"># Calculate Loss</span></span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward() <span class="comment"># Calculate Gradients</span></span><br><span class="line">        optimizer.step() <span class="comment"># Update Weights</span></span><br><span class="line"></span><br><span class="line">        total_loss += loss.item()</span><br><span class="line">        total_correct += get_num_correct(preds, labels)</span><br><span class="line"></span><br><span class="line">    print(</span><br><span class="line">        <span class="string">"epoch"</span>, epoch, </span><br><span class="line">        <span class="string">"total_correct:"</span>, total_correct, </span><br><span class="line">        <span class="string">"loss:"</span>, total_loss</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><h1><span id="6-关闭梯度">6. 关闭梯度</span></h1><p>关闭梯度有2种方法</p><ul><li><p>方法1：在模型训练的时候，需要计算梯度，但是在测试的时候不需要计算梯度，那我们就可以使用<code>@torch.no_grad()</code>。下面代码示例求所有的预测结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@torch.no_grad()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_all_preds</span><span class="params">(model, loader)</span>:</span></span><br><span class="line">    all_preds = torch.tensor([])</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> loader:</span><br><span class="line">        images, labels = batch</span><br><span class="line">        preds = model(images)</span><br><span class="line">        all_preds = torch.cat(</span><br><span class="line">            (all_preds, preds),dim=<span class="number">0</span>)</span><br><span class="line">  <span class="keyword">return</span> all_preds</span><br></pre></td></tr></table></figure></li></ul><p>使用<code>@torch.no_grad()</code>就不用再记录梯度的轨迹(不用再保存动态图的计算轨迹)，省内存。</p><ul><li><p>方法2：<br>使用<code>with torch.no_grad()</code>在函数内部</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">  prediction_loader = torch.utils.data.DataLoader(train_set, batch_size=<span class="number">10000</span>)</span><br><span class="line">  train_preds = get_all_preds(network, prediction_loader)</span><br></pre></td></tr></table></figure></li></ul><h1><span id="7-gpu">7. GPU</span></h1><p>在这里原先一直有个误区，误认为<code>device = torch.device(&quot;cuda&quot;)</code>获取所有的GPU，<code>device = torch.device(&quot;cuda:0&quot;)</code>获取第一个GPU。下面是正解：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#程序只能看到1,2,3序号的GPU，然后重新给它们编号为：0,1,2</span></span><br><span class="line">&gt; os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">'1,2,3'</span></span><br><span class="line"></span><br><span class="line">&gt; device = torch.device(<span class="string">"cuda:0"</span>)<span class="comment">#获取下标为0的GPU</span></span><br><span class="line">device(type=<span class="string">'cuda'</span>, index=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#如果不指定cuda编号，其实有一个默认编号，</span></span><br><span class="line"><span class="comment">#默认为torch.cuda.current_device()，该值默认为0</span></span><br><span class="line">&gt; device = torch.device(<span class="string">"cuda"</span>)</span><br><span class="line">device(type=<span class="string">'cuda'</span>)</span><br><span class="line"></span><br><span class="line">&gt; torch.cuda.current_device()</span><br><span class="line"><span class="number">0</span></span><br></pre></td></tr></table></figure><p>也就是说<code>device = torch.device(&quot;cuda&quot;)</code>还是1个GPU，等价于<code>device = torch.device(&quot;cuda:X&quot;)</code>,其中<code>X = torch.cuda.current_device()</code>  </p><p>【<strong>参考资料</strong>】</p><p><a href="https://pytorch.apachecn.org/docs/1.0/tensor_attributes.html" target="_blank" rel="noopener">torch.device</a></p><p><a href="https://pytorch.org/docs/stable/notes/cuda.html" target="_blank" rel="noopener">CUDA SEMANTICS</a></p><h1><span id="8-多gpu运行程序">8. 多GPU运行程序</span></h1><p><a href="https://echohhhhhh.github.io/2020/01/06/Pytorch%E4%B9%8BGPU%E7%A8%8B%E5%BA%8F/" target="_blank" rel="noopener">Pytorch之GPU程序</a></p><p><a href="https://echohhhhhh.github.io/2019/12/29/%E8%BF%90%E8%A1%8CGPU%E7%A8%8B%E5%BA%8F/" target="_blank" rel="noopener">运行GPU程序</a></p><h1><span id="9-tensor">9. Tensor</span></h1><p><a href="https://echohhhhhh.github.io/2020/02/17/Pytorch%E4%B9%8BTensor%E5%AD%A6%E4%B9%A0/" target="_blank" rel="noopener">Pytorch之Tensor学习</a></p><h1><span id="10-bn和dropout在训练和测试的不同">10. BN和Dropout在训练和测试的不同</span></h1><p><code>model.train()</code>:启用 BatchNormalization 和 Dropout<br><code>model.eval()</code>:不启用 BatchNormalization 和 Dropout<br>训练完train样本后，生成的模型model要用来测试样本。在model(test)之前，需要加上model.eval()，否则的话，有输入数据，即使不训练，它也会改变权值。这是model中含有batch normalization层所带来的的性质。</p><p>参考资料<br><a href="https://zhuanlan.zhihu.com/p/54986509" target="_blank" rel="noopener">Pytorch model.train 与 model.eval</a><br><a href="https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615/19" target="_blank" rel="noopener">‘model.eval()’ vs ‘with torch.no_grad()’</a><br><a href="https://github.com/pytorch/examples/blob/master/word_language_model/main.py" target="_blank" rel="noopener">https://github.com/pytorch/examples/word_language_model</a></p><h1><span id="11-linear">11. Linear</span></h1><p>原先误以为Pytorch中的Linear的输入只能接受二维数据，实际上Linear的输入数据可以是三维、四维等更多维。但是<strong>输入数据的最后一维一定要和<code>in_dim</code>一致，输出数据维度就是把<code>in_dim</code>换成了<code>out_dim</code>，前面所有的维度都不变</strong>。<br>例如定义一个全连接<code>nn.Linear(10,5)</code>，输入数据维度为(3,6,10),输出维度为(3,6,5)。即输入数据最后一个维度一定要和<code>in_dim</code>一致，也不用纠结到底3是batch_size,还是6是batch_size，因为最终输出的数据只有最后一个维度变化，前面维度都不变。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dense = nn.Linear(in_dim,out_dim)</span><br></pre></td></tr></table></figure><hr><p>2020.3.7更新</p><h1><span id="12-embedding">12. Embedding</span></h1><p><code>Embedding</code>层常用在词嵌入中，目的是将高维数据变成稠密的低维数据。例如：字典共9个字：[我,你,看,吃,吧,吗,饭,了,的]，例句：吃饭了吗，对这句话用向量表示有2种方式：</p><ul><li>one-hot表示<br>[0,0,0,1,0,0,0,0,0],<br>[0,0,0,0,0,0,1,0,0],<br>[0,0,0,0,0,0,0,1,0],<br>[0,0,0,0,0,1,0,0,0]<br>one-hot表示过于稀疏，如果字典中的层变大，维度会非常高</li><li><p>使用<code>Embedding</code>,字典中共有9个字，下标从0~8，例句被表示为[3,6,7,5],但是只用数字并不能表示字的含义和相似度，下面使用Embedding对其嵌入。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># example with padding_idx</span></span><br><span class="line">embedding = nn.Embedding(<span class="number">9</span>, <span class="number">3</span>)</span><br><span class="line">input = torch.LongTensor([[<span class="number">3</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">5</span>]])</span><br><span class="line">embedding(input)</span><br><span class="line">tensor([[[ <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>],</span><br><span class="line">       [ <span class="number">0.1535</span>, <span class="number">-2.0309</span>,  <span class="number">0.9315</span>],</span><br><span class="line">       [ <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>],</span><br><span class="line">       [<span class="number">-0.1655</span>,  <span class="number">0.9897</span>,  <span class="number">0.0635</span>]]])</span><br></pre></td></tr></table></figure><blockquote><p>CLASS torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None)</p></blockquote><p><strong>num_embeddings</strong>：原始数据维度，例如字典中有9个字，该值为9<br><strong>embedding_dim</strong>：嵌入维度，每个字用3维向量表示，该值为3<br><strong>输入维度</strong>：(<em>)任意维度<br><strong>输出维度</strong>：(\</em>,embedding_dim)，*表示输入维度<br>例如输入维度(16,100),输出为(16,100,3)，表示有16个句子，每个句子100个字，经过Embedding层后，有16个句子，每个句子100个字，每个字用3维特征表示。</p><p>在时空领域中，经常需要考虑外部因素，例如时间，天气，holiday等，需要对外部因素进行Embedding，例如<a href="https://github.com/UrbComp/DeepTTE" target="_blank" rel="noopener">https://github.com/UrbComp/DeepTTE</a></p></li></ul><hr><p>2020.7.8更新</p><h1><span id="13-linear参数维度">13. Linear参数维度</span></h1><p>做全连接时，我们平时看到的公式有以下形式：<br>$Y=XW+b$<br>$Y=XW^T+b$<br>$Y=W^TX+b$</p><p>因为不同的公式，此时的$W$形状也不同，假设$X\in\mathbb{R}^{100\times2}$表示100个样本，每个样本有2维，假设输出维度5<br>$y=XW+b$，$W\in\mathbb{R}^{2\times5}$<br>$y=XW^T+b$，$W\in\mathbb{R}^{5\times2}$<br>$y=W^TX+b$，对于这种情况，默认$X$中每个样本是列向量，即$X\in\mathbb{R}^{2\times100}$，$W\in\mathbb{R}^{5\times2}$</p><p>在Pytorch中的<code>Linear</code>中采用的是公式2，参数形状$W\in\mathbb{R}^{输出维度\times输入维度}$</p><p>但在实际使用中，为了方便，一般用公式1，此时$W\in\mathbb{R}^{输入维度\times输出维度}$</p><p>在写公式时，需要注意公式的大写还是小写</p><p>$Y=XW+b$这里的$X,Y$表示所有样本<br>$y=xW+b$这里的$x,y$表示一个样本<br>但这两种情况中，$W$始终是大写</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-简介&quot;&gt;&lt;a href=&quot;#1-简介&quot; class=&quot;headerlink&quot; title=&quot;1. 简介&quot;&gt;&lt;/a&gt;1. 简介&lt;/h1&gt;&lt;p&gt;汇总Pytorch的一些知识点&lt;/p&gt;
    
    </summary>
    
      <category term="Deep Learning" scheme="http://yoursite.com/categories/Deep-Learning/"/>
    
    
      <category term="Pytorch" scheme="http://yoursite.com/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>RiskOracle-A Minute-level Citywide Traffic Accident Forecasting Framework</title>
    <link href="http://yoursite.com/2020/02/18/RiskOracle-A-Minute-level-Citywide-Traffic-Accident-Forecasting-Framework/"/>
    <id>http://yoursite.com/2020/02/18/RiskOracle-A-Minute-level-Citywide-Traffic-Accident-Forecasting-Framework/</id>
    <published>2020-02-18T03:34:20.000Z</published>
    <updated>2020-04-03T16:06:10.102Z</updated>
    
    <content type="html"><![CDATA[<p>AAAI2020原文链接：<a href="https://github.com/zzyy0929/AAAI2020-RiskOracle" target="_blank" rel="noopener">RiskOracle-A Minute-level Citywide Traffic Accident Forecasting Framework</a><br>中国科大发<br><a id="more"></a></p><!-- TOC --><ul><li><a href="#1-%e6%91%98%e8%a6%81">1. 摘要</a></li><li><a href="#2-%e4%bb%8b%e7%bb%8d">2. 介绍</a></li><li><a href="#%e8%b4%a1%e7%8c%ae">贡献</a></li><li><a href="#3-%e9%97%ae%e9%a2%98%e5%ae%9a%e4%b9%89">3. 问题定义</a></li><li><a href="#4-minute-level-real-time-traffic-accident-forecasting">4. Minute-level Real-time Traffic Accident Forecasting</a><ul><li><a href="#41-framework-overview">4.1. Framework Overview</a></li><li><a href="#42-data-preprocessing">4.2. Data Preprocessing</a></li><li><a href="#43-multi-task-dtgn-for-accident-risk-prediction">4.3. Multi-task DTGN for Accident Risk Prediction</a></li></ul></li><li><a href="#5-%e5%ae%9e%e9%aa%8c">5. 实验</a><ul><li><a href="#51-%e6%95%b0%e6%8d%ae%e5%87%86%e5%a4%87">5.1. 数据准备</a></li><li><a href="#52-%e5%ae%9e%e7%8e%b0%e7%bb%86%e8%8a%82">5.2. 实现细节</a></li><li><a href="#53-%e8%af%84%e4%bb%b7%e6%8c%87%e6%a0%87">5.3. 评价指标</a></li><li><a href="#54-baseline">5.4. Baseline</a></li><li><a href="#55-%e5%ae%9e%e9%aa%8c%e7%bb%93%e6%9e%9c">5.5. 实验结果</a></li><li><a href="#56-%e8%b6%85%e5%8f%82%e6%95%b0">5.6. 超参数</a></li><li><a href="#57-%e6%a1%88%e4%be%8b%e5%88%86%e6%9e%90">5.7. 案例分析</a></li></ul></li><li><a href="#6-%e6%80%bb%e7%bb%93">6. 总结</a></li><li><a href="#7-%e7%9f%a5%e8%af%86%e8%a1%a5%e5%85%85">7. 知识补充</a></li></ul><!-- /TOC --><p>论文总结：</p><ol><li>根据网格构建图，将NYC划分了27*27个网格，但是其中只有354个网格有道路，所以图中有354个节点。</li><li>根据网格之间道路相似性和历史一周交通的动态相似性来构建图中边的权重。构建的是全连通图，计算任意2个子区域的相似性</li><li>多任务学习。主任务：预测m个子区域的risk，辅助任务1：预测m个子区域的flow，辅助任务2：预测q个中等区域的事故次数count</li><li>在训练时，将risk=0替换为对应的负值，使用全部的数据。在测试时，只计算高频时间段和高频区域的评价指标</li></ol><h1><span id="1-摘要">1. 摘要</span></h1><p>&ensp;&ensp;&ensp;&ensp;实时交通事故预测对公共安全和城市管理意义重大（例如.实时路径规划和应急响应部署）。之前的事故预测是在小时级别上，利用神经网络和静态的区域关系。然而，随着道路网络的高度动态性和交通师傅的稀有性，提高预测的粒度仍然是一个挑战，这将会导致结果偏差和零膨胀问题。在这篇论文中，我们提出一个新颖的RiskOracle框架，提高预测的粒度到分钟级别。具体来说，我们首先将0风险值转换为适合网络训练的值，然后，我们提出差分时变图神经网络(DTGN)来捕获交通状态的即时变化和子区间之间的动态相关性，并且，我们采用多任务和区域选择方案来突出显示全市范围内最可能发生事故的子区域，弥合了偏差的风险值和稀疏的事故分布。在2个真实数据集上做了大量实验证明了我们的RiskOracle框架的有效性和可扩展性。</p><h1><span id="2-介绍">2. 介绍</span></h1><p>&ensp;&ensp;&ensp;&ensp;交通事故预测对城市安全非常重要。构建一个细粒度级的事故预测模型，为乘客提供及时的安全路径规划，为新兴应用(智能交通和自动驾驶)提供准确的应急响应的需求越来越大。<br>&ensp;&ensp;&ensp;&ensp;关于事故预测周期的长短，现有的工作主要分为2类：长期（天级别预测）和中期（小时级别预测）。我们在表1中总结了所有相关的工作。即使最近关于天级别的预测模型通过建模时空异质数据取得了很好的效果，但是对于紧急的情况并没有意义。<br>&ensp;&ensp;&ensp;&ensp;在小时级别上的中期事故预测可以进一步划分为：传统方法和深度学习。传统方法包括：基于聚类，基于频率树，基于非负矩阵分解。但是，这些方法忽略了时间关系，不能建模复杂非线性的时空关系。深度学习方法例如，仅仅将历史交通事故数据输入到模型中，利用LSTM学习时间相关性，缺少了多源实时交通数据，效果不好。还有一些工作利用深度学习框架SDAE/SDCAE和ConvLSTM，结合人类实时移动数据，来学习交通事故模式，但是它们都不能提取区域间和区域内随时间变化的关系。<br>&ensp;&ensp;&ensp;&ensp;即使深度学习模型的进展为小时级别的事故预测带了可喜的结果，但是我们认为其忽略了3个重要的问题，使得在分钟级别的预测效果较差。第一，在2019中提到的，当预测任务的时空分辨率提高时，会出现零膨胀问题，将预测所有的结果都为0。由于没有方法来解决这个问题，稀少的非零值在训练时使模型无法生效。第二，尽管CNN可以学习静态的子区域相关性，但是随时间变化的子区域相关性在城市短期事故预测有着重要的作用，例如，由于潮汐流，2个子区域在早上相关性强，在下午相关性弱。第三，在同一子区域相邻时间段内交通状况的异常变化通常会诱发交通事故或其他事件。没有考虑以上3个时空因素，小时级别的预测模型能力将受到严重阻碍。</p><p><img src="/2020/02/18/RiskOracle-A-Minute-level-Citywide-Traffic-Accident-Forecasting-Framework/Summarization.png" alt=""></p><p>表中的论文<br><a href="https://echohhhhhh.github.io/2019/07/21/traffic-accident/#11-learning-deep-representation-from-big-and-heterogeneous-data-for-traffic-accident-inference2016aaai" target="_blank" rel="noopener">Learning Deep Representation from Big and Heterogeneous Data for Traffic Accident Inference(2016AAAI)</a></p><p><a href="https://echohhhhhh.github.io/2019/07/21/traffic-accident/#14-a-deep-learning-approach-to-the-citywide-traffic-accident-risk-prediction2018ieee-itsc" target="_blank" rel="noopener">A Deep Learning Approach to the Citywide Traffic Accident Risk Prediction(2018IEEE-ITSC)</a></p><p><a href="http://tony.9shi.cf/index.php?q=aHR0cHM6Ly93d3cua2RkLm9yZy9rZGQyMDE4L2FjY2VwdGVkLXBhcGVycy92aWV3L2hldGVyby1jb252bHN0bS1hLWRlZXAtbGVhcm5pbmctYXBwcm9hY2gtdG8tdHJhZmZpYy1hY2NpZGVudC1wcmVkaWN0aW9uLW9uLQ" target="_blank" rel="noopener">Hetero-ConvLSTM: A Deep Learning Approach to Traffic Accident Prediction on Heterogeneous Spatio-Tem(2018KDD)</a></p><p>&ensp;&ensp;&ensp;&ensp;这篇论文，我们研究了分钟级别的全市交通事故预测，提出了三阶段RiskOracle框架，该框架基于多任务差分时变图卷积(Multi-task DTGN)。三个阶段分别是：数据预处理阶段，训练阶段，预测阶段。在数据预处理阶段，我们提出一个感知策略以最大程度地推断全球交通状况，然后设计基于数据增强的先验知识来解决短期预测中的零膨胀问题。在训练阶段，我们提出Multi-task DTGN，其中时变总体上建模了短期子区域的动态相关性，差分特征生成器在交通状态即时变化和交通事故之间建立了高级联系。正如我们所知，交通事故和交通量在城市中通常分布不均衡，因此多任务方案旨在解决事故预测中的空间异质性，然后在预测阶段，我们利用学到的多尺度事故分布，获取到一组离散的最可能发生事故的子区域。在2个真实数据集上的实验证明了我们的框架在10-min和30-min级别的预测任务上都超过了state-of-the-art。</p><h1><span id="贡献">贡献</span></h1><ul><li>提升实时事故预测的时间粒度，从小时—&gt;分钟</li><li>提出多任务STDN来解决短期事故预测的挑战。这是第一篇使用图卷积来解决事故预测问题</li><li>距离远但是有潜在关系的区域在图中可以被动态连接</li><li>通过差分特征生成器，交通状况的异常变化可以被捕获</li><li>多任务学习用来解决稀疏和空间异质性问题。多尺度的事故分布可以突出强调最可能发生交通事故的子区域</li><li>提出数据增强策略来解决零膨胀问题</li><li>提出协同感知策略来处理稀疏的感知数据</li></ul><h1><span id="3-问题定义">3. 问题定义</span></h1><p>&ensp;&ensp;&ensp;&ensp;在这一节，介绍基本定义，使用公式定义问题。<br>&ensp;&ensp;&ensp;&ensp;在我们的工作中，如果直接将整个研究区域作为方形区域，使用CNN进行时空特征提取，尤其在实时事故预测中，则会导致不必要的冗余，因为城市轮廓通常是不规则的。如图2(a)所示，我们首先将路网中研究区域划分为<code>q</code>个中等大小的矩形区域，每一个矩形区域包含一些小的方形子区域。一共有<code>m</code>个子区域(subregion)，我们通过城市图对<code>m</code>个子区域建模。</p><p><strong>定义1：Urban Graph</strong>：研究区域可以定义成无向图，用$G(\mathcal{V},\mathcal{E})$表示。顶点集$\mathcal{V}=\{v_1,v_2,…,v_m\}$，其中$v_i$表示第$i$个方形子区域，给定2个节点$v_i,v_j\in \mathcal{V}$,边$e_{ij} \in \mathcal{E}$表示2个subregion的连接，边非0即1。</p><script type="math/tex; mode=display">e_{i j}=\left\{\begin{array}{ll}{1} & {\text { if the traffic elements within two }} \\ {} & {\text { subregions have strong correlations }} \\ {0} & {\text { otherwise }}\end{array}\right.</script><blockquote><p>上面邻接矩阵的定义只是为了图定义的完整性，本文用到的邻接矩阵并不是非0即1的</p></blockquote><p>&ensp;&ensp;&ensp;&ensp;在该论文中，1个节点的<code>traffic element</code>包括2方面，静态的道路特征和动态的traffic特征。$\rho$来控制<code>affinity matrix</code>$\mathcal{A}_s$和$\mathcal{A}^{\Delta t}_o$的稀疏性，表示整个<code>urban graph</code>的连通性，在<code>affinity matrix</code>中的非0值表示subregion之间有很强的相关性。<br>&ensp;&ensp;&ensp;&ensp;在一个时间段$\Delta t$中<code>subregion</code> $v_i$的动态traffic特征包括3部分，(a)人流量，用<code>traffic volume</code>$TV_{v_i}(\Delta t)$表示;(b)交通状况，用平均交通速度$a_{v_i}(\Delta t)$表示;(c)交通事故风险等级$r_{v_i}(\Delta t)$。</p><p><strong>定义2：Static Road Network Features</strong>：一个城市<code>subregion</code>节点$v_i \in \mathcal{V}$,它的静态路网特征包括道路个数，道路类型，道路长度和宽度，除雪等级，红绿灯个数，<code>subregion</code> $v_i$中的所有道路使用一个固定长度的向量$s_i$表示。整个<code>urban graph</code>的静态道路特征使用$S=\{s_1,s_2,…,s_m\}$表示。静态特征，不随着时间变化，没有时间下标。</p><p><strong>定义3：Dynamic Traffic Features</strong>：对一个<code>subregion</code>节点$v_i \in \mathcal{V}$,在时间段$\Delta t$中，它的动态交通特征被表示为$f_{v_i}(\Delta t)=\left\{T V_{v_{i}}(\Delta t), a_{v_{i}}(\Delta t), r_{v_{i}}(\Delta t)\right\}$，即该时间段的车流量，车平均速度，事故风险，$r_{v_i}(\Delta t)$是交通事故的risk求和，将交通事故分为3类：轻度，中度，重度，risk值分别是1,2,3.所有子区域在时间段$\Delta t$的交通事故风险分布表示为$\mathcal{R}(\Delta t)=\left\{r_{v_{1}}(\Delta t), r_{v_{2}}(\Delta t), \cdots, r_{v_{m}}(\Delta t)\right\}$，动态交通特征表示为$\mathcal{F}(\Delta t)=\left\{f_{v_{1}}(\Delta t), f_{v_{2}}(\Delta t), \cdots, f_{v_{m}}(\Delta t)\right\}$。动态交通特征随着时间变化，所以有区域和时间2个变量，动态特征包括：人流量，交通平均速度，事故风险</p><p><strong>定义4:Traffic Accident Prediction</strong>：给定所有子区域的静态道路特征$S$和所有子区域历史$T$个时间段的动态交通特征$\mathcal{F}(\Delta t)(\Delta t=1,2,…,T)$,目标是预测下一个时间段全市的事故风险$\mathcal{R}(T+1)$和选出高风险的子区域$\mathcal{V}_{acc}(T+1)$</p><blockquote><p>总结：根据m个子区域构建无向图，节点表示子区域，边表示2个子区域特征之间的相关性。子区域的特征包括2类：静态道路特征和动态交通特征。静态道路特征包括：道路个数，道路类型，长宽，道路除雪等级，红绿灯个数。动态交通特征包括：在该时间段内的车流量，车平均速度，该子区域事故风险。</p></blockquote><h1><span id="4-minute-level-real-time-traffic-accident-forecasting">4. Minute-level Real-time Traffic Accident Forecasting</span></h1><p>&ensp;&ensp;&ensp;&ensp;在这一节，先整体看一下我们的<code>RiskOracle</code>框架，然后再详细介绍。</p><p><img src="/2020/02/18/RiskOracle-A-Minute-level-Citywide-Traffic-Accident-Forecasting-Framework/RiskOracle.png" alt=""></p><h2><span id="41-framework-overview">4.1. Framework Overview</span></h2><p>&ensp;&ensp;&ensp;&ensp;如图1所示，<code>RiskOracle</code>框架包括3个阶段：数据预处理阶段，训练阶段，预测阶段。</p><h2><span id="42-data-preprocessing">4.2. Data Preprocessing</span></h2><p><strong>解决事故预测中的空间异质</strong>。高风险的值通常出现在城市区域，由于市中心发生事故多且车流量大，导致风险值在空间上不均衡，会忽略农村地区相对高风险的区域。为了实现全市预测，选择最有可能发生事故的区域来解决空间异质性是非常必要的。如图2(a)所示,按照层次结构组织这个子区域，中等大小区域用来收集粗粒度的事故分布，小的子区域用来收集细粒度的事故分布，然后进一步突出显示每个中等区域中的子区域。多尺度分布也可以看做分层事故分布。<br><strong>解决零膨胀问题</strong>。深度神经网络在训练中，如果非零值非常少的话，受到零膨胀的影响，将会预测出无效的值。如图2(b)所示，在选定的10min中，整个NYC只有6个交通事故，说明在短期事故的内在稀有性。为了解决这个问题实现实时事故预测，我们设计基于先验知识的数据增强(PKDE)策略来区分训练数据集中标签的风险值。具体来说，对时间段$\Delta t$,我们将所有区域在该时间段内的风险值$\mathcal{R}(\Delta t)$中的0转换为具有区分度的负值。转换分为2步：a)风险中的0值通过等式2转换为事故风险指标；b)指标值通过等式3转换为静态事故强度。给定子区域$v_i$，我们计算它的事故风险指标$\varepsilon_{v_i}$  ，事故风险指标是个比例值，在[0,1]之间</p><script type="math/tex; mode=display">\varepsilon_{v_{i}}=\frac{1}{N_{\text {week}}} \sum_{j=1}^{N_{\text {week}}} \frac{r_{v_{i}}(j)}{\sum_{k=1}^{m} r_{v_{k}}(j)}</script><p>其中$N_{week}$是训练集中总共的周数，$r_{v_{i}}(j)$是区域$v_i$在第$j$周总的风险值。然后，根据该子区域的事故风险指标$\varepsilon_{v_i}$,我们通过以下公式计算子区域$v_i$的统计事故强度。  </p><script type="math/tex; mode=display">\pi_{v_{i}}=b_{1} \log _{2} \varepsilon_{v_{i}}+b_{2}</script><blockquote><p>总结：给定时间段$\Delta t$，将子区域中的riks 0值转换为负值，先计算事故风险指标，再计算事故强度。有m个子区域，每个子区域都有一个固定的事故强度，将该子区域risk=0值用该子区域的事故强度替换</p></blockquote><p>其中$b_1$和$b_2$是算子，用来保持绝对值$\pi_{v_{i}}$的范围和真实风险值的范围对称。我们通过对数在0和1之间的区分性质，可以使转换后的数据易于区分并适合于训练网络。转换的方式为：1)事故风险为0的子区域的事故强度为负，小于非零风险的子区域，反映了零风险子区域有较低的事故风险;2)具有较低事故风险指标的子区域有较低的事故概率，保留了实际事故风险的等级。<br>事故风险指数$\varepsilon_{v_{i}}$值在[0,1]之间，取对数值在$(-\infin,0]%$，如果一个子区域的风险值为0，则事故风险指数为0，则事故强度$\pi_{v_{i}}$为负。</p><blockquote><p>其中b1和b2的值是反复试出来的。为了保证事故强度的绝对值和真实风险范围对称。假设真实风险在1至25之间，那事故强度的值要在-25至-1之间，通过设置b1和b2强度值在-25~-1</p></blockquote><p><img src="/2020/02/18/RiskOracle-A-Minute-level-Citywide-Traffic-Accident-Forecasting-Framework/nyc-map.png" alt=""></p><p><strong>补充稀疏的传感数据</strong>。实时交通信息的通常收集不足来进行事故预测，动态交通信息通常和静态空间路网结构相互影响，因此，我们提出了一个协同感知策略，利用FM的交互操作，修改<code>xDeepFM</code>为时空深度因式分解(ST-DFM)。<br>我们首先通过静态关联矩阵$\mathcal{A}_s$来提取2个子区域间的路网相似性和连接性。其中关联矩阵affinity matrix中的元素$\alpha_s(i,j)$表示子区域$v_i和v_j$间的静态相关性。</p><script type="math/tex; mode=display">\alpha_{s}(i, j)=\left\{\begin{array}{cc}{1} & {\text { if subregion } v_{i} \text { and }} {v_{j}} {\text { are adjacent }} \\{e^{-J S\left(s_{i} \| s_{j}\right)}} & {\text { otherwise }}\end{array}\right.</script><p>其中，$JS$函数是Jensen-Shannon divergence（散度），$s_{i}和s_{j}$是子区域$i,j$的静态道路特征，包括道路个数，类型，长宽，除雪等级，红绿灯个数。</p><script type="math/tex; mode=display">J S\left(s_{i} \| s_{j}\right)=\frac{1}{2} \sum_{k}\left(\begin{array}{c}{s_{i}(k) \log \frac{2 s_{i}(k)}{s_{i}(k)+s_{j}(k)}+} \\{s_{j}(k) \log \frac{2 s_{j}(k)}{s_{i}(k)+s_{j}(k)}}\end{array}\right)</script><p>和xDeepFM一样，ST-DFM包含压缩交互网络模块和DNN模块。在ST-DFM中嵌入了3个时空字段，即静态空间特征，动态交通特征和时间戳。然后ST-DFM通过CIN模块学习矢量级别不同时空特征间的交互关系，通过DNN模块学习特征的高级表示，最后获取高级特征的组合。我们将对应子区间的交通量输入到ST-DFM中来推断速度值，反之亦然。然后通过训练2个实时交通数据的交集数据，来最大程度推断交通信息，以此获取全局交通状态。</p><blockquote><p>补充：JS散度是一个衡量距离的函数，JS散度的值域在[0,1]之间，相同为0，反之为1。静态affinity matrix $\mathcal{A}_s \in R^{m \times m}$，如果2个子区域相邻，值为1，不相邻则计算2个子区域的静态道路特征的相似度，值在$[\frac{1}{e},1]$之间，越相似，值越靠近1，越不相似，值越靠近$\frac{1}{e}$<br>通过静态道路特征构建一个全连接图，任意2个节点都有边相连，只是权重不同。如果2个子区域相邻，边权重为1，如果子区域不相邻，计算2个子区域间的JS散度</p></blockquote><h2><span id="43-multi-task-dtgn-for-accident-risk-prediction">4.3. Multi-task DTGN for Accident Risk Prediction</span></h2><p><strong>时空DTGN</strong>.事故和交通拥堵在路网中通常相互影响，特别是节假日和高峰。由于GCN对非欧式空间很好的建模，我们提出了DTGN，通过time-varying overall affinity和differential feature generator来修改GCN，解决分钟级别预测事故的挑战。</p><p><strong>Time-varying overall affinity matrix with dynamic traffic features involved</strong>. 不同城市分区之间的交通状况有很强的时变相关性。并且，交通事故和交通状况有很强的时空相关性。因此，对于分钟级别的事故预测，需要通过动态affinity matrix $\mathcal{A}^{\Delta t}_o$捕获子区域间在时间段$\Delta t$的时间交通相关性。在$\mathcal{A}^{\Delta t}_o$中的元素$\alpha^{\Delta t}_o(i,j)$表示子区域$i,j$的动态相似性。</p><script type="math/tex; mode=display">\alpha_{O}^{\Delta t}(i, j)=e^{-J S\left(s_{i}^{*} \| s_{j}^{*}\right)}+\gamma * e^{-J S\left(C_{i}^{\Delta t} \| C_{j}^{\Delta t}\right)}</script><p>其中$C_{i}^{\Delta t}$表示子区域$v_i$上周每一天相同时间段的交通量$TV_{v_i}(\Delta t)$和平均速度$a_{v_i}(\Delta t)$。注意我们使用Attention机制，根据子区域的静态空间特征对事故的影响，修改了子区域静态空间特征的权重。并且子区域的静态特征表示为$s^*_i$.权重$\gamma$用来调节动态交通affinity占overall affinity matrix的比例。通过overall affinity matrix，距离较远但有潜在事故相关的子区域可以被动态连接。为了在谱域运行GCN，我们需要计算动态affinity matrix $\mathcal{A}^{\Delta t}_o$的拉普拉斯矩阵$L^{\Delta t}$，其中$\mathcal{A}^{\Delta t}_o$可以被看做邻接矩阵。首先定义$\mathcal{B}^{\Delta t}$</p><script type="math/tex; mode=display">\mathcal{B}^{\Delta t}=\mathcal{A}_{o}^{\Delta t}+I_{m}</script><p>其中$I_{m}$是维度$m \times m$的单位矩阵。然后计算度矩阵$\Phi^{\Delta t}$</p><script type="math/tex; mode=display">\Phi^{\Delta t}=\left[\begin{array}{cccc}{\varphi_{11}} & {0} & {\cdots} & {0} \\{0} & {\varphi_{22}} & {\cdots} & {0} \\{\vdots} & {\vdots} & {\ddots} & {\vdots} \\{0} & {0} & {\cdots} & {\varphi_{m m}}\end{array}\right]</script><p>其中$\varphi_{i i}=\sum_{j=1}^{m} b_{i j}$，将矩阵$\mathcal{B}^{\Delta t}$每一行的元素相加组成度矩阵。然后获取时间段$\Delta t$的拉普拉斯矩阵。</p><script type="math/tex; mode=display">L^{\Delta t}=\left(\Phi^{\Delta t}\right)^{-\frac{1}{2}} \mathcal{B}^{\Delta t}\left(\Phi^{\Delta t}\right)^{-\frac{1}{2}}</script><blockquote><p>补充：原始GCN中，拉普拉斯矩阵为$\hat{D}^{-\frac{1}{2}}\hat{A}\hat{D}^{-\frac{1}{2}}$，其中$\hat{A}=A+I$</p><p>总结：文中提到的affinity matrix有2类：静态affinity matrix $\mathcal{A}_s$和动态overall affinity matrix $\mathcal{A}_o^{\Delta t}$，这2个矩阵的维度都是$R^{m \times m}$，其中静态affinity matrix不随着时间变化，根据子区域的静态道路特征计算得到。动态overall affinity matrix随着时间变化，由子区域的静态道路特征和上周每一天同时间段的动态交通特征(车流量和车平均速度)计算得来。这里将动态overall affinity matrix看做邻接矩阵，计算拉普拉斯矩阵，每个时间段都有一个拉普拉斯矩阵，用在GCN中。</p></blockquote><p><strong>Differential GCN for extracting spatiotemporal features</strong>和常规的交通状况相比，事故或事件预测和交通状况的异常变化更相关。因此，我们引入了差分特征生成器来计算相邻时间段的差分图片。将差分动态交通特征输入到GCN中，可以对交通状况的异常变化的传播和相互作用进行建模，并且可以学习即时的交通状态变化和事故之间的高层关系，可以更好地用来分钟级的事故预测。给定时间段$\Delta t$,差分向量$\vec{\Theta}^{\Delta t}$计算如下：</p><script type="math/tex; mode=display">\vec{\Theta}^{\Delta t}=\mathcal{D}(\Delta t)-\mathcal{D}(\Delta t-1)</script><p>其中$\mathcal{D}(\Delta t)=\left\{d_{v_{1}}(\Delta t), d_{v_{2}}(\Delta t), \cdots, d_{v_{m}}(\Delta t)\right\}$,$d_{v_{i}}(\Delta t)=\left\{T V_{v_{i}}(\Delta t), a_{v_{i}}(\Delta t)\right\}$，差分不涉及到事故风险的计算。在时间段$\Delta t$中所有的子区域通过结合它们的动态交通特征和对应的差分向量，生成了统一的特征元组$\mathcal{U}(\Delta t)=\left\{\mathcal{F}(\Delta t), \vec{\Theta}^{\Delta t}\right\}$,在郑宇AAAI2017 ST-ResNet文中提到的，城市交通有3个时间周期：小时，天，长期趋势。所以，预测时间段$\Delta t$，我们选取$\mathcal{k}$个统一特征元组，按照ST-ResNet，设置$\mathcal{k}=3$,作为DTGN的输入。具体来说，选取时间段$\Delta t$的前$\mathcal{k}$个时间段作为小时周期，选取连续前$\mathcal{k}$天中相同的时间段作为天周期，至于长期趋势，向前每10天取1天，一共取$\mathcal{k}$天,在这$\mathcal{k}$天种，取相同的时间段作为长期趋势。即hour周期有$\mathcal{k}$个时间段,天周期有$\mathcal{k}$个时间段，长期区域有$\mathcal{k}$个时间段。如图1所示，将这3个时间周期的二元组分别输入到3个DTGN中。其中DTGN的模型细节在图3(a)中。对于每一个时间周期，将它的特征二元组用$\mathbb{U}_{<em>} \Delta t$表示，将$\mathbb{U}_{</em>} \Delta t$输入到FCN中，将特征嵌入成低维特征，然后输入到GCN中。</p><script type="math/tex; mode=display">\mathcal{H}^{n+1}=\text{Leaky-ReLU}(L^*  \mathcal{H}^{n} \mathcal{W}^{n}),\text { where } \mathcal{H}^{0}=\mathbb{U}_{*}^{\Delta t}</script><p>其中$\mathcal{H}^{n}$表示第n层GCN输入的特征，$\mathcal{W}^{n}$表示第n层GCN的卷积核参数。因为每个时间周期会输出多个时间段的数据，在做GCN操作时，需要用到拉普拉斯矩阵，这里的$L^*$是输入所有时间段的拉普拉斯矩阵$L^{\Delta t}$的平均。每2个GCN后使用1次BN，防止梯度爆炸。考虑到转换后的risk中有负值，使用Leaky_ReLU激活。同时，对应时间段的外部数据(时间戳和天气)经过嵌入层变成定长的向量，再和GCN的输入融合。因为有3个时间周期，DTGN有3个输出，分别用$\mathcal{O}_{h c}^{\Delta t}, \mathcal{O}_{d p}^{\Delta t}$ and $\mathcal{O}_{d t}^{\Delta t}$表示。</p><p><img src="/2020/02/18/RiskOracle-A-Minute-level-Citywide-Traffic-Accident-Forecasting-Framework/DTGN.png" alt=""></p><blockquote><p>总结：每一个时间段有一个差分向量，是该时间段所有区域的车流量和车平均速度减去上一时间段的值，得到差分向量。然后将该时间段所有子区域的动态交通特征$\mathcal{F}(\Delta t)$和该时间段的差分向量$\vec{\Theta}^{\Delta t}$组成一个统一的特征元组$\mathcal{U}(\Delta t)$。那么每个时间段都有一个特征元组，存储所有子区域的特征。受郑宇2017AAAI ST-ResNet的启发，事故的发生有小时，天，长期的周期性，假设预测时间段是t，为其找出小时，天，长期的时间段。小时周期：[t-1,t-2,t-3]，天周期：[昨天t,前天t,大前天t]，长期周期[10天前t,20天前t,30天前t],然后分别输入到3个DTGN中。这个拿1个DTGN举例。输入的图信号矩阵维度是(batch_size,N,T<em>D)=(batch_size,N,3\</em>5)将时间维度乘到特征上，先经过FCN对特征进行嵌入，变成低维特征。然后输入到GCN中，GCN操作需要使用拉普拉斯矩阵。上节中提到拉普拉斯矩阵是动态的，每一个时间段都有一个L，这里每个周期都有3个时间段，使用的拉普拉斯矩阵是3个时间段拉普拉斯矩阵的平均值。<br>预测第t时间段的risk，输入的图信号矩阵：<br>小时周期：<br>t-1,t-2,t-3时刻：车流，车速，risk，$\Delta$车流，$\Delta$车速<br>天周期：<br>昨天t，前天t，大前天t时刻：车流，车速，risk，$\Delta$车流，$\Delta$车速<br>周周期：<br>10天前t，20天前t，30天前t时刻：车流，车速，risk，$\Delta$车流，$\Delta$车速<br>一共有3个组件，每个组件输入的维度是(batch_size,N,3*5)</p></blockquote><p><strong>多任务学习来事故风险预测</strong>设计多任务学习方案，不仅可以增强深度学习的表示能力，还可以学到分层事故分布，为最可能发生事故区域的选取提供指导。为了预测子区域的事故风险，我们首先<strong>将事故风险分布作为主任务</strong>。考虑到交通事故和人类活动强度有关，我们将<strong>区域交通量预测作为第一个辅助任务</strong>，用来提高深度学习的表示能，。为了给分层事故区域的选取提供指导，将<strong>预测中等区域发生的事故总数作为第二个辅助任务</strong>。<br>具体地，我们将DTGN的3个输出$\mathcal{O}_{h c}^{\Delta t}, \mathcal{O}_{d p}^{\Delta t}$ and $\mathcal{O}_{d t}^{\Delta t}$输入到卷积融合模块中，然后进行多任务学习，如图3(b)所示，3个多任务shared是3个DTGN的输出结果。将3个输出结果分别输入到3个融合模块中，3个融合模块的参数是$\mathcal{W}_{risk}^{\Delta t},\mathcal{W}_{vol}^{\Delta t},\mathcal{W}_{count}^{\Delta t}$，首先生成每个子区域的预测风险$\mathcal{O}_{\text {risk}}^{\Delta t}$,使用$Leaky_ReLU$激活是因为label中的risk值有负值，其余都使用$ReLU$激活。然后生成每个子区域的预测流量$\mathcal{O}_{v o l}^{\Delta t}$，然后预测每个中等区域的风险次数，先经过融合模块，再经过全连接，生成$\mathcal{O}_{\text {count}}^{\Delta t}$</p><script type="math/tex; mode=display">\mathcal{O}_{r i s k}^{\Delta t}=\text { Leaky } \operatorname{ReLU}\left(\mathcal{W}_{risk}^{\Delta t} *\left[\mathcal{O}_{h c}^{\Delta t}, \mathcal{O}_{d p}^{\Delta t}, \mathcal{O}_{d t}^{\Delta t}\right]\right)</script><script type="math/tex; mode=display">\mathcal{O}_{v o l}^{\Delta t}=\operatorname{ReLU}\left(\mathcal{W}_{v o l}^{\Delta t} *\left[\mathcal{O}_{h c}^{\Delta t}, \mathcal{O}_{d p}^{\Delta t}, \mathcal{O}_{d t}^{\Delta t}\right]\right)</script><script type="math/tex; mode=display">\mathcal{O}_{\text {count}}^{\Delta t}=\operatorname{ReLU}\left(\mathcal{W}_{f c}^{\Delta t} *\left(\mathcal{W}_{\text {count}}^{\Delta t} *\left[\mathcal{O}_{h c}^{\Delta t}, \mathcal{O}_{d p}^{\Delta t}, \mathcal{O}_{d t}^{\Delta t}\right]\right)\right)</script><p>$\mathcal{O}_{\text {count}}^{\Delta t}$是中等区域的事故次数，将其输入到另一个全连接中，reshape成和$\mathcal{O}_{\text {risk}}^{\Delta t}$相同维度，和原先的细粒度事故分布相加，迫使学习粗粒度和细粒度的事故分布之间的关系。最终$\mathcal{O}_{\text {risk}}^{\Delta t}$被更新为</p><script type="math/tex; mode=display">\mathcal{O}_{risk*}^{\Delta t}=\text { Leaky } \operatorname{ReLU}\left(\mathcal{W}_{f c *} * \mathcal{O}_{c o u n t}^{\Delta t}+\mathcal{O}_{r i s k}^{\Delta t}\right)</script><p>其中$\mathcal{O}_{risk*}^{\Delta t}$是最终主任务的输出。</p><p><img src="/2020/02/18/RiskOracle-A-Minute-level-Citywide-Traffic-Accident-Forecasting-Framework/multitask.png" alt=""></p><p>多任务的总loss如下：</p><script type="math/tex; mode=display">\operatorname{Loss}(\theta)=m s e_{r i s k}+\lambda_{1} * m s e_{v o l}+\lambda_{2} * m s e_{c o u n t}+\lambda_{3} * L_{2}</script><p>其中$m s e_{r i s k}, m s e_{v o l},m s e_{c o u n t}$是主任务和2个辅助任务的loss，这里使用L2正则化来避免过拟合。$\lambda_{1},\lambda_{2},\lambda_{3}$是损失函数的超参数。$\lambda_{1}=0.8,\lambda_{2}=1,\lambda_{3}=1e-4$。</p><blockquote><p>只根据risk，count，flow的MSELoss进行反向传播，训练模型。在预测时，根据这3个输出，求出评价指标</p></blockquote><p><strong>分层最可能发生事故区域选择</strong>.交通事故和交通量在城市和农村经常不均衡，导致空间异质性问题。因此，用统一的风险阈值来选择最可能发生事故的区域是不合理的，我们基于多任务中预测出的risk，提出一个分层的最可能发生事故区域选择的方法。<br>输入数据是中等区域的事故次数和子区域的risk值，对每个中等区域$i$，我们从中选出$k_i(i=1,2,…,q)$个风险最高的子区域，其中参数$k_i$等于第二个辅助任务学到的$\mathcal{O}_{\text {count}}^{\Delta t}$中对应的值。因此，我们获得了一组最可能发生事故的子区域。并且通过这种方式获得的$k_i$可以减少区域的过度预测，并且模型符合时间和天气的变化。</p><blockquote><p>对于$k_i$的选择这里解释下：在测试阶段，根据q个中等区域的事故数和m个子区域的risk值来选择$k_i$，假设q=5，预测出来5个中等区域发生的事故次数为[0,2,4,1,6],那就从5个中等区域中，分别选0,2,4,1,6个子区域，选risk最高的$k_i$个对应的子区域，就是模型预测的事故高发子区域</p><p>在模型训练阶段，只预测子区域的risk，子区域的flow，中等区域的count来计算loss，训练模型。在训练阶段，并不预测发生事故最高的区域。预测发生事故最高的区域，只在测试集上进行。在训练集和验证集上，将risk中的0替换掉训练模型，在测试集上，不需要将risk=0替换掉，因为在测试集上我们只需要找出topK就可以了。</p></blockquote><h1><span id="5-实验">5. 实验</span></h1><p>分钟级别的事故预测模型，设置时间段分别为10min和30min</p><h2><span id="51-数据准备">5.1. 数据准备</span></h2><p>在2个真实数据集上做实验：NYC Opendata和苏州工业园区(SIP)。对于NYC数据集，由于缺少实时的交通流量数据，这里利用每个子区域的出租车流量来代表人流量。对于SIP数据集，它包含交通流量和速度。我们将其从新浪收集的交通事故数据集集成。2个数据集的统计信息在表2中。</p><p><img src="/2020/02/18/RiskOracle-A-Minute-level-Citywide-Traffic-Accident-Forecasting-Framework/dataset.png" alt=""></p><h2><span id="52-实现细节">5.2. 实现细节</span></h2><p>训练集:验证集:测试集=6:1:3，划分子区域参照AAAI2019<a href="https://echohhhhhh.github.io/2019/03/05/Spatiotemporal-Multi-Graph-Convolution-Network-for-Ride-hailing-Demand-Forecasting/" target="_blank" rel="noopener">Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting</a>和实际情况。堆叠9层GCN，每层有384个filter。损失函数中$\lambda_{1}=0.8,\lambda_{2}=1,\lambda_{3}=1e-4$。优化器使用Adam。</p><p>在训练阶段，动态交通数据和affinity matrix被划分为小时，天，长期共3组，2种scale的事故分布输入到多任务DTGN中。在测试阶段，将数据组织成以上格式并输入到模型中，最有可能发生事故的子区域可以从主任务和辅助任务2中得到。高风险子区域被突出显示，并与实际的事故记录比较。</p><h2><span id="53-评价指标">5.3. 评价指标</span></h2><p>从2个角度验证RiskOracle模型，回归角度：MSE，分类角度：a)Acc@M，常用于时空排名任务中，表示m个子区域中，预测的前M个风险最高的子区域中正确的比例。NYC数据集中，在30min预测时，M=20，在10min预测时，M=6。在SIP数据集中，M=5。b)Acc@K,其中K是第二个辅助任务学到的$k_i$的总和。其中Acc1表示发生事故频率较高时间段的准确率，例如早上7~9点，下午12~4点。</p><blockquote><p>测试时，$Acc@M$：每个时间步从m个子区域中选出M个事故高发的区域，然后看选对了多少。M是全局选M个，每个中等子区域选多少个并不限制。$Acc@K$，只针对高频时间段计算该指标。假设在一个时间段中辅助任务2预测结果为[0,2,4,1,6],即K=13，从m个子区域中选出13个，但是每个中等子区域要选$k_i$个。</p></blockquote><h2><span id="54-baseline">5.4. Baseline</span></h2><ol><li>ARIMA，用于时间序列预测</li><li>Hetero-ConvLSTM(2018KDD),调整超参数为4,blocks with 16 filters, and a size of 12x12 moving window with step=6.</li><li>ST-ResNet(2017AAAI郑宇)用来预测车流量</li><li>SDAE(2016AAAI)使用人流量来预测risk</li><li>SDCAE最新的小时级别风险预测模型</li></ol><h2><span id="55-实验结果">5.5. 实验结果</span></h2><p><strong>性能比较</strong><br>实验结果如表3.RiskOracle获得了最高的准确率，且MSE优于大部分baseline。使用分层事故区域选择HARS，我们的模型解决了空间异质性和过度预测的问题。尤其在NYC数据集上，我们模型在Acc@20比最好的模型高22.49%。对于稀疏的传感数据和短期的时空预测，可扩展性高。并且，我们的模型在高峰期的预测更好，在现实应用中有用。所有的指标NYC的都比SIP的要好，可能因为SIP数据中事故标签不完整。<br>总体上，随着时间粒度变小，我们的模型性能稍微下降，而其他的模型急剧下降因为遇到零膨胀问题。这表明我们的模型在短期事故预测中的有效性和可扩展性。在实际应用中有很少的事故记录时，2个数据集上的提升验证了我们模型的健壮性和普适性。</p><p><img src="/2020/02/18/RiskOracle-A-Minute-level-Citywide-Traffic-Accident-Forecasting-Framework/result.png" alt=""></p><p><strong>Acc@K和消融实验</strong>.如图4所示。Acc@20和Acc@6的结果略高于Acc@K，这是合理的，因为统一阈值无法适应实时条件，并且往往会高估事故率。相反，我们的框架具有使用多尺度事故分布预测，近似估计每个矩形区域中事故数量，具有灵活性。与表3中的结果相比，我们的框架胜过其他baseline，并在Acc@K达到可接受的准确性水平。<br>为了验证哪个组件起作用，做了消融实验，从模型中去掉一些组件。</p><ul><li>RO-1：去掉基于先验知识的数据增强PKDE，无法解决零膨胀问题。priori knowledge-based data enhancement</li><li>RO-2：去掉ST-DFM，无法解决实时交通数据缺失问题</li><li>RO-3：去掉overall affinity，无法实现时变的GCN,即图的邻接矩阵是静态的</li><li>RO-4：去掉差分特征生成器，在输入到GCN中没有差分特征</li><li>RO-5：去掉带有HARS的多任务</li><li>Integrated model：完整模型<br>其中最重要的组件是overall affinity和PKED，说明零膨胀和时变GCN是重要的。</li></ul><p><img src="/2020/02/18/RiskOracle-A-Minute-level-Citywide-Traffic-Accident-Forecasting-Framework/ablation.png" alt=""></p><h2><span id="56-超参数">5.6. 超参数</span></h2><p>在NYC数据集的30min展示超参数实验。</p><ul><li>9层GCN，每层有384个filter</li><li>损失函数中$\lambda_{1}=0.8,\lambda_{2}=1,\lambda_{3}=1e-4$</li><li>计算overall affinity时动态元素占的比重$\gamma=0.5$</li><li>中等区域个数$q=18$</li></ul><h2><span id="57-案例分析">5.7. 案例分析</span></h2><p>可视化NYC2017.5.22这一天中选取的3个30min时间段。上面是预测值，下面是真实值。可以看到预测的高风险子区域和真实值相似。由于在周日上午很少人外出，因此早晨7:00预测发生的事故很少。但是，下午事故数量会增加，而到了晚上，事故更加严重，由于当晚大雨，路况易发生事故。结果证明，辅助任务和HARS通过捕获外部因素，来学习事故分布的动态模式，调整推理，比统一阈值解决方案具有更好的适应性。</p><p><img src="/2020/02/18/RiskOracle-A-Minute-level-Citywide-Traffic-Accident-Forecasting-Framework/case.png" alt=""></p><h1><span id="6-总结">6. 总结</span></h1><p>在这篇论文中，我们提出了基于多任务DTGN的RiskOracle框架，解决分钟级的事故预测问题。首先提出2个方法来解决零膨胀和稀疏感知的问题。在多任务DTGN中，结合差分特征生成器和时间overall affinity，模型可以建模稀疏的时空数据，捕获短期的子区域相关性。学习多尺度事故分布，突出显示最可能发生事故的子区域来解决空间异质性。在2个真实数据集上的实验验证模型的优越性。</p><h1><span id="7-知识补充">7. 知识补充</span></h1><p><strong>【Factorization Machine】</strong> FM (Factorization Machine) 主要是为了解决数据稀疏的情况下，特征怎样组合的问题。<br><a href="https://zhuanlan.zhihu.com/p/80726100" target="_blank" rel="noopener">【推荐系统】Factorization Machine</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;AAAI2020原文链接：&lt;a href=&quot;https://github.com/zzyy0929/AAAI2020-RiskOracle&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;RiskOracle-A Minute-level Citywide Traffic Accident Forecasting Framework&lt;/a&gt;&lt;br&gt;中国科大发&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="时空领域" scheme="http://yoursite.com/tags/%E6%97%B6%E7%A9%BA%E9%A2%86%E5%9F%9F/"/>
    
  </entry>
  
  <entry>
    <title>时空论文列表</title>
    <link href="http://yoursite.com/2020/02/18/%E6%97%B6%E7%A9%BA%E8%AE%BA%E6%96%87%E5%88%97%E8%A1%A8/"/>
    <id>http://yoursite.com/2020/02/18/时空论文列表/</id>
    <published>2020-02-17T16:17:25.000Z</published>
    <updated>2020-02-18T08:32:08.173Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="简介">简介</span></h1><p>以下列出AAAI2020和ICLR2020关于时空领域的论文<br><a id="more"></a></p><h1><span id="aaai2020">AAAI2020</span></h1><p><strong>[1]. RiskOracle: A Minute‐level Citywide Traffic Accident Forecasting Framework</strong><br><a href="https://github.com/zzyy0929/AAAI2020-RiskOracle" target="_blank" rel="noopener">https://github.com/zzyy0929/AAAI2020-RiskOracle</a></p><blockquote><p>Zhengyang Zhou (University of Science and Technology of China); Yang Wang (University of Science and<br>Technology of China)*; Xike Xie (University of Science and Technology of China); Lianliang Chen (University of<br>Science and Technology of China); Hengchang Liu (USTC)</p></blockquote><p><strong>[2]. GMAN: A Graph Multi-­Attention Network for Traffic Prediction</strong><br><a href="https://github.com/zhengchuanpan/GMAN" target="_blank" rel="noopener">https://github.com/zhengchuanpan/GMAN</a></p><blockquote><p>Chuanpan Zheng (Xiamen University); Xiaoliang Fan (Xiamen University)*; Cheng Wang (Xiamen University);<br>Jianzhong Qi (The University of Melbourne)</p></blockquote><p><strong>[3]. Multi-­Range Attentive Bicomponent Graph Convolutional Network for Traffic Forecasting</strong><br><a href="https://github.com/naganandy/graph-based-deep-learning-literature/blob/master/conference-publications/folders/publications_aaai20/mrabgcn_aaai20/README.md" target="_blank" rel="noopener">https://github.com/naganandy/graph-based-deep-learning-literature/blob/master/conference-publications/folders/publications_aaai20/mrabgcn_aaai20/README.md</a><br><a href="https://arxiv.org/abs/1911.12093?context=cs" target="_blank" rel="noopener">https://arxiv.org/abs/1911.12093?context=cs</a></p><blockquote><p>Weiqi Chen (Zhejiang University); Ling Chen (Zhejiang University)*; Yu Xie (Alibaba Cloud); Wei Cao (Alibaba);<br>Yusong Gao (Alibaba Cloud); Xiaojie Feng (Alibaba Cloud)</p></blockquote><p><strong>[4]. Spatio­‐Temporal Graph Structure Learning for Traffic Forecasting</strong></p><blockquote><p>Qi Zhang (institute of automation, Chinese academy of science)*; Jianlong Chang (National Laboratory of Pattern<br>Recognition, Institute of Automation, Chinese Academy of Sciences); Gaofeng Meng (Chinese Academy of<br>Sciences); SHIMING XIANG (Chinese Academy of Sciences, China); Chunhong Pan (Institute of Automation, Chinese<br>Academy of Sciences)</p></blockquote><p><strong>[5]. Pay Your Trip for Traffic Congestion: Dynamic Pricing in Traffic­‐Aware Road Networks</strong></p><blockquote><p>Lisi Chen (HKBU)*; Shuo Shang (KAUST); Bin Yao (“Shanghai Jiaotong University, China”); Jing Li (Inception Institute<br>of Artificial Intelligence)</p></blockquote><p><strong>[6]. Self­‐Attention ConvLSTM for Spatiotemporal Prediction</strong></p><blockquote><p>Zhihui Lin (Tsinghua University)*; Maomao Li (Tsinghua university); Zhuobin Zheng ( Tsinghua University);<br>Yangyang Cheng (Tsinghua University); Chun Yuan (Tsinghua University)</p></blockquote><p><strong>[7]. An Attentional Recurrent Neural Network for Personalized Next Location Recommendation</strong></p><blockquote><p>Qing Guo (Nanyang Technological University)*; Zhu Sun (Nanyang Technological University); Jie Zhang (Nanyang<br>Technological University); Yin-­‐Leng Theng (Nanyang Technological University)</p></blockquote><p><strong>[8]. Spatial­‐Temporal Synchronous Graph Convolutional Networks: A New Framework for Spatial-­‐Temporal Network Data Forecasting</strong><br><a href="https://github.com/Davidham3/STSGCN" target="_blank" rel="noopener">https://github.com/Davidham3/STSGCN</a></p><blockquote><p>Chao Song (Beijing Jiaotong University)*; Youfang Lin (Beijing Jiaotong University); Shengnan Guo (Beijing Jiaotong<br>University); Huaiyu Wan (Beijing Jiaotong University)</p></blockquote><p><strong>[9]. STGRAT: A Spatio-Temporal Graph Attention Network for Traffic Forecasting</strong><br><a href="https://arxiv.org/abs/1911.13181" target="_blank" rel="noopener">https://arxiv.org/abs/1911.13181</a></p><blockquote><p>Cheonbok Park1, Chunggi Lee2, Hyojin Bahng1, Taeyun won1,<br>Kihwan Kim2, Seungmin Jin2, Sungahn Ko2, Jaegul Choo1<br>1 Korea University , 2 UNIST</p></blockquote><p><strong>[10]. Semi-Supervised Hierarchical Recurrent Graph Neural Network for City-Wide Parking Availability Prediction</strong><br><a href="https://arxiv.org/abs/1911.10516" target="_blank" rel="noopener">https://arxiv.org/abs/1911.10516</a></p><blockquote><p>Weijia Zhang (University of Science and Technology of China); Hao LIU (Business Intelligence Lab, Baidu<br>Research)*; Yanchi Liu (Rutgers University); Jingbo Zhou (Baidu Inc.); Hui Xiong (Rutgers University)</p></blockquote><p><strong>[11]. RoadTagger: Robust Road Attribute Inference with Graph Neural Networks</strong><br><a href="https://arxiv.org/abs/1912.12408" target="_blank" rel="noopener">https://arxiv.org/abs/1912.12408</a></p><blockquote><p>Songtao He (MIT CSAIL)*; Favyen Bastani (MIT CSAIL); Satvat Jagwani (MIT CSAIL); Edward Park (MIT CSAIL);<br>Sofiane Abbar (Qatar Computing Research Institute); Mohammad Alizadeh (MIT CSAIL); Dr.Hari Balakrishnan<br>(Massachusetts institute of technology); Sanjay Chawla (QCRI); Samuel Madden (MIT); Mohammad Amin Sadeghi<br>(MIT)  </p></blockquote><h1><span id="iclr2020">ICLR2020</span></h1><p><a href="http://tony.9shi.cf/index.php?q=aHR0cHM6Ly93d3cuZW5kdG9lbmQuYWkvYmxvZy9pY2xyMjAyMC8" target="_blank" rel="noopener">ICLR2020 Accepted Papers</a></p><p><strong>[1]. Geom-gcn: Geometric Graph Convolutional Networks</strong><br>Spotlight paper<br><a href="https://github.com/graphdml-uiuc-jlu/geom-gcn" target="_blank" rel="noopener">https://github.com/graphdml-uiuc-jlu/geom-gcn</a></p><blockquote><p>Hongbin Pei, Bingzhe Wei, Kevin Chen-Chuan Chang, Yu Lei, Bo Yang<br>Jilin University</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;p&gt;以下列出AAAI2020和ICLR2020关于时空领域的论文&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="时空领域" scheme="http://yoursite.com/tags/%E6%97%B6%E7%A9%BA%E9%A2%86%E5%9F%9F/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch之Tensor学习</title>
    <link href="http://yoursite.com/2020/02/17/Pytorch%E4%B9%8BTensor%E5%AD%A6%E4%B9%A0/"/>
    <id>http://yoursite.com/2020/02/17/Pytorch之Tensor学习/</id>
    <published>2020-02-17T14:56:16.000Z</published>
    <updated>2020-02-24T08:02:56.237Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="1-简介">1. 简介</span></h1><p>最近发现一个学习Pytorch的教程，有视频版和文字版<a href="https://deeplizard.com/" target="_blank" rel="noopener">deeplizard</a>,这里面详细介绍了关于Tensor的知识，真的讲得超级好，解决了我很多关于Tensor运算的疑惑，在此记录下。</p><a id="more"></a>  <!-- TOC --><ul><li><a href="#1-%e7%ae%80%e4%bb%8b">1. 简介</a></li><li><a href="#2-%e5%88%9b%e5%bb%batensor">2. 创建Tensor</a></li><li><a href="#3-tensor%e7%9a%844%e7%b1%bb%e6%93%8d%e4%bd%9c">3. Tensor的4类操作</a><ul><li><a href="#31-reshape%e6%93%8d%e4%bd%9c">3.1. Reshape操作</a><ul><li><a href="#311-reshape">3.1.1. reshape</a></li><li><a href="#312-squeeze%e5%92%8cunsqueeze%e5%87%bd%e6%95%b0">3.1.2. squeeze和unsqueeze函数</a></li><li><a href="#313-cat%e5%87%bd%e6%95%b0">3.1.3. cat函数</a></li><li><a href="#314-stack%e5%87%bd%e6%95%b0">3.1.4. stack函数</a></li><li><a href="#315-cat%e5%92%8cstack%e7%9a%84%e5%8c%ba%e5%88%ab">3.1.5. cat和stack的区别</a></li></ul></li><li><a href="#32-element-wise%e6%93%8d%e4%bd%9c">3.2. Element-wise操作</a></li><li><a href="#33-reduction%e6%93%8d%e4%bd%9c">3.3. Reduction操作</a><ul><li><a href="#331-%e6%b2%bf%e7%9d%80%e6%9f%90%e4%b8%aaaxis%e8%81%9a%e5%90%88">3.3.1. 沿着某个axis聚合</a></li><li><a href="#332-argmax%e5%87%bd%e6%95%b0%e4%bb%8b%e7%bb%8d">3.3.2. Argmax函数介绍</a></li></ul></li><li><a href="#34-access%e6%93%8d%e4%bd%9c">3.4. Access操作</a></li></ul></li></ul><!-- /TOC --><h1><span id="2-创建tensor">2. 创建Tensor</span></h1><p>创建Tensor有四种方式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建Tensor</span></span><br><span class="line">&gt; data = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">&gt; o1 = torch.Tensor(data)</span><br><span class="line">&gt; o2 = torch.tensor(data)</span><br><span class="line">&gt; o3 = torch.as_tensor(data)</span><br><span class="line">&gt; o4 = torch.from_numpy(data)</span><br><span class="line"></span><br><span class="line">&gt; print(o1)</span><br><span class="line">&gt; print(o2)</span><br><span class="line">&gt; print(o3)</span><br><span class="line">&gt; print(o4)</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>])</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=torch.int32)</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=torch.int32)</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=torch.int32)</span><br><span class="line"></span><br><span class="line">&gt; print(o1.dtype)</span><br><span class="line">&gt; print(o2.dtype)</span><br><span class="line">&gt; print(o3.dtype)</span><br><span class="line">&gt; print(o4.dtype)</span><br><span class="line">torch.float32</span><br><span class="line">torch.int32</span><br><span class="line">torch.int32</span><br><span class="line">torch.int32</span><br><span class="line"></span><br><span class="line"><span class="comment">#内存是否共享</span></span><br><span class="line">&gt; print(<span class="string">'old:'</span>, data)</span><br><span class="line">old: [<span class="number">1</span> <span class="number">2</span> <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">&gt; data[<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">&gt; print(<span class="string">'new:'</span>, data)</span><br><span class="line">new: [<span class="number">0</span> <span class="number">2</span> <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">&gt; print(o1)</span><br><span class="line">&gt; print(o2)</span><br><span class="line">&gt; print(o3)</span><br><span class="line">&gt; print(o4)</span><br><span class="line"></span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>])</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=torch.int32)</span><br><span class="line">tensor([<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=torch.int32)</span><br><span class="line">tensor([<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=torch.int32)</span><br></pre></td></tr></table></figure><ul><li><code>torch.Tensor()</code>和<code>torch.tensor()</code>区别<br><code>torch.Tensor()</code>是<code>Tensor</code>类的构造函数，<code>torch.tensor()</code>是factory function，该函数将传入的参数构造成一个<code>Tensor</code>对象并返回。<br>以上4个函数中，<code>torch.Tensor()</code>是构造函数，其余都是factory function。</li><li>这4个函数的主要区别是:<code>torch.Tensor()</code>返回的<code>Tensor</code>默认是<code>float32</code>类型，而其他3个函数返回的<code>Tensor</code>数据类型根据传入的数据而定。并且其他3个函数可以传入<code>dtype</code>来指定数据的类型，但是<code>torch.Tensor()</code>不能传入<code>dtype</code>参数。</li><li><p>通过<code>np.array</code>来创建<code>Tensor</code>，然后改变data的值，可以看到，前2个<code>Tensor</code>的值并没有改变，后2个<code>Tensor</code>的值改变。这是因为<code>torch.Tensor()</code>和<code>torch.tensor()</code>是copy输入数据的值，而<code>torch.as_tensor()</code>和<code>torch.from_numpy()</code>是share输入数据的memory</p><p>Shara Data | Copy Data<br>-|-|-|<br>torch.as_tensor() | torch.tensor()|<br>torch.from_numpy() |     torch.Tensor()|</p></li><li><p><code>torch.as_tensor()</code>和<code>torch.from_numpy()</code>都是factory function，且都是share data，那这2个函数有什么区别？<code>torch.from_numpy()</code>仅仅接受<code>np.array</code>的参数，然而<code>torch.as_tensor()</code>接受<a href="https://docs.scipy.org/doc/numpy/user/basics.creation.html#converting-python-array-like-objects-to-numpy-arrays" target="_blank" rel="noopener">array-like objects</a>类型的参数</p></li><li>综上所述，下面2个方法是创建Tensor的推荐方法：<ul><li><code>torch.tensor()</code></li><li><code>torch.as_tensor()</code></li></ul></li></ul><h1><span id="3-tensor的4类操作">3. Tensor的4类操作</span></h1><h2><span id="31-reshape操作">3.1. Reshape操作</span></h2><h3><span id="311-reshape">3.1.1. reshape</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; t = torch.tensor([</span><br><span class="line">    [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>],</span><br><span class="line">    [<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>]</span><br><span class="line">], dtype=torch.float32)</span><br></pre></td></tr></table></figure><p>有2种方式获取Tensor的shape:<code>t.size()和t.shape</code></p><h3><span id="312-squeeze和unsqueeze函数">3.1.2. squeeze和unsqueeze函数</span></h3><ol><li><code>torch.squeeze(input, dim=None, out=None) → Tensor</code><br>将维度中的1去掉，如果不指定dim，则去掉所有维度上的1；如果指定dim，则只去掉该维度上的1。<strong>dim是可选项</strong></li></ol><ul><li>输入维度是(A×1×B×C×1×D),不指定dim，输出维度(A×B×CxD)</li><li>输入维度是(A×1×B×C×1×D),不指定dim=1，输出维度(A×B×C×1×D)</li></ul><ol><li><code>torch.unsqueeze(input, dim, out=None) → Tensor</code><br>在指定维度上增加1个维度。<strong>dim是必填项</strong><br><code>torch.unsqueeze(x, 0)</code><h3><span id="313-cat函数">3.1.3. cat函数</span></h3></li></ol><p><code>torch.cat(tensors, dim=0, out=None) → Tensor</code><br>如果要拼接多个Tensor，需要将多个Tensor包装成tuple，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cat((t1,t2,t3),dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><strong>cat不改变数据维度个数</strong></p><h3><span id="314-stack函数">3.1.4. stack函数</span></h3><p><code>torch.stack(tensors, dim=0, out=None) → Tensor</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.stack((t1,t2,t3),dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><strong>stack改变数据维度个数,增加一个维度</strong></p><h3><span id="315-cat和stack的区别">3.1.5. cat和stack的区别</span></h3><p>cat和stack的区别可以用一句话描述：</p><ul><li>cat不会改变数据维度个数，原先是3维数据，n个tensor进行cat之后还是3维数据。</li><li>stack会增加维度个数，原先是3维，n个tensor进行stack会变成4维数据</li></ul><h2><span id="32-element-wise操作">3.2. Element-wise操作</span></h2><p><a href="https://deeplizard.com/learn/video/QscEWm0QTRY" target="_blank" rel="noopener">Broadcasting and Element-wise Operations with PyTorch</a><br><a href="https://deeplizard.com/learn/video/6_33ulFDuCg" target="_blank" rel="noopener">Broadcasting Explained</a></p><p>逐元素有以下4种叫法，意思都一样：</p><ul><li>Element-wise</li><li>Component-wise</li><li>Point-wise</li></ul><p>逐元素操作有以下几种:</p><ol><li><p><strong><code>t1+t2</code>维度相同</strong><br>其中t1和t2维度相同</p></li><li><p><strong><code>t1+2, t1-2, t1*2, t1/2</code></strong><br>实际上是对2进行了<code>broadcasting</code>，然后再和t1运算</p></li><li><p><strong><code>t1+t2</code>，rank相同，维度不同</strong><br>这种情况比较复杂。</p><ul><li><p>首先我们先看这2个Tensor在所有维度上是否兼容。判断2个Tensor在维度上是否兼容有2个条件，只要满足其中的一个条件就兼容，否则不兼容。</p><ul><li>相等</li><li><p>有一个值维1 </p><p>例如：t1维度(1,3)，t2维度(3,1)，<strong>从后往前对比</strong>，我们先看第二个维度的值，分别是3和1，不相等但是满足第二个条件，即第二个维度上兼容。再看第一个维度，分别是1和3，满足第二个条件，即第一个维度上兼容。所以2个Tensor在所有维度上兼容，可以进行下一步的操作。如果不兼容，则这2个Tensor无法进行逐元素运算。</p></li></ul></li><li><p>决定最终结果的输出维度。还是要看2个Tensor的维度。<strong>从后往前对比</strong>, t1维度(1,3)，t2维度(3,1)，先看第二维度是3和1，取最大值作为输出的第一个维度，即3，再看第一维度1和3，也是3作为输出的第二个维度。即输出的维度是(3,3)。</p></li><li>分别将t1维度(1,3)，t2维度(3,1)进行广播成(3,3)，然后再进行相加，得到最终的结果。</li></ul></li><li><p><strong><code>t1+t2</code>，rank不同</strong></p><ul><li>例子1：t1的维度(2,4),t2的维度是(4,)，这2个Tensor也可以进行，实际是先将低rank的t2最后一维和t1的最后一维相等，都等于4，但是t2只有一维，那就在缺失的维度上补1，变成(1,4),然后再广播成(2,4)维度，然后再和t1计算。</li><li>例子2：t1的维度(2,4),t2的维度是(2,)，这2个Tensor不可以进行。因为t1和t2的最后一维分别是4和2，不相等也不等于1，不兼容，无法进行下一步。</li><li>例子3：t1维度(1,2,3)，t2维度(3,3)，这个Tensor就不能做逐元素操作。先看所有维度是否兼容。最后一个维度3和3，相等即兼容，再看前一个维度2和3，既不相等也不等于1，不兼容。则不能进行逐元素操作</li></ul></li></ol><p><strong>以上2，3，4情况都涉及到了broadcasting的知识。</strong>  </p><ol><li><p>比较操作<br>比较也是逐元素操作的一种，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]) &lt; torch.tensor([<span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">tensor([<span class="keyword">True</span>, <span class="keyword">False</span>, <span class="keyword">False</span>])</span><br></pre></td></tr></table></figure></li></ol><h2><span id="33-reduction操作">3.3. Reduction操作</span></h2><p>聚合操作：减少Tesnor中元素的个数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; t = torch.tensor([</span><br><span class="line">    [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">2</span>,<span class="number">0</span>,<span class="number">2</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">3</span>,<span class="number">0</span>]</span><br><span class="line">], dtype=torch.float32)</span><br><span class="line">&gt; t.sum()</span><br><span class="line">tensor(<span class="number">8.</span>)</span><br></pre></td></tr></table></figure><p><code>sum()</code>返回的结果是scalar类型(0维的Tensor)，只包含1个元素</p><h3><span id="331-沿着某个axis聚合">3.3.1. 沿着某个axis聚合</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; t = torch.tensor([</span><br><span class="line">    [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>],</span><br><span class="line">    [<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>]</span><br><span class="line">], dtype=torch.float32)</span><br><span class="line">&gt; t.sum(dim=<span class="number">0</span>)</span><br><span class="line">tensor([<span class="number">6.</span>, <span class="number">6.</span>, <span class="number">6.</span>, <span class="number">6.</span>])</span><br></pre></td></tr></table></figure><h3><span id="332-argmax函数介绍">3.3.2. Argmax函数介绍</span></h3><p>当一个Tensor变量a调用<code>argmax()</code>函数时，返回只包含1个元素的Tensor，该元素表示a中最大值的下标。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">t = torch.tensor([</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">2</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">4</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">5</span>]</span><br><span class="line">], dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">&gt; t.max()</span><br><span class="line">tensor(<span class="number">5.</span>)</span><br><span class="line"></span><br><span class="line">&gt; t.argmax()</span><br><span class="line">tensor(<span class="number">11</span>)</span><br><span class="line"></span><br><span class="line">&gt; t.flatten()</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">2.</span>, <span class="number">0.</span>, <span class="number">3.</span>, <span class="number">3.</span>, <span class="number">0.</span>, <span class="number">4.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">5.</span>])</span><br></pre></td></tr></table></figure><p>如果<code>argmax()</code>没有指定axis，则返回整个Tensor最大值的下标。如果指定axis，则返回指定轴上最大值下标。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&gt; t.max(dim=<span class="number">0</span>)</span><br><span class="line">(tensor([<span class="number">4.</span>, <span class="number">3.</span>, <span class="number">3.</span>, <span class="number">5.</span>]), tensor([<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>]))</span><br><span class="line"></span><br><span class="line">&gt; t.argmax(dim=<span class="number">0</span>)</span><br><span class="line">tensor([<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">&gt; t.max(dim=<span class="number">1</span>)</span><br><span class="line">(tensor([<span class="number">2.</span>, <span class="number">3.</span>, <span class="number">5.</span>]), tensor([<span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>]))</span><br><span class="line"></span><br><span class="line">&gt; t.argmax(dim=<span class="number">1</span>)</span><br><span class="line">tensor([<span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><p>当调用<code>max()</code>函数时，返回2个Tensor，第一个Tensor表示返回轴上最大的值，第2个Tensor返回最大值的下标，也就是<code>argmax()</code>的返回值。<br>通常<code>argmax()</code>通常用在分类任务的输出上，决定哪类有最高的预测值。</p><h2><span id="34-access操作">3.4. Access操作</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&gt; t = torch.tensor([</span><br><span class="line">    [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line">    [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],</span><br><span class="line">    [<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]</span><br><span class="line">], dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">&gt; t.mean()</span><br><span class="line">tensor(<span class="number">5.</span>)</span><br><span class="line"></span><br><span class="line">&gt; t.mean().item()</span><br><span class="line"><span class="number">5.0</span></span><br><span class="line"></span><br><span class="line">&gt; t.mean(dim=<span class="number">0</span>).tolist()</span><br><span class="line">[<span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>]</span><br><span class="line"></span><br><span class="line">&gt; t.mean(dim=<span class="number">0</span>).numpy()</span><br><span class="line">array([<span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>], dtype=float32)</span><br></pre></td></tr></table></figure><p>如果返回的结果是scalar，只有1个元素，使用item()来获取其中的值。<br>如果返回的结果有多个值，可以将Tensor转换为pyhton中的list和array.</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-简介&quot;&gt;&lt;a href=&quot;#1-简介&quot; class=&quot;headerlink&quot; title=&quot;1. 简介&quot;&gt;&lt;/a&gt;1. 简介&lt;/h1&gt;&lt;p&gt;最近发现一个学习Pytorch的教程，有视频版和文字版&lt;a href=&quot;https://deeplizard.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;deeplizard&lt;/a&gt;,这里面详细介绍了关于Tensor的知识，真的讲得超级好，解决了我很多关于Tensor运算的疑惑，在此记录下。&lt;/p&gt;
    
    </summary>
    
      <category term="Deep Learning" scheme="http://yoursite.com/categories/Deep-Learning/"/>
    
    
      <category term="Pytorch" scheme="http://yoursite.com/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>openpai</title>
    <link href="http://yoursite.com/2020/01/10/openpai/"/>
    <id>http://yoursite.com/2020/01/10/openpai/</id>
    <published>2020-01-10T02:34:27.000Z</published>
    <updated>2020-03-05T08:07:13.226Z</updated>
    
    <content type="html"><![CDATA[<p>&ensp;&ensp;&ensp;&ensp;最近实验室安装了openpai平台，可以在上面提交程序运行。下面记录怎么使用OpenPai提交NNI程序，进行调参。<br><a id="more"></a><br><!-- TOC --></p><ul><li><a href="#1-%e4%bd%bf%e7%94%a8%e6%ad%a5%e9%aa%a4">1. 使用步骤</a><ul><li><a href="#11-%e7%bc%96%e5%86%99%e7%a8%8b%e5%ba%8f">1.1. 编写程序</a></li><li><a href="#12-%e5%87%86%e5%a4%87%e9%95%9c%e5%83%8f">1.2. 准备镜像</a></li><li><a href="#13-%e7%bc%96%e5%86%99nni%e7%9a%84yml%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6">1.3. 编写NNI的yml配置文件</a></li><li><a href="#14-%e5%ae%89%e8%a3%85nni">1.4. 安装NNI</a></li><li><a href="#15-%e5%90%af%e5%8a%a8nni">1.5. 启动NNI</a></li><li><a href="#16-nni%e6%b5%8f%e8%a7%88%e5%99%a8%e6%9f%a5%e7%9c%8b">1.6. NNI浏览器查看</a></li><li><a href="#17-%e5%9c%a8%e6%b5%8f%e8%a7%88%e5%99%a8%e4%b8%ad%e6%9f%a5%e7%9c%8bopenpai">1.7. 在浏览器中查看OpenPai</a></li><li><a href="#18-%e5%85%b3%e9%97%adnni">1.8. 关闭NNI</a></li></ul></li><li><a href="#%e5%86%85%e5%ad%98%e6%8c%87%e6%a0%87%e8%a7%a3%e8%af%bb">内存指标解读</a></li></ul><!-- /TOC --><h1><span id="1-使用步骤">1. 使用步骤</span></h1><h2><span id="11-编写程序">1.1. 编写程序</span></h2><p>   先在VSCode中完成代码，先在VSCode的虚拟环境中运行，如果可以运行，再使用OpemPai运行。<br>   <strong>注：在OpenPai上运行程序，不需要指定使用哪块GPU，因为OpenPai会自动申请需要使用的GPU。即以下代码注释掉</strong></p>   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># os.environ["CUDA_VISIBLE_DEVICES"] = "1,2,3"</span></span><br></pre></td></tr></table></figure><h2><span id="12-准备镜像">1.2. 准备镜像</span></h2><p>   准备一个包含hdfs的镜像，将需要用的镜像push到实验室服务器的仓库。<br>   下面是我本人的镜像：</p><ul><li>运行环境mxnet<br> <code>lin-ai-27:5000/wangbeibei/mxnet:cu100_hdfs</code></li><li>运行环境是pytorch<br> <code>172.31.246.45:5000/dlspree:hdfs_pyg</code></li></ul><h2><span id="13-编写nni的yml配置文件">1.3. 编写NNI的yml配置文件</span></h2><p>   使用<code>pip install nni==1.2</code>安装1.2版本的nni，如果不指定版本，默认安装最新版，目前最新是1.3，1.3版本的nni其yml配置文件和1.2有所区别<br>   <a href="https://nni.readthedocs.io/zh/latest/Tutorial/ExperimentConfig.html#openpai" target="_blank" rel="noopener">OpenPai模式</a><br>   1.3版本的nni的yml配置文件和1.2有所不同,<a href="https://nni.readthedocs.io/zh/latest/TrainingService/PaiMode.html" target="_blank" rel="noopener">最新版本的配置文件</a>，其中多了<code>nniManagerNFSMountPath,containerNFSMountPath,paiStoragePlugin</code>三个必填的键。<br>   下面使用的是1.2版本的nni配置文件</p>   <figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">authorName:</span> <span class="string">wangbeibei</span></span><br><span class="line"><span class="attr">experimentName:</span><span class="string">hetero_convlstm_grid_experiment</span></span><br><span class="line"><span class="comment">#并发尝试任务的最大数量，有1张gpu卡就是1，有2gpu卡就是2</span></span><br><span class="line"><span class="attr">trialConcurrency:</span> <span class="number">6</span></span><br><span class="line"><span class="attr">maxExecDuration:</span> <span class="number">100</span><span class="string">h</span></span><br><span class="line"><span class="comment">#Trial 任务的最大数量，成功和失败的都计算在内</span></span><br><span class="line"><span class="attr">maxTrialNum:</span> <span class="number">600</span></span><br><span class="line"><span class="comment">#choice: local, remote, pai</span></span><br><span class="line"><span class="attr">trainingServicePlatform:</span> <span class="string">pai</span></span><br><span class="line"><span class="comment"># 指定nni管理器ip 为29号服务器</span></span><br><span class="line"><span class="attr">nniManagerIp:</span> <span class="number">202.205</span><span class="number">.99</span><span class="number">.174</span></span><br><span class="line"><span class="attr">searchSpacePath:</span><span class="string">hetero_convlstm_search_space.json</span></span><br><span class="line"><span class="comment">#choice: true, false</span></span><br><span class="line"><span class="attr">useAnnotation:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># 存储日志和数据的目录, 默认值是 /dataWangBeibei/nni/  experiments</span></span><br><span class="line"><span class="comment">#如果在虚拟环境中运行该代码，logDir是服务器下绝对路径，/data/ WangBeibei/graduation/Codenni_save_logs</span></span><br><span class="line"><span class="comment">#如果在docker下运行该代码，logDir是容器下的绝路径，/root/ Code/nni_save_logs/</span></span><br><span class="line"><span class="attr">logDir:</span> <span class="string">/data/WangBeibei/graduation/Codenni_save_logs</span></span><br><span class="line"><span class="attr">tuner:</span></span><br><span class="line">  <span class="comment">#choice: TPE, Random, Anneal, Evolution,BatchTuner,  MetisTuner, GPTuner</span></span><br><span class="line">  <span class="comment">#SMAC (SMAC should be installed throughnnictl)</span></span><br><span class="line"><span class="attr">  builtinTunerName:</span> <span class="string">TPE</span></span><br><span class="line"><span class="attr">  classArgs:</span></span><br><span class="line">    <span class="comment">#choice: maximize, minimize</span></span><br><span class="line"><span class="attr">    optimize_mode:</span> <span class="string">minimize</span></span><br><span class="line"><span class="attr">trial:</span></span><br><span class="line">  <span class="comment"># 指定了运行 Trial 进程的命令行</span></span><br><span class="line"><span class="attr">  command:</span> <span class="string">cd</span> <span class="string">baseline</span> <span class="string">&amp;&amp;</span> <span class="string">python3</span>  <span class="string">hetero_convlstm_baseline.py</span></span><br><span class="line">  <span class="comment">#指定了 Trial 代码文件的目录,../会进入到Cod目录下</span></span><br><span class="line"><span class="attr">  codeDir:</span> <span class="string">../</span></span><br><span class="line"><span class="attr">  gpuNum:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  cpuNum:</span> <span class="number">8</span></span><br><span class="line"><span class="attr">  memoryMB:</span> <span class="number">14000</span></span><br><span class="line">  <span class="comment"># docker 镜像地址</span></span><br><span class="line">  <span class="comment">#pytorch镜像：172.31.246.45:5000dlspree:hdfs_pyg</span></span><br><span class="line">  <span class="comment">#mxnet镜像：lin-ai-27:5000/wangbeibeimxnet:cu100_hdfs</span></span><br><span class="line"><span class="attr">  image:</span> <span class="number">172.31</span><span class="number">.246</span><span class="number">.45</span><span class="string">:5000/dlspree:hdfs_pyg</span></span><br><span class="line"><span class="comment"># 配置访问的 OpenPAI 集群</span></span><br><span class="line"><span class="attr">paiConfig:</span></span><br><span class="line">  <span class="comment">#OpenPai网页的用户名和密码，也是53号服务器用户名和密码</span></span><br><span class="line"><span class="attr">  userName:</span> <span class="string">user</span></span><br><span class="line">  <span class="comment"># 密码如果是全数字需要 ""</span></span><br><span class="line"><span class="attr">  passWord:</span> <span class="string">psw</span></span><br><span class="line">  <span class="comment">#OpenPai集群的主节点</span></span><br><span class="line"><span class="attr">  host:</span> <span class="number">172.31</span><span class="number">.246</span><span class="number">.52</span></span><br></pre></td></tr></table></figure><p>   <strong>这里资源的配置都是针对一个trail的，memoryMB也是针对一个trail的。</strong><br>   <strong>注意：</strong> pai 模式下，NNIManager 会启动 RESTful 服务，监听端口为 NNI 网页服务器的端口加1。 例如，如果网页端口为<code>8080</code>，那么 RESTful 服务器会监听在 <code>8081</code>端口，来接收运行在 Kubernetes 中的 Trial 作业的指标。 因此，需要在防火墙中启用端口 <code>8081</code> 的 TCP 协议，以允许传入流量。</p><p>通常在服务器中8080端口无法使用，我们需要在启动NNI管理器时手动通过 —port 指定端口。</p><h2><span id="14-安装nni">1.4. 安装NNI</span></h2><p>   由于NNI并不依赖于任何环境，因此当我们使用OpenPAI提交NNI任务时，为了方便（需要解决ip和端口映射问题），<strong>不需要在docker中启动NNI，直接在服务器环境下安装NNI，启动即可</strong>。<br>   使用<code>pip install nni==1.2</code>安装nni</p><h2><span id="15-启动nni">1.5. 启动NNI</span></h2><p>   使用<code>nnictl create --port 6688 --config xxx.yml</code>来启动一个Experiment,如果端口被占用，换别的端口</p><h2><span id="16-nni浏览器查看">1.6. NNI浏览器查看</span></h2><p>   在浏览器中输入<code>服务器ip:6688</code></p><h2><span id="17-在浏览器中查看openpai">1.7. 在浏览器中查看OpenPai</span></h2><p>   在浏览器中登录OpenPai，可以查看启动的trail，在代码中的print输出的内容在stdout中查看。<br>   <strong>注：有时候print语句输出的内容在stdout显示不出来，添加<code>flush=True</code>就可以了</strong></p>   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"************进入main函数"</span>,flush=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p>   <img src="/2020/01/10/openpai/logs.png" alt=""></p><h2><span id="18-关闭nni">1.8. 关闭NNI</span></h2><p>直接在服务器中使用<code>nnictl stop</code>即可关闭nni的Experiment</p><hr><p>2020.3.5更新</p><h1><span id="内存指标解读">内存指标解读</span></h1><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">trial:</span></span><br><span class="line">    <span class="comment"># 指定了运行 Trial 进程的命令行</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">cd</span> <span class="string">baseline</span> <span class="string">&amp;&amp;</span> <span class="string">python3</span>  <span class="string">hetero_convlstm_baseline.py</span></span><br><span class="line">    <span class="comment">#指定了 Trial 代码文件的目录,../会进入到Cod目录下</span></span><br><span class="line"><span class="attr">    codeDir:</span> <span class="string">../</span></span><br><span class="line"><span class="attr">    gpuNum:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">    cpuNum:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">    memoryMB:</span> <span class="number">20000</span></span><br></pre></td></tr></table></figure><p><strong>【gpuNum】</strong>：设置为2，表示该程序使用2张GPU，即该程序独占2张GPU卡，<strong>独占2张卡的显存和计算力</strong><br><strong>【cpuNum】</strong>：设置为3，占用3块CPU来计算<br><strong>【memoryMB】</strong>：设置为20000MB，表示该程序总共占2000MB的内存，在openpai上内存是共享的，显存是独享的。</p><p>当我设置如上资源来跑程序时，可以看到程序的资源占用情况如下所示：<br><img src="/2020/01/10/openpai/指标示意图.png" alt=""></p><p><strong>【指标解读】</strong></p><p>上面从左到右一共有6张图，我们只关注<code>CPU,memory usage,GPU Utilization,GPU Memory</code>这4张图。</p><ul><li><strong>CPU</strong>：CPU的占用率稳定在300%，说明程序分配的3张CPU卡都用来做计算，CPU一直是满载状况，这时候可以适当增加cpuNum的个数</li><li><strong>memory usage</strong>：内存占用率稳定在12G，我们分配给该程序的资源是20G，分配的有点多，可以适当减少些。内存分配的资源也不是越多越好，因为openpai在跑程序时，当有足够的GPU但是却没有足够的内存，程序依然不能运行，会一直处于waiting状态</li><li><strong>GPU Utilization和GPU Memory</strong>：GPU的占用率稳定在25%，给该程序分配了2张GPU卡，一张卡有11G显存，但是程序只占了25%，也就是大约3G，2张卡对该程序有点多，可以改为1张卡</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;最近实验室安装了openpai平台，可以在上面提交程序运行。下面记录怎么使用OpenPai提交NNI程序，进行调参。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="工具" scheme="http://yoursite.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="openpai" scheme="http://yoursite.com/tags/openpai/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch之GPU程序</title>
    <link href="http://yoursite.com/2020/01/06/Pytorch%E4%B9%8BGPU%E7%A8%8B%E5%BA%8F/"/>
    <id>http://yoursite.com/2020/01/06/Pytorch之GPU程序/</id>
    <published>2020-01-06T06:35:30.000Z</published>
    <updated>2020-02-24T08:24:54.101Z</updated>
    
    <content type="html"><![CDATA[<p>介绍Pytorch的一些使用方法<br><a id="more"></a></p><h1><span id="gpu">GPU</span></h1><p><a href="https://zhuanlan.zhihu.com/p/71566775" target="_blank" rel="noopener">转载出处</a></p><p><a href="https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter04_DL_computation/4.6_use-gpu" target="_blank" rel="noopener">GPU计算</a></p><h2><span id="查看-gpu-信息">查看 GPU 信息</span></h2><p>更多接口，参考 <a href="https://pytorch.org/docs/stable/cuda.html" target="_blank" rel="noopener">torch.cuda</a></p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">torch</span><span class="selector-class">.cuda</span><span class="selector-class">.is_available</span>()       # 判断 <span class="selector-tag">GPU</span> 是否可用</span><br><span class="line"><span class="selector-tag">torch</span><span class="selector-class">.cuda</span><span class="selector-class">.device_count</span>()       # 判断有多少 <span class="selector-tag">GPU</span></span><br><span class="line"><span class="selector-tag">torch</span><span class="selector-class">.cuda</span><span class="selector-class">.get_device_name</span>(0)   # 返回 <span class="selector-tag">gpu</span> 名字，设备索引默认从 0 开始</span><br><span class="line"><span class="selector-tag">torch</span><span class="selector-class">.cuda</span><span class="selector-class">.current_device</span>()     # 返回当前设备索引</span><br></pre></td></tr></table></figure><h2><span id="torchdevice">torch.device</span></h2><p><code>torch.device</code> 表示 <code>torch.Tensor</code> 分配到的设备的对象。其包含一个设备类型（<code>cpu</code> 或 <code>cuda</code>），以及可选的设备序号。如果设备序号不存在，则为当前设备，即 <code>torch.cuda.current_device()</code> 的返回结果。</p><p>可以通过如下方式创建 <code>torch.device</code> 对象：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过字符串</span></span><br><span class="line"><span class="attr">device</span> = torch.device(<span class="string">'cpu'</span>)</span><br><span class="line"><span class="attr">device</span> = torch.device(<span class="string">'cuda:1'</span>)  # 指定类型及编号。注意，代码不会检查编号是否合法</span><br><span class="line"><span class="attr">device</span> = torch.device(<span class="string">'cuda'</span>)    # 默认为当前设备，如果是多GPU，默认使用全部GPU</span><br></pre></td></tr></table></figure><p>还可以通过设备类型加上编号，来创建 <code>device</code> 对象：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">device</span> = torch.device(<span class="string">'cuda'</span>, <span class="number">0</span>)</span><br><span class="line"><span class="attr">device</span> = torch.device(<span class="string">'cpu'</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure><h2><span id="配置-cuda-访问限制">配置 CUDA 访问限制</span></h2><p>可以通过如下方式，设置当前 <code>Python</code> 脚本可见的 <code>GPU</code>。</p><h3><span id="在命令行设置">在命令行设置</span></h3><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">CUDA_VISIBLE_DEVICES</span>=<span class="number">1</span> python my_script.py</span><br></pre></td></tr></table></figure><p><strong>实例</strong></p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Environment Variable Syntax      Results</span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">1</span>           Only device <span class="number">1</span> will be seen</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span>         Devices <span class="number">0</span> <span class="keyword">and</span> <span class="number">1</span> will be visible</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="string">"0,1"</span>       Same as above, quotation marks are optional</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>       Devices <span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span> will be visible; device <span class="number">1</span> <span class="keyword">is</span> masked</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="string">""</span>          No GPU will be visible</span><br></pre></td></tr></table></figure><h3><span id="在-python-代码中设置">在 Python 代码中设置</span></h3><figure class="highlight moonscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="built_in">os</span></span><br><span class="line"><span class="built_in">os</span>.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"0, 2"</span></span><br></pre></td></tr></table></figure><h3><span id="使用函数-set_device">使用函数 set_device</span></h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">torch<span class="selector-class">.cuda</span><span class="selector-class">.set_device</span>(id)</span><br></pre></td></tr></table></figure><blockquote><p>官方建议使用 <code>CUDA_VISIBLE_DEVICES</code>，不建议使用 <code>set_device</code> 函数。</p></blockquote><h2><span id="用-gpu-训练">用 GPU 训练</span></h2><p>默认情况下，使用 <code>CPU</code> 训练模型。可以通过如下方式，通过 <code>GPU</code> 进行训练。<strong>使用 GPU 时，模型和输入必须位于同一张 GPU 上。</strong></p><p><code>.to(device)</code> 和 <code>.cuda()</code> 的区别如下：</p><p><a href="https://stackoom.com/question/3bltP/Pytorch-%E5%9C%A8CUDA%E8%AE%BE%E5%A4%87%E4%B8%8A%E6%9C%89%E4%B8%89%E7%A7%8D%E6%96%B9%E6%B3%95%E5%8F%AF%E4%BB%A5%E5%88%9B%E5%BB%BA%E5%BC%A0%E9%87%8F-%E5%AE%83%E4%BB%AC%E4%B9%8B%E9%97%B4%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%E5%90%97" target="_blank" rel="noopener">to和cuda的区别</a><br><img src="/2020/01/06/Pytorch之GPU程序/pytorch-学习/to和cuda区别.png" alt="to和cuda区别"></p><ol><li><code>.to()</code> 中的参数必不可少</li><li>对于 <code>module</code> 而言，<code>.to()</code> 是 <code>inplace</code> 的，而 <code>.cuda()</code> 不是；而对于 <code>tensor</code> 而言，两者一致。</li></ol><blockquote><p><strong>注</strong>：实测，两者时间消耗持平。推荐使用<code>.to()函数</code></p></blockquote><p><strong>方式 1 ：使用cuda</strong></p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">device</span> = torch.device(<span class="string">"cuda:1"</span>)   <span class="comment"># 指定模型训练所在 GPU</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 CPU 转移至 GPU</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available() <span class="literal">and</span> use_gpu:</span><br><span class="line">    <span class="attr">net</span> = net.cuda(device)    <span class="comment"># 默认在第一块 GPU 上训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 同时将数据转移至 GPU,注意cuda有返回值</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available() <span class="literal">and</span> use_gpu:</span><br><span class="line">    <span class="attr">inputs</span> = inputs.cuda(device)</span><br><span class="line">    <span class="attr">labels</span> = labels.cuda(device)</span><br></pre></td></tr></table></figure><p><strong>方法 2 ：使用to</strong></p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">device</span> = torch.device(<span class="string">"cuda:1"</span>)   <span class="comment"># 指定模型训练所在 GPU</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 CPU 转移至 GPU</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available() <span class="literal">and</span> use_gpu:</span><br><span class="line">    <span class="attr">net</span> = net.to(device)    <span class="comment"># 默认在第一块 GPU 上训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 同时将数据转移至 GPU</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available() <span class="literal">and</span> use_gpu:</span><br><span class="line">    <span class="attr">inputs</span> = inputs.to(device)</span><br><span class="line">    <span class="attr">labels</span> = labels.to(device)</span><br></pre></td></tr></table></figure><h2><span id="存在的问题">存在的问题</span></h2><h3><span id="batch-size-太大">batch size 太大</span></h3><p>当想要用大批量进行训练，但是 <code>GPU</code> 资源有限，此时可以通过<strong>梯度累加</strong>（<code>accumulating gradients</code>）的方式进行。</p><p>梯度累加的基本思想在于，在优化器更新参数前，也就是执行 <code>optimizer.step()</code> 前，进行多次反向传播，使得梯度累计值自动保存在 <code>parameter.grad</code> 中，最后使用累加的梯度进行参数更新。</p><p>这个在 <code>PyTorch</code> 中特别容易实现，因为 <code>PyTorch</code> 中，梯度值本身会保留，除非我们调用 <code>model.zero_grad()</code> 或 <code>optimizer.zero_grad()</code>。</p><p>修改后的代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model.zero_grad() <span class="comment"># 重置保存梯度值的张量</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, (inputs, labels) <span class="keyword">in</span> enumerate(training_set):</span><br><span class="line">    predictions = model(inputs)<span class="comment"># 前向计算</span></span><br><span class="line">    loss = loss_function(predictions, labels)<span class="comment"># 计算损失函数</span></span><br><span class="line">    loss.backward()<span class="comment"># 计算梯度</span></span><br><span class="line">    <span class="keyword">if</span> (i + <span class="number">1</span>) % accumulation_steps == <span class="number">0</span>:<span class="comment">#重复多次前面的过程</span></span><br><span class="line">        optimizer.step()<span class="comment">#更新梯度</span></span><br><span class="line">        model.zero_grad()<span class="comment">#重置梯度</span></span><br></pre></td></tr></table></figure><h3><span id="model-太大">model 太大</span></h3><p>当模型本身太大，以至于不能放置于一个 <code>GPU</code> 中时，可以通过<strong>梯度检查点</strong> (<code>gradient-checkpoingting</code>) 的方式进行处理。</p><p>梯度检查点的基本思想是<strong>以计算换内存</strong>。具体来说就是，在反向传播的过程中，把梯度切分成几部分，分别对网络上的部分参数进行更新。如下图所示：</p><p><img src="http://tankzhou.cn/images/%E6%A2%AF%E5%BA%A6%E6%A3%80%E6%9F%A5%E7%82%B9.gif" alt=""></p><p>梯度检查点图示</p><p>这种方法速度很慢，但在某些例子上很有用，比如训练长序列的 RNN 模型等。</p><p>具体可参考：<a href="https://medium.com/huggingface/from-zero-to-research-an-introduction-to-meta-learning-8e16e677f78a" target="_blank" rel="noopener">From zero to research — An introduction to Meta-learning</a></p><p>单机多卡训练，即<strong>并行训练</strong>。并行训练又分为<strong>数据并行</strong> (<code>Data Parallelism</code>) 和<strong>模型并行</strong>两种。</p><p>数据并行指的是，多张 <code>GPU</code> 使用相同的模型副本，但是使用不同的数据批进行训练。而模型并行指的是，多张<code>GPU</code> 分别训练模型的不同部分，使用同一批数据。</p><p>两者对比如下图所示：</p><p><img src="/2020/01/06/Pytorch之GPU程序/pytorch-学习/多GPU.jpg" alt=""></p><p>模型并行 VS 数据并行</p><h2><span id="数据并行">数据并行</span></h2><p><a href="https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html" target="_blank" rel="noopener">Pytorch多GPU官方实例</a></p><h3><span id="pytorch-api">Pytorch API</span></h3><p>【<strong>Class 原型</strong>】</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.DataParallel(module, <span class="attribute">device_ids</span>=None, <span class="attribute">output_device</span>=None, <span class="attribute">dim</span>=0)</span><br></pre></td></tr></table></figure><p>【<strong>参数</strong>】</p><ul><li><strong>module</strong> ：要进行并行的 <code>module</code>。这里隐含了一点 ，即网络中的某一层也是可以进行数据并行的，但是一般不会这么使用。</li><li><strong>device_ids</strong> : <code>CUDA</code> 列表，可以为 <code>torch.device</code> 类型，也可以是编号组成的 <code>int</code> 列表。<strong>默认使用全部 GPU</strong></li><li><strong>output_device</strong> : 某一 <code>GPU</code> 编号或 <code>torch.device</code> 。指定输出的 <code>GPU</code>，默认为第一个，即 <code>device_ids[0]</code></li></ul><p>【<strong>返回值</strong>】</p><p>要进行并行的模型。</p><p>【<strong>基本使用方式</strong>】</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; net = torch.nn.DataParallel(model, device_ids=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; output = net(input_var)  <span class="comment"># input_var can be on any device, including CP</span></span><br></pre></td></tr></table></figure><h3><span id="数据并行的原理">数据并行的原理</span></h3><p>数据并行的具体原理流程为：</p><p><img src="/2020/01/06/Pytorch之GPU程序/pytorch-学习/数据并行.png" alt=""></p><ol><li><p>将模型加载至主设备上，作为 <code>controller</code>，一般设置为 <code>cuda:0</code></p></li><li><p>在每次迭代时，执行如下操作：</p><ol><li><p>将 <code>controller</code> 模型复制（<code>broadcast</code>）到每一个指定的 <code>GPU</code> 上</p></li><li><p>将总输入的数据 <code>batch</code>，进行均分，分别作为各对应副本的输入 (<code>scatter</code>)</p></li><li><p>每个副本独立进行前向传播，并进行反向传播，但只是求取梯度，每个GPU上的loss都要进行<code>loss.backward()</code>,得到各自的梯度</p></li><li><p>将各副本的梯度汇总（<code>gather</code>）到 <code>controller</code> 设备，并进行求和 (<code>reduced add</code>)</p><blockquote><p>During the backwards pass, gradients from each replica are summed into the original module.</p></blockquote></li><li><p>更具总体度，更新 <code>controller</code> 设备上的参数</p></li></ol></li></ol><h3><span id="注意事项">注意事项</span></h3><p>【<strong>警告 1</strong>】</p><ul><li>设置的 <code>batch size</code> 为总的批量尺寸，其必须大于 <code>GPU</code> 数量。</li><li>在 <code>parallelized module</code> 运行之前，必须保证其在 <code>controller</code> 设备上，存在参数和 <code>buffers</code>。</li><li>并行的 <code>GPU</code> 列表中，必须包含主 <code>GPU</code></li><li>当 <code>forward()</code> 中，<code>module</code> 返回一个标量，那么并行的结果将返回一个 <code>vector</code>，其长度等于 <code>device</code> 的数量，对应于各个设备的结果。</li></ul><p>【<strong>警告 2</strong>】</p><p>在每次前向传播过程中，<code>module</code> 都先会被复制到每一个 <code>device</code> 上。因此，在前向传播中，任何对该运行的 <code>module</code> 的副本的更新，在此后都将会丢失。</p><p>比方说，如果 <code>module</code> 有一个 <code>counter</code> 属性，每次前向传播都会进行累加，则它将会保持为初始值。因为更新是发生在模型的副本（在其他 <code>device</code> 上的副本）上的，并且这些更新在前向传播结束之后将会被销毁。</p><p>然而，<code>DataParallel</code> 保证 <code>controller</code> 设备上的副本的参数和 <code>buffers</code> 与其他并行的 <code>modules</code> 之间共享存储。因此，如若对 <code>controller device</code> 的 参数和 <code>buffers</code> 的更改，将会被记录。例如，<code>BatchNorm2d</code> 和 <code>spectral_norm()</code> 依赖于这种行为来更新 <code>buffers</code>。</p><p>【<strong>警告 3</strong>】</p><p>定义于 <code>module</code> 及其子 <code>module</code> 上的前向传播和反向传播 <code>hooks</code>，将会被调用 <code>len(device_ids)</code> 次，每个设备对应一次。</p><p>具体来说，<code>hooks</code> 只能保证按照正确的顺序执行对应设备上的操作，即在对应设备上的 <code>forward()</code> 调用之前执行，但是不能保证，在所有 <code>forward)()</code> 执行之前，通过 <code>register_forward_pre_hook()</code> 执行完成所有的 <code>hooks</code>。</p><p>【<strong>警告 4</strong>】</p><p>任何位置和关键字 (<code>positional and keyword</code>) 输入都可以传递给 <code>DataParallel</code>，处理一些需要特殊处理的类型。</p><p><code>tensors</code> 将会在指定维度（默认为 <code>0</code>）上被 <code>scattered</code>。 <code>tuple</code>， <code>list</code> 和 <code>dict</code> 类型则会被浅拷贝。其他类型则会在不同的线程之间进行共享，且在模型前向传播过程中，如果进行写入，则可被打断。</p><p>【<strong>警告 5</strong>】</p><p>当对 <code>pack sequence -&gt; recurrent network -&gt; unpack sequence</code> 模式的 <code>module</code> 使用 <code>DataParallel</code> 或 <code>data_parallel</code> 时，有一些小的问题。</p><p>每个设备上的 <code>forward</code> 的对应输入，将仅仅是整个输入的一部分。因为默认的 <code>unpack</code> 操作 <code>torch.nn.utils.rnn.pad_packed_sequence()</code> 只会将该设备上的输入 <code>padding</code> 成该设备上的最长的输入长度，因此，将所有设备的结构进行汇总时，可能会发生长度的不匹配的情况。</p><p>因此，可以利用 <code>pad_packed_sequence()</code> 的 <code>total_length</code> 参数来保证 <code>forward()</code> 调用返回的序列长度一致。代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.nn.utils.rnn <span class="keyword">import</span> pack_padded_sequence, pad_packed_sequence</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModule</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="comment"># ... __init__, other methods, etc.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># padded_input is of shape [B x T x *] (batch_first mode) and contains</span></span><br><span class="line">    <span class="comment"># the sequences sorted by lengths</span></span><br><span class="line">    <span class="comment">#   B is the batch size</span></span><br><span class="line">    <span class="comment">#   T is max sequence length</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, padded_input, input_lengths)</span>:</span></span><br><span class="line">        total_length = padded_input.size(<span class="number">1</span>)  <span class="comment"># get the max sequence length</span></span><br><span class="line">        packed_input = pack_padded_sequence(padded_input, input_lengths,</span><br><span class="line">                                            batch_first=<span class="keyword">True</span>)</span><br><span class="line">        packed_output, _ = self.my_lstm(packed_input)</span><br><span class="line">        output, _ = pad_packed_sequence(packed_output, batch_first=<span class="keyword">True</span>,</span><br><span class="line">                                        total_length=total_length)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">m = MyModule().cuda()        <span class="comment"># 设置 controller 模型</span></span><br><span class="line">dp_m = nn.DataParallel(m)    <span class="comment"># 进行副本拷贝</span></span><br></pre></td></tr></table></figure><h3><span id="示例程序">示例程序</span></h3><p>下面是使用 <code>DataParrel</code> 的核心代码，其余部分与一般的训练流程一致。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置当前脚本可见的 GPU 列表</span></span><br><span class="line"><span class="comment"># 这里设置 0 号和 1 号 GPU 对当前脚本可见。</span></span><br><span class="line"><span class="comment"># 此时，若 DataParallel 中指定使用其他 GPU 资源，额外的编号将会被忽略</span></span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"0, 1"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用数据并行</span></span><br><span class="line"><span class="comment"># 1. 将 model 转移到某 GPU 上 -- net.cuda()</span></span><br><span class="line"><span class="comment"># 2. 指定并行训练要用到的 GPU -- device_ids=[0, 1]</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.device_count() &gt; <span class="number">1</span>:</span><br><span class="line">    print(<span class="string">"Let's use"</span>, torch.cuda.device_count(), <span class="string">"GPUs!"</span>)</span><br><span class="line">    net = nn.DataParallel(net.cuda(), device_ids=[<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据转移到 controller 所在 GPU</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">and</span> use_gpu:</span><br><span class="line">    inputs = inputs.cuda(device)</span><br><span class="line">    labels = labels.cuda(device)</span><br></pre></td></tr></table></figure><h3><span id="模型的加载">模型的加载</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_Single2Parallel</span><span class="params">(self, origin_state)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    将串行的权值参数转换为并行的权值参数</span></span><br><span class="line"><span class="string">    :param origin_state : 原始串行权值参数</span></span><br><span class="line"><span class="string">    :return             : 并行的权值参数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">  converted = OrderedDict()</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> origin_state.items():</span><br><span class="line">      name = <span class="string">"module."</span> + k</span><br><span class="line">      converted[name] = v</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> converted</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_Parallel2Single</span><span class="params">(self, origin_state)</span>:</span></span><br><span class="line">  <span class="string">"""</span></span><br><span class="line"><span class="string">  将并行的权值参数转换为串行的权值参数</span></span><br><span class="line"><span class="string">  :param origin_state : 原始串行权值参数</span></span><br><span class="line"><span class="string">  :return             : 并行的权值参数</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">    </span><br><span class="line">    converted = OrderedDict()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> origin_state.items():</span><br><span class="line">      name = k[<span class="number">7</span>:]</span><br><span class="line">      converted[name] = v</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">return</span> converted</span><br></pre></td></tr></table></figure><h2><span id="模型并行">模型并行</span></h2><p>如果模型本身较大，一张 <code>GPU</code> 放置不下时，要通过模型并行来处理。模型并行指的是，将模型的不同部分，分别放置于不同的 <code>GPU</code> 上，并将中间结果在 <code>GPU</code> 之间进行传递。</p><p>尽管从执行时间上来看，将模型的不同部分部署在不同设备上确实有好处，但是它通常是出于避免内存限制才使用。具有特别多参数的模型会受益于这种并行策略，因为这类模型需要很高的内存占用，很难适应到单个系统。</p><h3><span id="基本使用">基本使用</span></h3><p>下面，我们以一个 <code>toy</code> 模型为例，讲解模型并行。模型并行的实现方式如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.features_1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels=<span class="number">3</span>, out_channels=<span class="number">16</span>, kernel_size=<span class="number">3</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">16</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="keyword">True</span>),  <span class="comment"># 30</span></span><br><span class="line">            ......</span><br><span class="line">            nn.Conv2d(in_channels=<span class="number">64</span>, out_channels=<span class="number">128</span>, kernel_size=<span class="number">3</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="keyword">True</span>),  <span class="comment"># 12</span></span><br><span class="line">        ).to(<span class="string">'cuda:0'</span>)</span><br><span class="line"></span><br><span class="line">        self.features_2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels=<span class="number">128</span>, out_channels=<span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="keyword">True</span>),  <span class="comment"># 5</span></span><br><span class="line">            ......).to(<span class="string">'cuda:1'</span>)  <span class="comment"># 1</span></span><br><span class="line"></span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            ......</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, class_num)).to(<span class="string">'cuda:1'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        out = self.features_1(x.to(<span class="string">'cuda:0'</span>))</span><br><span class="line">        out = self.features_2(out.to(<span class="string">'cuda:1'</span>))</span><br><span class="line">        out = out.view(<span class="number">-1</span>, <span class="number">384</span>)</span><br><span class="line">        out = self.classifier(out)</span><br><span class="line">        out = F.softmax(out, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>上面的 <code>toy</code> 模型看起来和在单个 <code>GPU</code> 上运行的模型没什么区别，只不过用 <code>to(device)</code> 来将模型内的不同层分散到不同的 <code>GPU</code> 上进行运行，并且将中间结果转移到对应的 <code>GPU</code> 上即可。</p><p><code>backward()</code> 和 <code>torch.optim</code> 将会自动考虑梯度，与在一个 <code>GPU</code> 上没有区别。</p><blockquote><p><strong>注意</strong>：在调用 <code>loss</code> 函数时，<code>labels</code> 与 <code>output</code> 必须在同一个 <code>GPU</code> 上。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此时，不在此需要使用 model = model.cuda()</span></span><br><span class="line">model = ToyModel()</span><br><span class="line"></span><br><span class="line">loss_fn = nn.MSELoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> trainloader:</span><br><span class="line">    images, labels = data</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 要处理的部分</span></span><br><span class="line">    images = images.to(<span class="string">'cuda:0'</span>)</span><br><span class="line">    labels = labels.to(<span class="string">'cuda:1'</span>)   <span class="comment"># 必须与输出所在 GPU 一致</span></span><br><span class="line">    </span><br><span class="line">    outputs = net(images)</span><br><span class="line">    loss = criterion(outputs, labels)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure><h3><span id="模型并行的性能分析">模型并行的性能分析</span></h3><p>以上的实现解决了单个模型太大，不能存放于一个 <code>GPU</code> 的情况。然而，需要注意的是，相较于在单个 <code>GPU</code> 上运行，其速度更慢。因为任何时候，只有一个 <code>GPU</code> 在工作，而另一个则闲置。而当中间结果在 <code>GPU</code> 之间进行转移时，速度会进一步下降。</p><p>下面同时实例分析。以 <code>resnet50</code> 为例，用随机生成的数据输入，比较两个版本的运行时间。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision.models.resnet <span class="keyword">import</span> ResNet, Bottleneck</span><br><span class="line"></span><br><span class="line">num_classes = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ModelParallelResNet50</span><span class="params">(ResNet)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, *args, **kwargs)</span>:</span></span><br><span class="line">        super(ModelParallelResNet50, self).__init__(</span><br><span class="line">            Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], num_classes=num_classes, *args, **kwargs)</span><br><span class="line"></span><br><span class="line">        self.seq1 = nn.Sequential(</span><br><span class="line">            self.conv1,</span><br><span class="line">            self.bn1,</span><br><span class="line">            self.relu,</span><br><span class="line">            self.maxpool,</span><br><span class="line"></span><br><span class="line">            self.layer1,</span><br><span class="line">            self.layer2</span><br><span class="line">        ).to(<span class="string">'cuda:0'</span>)</span><br><span class="line"></span><br><span class="line">        self.seq2 = nn.Sequential(</span><br><span class="line">            self.layer3,</span><br><span class="line">            self.layer4,</span><br><span class="line">            self.avgpool,</span><br><span class="line">        ).to(<span class="string">'cuda:1'</span>)</span><br><span class="line"></span><br><span class="line">        self.fc.to(<span class="string">'cuda:1'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.seq2(self.seq1(x).to(<span class="string">'cuda:1'</span>))</span><br><span class="line">        <span class="keyword">return</span> self.fc(x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"></span><br><span class="line">num_batches = <span class="number">3</span></span><br><span class="line">batch_size = <span class="number">120</span></span><br><span class="line">image_w = <span class="number">128</span></span><br><span class="line">image_h = <span class="number">128</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(model)</span>:</span></span><br><span class="line">    model.train(<span class="keyword">True</span>)</span><br><span class="line">    loss_fn = nn.MSELoss()</span><br><span class="line">    optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">    one_hot_indices = torch.LongTensor(batch_size) \</span><br><span class="line">                           .random_(<span class="number">0</span>, num_classes) \</span><br><span class="line">                           .view(batch_size, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(num_batches):</span><br><span class="line">        <span class="comment"># generate random inputs and labels</span></span><br><span class="line">        inputs = torch.randn(batch_size, <span class="number">3</span>, image_w, image_h)</span><br><span class="line">        labels = torch.zeros(batch_size, num_classes) \</span><br><span class="line">                      .scatter_(<span class="number">1</span>, one_hot_indices, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># run forward pass</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = model(inputs.to(<span class="string">'cuda:0'</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># run backward pass</span></span><br><span class="line">        labels = labels.to(outputs.device)</span><br><span class="line">        loss_fn(outputs, labels).backward()</span><br><span class="line">        optimizer.step()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.switch_backend(<span class="string">'Agg'</span>)</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> timeit</span><br><span class="line"></span><br><span class="line">num_repeat = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">stmt = <span class="string">"train(model)"</span></span><br><span class="line"></span><br><span class="line">setup = <span class="string">"model = ModelParallelResNet50()"</span></span><br><span class="line"><span class="comment"># globals arg is only available in Python 3. In Python 2, use the following</span></span><br><span class="line"><span class="comment"># import __builtin__</span></span><br><span class="line"><span class="comment"># __builtin__.__dict__.update(locals())</span></span><br><span class="line">mp_run_times = timeit.repeat(</span><br><span class="line">    stmt, setup, number=<span class="number">1</span>, repeat=num_repeat, globals=globals())</span><br><span class="line">mp_mean, mp_std = np.mean(mp_run_times), np.std(mp_run_times)</span><br><span class="line"></span><br><span class="line">setup = <span class="string">"import torchvision.models as models;"</span> + \</span><br><span class="line">        <span class="string">"model = models.resnet50(num_classes=num_classes).to('cuda:0')"</span></span><br><span class="line">rn_run_times = timeit.repeat(</span><br><span class="line">    stmt, setup, number=<span class="number">1</span>, repeat=num_repeat, globals=globals())</span><br><span class="line">rn_mean, rn_std = np.mean(rn_run_times), np.std(rn_run_times)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot</span><span class="params">(means, stds, labels, fig_name)</span>:</span></span><br><span class="line">    fig, ax = plt.subplots()</span><br><span class="line">    ax.bar(np.arange(len(means)), means, yerr=stds,</span><br><span class="line">           align=<span class="string">'center'</span>, alpha=<span class="number">0.5</span>, ecolor=<span class="string">'red'</span>, capsize=<span class="number">10</span>, width=<span class="number">0.6</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">'ResNet50 Execution Time (Second)'</span>)</span><br><span class="line">    ax.set_xticks(np.arange(len(means)))</span><br><span class="line">    ax.set_xticklabels(labels)</span><br><span class="line">    ax.yaxis.grid(<span class="keyword">True</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.savefig(fig_name)</span><br><span class="line">    plt.close(fig)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plot([mp_mean, rn_mean],</span><br><span class="line">     [mp_std, rn_std],</span><br><span class="line">     [<span class="string">'Model Parallel'</span>, <span class="string">'Single GPU'</span>],</span><br><span class="line">     <span class="string">'mp_vs_rn.png'</span>)</span><br></pre></td></tr></table></figure><p>结果如下所示。模型并行相较于单 <code>GPU</code> 训练的模型，训练时间开销多出 <code>4.02/3.75-1=7%</code> 左右。当然，这存在优化空间，因为多 <code>GPU</code> 中，每一时刻只有一个 <code>GPU</code> 进行训练，其他闲置。而在中间数据转移过程中，又消耗一定的时间。</p><p><img src="/2020/01/06/Pytorch之GPU程序/pytorch-学习/模型并行.jpg" alt=""></p><p>模型并行 VS 单 GPU</p><h3><span id="输入流水线">输入流水线</span></h3><p>解决上面的问题的最直接的方式就是使用流水线技术，即 <code>GPU-0</code> 输出到 <code>GPU-1</code> 之后，在 <code>GPU-1</code> 训练的同时，<code>GPU-0</code> 接收下一批数据，这样就可以多 <code>GPU</code> 同时执行了。</p><p>下面，我们将 <code>120</code> 个样本的 <code>batch</code> 再次细分，分为 <code>20</code> 张样本每份的小 <code>batch</code>。由于 <code>Pytorch</code> 同步启动 <code>CUDA</code> 操作，因此，该操作不需要使用额外的多线程来处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PipelineParallelResNet50</span><span class="params">(ModelParallelResNet50)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, split_size=<span class="number">20</span>, *args, **kwargs)</span>:</span></span><br><span class="line">        super(PipelineParallelResNet50, self).__init__(*args, **kwargs)</span><br><span class="line">        self.split_size = split_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        splits = iter(x.split(self.split_size, dim=<span class="number">0</span>))</span><br><span class="line">        s_next = next(splits)</span><br><span class="line">        s_prev = self.seq1(s_next).to(<span class="string">'cuda:1'</span>)</span><br><span class="line">        ret = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> s_next <span class="keyword">in</span> splits:</span><br><span class="line">            <span class="comment"># A. s_prev runs on cuda:1</span></span><br><span class="line">            s_prev = self.seq2(s_prev)</span><br><span class="line">            ret.append(self.fc(s_prev.view(s_prev.size(<span class="number">0</span>), <span class="number">-1</span>)))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># B. s_next runs on cuda:0, which can run concurrently with A</span></span><br><span class="line">            s_prev = self.seq1(s_next).to(<span class="string">'cuda:1'</span>)</span><br><span class="line"></span><br><span class="line">        s_prev = self.seq2(s_prev)</span><br><span class="line">        ret.append(self.fc(s_prev.view(s_prev.size(<span class="number">0</span>), <span class="number">-1</span>)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> torch.cat(ret)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">setup = <span class="string">"model = PipelineParallelResNet50()"</span></span><br><span class="line">pp_run_times = timeit.repeat(</span><br><span class="line">    stmt, setup, number=<span class="number">1</span>, repeat=num_repeat, globals=globals())</span><br><span class="line">pp_mean, pp_std = np.mean(pp_run_times), np.std(pp_run_times)</span><br><span class="line"></span><br><span class="line">plot([mp_mean, rn_mean, pp_mean],</span><br><span class="line">     [mp_std, rn_std, pp_std],</span><br><span class="line">     [<span class="string">'Model Parallel'</span>, <span class="string">'Single GPU'</span>, <span class="string">'Pipelining Model Parallel'</span>],</span><br><span class="line">     <span class="string">'mp_vs_rn_vs_pp.png'</span>)</span><br></pre></td></tr></table></figure><p>需要注意的是，<code>device-to-device</code> 的 <code>tensor copy</code> 操作是同步的。如果创建多个数据流，则需要保证 <code>copy</code> 操作以合适的同步方式进行。</p><p>在完成 <code>tensor</code> 拷贝之前，对 <code>source tensor</code> 进行写入，或者对 <code>target tensor</code> 进行读写，都可能会导致不可预期的行为。上面的实现中，在源和目标设备中，均只使用了默认的 <code>stream</code>，因此无需额外的强化同步操作。</p><p><img src="/2020/01/06/Pytorch之GPU程序/pytorch-学习/模型并行2.jpg" alt=""><br>模型并行 VS 单 GPU VS 流水线模型并行</p><p>如上图所示，流水线输入确实加速了训练进程，大约 <code>3.75/2.51-1=49%</code>，但距离 <code>100%</code> 的加速相去甚远。由于我们在流水线并行实现中，引入了一个新的参数 <code>split_sizes</code>，但是并不知晓其对训练时间的影响。</p><p>直觉上来说，使用一个小的 <code>split_sizes</code> 将会导致许多微小的 <code>CUDA</code> 内核的启动，而使用较大的 <code>split_sizes</code>，则会导致较长的空闲时间。下面是一个搜索最佳 <code>split_sizes</code> 的实验。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">means = []</span><br><span class="line">stds = []</span><br><span class="line">split_sizes = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">8</span>, <span class="number">10</span>, <span class="number">12</span>, <span class="number">20</span>, <span class="number">40</span>, <span class="number">60</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> split_size <span class="keyword">in</span> split_sizes:</span><br><span class="line">    setup = <span class="string">"model = PipelineParallelResNet50(split_size=%d)"</span> % split_size</span><br><span class="line">    pp_run_times = timeit.repeat(</span><br><span class="line">        stmt, setup, number=<span class="number">1</span>, repeat=num_repeat, globals=globals())</span><br><span class="line">    means.append(np.mean(pp_run_times))</span><br><span class="line">    stds.append(np.std(pp_run_times))</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(split_sizes, means)</span><br><span class="line">ax.errorbar(split_sizes, means, yerr=stds, ecolor=<span class="string">'red'</span>, fmt=<span class="string">'ro'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'ResNet50 Execution Time (Second)'</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">'Pipeline Split Size'</span>)</span><br><span class="line">ax.set_xticks(split_sizes)</span><br><span class="line">ax.yaxis.grid(<span class="keyword">True</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.savefig(<span class="string">"split_size_tradeoff.png"</span>)</span><br><span class="line">plt.close(fig)</span><br></pre></td></tr></table></figure><p>实验结果如下所示：</p><p><img src="/2020/01/06/Pytorch之GPU程序/pytorch-学习/pipeline.jpg" alt=""></p><p>流水线输入分割份数</p><p>如上图所示，最佳的参数为 <code>12</code>，其将导致 <code>3.75/2.43-1=54%</code> 的加速。但这仍存在加速的可能。例如，所有在 <code>cuda:0</code> 上的操作放在默认的 <code>stream</code> 上。这意味着，在下一个 <code>split</code> 上的计算，不能与上一个 <code>split</code> 的 <code>copy</code> 操作进行重叠。然而，由于 <code>next_split</code> 和 <code>prev_plit</code> 是不同的 <code>tensor</code>，因此这不存在问题。</p><p>该实现需要在每个 <code>GPU</code> 上使用多个 <code>stream</code>，并且模型中不同的子网络需要使用不同的 <code>stream</code> 管理策略。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;介绍Pytorch的一些使用方法&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Deep Learning" scheme="http://yoursite.com/categories/Deep-Learning/"/>
    
    
      <category term="Pytorch" scheme="http://yoursite.com/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>Mxnet和Pytorch区别</title>
    <link href="http://yoursite.com/2019/12/29/Mxnet%E5%92%8CPytorch%E5%8C%BA%E5%88%AB/"/>
    <id>http://yoursite.com/2019/12/29/Mxnet和Pytorch区别/</id>
    <published>2019-12-29T09:05:01.000Z</published>
    <updated>2020-03-22T15:31:10.733Z</updated>
    
    <content type="html"><![CDATA[<p>平时主要使用mxnet和pytorch，下面记录下在代码中怎么使用GPU<br><a id="more"></a></p><!-- TOC --><ul><li><a href="#1-mxnet">1. mxnet</a><ul><li><a href="#11-%e5%8d%95gpu">1.1. 单GPU</a></li><li><a href="#12-%e5%a4%9agpu">1.2. 多GPU</a></li></ul></li><li><a href="#2-pytorch">2. pytorch</a><ul><li><a href="#21-%e5%8d%95gpu">2.1. 单GPU</a></li><li><a href="#22-%e5%a4%9agpu">2.2. 多GPU</a></li></ul></li><li><a href="#3-mxnet%e5%92%8cpytorch%e5%8c%ba%e5%88%ab">3. mxnet和pytorch区别</a><ul><li><a href="#31-ndarray%e5%92%8ctensor">3.1. NDArray和Tensor</a><ul><li><a href="#311-%e5%92%8cnumpy%e8%bd%ac%e6%8d%a2">3.1.1. 和numpy转换</a></li><li><a href="#312-%e8%bd%ac%e6%8d%a2%e4%b8%ba%e6%a0%87%e9%87%8f">3.1.2. 转换为标量</a></li><li><a href="#313-%e6%94%b9%e5%8f%98%e6%95%b0%e6%8d%ae%e5%bd%a2%e7%8a%b6">3.1.3. 改变数据形状</a></li><li><a href="#314-%e6%95%b0%e6%8d%ae%e8%bd%ac%e5%88%b0gpu%e4%b8%8a">3.1.4. 数据转到GPU上</a></li></ul></li><li><a href="#32-loss%e8%ae%a1%e7%ae%97">3.2. loss计算</a></li><li><a href="#33-rnn%e8%be%93%e5%85%a5%e7%bb%b4%e5%ba%a6">3.3. RNN输入维度</a></li><li><a href="#34-transformer%e8%be%93%e5%85%a5%e7%bb%b4%e5%ba%a6">3.4. Transformer输入维度</a></li><li><a href="#35-%e5%a4%9agpu%e8%bf%90%e8%a1%8c">3.5. 多GPU运行</a></li><li><a href="#36-%e5%b0%86%e7%bd%91%e7%bb%9c%e5%8a%a0%e5%85%a5list%e4%b8%ad">3.6. 将网络加入list中</a></li><li><a href="#%e5%9b%ba%e5%ae%9a%e9%9a%8f%e6%9c%ba%e7%a7%8d%e5%ad%90">固定随机种子</a></li><li><a href="#%e8%ae%bf%e9%97%ae%e6%a8%a1%e5%9e%8b%e5%8f%82%e6%95%b0">访问模型参数</a></li></ul></li></ul><!-- /TOC --><h1><span id="1-mxnet">1. mxnet</span></h1><h2><span id="11-单gpu">1.1. 单GPU</span></h2><p><a href="http://zh.gluon.ai/chapter_deep-learning-computation/use-gpu.html" target="_blank" rel="noopener">GPU计算</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment">#指定使用哪块GPU</span></span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"3"</span></span><br><span class="line"><span class="comment">#被指定的GPU编号默认为0</span></span><br><span class="line">ctx = mx.gpu(<span class="number">0</span>)</span><br><span class="line"><span class="comment">#模型、数据都需要拷贝到GPU中</span></span><br><span class="line">nd.array(data,ctx)</span><br><span class="line">data.as_in_context(ctx)</span><br></pre></td></tr></table></figure><h2><span id="12-多gpu">1.2. 多GPU</span></h2><p><a href="http://zh.gluon.ai/chapter_computational-performance/multiple-gpus-gluon.html" target="_blank" rel="noopener">多GPU计算</a><br><a href="http://mxnet.incubator.apache.org/api/faq/multi_device" target="_blank" rel="noopener">Run MXNet on Multiple CPU/GPUs with Data Parallelism</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">ctx_id = <span class="string">'1,2,3,4'</span></span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = ctx_id</span><br><span class="line">num_gpus = len(ctx_id.split(<span class="string">','</span>))</span><br><span class="line">ctx = [mx.gpu(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(num_gpus)]</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用split_and_load()将数据分配到多个GPU上</span></span><br></pre></td></tr></table></figure><h1><span id="2-pytorch">2. pytorch</span></h1><h2><span id="21-单gpu">2.1. 单GPU</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"1"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">"cuda:0"</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    device = torch.device(<span class="string">"cpu"</span>)</span><br><span class="line"><span class="comment">#使用to()将数据拷贝到GPU上</span></span><br><span class="line">train_feature.to(device)</span><br></pre></td></tr></table></figure><h2><span id="22-多gpu">2.2. 多GPU</span></h2><p><a href="https://github.com/dnddnjs/pytorch-multigpu/blob/master/data_parallel/train.py" target="_blank" rel="noopener">pytorch-multigpu</a></p><p><a href="https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html" target="_blank" rel="noopener">OPTIONAL: DATA PARALLELISM</a></p><p><a href="https://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html" target="_blank" rel="noopener">MULTI-GPU EXAMPLES</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"1,2,3"</span>  </span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">"cuda:0"</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    device = torch.device(<span class="string">"cpu"</span>)</span><br><span class="line"><span class="comment">#pytorch在使用多GPU时，需要先将数据和模型拷贝到GPU-0上，</span></span><br><span class="line"><span class="comment">#使用多GPU的关键代码</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.device_count() &gt; <span class="number">1</span>:</span><br><span class="line">    print(<span class="string">"Let's use"</span>, torch.cuda.device_count(), <span class="string">"GPUs!"</span>,flush=<span class="keyword">True</span>)</span><br><span class="line">    <span class="comment">#数据并行</span></span><br><span class="line">    model = nn.DataParallel(model)</span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> rand_loader:</span><br><span class="line">    input = data.to(device)</span><br><span class="line">    output = model(input)</span><br><span class="line">    print(<span class="string">"Outside: input size"</span>, input.size(),</span><br><span class="line">          <span class="string">"output_size"</span>, output.size())</span><br></pre></td></tr></table></figure><p><code>DataParallel</code>自动分割数据，并发送到多个GPU上，每个GPU上完成前向传播， <code>DataParallel</code>收集每个GPU上的结果。</p><hr><p>2020.2.11更新</p><h1><span id="3-mxnet和pytorch区别">3. mxnet和pytorch区别</span></h1><p>在写程序时，主要用到<code>mxnet和pytorch</code>框架，这里针对2者在代码上的不同做个总结，下面的不同都是我自己在写程序遇到的，仅仅是一部分，仅供参考。</p><h2><span id="31-ndarray和tensor">3.1. NDArray和Tensor</span></h2><h3><span id="311-和numpy转换">3.1.1. 和numpy转换</span></h3><ul><li><p>mxnet</p><ul><li><strong>Numpy—&gt;NDArray</strong><br><code>nd.array(a)</code></li><li><strong>NDArray—&gt;Numpy</strong><br><code>D.asnumpy()</code></li></ul></li><li><p>pytorch</p><ul><li><strong>Numpy—&gt;Tensor</strong><br><code>D = torch.from_numpy(a)</code></li><li><strong>Tensor—&gt;Numpy</strong><br><code>a = D.numpy()</code></li></ul></li></ul><h3><span id="312-转换为标量">3.1.2. 转换为标量</span></h3><ul><li>mxnet<br><code>asscalar()</code>将函数结果转换成Python的标量<br><code>X.sum().asscalar()</code></li><li>pytorch<br><code>item()</code>将函数结果转换成Python的标量<br><code>X.sum().item()</code></li></ul><h3><span id="313-改变数据形状">3.1.3. 改变数据形状</span></h3><ul><li><p>mxnet</p><ul><li><p><strong>reshape()</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = x.reshape((<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">X = x.reshape((<span class="number">-1</span>, <span class="number">4</span>))</span><br></pre></td></tr></table></figure></li></ul></li><li><p>pytorch</p><ul><li><p><strong>view()</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = x.view(<span class="number">15</span>)</span><br><span class="line">z = x.view(<span class="number">-1</span>, <span class="number">5</span>)  <span class="comment"># -1所指的维度可以根据其他维度的值推出来</span></span><br></pre></td></tr></table></figure></li></ul></li></ul><h3><span id="314-数据转到gpu上">3.1.4. 数据转到GPU上</span></h3><ul><li><p>mxnet<br>使用<code>as_in_context()</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在gpu上创建NDArray</span></span><br><span class="line">B = nd.random.uniform(shape=(<span class="number">2</span>, <span class="number">3</span>), ctx=mx.gpu(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">z = x.as_in_context(mx.gpu())</span><br></pre></td></tr></table></figure></li><li><p>pytorch<br>使用<code>to()</code>函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">"cuda"</span>) <span class="comment"># GPU</span></span><br><span class="line">y = torch.ones_like(x, device=device)  <span class="comment"># 直接创建一个在GPU上的Tensor</span></span><br><span class="line">x = x.to(device)</span><br></pre></td></tr></table></figure></li></ul><h2><span id="32-loss计算">3.2. loss计算</span></h2><ul><li>maxnet</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">loss = L2Loss()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>,num_epochs + <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> X,y <span class="keyword">in</span> data_iter:</span><br><span class="line">        <span class="keyword">with</span> autograd.record()：</span><br><span class="line">            <span class="comment">#l维度(batch_size,)</span></span><br><span class="line">            l = loss(net(X),y)</span><br><span class="line">        <span class="comment">#等价于l.sum().backward()</span></span><br><span class="line">        l.backward()</span><br><span class="line">        <span class="comment">#step对参数的梯度进行更新，传入batch_size是因为计算得到的梯度是一个batch样本的梯度和，需要除以batch_size得到梯度的平均值</span></span><br><span class="line">        trainer.step(batch_size)</span><br></pre></td></tr></table></figure><blockquote><p>注1：在使用<code>y.backward()</code>自动求梯度时，如果<code>y</code>不是一个标量，mxnet将默认先对<code>y</code>中元素求和得到新的变量，在求该变量关于<code>x</code>的梯度 </p><p>注2：mxnet的<code>L2Loss()</code>返回值维度<code>(batch_size,)</code>，即batch中每个样本的loss。需要在<code>step()</code>中传入<code>batch_size</code>参数</p></blockquote><ul><li>pytorch</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">loss = MSELoss()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>,num_epochs + <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> X,y <span class="keyword">in</span> data_iter:</span><br><span class="line">        <span class="comment">#l维度(1,)</span></span><br><span class="line">        l = loss(net(X),y)</span><br><span class="line">        optimizer.zero_grad() <span class="comment"># 梯度清零，等价于net.zero_grad()</span></span><br><span class="line">        l.backward()</span><br><span class="line">        <span class="comment">#step对参数的梯度进行更新，不需要传入batch_size参数</span></span><br><span class="line">        trainer.step()</span><br></pre></td></tr></table></figure><blockquote><p>注1：在<code>y.backward()</code>时，如果<code>y</code>是标量，则<code>backward()</code>不需要传入任何参数，否则，需要传入与<code>y</code>同形的Tensor</p><p>注2：grad在反向传播过程中是累加的，这意味着每一个batch运行反向传播，梯度都会累加之前batch的梯度，所以一般在反向传播传播之前需要把梯度清零。</p><p>注3：pytorch的<code>MSELoss()</code>返回值维度<code>(1,)</code>，Tensor中只有1个数，也称作<code>scalar:零维的张量</code>。因为<code>MSELoss()</code>返回值是batch中所有样本loss的平均值。所以在<code>step()</code>中不需要传入<code>batch_size</code>参数</p></blockquote><h2><span id="33-rnn输入维度">3.3. RNN输入维度</span></h2><p>这里只讨论单向RNN</p><ul><li>mxnet<ul><li>输入数据维度默认<code>(T,batch_size,input_size)</code></li><li>初始化state维度<code>(num_layers,batch_size,hidden_size)</code>,可以不输入，则默认用全0初始化</li><li>output输出数据维度<code>(T,batch_size,hidden_size)</code>，表示最后一层所有时间步的隐藏状态</li><li>out_state：输出维度和state一样，都是<code>(num_layers,batch_size,hidden_size)</code>,表示所有层最后一个时间步的隐藏状态,如果state不输入，则out_state不会被返回</li><li>如果想让输入维度是(B,T,C),则指定参数<code>layout=NTC</code></li></ul></li><li>pytorch<ul><li>输入数据维度默认<code>(T,batch_size,input_size)</code></li><li>初始化state维度<code>(num_layers,batch_size,hidden_size)</code>,可以不输入，则默认用全0初始化</li><li>output输出数据维度<code>(T,batch_size,hidden_size)</code>，表示最后一层所有时间步的隐藏状态</li><li>out_state：输出维度和state一样，都是<code>(num_layers,batch_size,hidden_size)</code>,表示所有层最后一个时间步的隐藏状态,如果state不输入，则out_state不会被返回</li><li>如果想让输入维度是(B,T,C),则指定参数<code>batch_first=True</code></li></ul></li></ul><p><strong>注意：Mxnet和Pytorch的唯一区域是：mxnet的state不指定，out_state就不会输出，pytorch不管state是否指定，out_state都会输出</strong></p><h2><span id="34-transformer输入维度">3.4. Transformer输入维度</span></h2><ul><li><p>mxnet<br>Mxnet中有一个NLP相关的包<code>gluonnlp</code>,里面封装了<code>Transformer</code>，这里只讨论<code>TransformerEncoder</code></p><ul><li>输入维度为<code>(batch_size, length, C_in)</code></li><li>输出维度为<code>(batch_size, length, C_out)</code></li></ul></li><li><p>pytorch<br>Pytorch中也封装了Transformer，<code>TransformerEncoder</code></p><ul><li>输入维度为<code>(length, batch_size, Embedding)</code></li><li>输出维度为<code>(length, batch_size, Embedding)</code><br><code>nn.TransformerEncoderLayer</code></li><li>输入维度为<code>(length, batch_size, Embedding)</code></li><li>输出维度为<code>(length, batch_size, Embedding)</code></li></ul></li></ul><p>【注意】Mxnet版的Tranformer中Dropout的p默认为0，Pytorch版的Transformer中Dropout的p默认为0.1</p><h2><span id="35-多gpu运行">3.5. 多GPU运行</span></h2><ul><li><p>mxnet</p><blockquote><p>mxnet.gluon.utils.split_and_load(data, ctx_list, batch_axis=0, even_split=True)</p></blockquote><p><code>split_and_load()</code>将一个batch中的数据划分为多个小batch到多个GPU上。<br><strong>【注意】默认batch_axis=0，也就是默认划分axis=0的维度，如果batch不在第0维，例如RNN中，输入的维度默认为TNC，batch在第1维，那就需要在split_and_load中指定batch_axis=1</strong><br><code>split_and_load()</code>返回值是list，里面每个元素是<code>NDArray</code>,经过<code>split_and_load()</code>对一个batch数据进行分割，得到的<code>X,y</code>的shape变成<code>(batch_size/n,*)</code>,经过模型输出得到的predicted维度也是<code>(batch_size/n,*)</code><br>计算得到的loss也是list类型，里面存储一个batch在多个GPU上计算的loss，对每个loss分别反向传播求梯度，然后再使用<code>step()</code>更新参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    <span class="keyword">for</span> X,y <span class="keyword">in</span> train_iter:</span><br><span class="line">        gpu_Xs = gutils.split_and_load(X,ctx)</span><br><span class="line">        gpu_ys = gutils.split_and_load(y,ctx)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> autograd.record():</span><br><span class="line">            <span class="comment">#ls是list，里面有n个NDArray，n是GPU的个数</span></span><br><span class="line">            ls = [loss(net(gpu_X),gpu_y <span class="keyword">for</span> gpu_X,gpu_y <span class="keyword">in</span> zip(gpu_Xs,gpu_ys)</span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> ls:</span><br><span class="line">            l.backward()</span><br><span class="line"></span><br><span class="line">        train.step(batch_size)</span><br></pre></td></tr></table></figure><p><img src="/2019/12/29/Mxnet和Pytorch区别/gpus-mxnet.png" alt=""></p></li><li><p>pytorch<br><a href="https://echohhhhhh.github.io/2019/01/31/%E8%BF%90%E8%A1%8CGPU%E7%A8%8B%E5%BA%8F/" target="_blank" rel="noopener">Pytorch学习</a>  </p><blockquote><p>CLASS torch.nn.DataParallel(module, device_ids=None, output_device=None, dim=0)</p></blockquote><p><strong><code>DataParallel</code>自动将batch进行划分，划分维度默认dim=0，如果batch在其他维度，通过dim指定</strong><br>pytorch使用<code>DataParallel()</code>来进行数据并行，不需要手动将数据划分到多个GPU上，即<code>train_feature</code>的维度是<code>(batch_size,*)</code>，经过模型输出的<code>predicted</code>的维度也是<code>(batch_size,*)</code>，这一点和<code>mxnet</code>不同</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用多GPU的关键代码</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.device_count() &gt; <span class="number">1</span>:</span><br><span class="line">    transformer_model = nn.DataParallel(transformer_model)<span class="comment">#默认全部GPU</span></span><br><span class="line">transformer_model.to(device0)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>,training_epoch+<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> train_feature,train_label <span class="keyword">in</span> train_loader:</span><br><span class="line">        train_feature = train_feature.to(device0)</span><br><span class="line">        train_label = train_label.to(device0)</span><br><span class="line">        <span class="comment">#train_label:(tabch_size,*)</span></span><br><span class="line">        predicted = transformer_model(train_feature)</span><br><span class="line">        l = loss(predicted,train_label)<span class="comment">#l的shape：(1,)</span></span><br><span class="line">        trainer.zero_grad()</span><br><span class="line">        l.backward()</span><br><span class="line">        trainer.step()</span><br></pre></td></tr></table></figure></li></ul><p>  <img src="/2019/12/29/Mxnet和Pytorch区别/gpus-pytorch.png" alt=""></p><blockquote><p>从这2个图中可以看出Mxnet和Pytorch多GPU运行的区别。<br>  <strong>Mxnet</strong>将batch数据和label都分配到每个GPU上，然后在每个GPU上都计算loss，然后再把loss聚合。<br>  <strong>Pytorch</strong>只把batch数据分配到每个GPU上，在每个GPU上得到输出，gather到主设备上，然后再和label计算loss。<br>  Mxnet会比Pytorch会一些，因为Mxnet的loss是在不同的GPU上计算的，但Pytorch的写法更简单。<br>  为了解决Pytorch在一张卡上计算loss的问题，有人提出了解决方案，参考<a href="https://liumin.blog.csdn.net/article/details/89437058" target="_blank" rel="noopener">基于PyTorch使用大batch训练神经网络</a>和<a href="https://blog.csdn.net/weixin_40087578/article/details/87186613?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">pytorch 多GPU训练总结（DataParallel的使用）</a></p></blockquote><h2><span id="36-将网络加入list中">3.6. 将网络加入list中</span></h2><ul><li><p>mxnet</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">self.submodules = []</span><br><span class="line">      <span class="keyword">with</span> self.name_scope():</span><br><span class="line">          <span class="keyword">for</span> backbones <span class="keyword">in</span> all_backbones:</span><br><span class="line">              self.submodules.append(</span><br><span class="line">                  ASTGCN_submodule(num_for_prediction, backbones))</span><br><span class="line">              self.register_child(self.submodules[<span class="number">-1</span>])</span><br></pre></td></tr></table></figure></li><li><p>pytorch<br>Pytorch中<code>nn.Module, nn.ModuleList, nn.Sequential</code>，统称为容器，因为我们可以添加模块module到它们中。但有时候容易混淆，我们主要讨论<code>nn.ModuleList, nn.Sequential</code>的使用。</p><p><strong>【nn.ModuleList】</strong><br><a href="https://zhuanlan.zhihu.com/p/64990232" target="_blank" rel="noopener">PyTorch 中的 ModuleList 和 Sequential: 区别和使用场景</a><br><a href="https://blog.csdn.net/qq_38863413/article/details/104118055" target="_blank" rel="noopener">Pytorch使用 nn.ModuleList() 和nn.Sequential()编写神经网络模型</a><br>ModuleList是一个类，可以将Module任意子类(Conv2d,Linear等)加入到list中，方法和Python自带的list一样，使用append或extend等操作。但不同于一般的list，<strong>加入到ModuleList里的module会自动注册到整个网络上，同时module的参数也会自动添加到整个网络中</strong>。</p></li></ul>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModel</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">      super(MyModel, self).__init__()</span><br><span class="line">      self.linears = nn.ModuleList([nn.linear <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)])</span><br><span class="line"></span><br><span class="line">  <span class="comment"># ModuleList can act as an iterable, or be indexed using ints</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">      <span class="keyword">for</span> i, l <span class="keyword">in</span> enumerate(self.linears):</span><br><span class="line">          x = self.linears[i // <span class="number">2</span>](x) + l(x)</span><br><span class="line">      <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h2><span id="固定随机种子">固定随机种子</span></h2><ul><li><p>mxnet版本</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">   seed = <span class="number">2020</span></span><br><span class="line">   mx.random.seed(seed)</span><br><span class="line">np.random.seed(seed)</span><br><span class="line">random.seed(seed)</span><br></pre></td></tr></table></figure></li><li><p>pytorch版本</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">seed = <span class="number">2020</span></span><br><span class="line">torch.manual_seed(seed) <span class="comment"># cpu</span></span><br><span class="line">torch.cuda.manual_seed(seed) <span class="comment">#gpu</span></span><br><span class="line">torch.backends.cudnn.deterministic=<span class="keyword">True</span><span class="comment">#cudn,cpu/gpu结果一致</span></span><br><span class="line">np.random.seed(seed)<span class="comment">#numpy</span></span><br><span class="line">random.seed(seed)<span class="comment">#ramdom</span></span><br></pre></td></tr></table></figure></li></ul><h2><span id="访问模型参数">访问模型参数</span></h2><ul><li><p>mxnet</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name,param <span class="keyword">in</span> gru.collect_params().items():</span><br><span class="line">    print(name,<span class="string">':'</span>,parameters.size())</span><br></pre></td></tr></table></figure></li><li><p>pytorch</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name,parameters <span class="keyword">in</span> net.named_parameters():</span><br><span class="line">  print(name,<span class="string">':'</span>,parameters.size())</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> parameters <span class="keyword">in</span> net.parameters():</span><br><span class="line">  print(parameters)</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;平时主要使用mxnet和pytorch，下面记录下在代码中怎么使用GPU&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Deep Learning" scheme="http://yoursite.com/categories/Deep-Learning/"/>
    
    
      <category term="Mxnet" scheme="http://yoursite.com/tags/Mxnet/"/>
    
      <category term="GPU" scheme="http://yoursite.com/tags/GPU/"/>
    
      <category term="Pytorch" scheme="http://yoursite.com/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>leetcode踩坑</title>
    <link href="http://yoursite.com/2019/12/26/leecode-tirck/"/>
    <id>http://yoursite.com/2019/12/26/leecode-tirck/</id>
    <published>2019-12-26T11:25:57.000Z</published>
    <updated>2020-03-28T02:14:38.190Z</updated>
    
    <content type="html"><![CDATA[<p>&ensp;&ensp;&ensp;&ensp;最近开始刷Leecode，使用Python语言，踩了很多坑，在此记录。</p><a id="more"></a><!-- TOC --><ul><li><a href="#1-%e4%b8%80%e4%b8%aa%e8%90%9d%e5%8d%9c%e4%b8%80%e4%b8%aa%e5%9d%91">1. 一个萝卜一个坑</a><ul><li><a href="#11-int%e5%87%bd%e6%95%b0">1.1. int函数</a></li><li><a href="#12-bin%e5%87%bd%e6%95%b0">1.2. bin函数</a></li><li><a href="#13-zip%e5%87%bd%e6%95%b0">1.3. zip函数</a></li><li><a href="#14-%e4%ba%8c%e5%88%86%e6%b3%95%e8%ae%b2%e8%a7%a3">1.4. 二分法讲解</a></li><li><a href="#%e6%ad%a3%e6%97%a0%e7%a9%b7%e5%92%8c%e8%b4%9f%e6%97%a0%e7%a9%b7">正无穷和负无穷</a></li></ul></li></ul><!-- /TOC --><h1><span id="1-一个萝卜一个坑">1. 一个萝卜一个坑</span></h1><h2><span id="11-int函数">1.1. int函数</span></h2><p>int()函数用于将一个字符串或数字转换为整型。<br><code>int(x,base=10)</code>:x—字符串或数字，base—进制数，默认十进制。 如果显示的指定base参数，x必须为str。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int(<span class="number">3</span>) = <span class="number">3</span></span><br><span class="line">int(<span class="number">3.6</span>) = <span class="number">3</span></span><br><span class="line">int(<span class="string">'12'</span>,<span class="number">16</span>) = <span class="number">18</span></span><br><span class="line">int(<span class="string">'11'</span>,<span class="number">2</span>) = <span class="number">3</span><span class="comment">#将字符串解析为2进制</span></span><br></pre></td></tr></table></figure><h2><span id="12-bin函数">1.2. bin函数</span></h2><p>bin()返回一个整数int的二进制表示，返回类型str<br><code>bin(x)</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#返回的结果前2个字符是固定的'0b'，后面才是真正的值。</span></span><br><span class="line">bin(<span class="number">10</span>) = <span class="string">'0b1010'</span></span><br><span class="line">bin(<span class="number">20</span>) = <span class="string">'0b10100'</span></span><br></pre></td></tr></table></figure><h2><span id="13-zip函数">1.3. zip函数</span></h2><p>zip()接受一系列(多个，个数不固定)可迭代对象(最常用list,tuple)作为参数，将多个对象中，对应位置的元素打包成一个个tuple，然后返回由这些tuple组成的list。若传入参数中长度不一样，则返回liist的长度和参数中最短的相同。  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">x = [<span class="string">'wang'</span>,<span class="string">'bei'</span>]</span><br><span class="line">y = [<span class="string">'lei'</span>,<span class="string">'xiao'</span>,<span class="string">'kang'</span>]</span><br><span class="line">list(zip(x,y))</span><br><span class="line">输出：[(<span class="string">'wang'</span>,<span class="string">'lei'</span>),(<span class="string">'bei'</span>,<span class="string">'xiao'</span>)]</span><br><span class="line"></span><br><span class="line">x = <span class="string">'wang'</span></span><br><span class="line">y = <span class="string">'lei'</span></span><br><span class="line">list(zip(x,y))</span><br><span class="line">输出：[(<span class="string">'w'</span>,<span class="string">'l'</span>),(<span class="string">'a'</span>,<span class="string">'e'</span>),(<span class="string">'n'</span>,<span class="string">'i'</span>)]  </span><br><span class="line"></span><br><span class="line"><span class="comment">#假设zip传入的参数是x，y，zip依次将(x[0],y[0]),(x[1],y[1])..</span></span><br><span class="line"><span class="comment">#以可迭代对象返回，可强制转换为list或tuple</span></span><br></pre></td></tr></table></figure><p>zip(<em>)传入的参数是zip()的返回值类型，从<zip\>类型中每一个tuple中，取出第0个元素组成一个list，再取出第1个元素组成一个list，即zip(\</zip\></em>)返回值是一个大list，里面有2个tuple</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line">b = [<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>]</span><br><span class="line">zipped = list(zip(a,b))</span><br><span class="line"><span class="comment">#zipped = [(1,'a'),(2,'b'),(3,'c')]</span></span><br><span class="line">c = list(zip(*zipped))</span><br><span class="line"><span class="comment">#c = [(1,2,3),('a','b','c')]</span></span><br></pre></td></tr></table></figure><h2><span id="14-二分法讲解">1.4. 二分法讲解</span></h2><p><a href="https://leetcode-cn.com/problems/search-insert-position/solution/te-bie-hao-yong-de-er-fen-cha-fa-fa-mo-ban-python-/" target="_blank" rel="noopener">参考资料</a></p><h2><span id="正无穷和负无穷">正无穷和负无穷</span></h2><p>在比较大小时，通常先将结果初始化为inf和-inf，使用下面的语句</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">res = float(<span class="string">"inf"</span>)</span><br><span class="line">res = float(<span class="string">"-inf"</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;最近开始刷Leecode，使用Python语言，踩了很多坑，在此记录。&lt;/p&gt;
    
    </summary>
    
      <category term="算法" scheme="http://yoursite.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>nni</title>
    <link href="http://yoursite.com/2019/11/25/nni/"/>
    <id>http://yoursite.com/2019/11/25/nni/</id>
    <published>2019-11-25T06:23:50.000Z</published>
    <updated>2020-03-05T07:38:11.238Z</updated>
    
    <content type="html"><![CDATA[<p>NN是微软官方出的一个自动调参的第三方库。非常好用。但是用起来还是有一些需要注意的地方。这里记录一下。<br><a id="more"></a><br><!-- TOC --></p><ul><li><a href="#1-%e6%9c%af%e8%af%ad">1. 术语</a><ul><li><a href="#11-%e4%bd%bf%e7%94%a8%e6%ad%a5%e9%aa%a4">1.1. 使用步骤</a></li></ul></li><li><a href="#2-nni%e5%91%bd%e4%bb%a4">2. NNI命令</a></li></ul><!-- /TOC --><p><a href="https://nni.readthedocs.io/zh/latest/Tutorial/QuickStart.html" target="_blank" rel="noopener">NNi官方文档</a></p><h1><span id="1-术语">1. 术语</span></h1><p>主要有2个术语experiment和trial。<br>experiment：如果需要调整LSTM的超参数，则需要指定每个超参数的可选项，然后运行程序，让nni自动调参。运行的这个调参程序就是experiment。<br>trial：上面运行的程序中，有很多的参数组合，每一个超参数组合是trial。<br>每一个experiment有一个ID，experiment中的每一个trial也有一个ID。在网页中可以看到</p><p><img src="/2019/11/25/nni/experiment_id.png" alt=""></p><p><img src="/2019/11/25/nni/trial_id.png" alt=""></p><h2><span id="11-使用步骤">1.1. 使用步骤</span></h2><ol><li><p>创建搜索空间json文件<br>这里定义需要调整的超参数</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> <span class="attr">"num_layer"</span>:&#123;<span class="attr">"_type"</span>:<span class="string">"choice"</span>,<span class="attr">"_value"</span>:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]&#125;,</span><br><span class="line"> <span class="attr">"hidden_size"</span>:&#123;<span class="attr">"_type"</span>:<span class="string">"choice"</span>,<span class="attr">"_value"</span>:[<span class="number">64</span>,<span class="number">128</span>,<span class="number">256</span>,<span class="number">512</span>]&#125;,</span><br><span class="line"> <span class="attr">"batch_size"</span>: &#123;<span class="attr">"_type"</span>:<span class="string">"choice"</span>, <span class="attr">"_value"</span>: [<span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>,<span class="number">64</span>,<span class="number">128</span>,<span class="number">256</span>]&#125;,</span><br><span class="line"> <span class="attr">"learning_rate"</span>:&#123;<span class="attr">"_type"</span>:<span class="string">"uniform"</span>,<span class="attr">"_value"</span>:[<span class="number">0.0001</span>,<span class="number">0.001</span>]&#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></li><li><p>首先在程序中import nni </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nni  </span><br><span class="line"><span class="keyword">import</span> os  </span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"2"</span><span class="comment">#单GPU</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>,train_epoch):</span><br><span class="line">    每一个batch，在测试集上训练，并反向传播  </span><br><span class="line">    每一个epoch，计算验证集/测试集的loss</span><br><span class="line">    每一个epoch，计算验证集/测试集的评价指标(mae,rmse)</span><br><span class="line">    <span class="comment">#将验证集的评价指标加入到nni中</span></span><br><span class="line">    <span class="keyword">if</span> epoch &lt; train_epoch:</span><br><span class="line">         nni.report_intermediate_result(valid_mae)</span><br><span class="line">     <span class="keyword">else</span>:</span><br><span class="line">         nni.report_final_result(valid_mae)</span><br></pre></td></tr></table></figure><p>在下面的yml文件中，需要指定gpuNum,即需要使用多少张GPU卡。但是nni会自动申请gpu，你也不知道会申请到哪个gpu。为了解决这个问题，需要指定程序只能看见哪些卡，那么就会只申请看见的卡。<br>通过以下代码指定：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"2"</span><span class="comment">#单GPU</span></span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"1,2"</span><span class="comment">#多GPU</span></span><br></pre></td></tr></table></figure><p><strong>注意：如果只指定能看见第2张卡，但是程序中，会给第2张卡编号的为0，即通过ctx=mx.gpu(0)来获取。如果指定能看见1和2卡，那么程序中会分别编号0和1。</strong></p></li><li><p>nni的配置文件config.yml</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">authorName:</span> <span class="string">wangbeibei</span></span><br><span class="line"><span class="attr">experimentName:</span> <span class="string">gru_grid_experiment</span></span><br><span class="line"><span class="comment">#并发尝试任务的最大数量，有1张gpu卡就是1，有2张gpu卡就是2</span></span><br><span class="line"><span class="attr">trialConcurrency:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">maxExecDuration:</span> <span class="number">100</span><span class="string">h</span></span><br><span class="line"><span class="comment">#Trial 任务的最大数量，成功和失败的都计算在内</span></span><br><span class="line"><span class="attr">maxTrialNum:</span> <span class="number">10</span></span><br><span class="line"><span class="comment">#choice: local, remote, pai,在虚拟环境和docker运行时，都写local</span></span><br><span class="line"><span class="attr">trainingServicePlatform:</span> <span class="string">local</span></span><br><span class="line"><span class="comment">#在第一步创建的json文件的路径，这里需要写相对路径，因为当前的yml文件和json文件在同一文件夹下</span></span><br><span class="line"><span class="attr">searchSpacePath:</span> <span class="string">lstm_search_space.json</span></span><br><span class="line"><span class="comment">#choice: true, false</span></span><br><span class="line"><span class="attr">useAnnotation:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># 存储日志和数据的目录, 默认值是 /data/WangBeibei/nni/experiments</span></span><br><span class="line"><span class="comment">#如果在虚拟环境中运行该代码，logDir是服务器下的绝对路径，/data/WangBeibei/graduation/Code/nni_save_logs</span></span><br><span class="line"><span class="comment">#如果在docker下运行该代码，logDir是容器下的绝对路径，/root/Code/nni_save_logs/</span></span><br><span class="line"><span class="attr">logDir:</span> <span class="string">/root/Code/nni_save_logs/</span></span><br><span class="line"><span class="attr">tuner:</span></span><br><span class="line">    <span class="comment">#choice: TPE, Random, Anneal, Evolution, BatchTuner, MetisTuner, GPTuner</span></span><br><span class="line">    <span class="comment">#SMAC (SMAC should be installed through nnictl)</span></span><br><span class="line"><span class="attr">    builtinTunerName:</span> <span class="string">TPE</span></span><br><span class="line"><span class="attr">    classArgs:</span></span><br><span class="line">        <span class="comment">#choice: maximize, minimize</span></span><br><span class="line">        <span class="comment">#mae、rmse、mse都是最小化</span></span><br><span class="line"><span class="attr">        optimize_mode:</span> <span class="string">minimize</span></span><br><span class="line"><span class="attr">trial:</span></span><br><span class="line"><span class="comment"># 指定了运行 Trial 进程的命令行</span></span><br><span class="line"><span class="attr">command:</span> <span class="string">cd</span> <span class="string">baseline</span> <span class="string">&amp;&amp;</span> <span class="string">python3</span> <span class="string">lstm_baseline.py</span></span><br><span class="line"><span class="comment">#指定了 Trial 代码文件的目录</span></span><br><span class="line"><span class="comment">#首先从yml目录下，进入到代码的根目录下</span></span><br><span class="line"><span class="attr">codeDir:</span> <span class="string">../</span></span><br><span class="line"><span class="comment">#指定需要使用</span></span><br><span class="line"><span class="attr">gpuNum:</span> <span class="number">1</span></span><br></pre></td></tr></table></figure></li><li><p>启动容器<br>nni网页的默认端口是8080，所以需要和本地映射一下，</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker run -it -p 7000:8080 -v $PWD:/root --runtime=nvidia --rm -u 1018 --name wbbnni lin-ai-27:5000/wangbeibei/mxnet:cu_100  </span><br><span class="line"></span><br><span class="line">docker run -it -p 7000:8080 -v $PWD:/root --runtime=nvidia --rm -u 1018 --name wbbnni lin-ai-27:5000/wangbeibei/pytorch_nni</span><br></pre></td></tr></table></figure></li><li><p>启动一个nni的experiment<br>进入到yml所在的目录，使用以下命令，启动一个experiment实例，然后就可以在网页上查看<br>使用<code>nnictl create --config config.yml</code><br>出现以下提示，说明启动成功。</p><p><img src="/2019/11/25/nni/create.png" alt=""></p></li><li><p>在网页上访问<br>在网页上打开<code>服务器ip:7000</code></p><p><img src="/2019/11/25/nni/success.png" alt=""></p></li><li><p>错误日志<br>如果提交的任务都失败了，可以去看日志文件。日志文件的位置在下图中。在容器中进入到下面的目录中。</p><p><img src="/2019/11/25/nni/error1.png" alt=""></p><p><img src="/2019/11/25/nni/error2.png" alt=""></p><p>在容器中进入到日志目录中，找到对应id的文件夹。</p><p><img src="/2019/11/25/nni/log.png" alt=""></p></li><li><p>成功日志<br>如果trial成功运行，那么关于这次trial的</p><p><img src="/2019/11/25/nni/success1.png" alt=""></p></li></ol><h1><span id="2-nni命令">2. NNI命令</span></h1><p><a href="https://github.com/microsoft/nni/blob/master/docs/zh_CN/Tutorial/Nnictl.md" target="_blank" rel="noopener">NNI命令参考文档</a></p><ol><li>nnictl create<br>（1）在默认端口8080上创建一个新的Experiment<br><code>nnictl create --config nni/examples/trials/mnist/config.yml</code><br>（2）在指定的端口上8088创建新的Experiment<br><code>nnictl create --config nni/examples/trials/mnist/config.yml --port 8088</code></li><li>nnictl stop<br>停止正在运行的单个或多个Experiment<br>（1）没有指定id，停止所有正在运行的Experiment<br><code>nnictl stop</code><br>（2）停止指定id的Experiment<br><code>nnictl stop [experiment_id]</code></li><li>nnictl update<br>更新 Experiment 的搜索空间，其中<code>experiment_id</code>是可选的参数，后面的<code>--filename</code>是必填的参数。<br>先使用vscode修改搜索空间的json文件，然后再使用下面的命令来更新搜索空间文件。<br><code>nnictl update searchspace [experiment_id] --filename examples/trials/mnist/search_space.json</code></li><li><p>nnictl view<br>如果使用stop结束调参程序，以后还想看一下网页上的调参结果，使用该命令。这个命令只是在前端展示调参的结果，调参程序不会再次启动。  </p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nnictl <span class="keyword">view</span> [<span class="keyword">OPTIONS</span>]</span><br><span class="line">其中experiment_id是必填的，port是选填的</span><br><span class="line">nnictl <span class="keyword">view</span> [experiment_id] <span class="comment">--port 8088</span></span><br></pre></td></tr></table></figure></li><li><p>nnictl top<br>查看正在运行的Experiment</p></li><li>nnictl experiment show<br>显示Experiment的信息</li><li>nnictl experiment status<br>显示Experiment的状态</li><li>nnictl experiment list<br>显示正在运行的Experiment的信息</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;NN是微软官方出的一个自动调参的第三方库。非常好用。但是用起来还是有一些需要注意的地方。这里记录一下。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="工具" scheme="http://yoursite.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="Docker" scheme="http://yoursite.com/tags/Docker/"/>
    
      <category term="NNI" scheme="http://yoursite.com/tags/NNI/"/>
    
  </entry>
  
</feed>
