<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Echo&#39;s blog</title>
  
  <subtitle>远方到底有多远</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-01-22T15:38:57.299Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Echo</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2020/01/10/openpai/"/>
    <id>http://yoursite.com/2020/01/10/openpai/</id>
    <published>2020-01-10T02:34:27.485Z</published>
    <updated>2020-01-22T15:38:57.299Z</updated>
    
    <content type="html"><![CDATA[<hr><p>title: openpai<br>date: 2020-01-10T10:34:27.000Z<br>categories: 工具<br>tags:</p><ul><li>openpai<br>comments: false</li></ul><hr><p>&ensp;&ensp;&ensp;&ensp;最近实验室安装了openpai平台，可以在上面提交程序运行。下面记录怎么使用OpenPai提交NNI程序，进行调参。<br><a id="more"></a></p><h1><span id="1-使用步骤">1. 使用步骤</span></h1><h2><span id="11-编写程序">1.1. 编写程序</span></h2><p>   先在VSCode中完成代码，先在VSCode的虚拟环境中运行，如果可以运行，再使用OpemPai运行。<br>   <strong>注：在OpenPai上运行程序，不需要指定使用哪块GPU，因为OpenPai会自动申请需要使用的GPU。即以下代码注释掉</strong><br>   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># os.environ["CUDA_VISIBLE_DEVICES"] = "1,2,3"</span></span><br></pre></td></tr></table></figure></p><h2><span id="12-准备镜像">1.2. 准备镜像</span></h2><p>   先将需要用的镜像push到实验室服务器的仓库。<br>   下面是我本人的镜像：</p><ul><li>运行环境mxnet<br><code>lin-ai-27:5000/wangbeibei/mxnet:cu100_hdfs</code></li><li><p>运行环境是pytorch<br><code>172.31.246.45:5000/dlspree:hdfs_pyg</code></p><h2><span id="13-编写nni的yml配置文件">1.3. 编写NNI的yml配置文件</span></h2><p>使用<code>pip install nni==1.2</code>安装1.2版本的nni，如果不指定版本，默认安装最新版，目前最新是1.3，1.3版本的nni其yml配置文件和1.2有所区别<br><a href="https://nni.readthedocs.io/zh/latest/Tutorial/ExperimentConfig.html#openpai" target="_blank" rel="noopener">OpenPai模式</a><br>1.3版本的nni的yml配置文件和1.2有所不同,<a href="https://nni.readthedocs.io/zh/latest/TrainingService/PaiMode.html" target="_blank" rel="noopener">最新版本的配置文件</a>，其中多了<code>nniManagerNFSMountPath,containerNFSMountPath,paiStoragePlugin</code>三个必填的键。<br>下面使用的是1.2版本的nni配置文件</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">    authorName:</span> <span class="string">wangbeibei</span></span><br><span class="line"><span class="attr">    experimentName:</span> <span class="string">hetero_convlstm_grid_experiment</span></span><br><span class="line">    <span class="comment">#并发尝试任务的最大数量，有1张gpu卡就是1，有2张gpu卡就是2</span></span><br><span class="line"><span class="attr">    trialConcurrency:</span> <span class="number">6</span></span><br><span class="line"><span class="attr">    maxExecDuration:</span> <span class="number">100</span><span class="string">h</span></span><br><span class="line">    <span class="comment">#Trial 任务的最大数量，成功和失败的都计算在内</span></span><br><span class="line"><span class="attr">    maxTrialNum:</span> <span class="number">600</span></span><br><span class="line">    <span class="comment">#choice: local, remote, pai</span></span><br><span class="line"><span class="attr">    trainingServicePlatform:</span> <span class="string">pai</span></span><br><span class="line">    <span class="comment"># 指定nni管理器ip 为29号服务器</span></span><br><span class="line"><span class="attr">    nniManagerIp:</span> <span class="number">202.205</span><span class="number">.99</span><span class="number">.174</span></span><br><span class="line"><span class="attr">    searchSpacePath:</span> <span class="string">hetero_convlstm_search_space.json</span></span><br><span class="line">    <span class="comment">#choice: true, false</span></span><br><span class="line"><span class="attr">    useAnnotation:</span> <span class="literal">false</span></span><br><span class="line">    <span class="comment"># 存储日志和数据的目录, 默认值是 /data/WangBeibei/nni/  experiments</span></span><br><span class="line">    <span class="comment">#如果在虚拟环境中运行该代码，logDir是服务器下的绝对路径，/data/ WangBeibei/graduation/Code/nni_save_logs</span></span><br><span class="line">    <span class="comment">#如果在docker下运行该代码，logDir是容器下的绝对路径，/root/ Code/nni_save_logs/</span></span><br><span class="line"><span class="attr">    logDir:</span> <span class="string">/data/WangBeibei/graduation/Code/nni_save_logs</span></span><br><span class="line"><span class="attr">    tuner:</span></span><br><span class="line">      <span class="comment">#choice: TPE, Random, Anneal, Evolution, BatchTuner,  MetisTuner, GPTuner</span></span><br><span class="line">      <span class="comment">#SMAC (SMAC should be installed through nnictl)</span></span><br><span class="line"><span class="attr">      builtinTunerName:</span> <span class="string">TPE</span></span><br><span class="line"><span class="attr">      classArgs:</span></span><br><span class="line">        <span class="comment">#choice: maximize, minimize</span></span><br><span class="line"><span class="attr">        optimize_mode:</span> <span class="string">minimize</span></span><br><span class="line"><span class="attr">    trial:</span></span><br><span class="line">      <span class="comment"># 指定了运行 Trial 进程的命令行</span></span><br><span class="line"><span class="attr">      command:</span> <span class="string">cd</span> <span class="string">baseline</span> <span class="string">&amp;&amp;</span> <span class="string">python3</span>   <span class="string">hetero_convlstm_baseline.py</span></span><br><span class="line">      <span class="comment">#指定了 Trial 代码文件的目录,../会进入到Code目录下</span></span><br><span class="line"><span class="attr">      codeDir:</span> <span class="string">../</span></span><br><span class="line"><span class="attr">      gpuNum:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">      cpuNum:</span> <span class="number">8</span></span><br><span class="line"><span class="attr">      memoryMB:</span> <span class="number">14000</span></span><br><span class="line">      <span class="comment"># docker 镜像地址</span></span><br><span class="line">      <span class="comment">#pytorch镜像：172.31.246.45:5000/dlspree:hdfs_pyg</span></span><br><span class="line">      <span class="comment">#mxnet镜像：lin-ai-27:5000/wangbeibei/mxnet:cu100_hdfs</span></span><br><span class="line"><span class="attr">      image:</span> <span class="number">172.31</span><span class="number">.246</span><span class="number">.45</span><span class="string">:5000/dlspree:hdfs_pyg</span></span><br><span class="line">    <span class="comment"># 配置访问的 OpenPAI 集群</span></span><br><span class="line"><span class="attr">    paiConfig:</span></span><br><span class="line">      <span class="comment">#OpenPai网页的用户名和密码，也是53号服务器的用户名和密码</span></span><br><span class="line"><span class="attr">      userName:</span> <span class="string">user</span></span><br><span class="line">      <span class="comment"># 密码如果是全数字需要 ""</span></span><br><span class="line"><span class="attr">      passWord:</span> <span class="string">psw</span></span><br><span class="line">      <span class="comment">#OpenPai集群的主节点</span></span><br><span class="line"><span class="attr">      host:</span> <span class="number">172.31</span><span class="number">.246</span><span class="number">.52</span></span><br><span class="line">   <span class="string">```</span>   </span><br><span class="line">   <span class="string">**这里资源的配置都是针对一个trail的，memoryMB也是针对一个trail的。**</span>  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 1.4. 安装NNI</span></span><br><span class="line">   <span class="string">由于NNI并不依赖于任何环境，因此当我们使用OpenPAI提交NNI任务时，为了方便（需要解决ip和端口映射问题），**不需要在docker中启动NNI，直接在服务器环境下安装NNI，启动即可**。</span></span><br><span class="line">   <span class="string">使用`pip</span> <span class="string">install</span> <span class="string">nni==1.2`安装nni</span></span><br><span class="line"><span class="comment">## 1.5. 启动NNI</span></span><br><span class="line">   <span class="string">使用`nnictl</span> <span class="string">create</span> <span class="bullet">--port</span> <span class="number">6688</span> <span class="bullet">--config</span> <span class="string">xxx.yml`来启动一个Experiment,如果端口被占用，换别的端口</span></span><br><span class="line"><span class="comment">## 1.6. NNI浏览器查看</span></span><br><span class="line">   <span class="string">在浏览器中输入`服务器ip:6688`</span>  </span><br><span class="line"><span class="comment">## 1.7. 在浏览器中查看OpenPai</span></span><br><span class="line">   <span class="string">在浏览器中登录OpenPai，可以查看启动的trail，在代码中的print输出的内容在stdout中查看。</span>   </span><br><span class="line">   <span class="string">**注：有时候print语句输出的内容在stdout显示不出来，添加`flush=True`就可以了**</span> </span><br><span class="line">   <span class="string">```python</span>  </span><br><span class="line">   <span class="string">print("************进入main函数",flush=True)</span></span><br></pre></td></tr></table></figure><p><img src="/2020/01/10/openpai/logs.png" alt="">     </p><h2><span id="18-关闭nni">1.8. 关闭NNI</span></h2><p>直接在服务器中使用<code>nnictl stop</code>即可关闭nni的Experiment</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;title: openpai&lt;br&gt;date: 2020-01-10T10:34:27.000Z&lt;br&gt;categories: 工具&lt;br&gt;tags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;openpai&lt;br&gt;comments: false&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;最近实验室安装了openpai平台，可以在上面提交程序运行。下面记录怎么使用OpenPai提交NNI程序，进行调参。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2020/01/06/pytorch-%E5%AD%A6%E4%B9%A0/"/>
    <id>http://yoursite.com/2020/01/06/pytorch-学习/</id>
    <published>2020-01-06T06:35:30.810Z</published>
    <updated>2020-01-22T14:10:39.857Z</updated>
    
    <content type="html"><![CDATA[<hr><p>title: pytorch 学习<br>date: 2020-01-06T14:35:30.000Z<br>categories: Deep Learning<br>tags:</p><ul><li>Pytorch<br>comments: false</li></ul><hr><p>介绍Pytorch的一些使用方法<br><a id="more"></a> </p><h1><span id="gpu">GPU</span></h1><p><a href="http://tankzhou.cn/2019/06/29/%E5%8D%95%E6%9C%BA%E5%B9%B6%E8%A1%8C%E8%AE%AD%E7%BB%83/" target="_blank" rel="noopener">参考资料</a><br><a href="https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter04_DL_computation/4.6_use-gpu" target="_blank" rel="noopener">GPU计算</a> </p><h2><span id="查看-gpu-信息">查看 GPU 信息</span></h2><p>更多接口，参考 <a href="https://pytorch.org/docs/stable/cuda.html" target="_blank" rel="noopener">torch.cuda</a>。</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">torch</span><span class="selector-class">.cuda</span><span class="selector-class">.is_available</span>()       # 判断 <span class="selector-tag">GPU</span> 是否可用</span><br><span class="line"><span class="selector-tag">torch</span><span class="selector-class">.cuda</span><span class="selector-class">.device_count</span>()       # 判断有多少 <span class="selector-tag">GPU</span></span><br><span class="line"><span class="selector-tag">torch</span><span class="selector-class">.cuda</span><span class="selector-class">.get_device_name</span>(0)   # 返回 <span class="selector-tag">gpu</span> 名字，设备索引默认从 0 开始</span><br><span class="line"><span class="selector-tag">torch</span><span class="selector-class">.cuda</span><span class="selector-class">.current_device</span>()     # 返回当前设备索引</span><br></pre></td></tr></table></figure><h2><span id="torchdevice">torch.device</span></h2><p><code>torch.device</code> 表示 <code>torch.Tensor</code> 分配到的设备的对象。其包含一个设备类型（<code>cpu</code> 或 <code>cuda</code>），以及可选的设备序号。如果设备序号不存在，则为当前设备，即 <code>torch.cuda.current_device()</code> 的返回结果。</p><p>可以通过如下方式创建 <code>torch.device</code> 对象：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过字符串</span></span><br><span class="line"><span class="attr">device</span> = torch.device(<span class="string">'cpu'</span>)</span><br><span class="line"><span class="attr">device</span> = torch.device(<span class="string">'cuda:1'</span>)  # 指定类型及编号。注意，代码不会检查编号是否合法</span><br><span class="line"><span class="attr">device</span> = torch.device(<span class="string">'cuda'</span>)    # 默认为当前设备</span><br></pre></td></tr></table></figure><p>还可以通过设备类型加上编号，来创建 <code>device</code> 对象：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">device</span> = torch.device(<span class="string">'cuda'</span>, <span class="number">0</span>)</span><br><span class="line"><span class="attr">device</span> = torch.device(<span class="string">'cpu'</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure><h2><span id="配置-cuda-访问限制">配置 CUDA 访问限制</span></h2><p>可以通过如下方式，设置当前 <code>Python</code> 脚本可见的 <code>GPU</code>。</p><h3><span id="在命令行设置">在命令行设置</span></h3><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">CUDA_VISIBLE_DEVICES</span>=<span class="number">1</span> python my_script.py</span><br></pre></td></tr></table></figure><p><strong>实例</strong></p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Environment Variable Syntax      Results</span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">1</span>           Only device <span class="number">1</span> will be seen</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span>         Devices <span class="number">0</span> <span class="keyword">and</span> <span class="number">1</span> will be visible</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="string">"0,1"</span>       Same as above, quotation marks are optional</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>       Devices <span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span> will be visible; device <span class="number">1</span> <span class="keyword">is</span> masked</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="string">""</span>          No GPU will be visible</span><br></pre></td></tr></table></figure><h3><span id="在-python-代码中设置">在 Python 代码中设置</span></h3><figure class="highlight moonscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="built_in">os</span></span><br><span class="line"><span class="built_in">os</span>.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"0, 2"</span></span><br></pre></td></tr></table></figure><h3><span id="使用函数-set_device">使用函数 set_device</span></h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">torch<span class="selector-class">.cuda</span><span class="selector-class">.set_device</span>(id)</span><br></pre></td></tr></table></figure><blockquote><p>官方建议使用 <code>CUDA_VISIBLE_DEVICES</code>，不建议使用 <code>set_device</code> 函数。</p></blockquote><h2><span id="用-gpu-训练">用 GPU 训练</span></h2><p>默认情况下，使用 <code>CPU</code> 训练模型。可以通过如下方式，通过 <code>GPU</code> 进行训练。<strong>使用 GPU 时，模型和输入必须位于同一张 GPU 上。</strong></p><p><code>.to(device)</code> 和 <code>.cuda()</code> 的区别如下：</p><p><a href="https://stackoom.com/question/3bltP/Pytorch-%E5%9C%A8CUDA%E8%AE%BE%E5%A4%87%E4%B8%8A%E6%9C%89%E4%B8%89%E7%A7%8D%E6%96%B9%E6%B3%95%E5%8F%AF%E4%BB%A5%E5%88%9B%E5%BB%BA%E5%BC%A0%E9%87%8F-%E5%AE%83%E4%BB%AC%E4%B9%8B%E9%97%B4%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%E5%90%97" target="_blank" rel="noopener">to和cuda的区别</a></p><ol><li><code>.to()</code> 中的参数必不可少</li><li>对于 <code>module</code> 而言，<code>.to()</code> 是 <code>inplace</code> 的，而 <code>.cuda()</code> 不是；而对于 <code>tensor</code> 而言，两者一致。</li></ol><blockquote><p><strong>注</strong>：实测，两者时间消耗持平。</p></blockquote><p><strong>方式 1 ：</strong></p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">device</span> = torch.device(<span class="string">"cuda:1"</span>)   <span class="comment"># 指定模型训练所在 GPU</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 GPU 转移至 GPU</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available() <span class="literal">and</span> use_gpu:</span><br><span class="line">    <span class="attr">net</span> = net.cuda(device)    <span class="comment"># 默认在第一块 GPU 上训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 同时将数据转移至 GPU,注意cuda有返回值</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available() <span class="literal">and</span> use_gpu:</span><br><span class="line">    <span class="attr">inputs</span> = inputs.cuda(device)</span><br><span class="line">    <span class="attr">labels</span> = labels.cuda(device)</span><br></pre></td></tr></table></figure><p><strong>方法 2 ：</strong></p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">device</span> = torch.device(<span class="string">"cuda:1"</span>)   <span class="comment"># 指定模型训练所在 GPU</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 GPU 转移至 GPU</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available() <span class="literal">and</span> use_gpu:</span><br><span class="line">    <span class="attr">net</span> = net.to(device)    <span class="comment"># 默认在第一块 GPU 上训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 同时将数据转移至 GPU</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available() <span class="literal">and</span> use_gpu:</span><br><span class="line">    <span class="attr">inputs</span> = inputs.to(device)</span><br><span class="line">    <span class="attr">labels</span> = labels.to(device)</span><br></pre></td></tr></table></figure><h2><span id="存在的问题">存在的问题</span></h2><h3><span id="batch-size-太大">batch size 太大</span></h3><p>当想要用大批量进行训练，但是 <code>GPU</code> 资源有限，此时可以通过<strong>梯度累加</strong>（<code>accumulating gradients</code>）的方式进行。</p><p>梯度累加的基本思想在于，在优化器更新参数前，也就是执行 <code>optimizer.step()</code> 前，进行多次反向传播，使得梯度累计值自动保存在 <code>parameter.grad</code> 中，最后使用累加的梯度进行参数更新。</p><p>这个在 <code>PyTorch</code> 中特别容易实现，因为 <code>PyTorch</code> 中，梯度值本身会保留，除非我们调用 <code>model.zero_grad()</code> 或 <code>optimizer.zero_grad()</code>。</p><p>修改后的代码如下所示：</p><figure class="highlight stan"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">model</span>.zero_grad()                                   <span class="comment"># 重置保存梯度值的张量</span></span><br><span class="line"></span><br><span class="line"><span class="name">for</span> i, (inputs, labels) <span class="name">in</span> enumerate(training_set):</span><br><span class="line">    predictions = <span class="title">model</span>(inputs)                     <span class="comment"># 前向计算</span></span><br><span class="line">    loss = loss_function(predictions, labels)       <span class="comment"># 计算损失函数</span></span><br><span class="line">    loss.backward()                                 <span class="comment"># 计算梯度</span></span><br><span class="line">    <span class="name">if</span> (i + <span class="number">1</span>) % accumulation_steps == <span class="number">0</span>:           <span class="comment"># 重复多次前面的过程</span></span><br><span class="line">        optimizer.step()                            <span class="comment"># 更新梯度</span></span><br><span class="line">        <span class="title">model</span>.zero_grad()                           <span class="comment"># 重置梯度</span></span><br></pre></td></tr></table></figure><h3><span id="model-太大">model 太大</span></h3><p>当模型本身太大，以至于不能放置于一个 <code>GPU</code> 中时，可以通过<strong>梯度检查点</strong> (<code>gradient-checkpoingting</code>) 的方式进行处理。</p><p>梯度检查点的基本思想是<strong>以计算换内存</strong>。具体来说就是，在反向传播的过程中，把梯度切分成几部分，分别对网络上的部分参数进行更新。如下图所示：</p><p><img src="http://tankzhou.cn/images/%E6%A2%AF%E5%BA%A6%E6%A3%80%E6%9F%A5%E7%82%B9.gif" alt=""></p><p>梯度检查点图示</p><p>这种方法速度很慢，但在某些例子上很有用，比如训练长序列的 RNN 模型等。</p><p>具体可参考：<a href="https://medium.com/huggingface/from-zero-to-research-an-introduction-to-meta-learning-8e16e677f78a" target="_blank" rel="noopener">From zero to research — An introduction to Meta-learning</a></p><p>单机多卡训练，即<strong>并行训练</strong>。并行训练又分为<strong>数据并行</strong> (<code>Data Parallelism</code>) 和<strong>模型并行</strong>两种。</p><p>数据并行指的是，多张 <code>GPU</code> 使用相同的模型副本，但是使用不同的数据批进行训练。而模型并行指的是，多张<code>GPU</code> 分别训练模型的不同部分，使用同一批数据。</p><p>两者对比如下图所示：</p><p><img src="http://tankzhou.cn/images/%E6%A8%A1%E5%9E%8B%E5%B9%B6%E8%A1%8C%20VS%20%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C.png" alt=""></p><p>模型并行 VS 数据并行</p><h2><span id="数据并行">数据并行</span></h2><p><a href="https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html" target="_blank" rel="noopener">Pytorch多GPU官方实例</a></p><h3><span id="pytorch-api">Pytorch API</span></h3><p>【<strong>Class 原型</strong>】</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.DataParallel(module, <span class="attribute">device_ids</span>=None, <span class="attribute">output_device</span>=None, <span class="attribute">dim</span>=0)</span><br></pre></td></tr></table></figure><p>【<strong>参数</strong>】</p><ul><li><strong>module</strong> ：要进行并行的 <code>module</code>。这里隐含了一点 ，即网络中的某一层也是可以进行数据并行的，但是一般不会这么使用。</li><li><strong>device_ids</strong> : <code>CUDA</code> 列表，可以为 <code>torch.device</code> 类型，也可以是编号组成的 <code>int</code> 列表。<strong>默认使用全部 GPU</strong></li><li><strong>output_device</strong> : 某一 <code>GPU</code> 编号或 <code>torch.device</code> 。指定输出的 <code>GPU</code>，默认为第一个，即 <code>device_ids[0]</code></li></ul><p>【<strong>返回值</strong>】</p><p>要进行并行的模型。</p><p>【<strong>基本使用方式</strong>】</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; net = torch.nn.DataParallel(model, device_ids=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; output = net(input_var)  <span class="comment"># input_var can be on any device, including CP</span></span><br></pre></td></tr></table></figure><h3><span id="数据并行的原理">数据并行的原理</span></h3><p>数据并行的具体原理流程为：<br><img src="/2020/01/06/pytorch-学习/数据并行.png" alt=""></p><ol><li><p>将模型加载至主设备上，作为 <code>controller</code>，一般设置为 <code>cuda:0</code></p></li><li><p>在每次迭代时，执行如下操作：</p><ol><li><p>将 <code>controller</code> 模型复制（<code>broadcast</code>）到每一个指定的 <code>GPU</code> 上</p></li><li><p>将总输入的数据 <code>batch</code>，进行均分，分别作为各对应副本的输入 (<code>scatter</code>)</p></li><li><p>每个副本独立进行前向传播，并进行反向传播，但只是求取梯度</p></li><li><p>将各副本的梯度汇总（<code>gather</code>）到 <code>controller</code> 设备，并进行求和 (<code>reduced add</code>)</p><blockquote><p>During the backwards pass, gradients from each replica are summed into the original module.</p></blockquote></li><li><p>更具总体度，更新 <code>controller</code> 设备上的参数</p></li></ol></li></ol><h3><span id="注意事项">注意事项</span></h3><p>【<strong>警告 1</strong>】</p><ul><li>设置的 <code>batch size</code> 为总的批量尺寸，其必须大于 <code>GPU</code> 数量。</li><li>在 <code>parallelized module</code> 运行之前，必须保证其在 <code>controller</code> 设备上，存在参数和 <code>buffers</code>。</li><li>并行的 <code>GPU</code> 列表中，必须包含主 <code>GPU</code></li><li>当 <code>forward()</code> 中，<code>module</code> 返回一个标量，那么并行的结果将返回一个 <code>vector</code>，其长度等于 <code>device</code> 的数量，对应于各个设备的结果。</li></ul><p>【<strong>警告 2</strong>】</p><p>在每次前向传播过程中，<code>module</code> 都先会被复制到每一个 <code>device</code> 上。因此，在前向传播中，任何对该运行的 <code>module</code> 的副本的更新，在此后都将会丢失。</p><p>比方说，如果 <code>module</code> 有一个 <code>counter</code> 属性，每次前向传播都会进行累加，则它将会保持为初始值。因为更新是发生在模型的副本（在其他 <code>device</code> 上的副本）上的，并且这些更新在前向传播结束之后将会被销毁。</p><p>然而，<code>DataParallel</code> 保证 <code>controller</code> 设备上的副本的参数和 <code>buffers</code> 与其他并行的 <code>modules</code> 之间共享存储。因此，如若对 <code>controller device</code> 的 参数和 <code>buffers</code> 的更改，将会被记录。例如，<code>BatchNorm2d</code> 和 <code>spectral_norm()</code> 依赖于这种行为来更新 <code>buffers</code>。</p><p>【<strong>警告 3</strong>】</p><p>定义于 <code>module</code> 及其子 <code>module</code> 上的前向传播和反向传播 <code>hooks</code>，将会被调用 <code>len(device_ids)</code> 次，每个设备对应一次。</p><p>具体来说，<code>hooks</code> 只能保证按照正确的顺序执行对应设备上的操作，即在对应设备上的 <code>forward()</code> 调用之前执行，但是不能保证，在所有 <code>forward)()</code> 执行之前，通过 <code>register_forward_pre_hook()</code> 执行完成所有的 <code>hooks</code>。</p><p>【<strong>警告 4</strong>】</p><p>任何位置和关键字 (<code>positional and keyword</code>) 输入都可以传递给 <code>DataParallel</code>，处理一些需要特殊处理的类型。</p><p><code>tensors</code> 将会在指定维度（默认为 <code>0</code>）上被 <code>scattered</code>。 <code>tuple</code>， <code>list</code> 和 <code>dict</code> 类型则会被浅拷贝。其他类型则会在不同的线程之间进行共享，且在模型前向传播过程中，如果进行写入，则可被打断。</p><p>【<strong>警告 5</strong>】</p><p>当对 <code>pack sequence -&gt; recurrent network -&gt; unpack sequence</code> 模式的 <code>module</code> 使用 <code>DataParallel</code> 或 <code>data_parallel</code> 时，有一些小的问题。</p><p>每个设备上的 <code>forward</code> 的对应输入，将仅仅是整个输入的一部分。因为默认的 <code>unpack</code> 操作 <code>torch.nn.utils.rnn.pad_packed_sequence()</code> 只会将该设备上的输入 <code>padding</code> 成该设备上的最长的输入长度，因此，将所有设备的结构进行汇总时，可能会发生长度的不匹配的情况。</p><p>因此，可以利用 <code>pad_packed_sequence()</code> 的 <code>total_length</code> 参数来保证 <code>forward()</code> 调用返回的序列长度一致。代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.nn.utils.rnn <span class="keyword">import</span> pack_padded_sequence, pad_packed_sequence</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModule</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="comment"># ... __init__, other methods, etc.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># padded_input is of shape [B x T x *] (batch_first mode) and contains</span></span><br><span class="line">    <span class="comment"># the sequences sorted by lengths</span></span><br><span class="line">    <span class="comment">#   B is the batch size</span></span><br><span class="line">    <span class="comment">#   T is max sequence length</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, padded_input, input_lengths)</span>:</span></span><br><span class="line">        total_length = padded_input.size(<span class="number">1</span>)  <span class="comment"># get the max sequence length</span></span><br><span class="line">        packed_input = pack_padded_sequence(padded_input, input_lengths,</span><br><span class="line">                                            batch_first=<span class="keyword">True</span>)</span><br><span class="line">        packed_output, _ = self.my_lstm(packed_input)</span><br><span class="line">        output, _ = pad_packed_sequence(packed_output, batch_first=<span class="keyword">True</span>,</span><br><span class="line">                                        total_length=total_length)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">m = MyModule().cuda()        <span class="comment"># 设置 controller 模型</span></span><br><span class="line">dp_m = nn.DataParallel(m)    <span class="comment"># 进行副本拷贝</span></span><br></pre></td></tr></table></figure><h3><span id="示例程序">示例程序</span></h3><p>下面是使用 <code>DataParrel</code> 的核心代码，其余部分与一般的训练流程一致。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置当前脚本可见的 GPU 列表</span></span><br><span class="line"><span class="comment"># 这里设置 0 号和 1 号 GPU 对当前脚本可见。</span></span><br><span class="line"><span class="comment"># 此时，若 DataParallel 中指定使用其他 GPU 资源，额外的编号将会被忽略</span></span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"0, 1"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用数据并行</span></span><br><span class="line"><span class="comment"># 1. 将 model 转移到某 GPU 上 -- net.cuda()</span></span><br><span class="line"><span class="comment"># 2. 指定并行训练要用到的 GPU -- device_ids=[0, 1]</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.device_count() &gt; <span class="number">1</span>:</span><br><span class="line">    print(<span class="string">"Let's use"</span>, torch.cuda.device_count(), <span class="string">"GPUs!"</span>)</span><br><span class="line">    net = nn.DataParallel(net.cuda(), device_ids=[<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据转移到 controller 所在 GPU</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">and</span> use_gpu:</span><br><span class="line">    inputs = inputs.cuda(device)</span><br><span class="line">    labels = labels.cuda(device)</span><br></pre></td></tr></table></figure><h3><span id="模型的加载">模型的加载</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_Single2Parallel</span><span class="params">(self, origin_state)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    将串行的权值参数转换为并行的权值参数</span></span><br><span class="line"><span class="string">    :param origin_state : 原始串行权值参数</span></span><br><span class="line"><span class="string">    :return             : 并行的权值参数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">  converted = OrderedDict()</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> origin_state.items():</span><br><span class="line">      name = <span class="string">"module."</span> + k</span><br><span class="line">      converted[name] = v</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> converted</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_Parallel2Single</span><span class="params">(self, origin_state)</span>:</span></span><br><span class="line">  <span class="string">"""</span></span><br><span class="line"><span class="string">  将并行的权值参数转换为串行的权值参数</span></span><br><span class="line"><span class="string">  :param origin_state : 原始串行权值参数</span></span><br><span class="line"><span class="string">  :return             : 并行的权值参数</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">    </span><br><span class="line">    converted = OrderedDict()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> origin_state.items():</span><br><span class="line">      name = k[<span class="number">7</span>:]</span><br><span class="line">      converted[name] = v</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">return</span> converted</span><br></pre></td></tr></table></figure><h2><span id="模型并行">模型并行</span></h2><p>如果模型本身较大，一张 <code>GPU</code> 放置不下时，要通过模型并行来处理。模型并行指的是，将模型的不同部分，分别放置于不同的 <code>GPU</code> 上，并将中间结果在 <code>GPU</code> 之间进行传递。</p><p>尽管从执行时间上来看，将模型的不同部分部署在不同设备上确实有好处，但是它通常是出于避免内存限制才使用。具有特别多参数的模型会受益于这种并行策略，因为这类模型需要很高的内存占用，很难适应到单个系统。</p><h3><span id="基本使用">基本使用</span></h3><p>下面，我们以一个 <code>toy</code> 模型为例，讲解模型并行。模型并行的实现方式如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.features_1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels=<span class="number">3</span>, out_channels=<span class="number">16</span>, kernel_size=<span class="number">3</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">16</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="keyword">True</span>),  <span class="comment"># 30</span></span><br><span class="line">            ......</span><br><span class="line">            nn.Conv2d(in_channels=<span class="number">64</span>, out_channels=<span class="number">128</span>, kernel_size=<span class="number">3</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="keyword">True</span>),  <span class="comment"># 12</span></span><br><span class="line">        ).to(<span class="string">'cuda:0'</span>)</span><br><span class="line"></span><br><span class="line">        self.features_2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels=<span class="number">128</span>, out_channels=<span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="keyword">True</span>),  <span class="comment"># 5</span></span><br><span class="line">            ......).to(<span class="string">'cuda:1'</span>)  <span class="comment"># 1</span></span><br><span class="line"></span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            ......</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, class_num)).to(<span class="string">'cuda:1'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        out = self.features_1(x.to(<span class="string">'cuda:0'</span>))</span><br><span class="line">        out = self.features_2(out.to(<span class="string">'cuda:1'</span>))</span><br><span class="line">        out = out.view(<span class="number">-1</span>, <span class="number">384</span>)</span><br><span class="line">        out = self.classifier(out)</span><br><span class="line">        out = F.softmax(out, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>上面的 <code>toy</code> 模型看起来和在单个 <code>GPU</code> 上运行的模型没什么区别，只不过用 <code>to(device)</code> 来将模型内的不同层分散到不同的 <code>GPU</code> 上进行运行，并且将中间结果转移到对应的 <code>GPU</code> 上即可。</p><p><code>backward()</code> 和 <code>torch.optim</code> 将会自动考虑梯度，与在一个 <code>GPU</code> 上没有区别。</p><blockquote><p><strong>注意</strong>：在调用 <code>loss</code> 函数时，<code>labels</code> 与 <code>output</code> 必须在同一个 <code>GPU</code> 上。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此时，不在此需要使用 model = model.cuda()</span></span><br><span class="line">model = ToyModel()</span><br><span class="line"></span><br><span class="line">loss_fn = nn.MSELoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> trainloader:</span><br><span class="line">    images, labels = data</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 要处理的部分</span></span><br><span class="line">    images = images.to(<span class="string">'cuda:0'</span>)</span><br><span class="line">    labels = labels.to(<span class="string">'cuda:1'</span>)   <span class="comment"># 必须与输出所在 GPU 一致</span></span><br><span class="line">    </span><br><span class="line">    outputs = net(images)</span><br><span class="line">    loss = criterion(outputs, labels)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure><h3><span id="模型并行的性能分析">模型并行的性能分析</span></h3><p>以上的实现解决了单个模型太大，不能存放于一个 <code>GPU</code> 的情况。然而，需要注意的是，相较于在单个 <code>GPU</code> 上运行，其速度更慢。因为任何时候，只有一个 <code>GPU</code> 在工作，而另一个则闲置。而当中间结果在 <code>GPU</code> 之间进行转移时，速度会进一步下降。</p><p>下面同时实例分析。以 <code>resnet50</code> 为例，用随机生成的数据输入，比较两个版本的运行时间。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision.models.resnet <span class="keyword">import</span> ResNet, Bottleneck</span><br><span class="line"></span><br><span class="line">num_classes = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ModelParallelResNet50</span><span class="params">(ResNet)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, *args, **kwargs)</span>:</span></span><br><span class="line">        super(ModelParallelResNet50, self).__init__(</span><br><span class="line">            Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], num_classes=num_classes, *args, **kwargs)</span><br><span class="line"></span><br><span class="line">        self.seq1 = nn.Sequential(</span><br><span class="line">            self.conv1,</span><br><span class="line">            self.bn1,</span><br><span class="line">            self.relu,</span><br><span class="line">            self.maxpool,</span><br><span class="line"></span><br><span class="line">            self.layer1,</span><br><span class="line">            self.layer2</span><br><span class="line">        ).to(<span class="string">'cuda:0'</span>)</span><br><span class="line"></span><br><span class="line">        self.seq2 = nn.Sequential(</span><br><span class="line">            self.layer3,</span><br><span class="line">            self.layer4,</span><br><span class="line">            self.avgpool,</span><br><span class="line">        ).to(<span class="string">'cuda:1'</span>)</span><br><span class="line"></span><br><span class="line">        self.fc.to(<span class="string">'cuda:1'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.seq2(self.seq1(x).to(<span class="string">'cuda:1'</span>))</span><br><span class="line">        <span class="keyword">return</span> self.fc(x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"></span><br><span class="line">num_batches = <span class="number">3</span></span><br><span class="line">batch_size = <span class="number">120</span></span><br><span class="line">image_w = <span class="number">128</span></span><br><span class="line">image_h = <span class="number">128</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(model)</span>:</span></span><br><span class="line">    model.train(<span class="keyword">True</span>)</span><br><span class="line">    loss_fn = nn.MSELoss()</span><br><span class="line">    optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">    one_hot_indices = torch.LongTensor(batch_size) \</span><br><span class="line">                           .random_(<span class="number">0</span>, num_classes) \</span><br><span class="line">                           .view(batch_size, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(num_batches):</span><br><span class="line">        <span class="comment"># generate random inputs and labels</span></span><br><span class="line">        inputs = torch.randn(batch_size, <span class="number">3</span>, image_w, image_h)</span><br><span class="line">        labels = torch.zeros(batch_size, num_classes) \</span><br><span class="line">                      .scatter_(<span class="number">1</span>, one_hot_indices, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># run forward pass</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = model(inputs.to(<span class="string">'cuda:0'</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># run backward pass</span></span><br><span class="line">        labels = labels.to(outputs.device)</span><br><span class="line">        loss_fn(outputs, labels).backward()</span><br><span class="line">        optimizer.step()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.switch_backend(<span class="string">'Agg'</span>)</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> timeit</span><br><span class="line"></span><br><span class="line">num_repeat = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">stmt = <span class="string">"train(model)"</span></span><br><span class="line"></span><br><span class="line">setup = <span class="string">"model = ModelParallelResNet50()"</span></span><br><span class="line"><span class="comment"># globals arg is only available in Python 3. In Python 2, use the following</span></span><br><span class="line"><span class="comment"># import __builtin__</span></span><br><span class="line"><span class="comment"># __builtin__.__dict__.update(locals())</span></span><br><span class="line">mp_run_times = timeit.repeat(</span><br><span class="line">    stmt, setup, number=<span class="number">1</span>, repeat=num_repeat, globals=globals())</span><br><span class="line">mp_mean, mp_std = np.mean(mp_run_times), np.std(mp_run_times)</span><br><span class="line"></span><br><span class="line">setup = <span class="string">"import torchvision.models as models;"</span> + \</span><br><span class="line">        <span class="string">"model = models.resnet50(num_classes=num_classes).to('cuda:0')"</span></span><br><span class="line">rn_run_times = timeit.repeat(</span><br><span class="line">    stmt, setup, number=<span class="number">1</span>, repeat=num_repeat, globals=globals())</span><br><span class="line">rn_mean, rn_std = np.mean(rn_run_times), np.std(rn_run_times)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot</span><span class="params">(means, stds, labels, fig_name)</span>:</span></span><br><span class="line">    fig, ax = plt.subplots()</span><br><span class="line">    ax.bar(np.arange(len(means)), means, yerr=stds,</span><br><span class="line">           align=<span class="string">'center'</span>, alpha=<span class="number">0.5</span>, ecolor=<span class="string">'red'</span>, capsize=<span class="number">10</span>, width=<span class="number">0.6</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">'ResNet50 Execution Time (Second)'</span>)</span><br><span class="line">    ax.set_xticks(np.arange(len(means)))</span><br><span class="line">    ax.set_xticklabels(labels)</span><br><span class="line">    ax.yaxis.grid(<span class="keyword">True</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.savefig(fig_name)</span><br><span class="line">    plt.close(fig)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plot([mp_mean, rn_mean],</span><br><span class="line">     [mp_std, rn_std],</span><br><span class="line">     [<span class="string">'Model Parallel'</span>, <span class="string">'Single GPU'</span>],</span><br><span class="line">     <span class="string">'mp_vs_rn.png'</span>)</span><br></pre></td></tr></table></figure><p>结果如下所示。模型并行相较于单 <code>GPU</code> 训练的模型，训练时间开销多出 <code>4.02/3.75-1=7%</code> 左右。当然，这存在优化空间，因为多 <code>GPU</code> 中，每一时刻只有一个 <code>GPU</code> 进行训练，其他闲置。而在中间数据转移过程中，又消耗一定的时间。</p><p><img src="http://tankzhou.cn/images/mp_vs_rn.png" alt=""></p><p>模型并行 VS 单 GPU</p><h3><span id="输入流水线">输入流水线</span></h3><p>解决上面的问题的最直接的方式就是使用流水线技术，即 <code>GPU-0</code> 输出到 <code>GPU-1</code> 之后，在 <code>GPU-1</code> 训练的同时，<code>GPU-0</code> 接收下一批数据，这样就可以多 <code>GPU</code> 同时执行了。</p><p>下面，我们将 <code>120</code> 个样本的 <code>batch</code> 再次细分，分为 <code>20</code> 张样本每份的小 <code>batch</code>。由于 <code>Pytorch</code> 同步启动 <code>CUDA</code> 操作，因此，该操作不需要使用额外的多线程来处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PipelineParallelResNet50</span><span class="params">(ModelParallelResNet50)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, split_size=<span class="number">20</span>, *args, **kwargs)</span>:</span></span><br><span class="line">        super(PipelineParallelResNet50, self).__init__(*args, **kwargs)</span><br><span class="line">        self.split_size = split_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        splits = iter(x.split(self.split_size, dim=<span class="number">0</span>))</span><br><span class="line">        s_next = next(splits)</span><br><span class="line">        s_prev = self.seq1(s_next).to(<span class="string">'cuda:1'</span>)</span><br><span class="line">        ret = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> s_next <span class="keyword">in</span> splits:</span><br><span class="line">            <span class="comment"># A. s_prev runs on cuda:1</span></span><br><span class="line">            s_prev = self.seq2(s_prev)</span><br><span class="line">            ret.append(self.fc(s_prev.view(s_prev.size(<span class="number">0</span>), <span class="number">-1</span>)))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># B. s_next runs on cuda:0, which can run concurrently with A</span></span><br><span class="line">            s_prev = self.seq1(s_next).to(<span class="string">'cuda:1'</span>)</span><br><span class="line"></span><br><span class="line">        s_prev = self.seq2(s_prev)</span><br><span class="line">        ret.append(self.fc(s_prev.view(s_prev.size(<span class="number">0</span>), <span class="number">-1</span>)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> torch.cat(ret)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">setup = <span class="string">"model = PipelineParallelResNet50()"</span></span><br><span class="line">pp_run_times = timeit.repeat(</span><br><span class="line">    stmt, setup, number=<span class="number">1</span>, repeat=num_repeat, globals=globals())</span><br><span class="line">pp_mean, pp_std = np.mean(pp_run_times), np.std(pp_run_times)</span><br><span class="line"></span><br><span class="line">plot([mp_mean, rn_mean, pp_mean],</span><br><span class="line">     [mp_std, rn_std, pp_std],</span><br><span class="line">     [<span class="string">'Model Parallel'</span>, <span class="string">'Single GPU'</span>, <span class="string">'Pipelining Model Parallel'</span>],</span><br><span class="line">     <span class="string">'mp_vs_rn_vs_pp.png'</span>)</span><br></pre></td></tr></table></figure><p>需要注意的是，<code>device-to-device</code> 的 <code>tensor copy</code> 操作是同步的。如果创建多个数据流，则需要保证 <code>copy</code> 操作以合适的同步方式进行。</p><p>在完成 <code>tensor</code> 拷贝之前，对 <code>source tensor</code> 进行写入，或者对 <code>target tensor</code> 进行读写，都可能会导致不可预期的行为。上面的实现中，在源和目标设备中，均只使用了默认的 <code>stream</code>，因此无需额外的强化同步操作。</p><p><img src="http://tankzhou.cn/images/mp_vs_rn_vs_pp.png" alt=""></p><p>模型并行 VS 单 GPU VS 流水线模型并行</p><p>如上图所示，流水线输入确实加速了训练进程，大约 <code>3.75/2.51-1=49%</code>，但距离 <code>100%</code> 的加速相去甚远。由于我们在流水线并行实现中，引入了一个新的参数 <code>split_sizes</code>，但是并不知晓其对训练时间的影响。</p><p>直觉上来说，使用一个小的 <code>split_sizes</code> 将会导致许多微小的 <code>CUDA</code> 内核的启动，而使用较大的 <code>split_sizes</code>，则会导致较长的空闲时间。下面是一个搜索最佳 <code>split_sizes</code> 的实验。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">means = []</span><br><span class="line">stds = []</span><br><span class="line">split_sizes = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">8</span>, <span class="number">10</span>, <span class="number">12</span>, <span class="number">20</span>, <span class="number">40</span>, <span class="number">60</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> split_size <span class="keyword">in</span> split_sizes:</span><br><span class="line">    setup = <span class="string">"model = PipelineParallelResNet50(split_size=%d)"</span> % split_size</span><br><span class="line">    pp_run_times = timeit.repeat(</span><br><span class="line">        stmt, setup, number=<span class="number">1</span>, repeat=num_repeat, globals=globals())</span><br><span class="line">    means.append(np.mean(pp_run_times))</span><br><span class="line">    stds.append(np.std(pp_run_times))</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(split_sizes, means)</span><br><span class="line">ax.errorbar(split_sizes, means, yerr=stds, ecolor=<span class="string">'red'</span>, fmt=<span class="string">'ro'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'ResNet50 Execution Time (Second)'</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">'Pipeline Split Size'</span>)</span><br><span class="line">ax.set_xticks(split_sizes)</span><br><span class="line">ax.yaxis.grid(<span class="keyword">True</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.savefig(<span class="string">"split_size_tradeoff.png"</span>)</span><br><span class="line">plt.close(fig)</span><br></pre></td></tr></table></figure><p>实验结果如下所示：</p><p><img src="http://tankzhou.cn/images/split_size_tradeoff.png" alt=""></p><p>流水线输入分割份数</p><p>如上图所示，最佳的参数为 <code>12</code>，其将导致 <code>3.75/2.43-1=54%</code> 的加速。但这仍存在加速的可能。例如，所有在 <code>cuda:0</code> 上的操作放在默认的 <code>stream</code> 上。这意味着，在下一个 <code>split</code> 上的计算，不能与上一个 <code>split</code> 的 <code>copy</code> 操作进行重叠。然而，由于 <code>next_split</code> 和 <code>prev_plit</code> 是不同的 <code>tensor</code>，因此这不存在问题。</p><p>该实现需要在每个 <code>GPU</code> 上使用多个 <code>stream</code>，并且模型中不同的子网络需要使用不同的 <code>stream</code> 管理策略。</p>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;title: pytorch 学习&lt;br&gt;date: 2020-01-06T14:35:30.000Z&lt;br&gt;categories: Deep Learning&lt;br&gt;tags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pytorch&lt;br&gt;comments: false&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;介绍Pytorch的一些使用方法&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>leetcode tirck</title>
    <link href="http://yoursite.com/2019/12/26/leecode-tirck/"/>
    <id>http://yoursite.com/2019/12/26/leecode-tirck/</id>
    <published>2019-12-26T11:25:57.000Z</published>
    <updated>2020-01-22T13:26:49.883Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="简介">简介</span></h1><p>&ensp;&ensp;&ensp;&ensp;最近开始刷Leecode，使用Python语言，踩了很多坑，在此记录。<br><a id="more"></a>   </p><h1><span id="一个萝卜一个坑">一个萝卜一个坑</span></h1><h2><span id="int函数">int函数</span></h2><p>int()函数用于将一个字符串或数字转换为整型。<br><code>int(x,base=10)</code>:x—字符串或数字，base—进制数，默认十进制。 如果显示的指定base参数，x必须为str。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">int(<span class="number">3</span>) = <span class="number">3</span></span><br><span class="line">int(<span class="number">3.6</span>) = <span class="number">3</span></span><br><span class="line">int(<span class="string">'12'</span>,<span class="number">16</span>) = <span class="number">18</span></span><br><span class="line">int(<span class="string">'11'</span>,<span class="number">2</span>) = <span class="number">3</span><span class="comment">#将字符串解析为2进制</span></span><br><span class="line">```    </span><br><span class="line"><span class="comment">## bin函数  </span></span><br><span class="line">bin()返回一个整数int的二进制表示，返回类型str</span><br><span class="line">`bin(x)`  </span><br><span class="line">```python   </span><br><span class="line"><span class="comment">#返回的结果前2个字符是固定的'0b'，后面才是真正的值。</span></span><br><span class="line">bin(<span class="number">10</span>) = <span class="string">'0b1010'</span></span><br><span class="line">bin(<span class="number">20</span>) = <span class="string">'0b10100'</span></span><br></pre></td></tr></table></figure></p><h2><span id="zip函数">zip函数</span></h2><p>zip()接受一系列(多个，个数不固定)可迭代对象(最常用list,tuple)作为参数，将多个对象中，对应位置的元素打包成一个个tuple，然后返回由这些tuple组成的list。若传入参数中长度不一样，则返回liist的长度和参数中最短的相同。  </p><pre><code class="lang-python">x = [&#39;wang&#39;,&#39;bei&#39;]y = [&#39;lei&#39;,&#39;xiao&#39;,&#39;kang&#39;]list(zip(x,y))输出：[(&#39;wang&#39;,&#39;lei&#39;),(&#39;bei&#39;,&#39;xiao&#39;)] x = &#39;wang&#39;y = &#39;lei&#39;list(zip(x,y))输出：[(&#39;w&#39;,&#39;l&#39;),(&#39;a&#39;,&#39;e&#39;),(&#39;n&#39;,&#39;i&#39;)]  #假设zip传入的参数是x，y，zip依次将(x[0],y[0]),(x[1],y[1])..#以可迭代对象返回，可强制转换为list或tuple</code></pre><p>zip(<em>)传入的参数是zip()的返回值类型，从<zip\>类型中每一个tuple中，取出第0个元素组成一个list，再取出第1个元素组成一个list，即zip(\</zip\></em>)返回值是一个大list，里面有2个tuple  </p><pre><code class="lang-python">a = [1,2,3,4,5]b = [&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]zipped = list(zip(a,b))#zipped = [(1,&#39;a&#39;),(2,&#39;b&#39;),(3,&#39;c&#39;)]c = list(zip(*zipped))#c = [(1,2,3),(&#39;a&#39;,&#39;b&#39;,&#39;c&#39;)]</code></pre><h2><span id="二分法讲解">二分法讲解</span></h2><p><a href="https://leetcode-cn.com/problems/search-insert-position/solution/te-bie-hao-yong-de-er-fen-cha-fa-fa-mo-ban-python-/" target="_blank" rel="noopener">参考资料</a><br>需要注意的问题：</p><ul><li>怎么获取mid</li><li>while条件</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;最近开始刷Leecode，使用Python语言，踩了很多坑，在此记录。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="算法" scheme="http://yoursite.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>nni</title>
    <link href="http://yoursite.com/2019/11/25/nni/"/>
    <id>http://yoursite.com/2019/11/25/nni/</id>
    <published>2019-11-25T06:23:50.000Z</published>
    <updated>2020-01-22T13:27:33.610Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="1-简介">1. 简介</span></h1><p>NN是微软官方出的一个自动调参的第三方库。非常好用。但是用起来还是有一些需要注意的地方。这里记录一下。<br><a id="more"></a><br><!-- TOC --></p><ul><li><a href="#1-%e7%ae%80%e4%bb%8b">1. 简介</a></li><li><a href="#2-%e6%9c%af%e8%af%ad">2. 术语</a><ul><li><a href="#21-%e4%bd%bf%e7%94%a8%e6%ad%a5%e9%aa%a4">2.1. 使用步骤</a></li></ul></li><li><a href="#3-nni%e5%91%bd%e4%bb%a4">3. NNI命令</a></li></ul><!-- /TOC --><p><a href="https://nni.readthedocs.io/zh/latest/Tutorial/QuickStart.html" target="_blank" rel="noopener">NNi官方文档</a>     </p><h1><span id="2-术语">2. 术语</span></h1><p>主要有2个术语experiment和trial。<br>experiment：如果需要调整LSTM的超参数，则需要指定每个超参数的可选项，然后运行程序，让nni自动调参。运行的这个调参程序就是experiment。<br>trial：上面运行的程序中，有很多的参数组合，每一个超参数组合是trial。<br>每一个experiment有一个ID，experiment中的每一个trial也有一个ID。在网页中可以看到<br><img src="/2019/11/25/nni/experiment_id.png" alt=""><br><img src="/2019/11/25/nni/trial_id.png" alt=""></p><h2><span id="21-使用步骤">2.1. 使用步骤</span></h2><ol><li><p>创建搜索空间json文件<br>这里定义需要调整的超参数  </p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> <span class="attr">"num_layer"</span>:&#123;<span class="attr">"_type"</span>:<span class="string">"choice"</span>,<span class="attr">"_value"</span>:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]&#125;,</span><br><span class="line"> <span class="attr">"hidden_size"</span>:&#123;<span class="attr">"_type"</span>:<span class="string">"choice"</span>,<span class="attr">"_value"</span>:[<span class="number">64</span>,<span class="number">128</span>,<span class="number">256</span>,<span class="number">512</span>]&#125;,</span><br><span class="line"> <span class="attr">"batch_size"</span>: &#123;<span class="attr">"_type"</span>:<span class="string">"choice"</span>, <span class="attr">"_value"</span>: [<span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>,<span class="number">64</span>,<span class="number">128</span>,<span class="number">256</span>]&#125;,</span><br><span class="line"> <span class="attr">"learning_rate"</span>:&#123;<span class="attr">"_type"</span>:<span class="string">"uniform"</span>,<span class="attr">"_value"</span>:[<span class="number">0.0001</span>,<span class="number">0.001</span>]&#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></li><li><p>首先在程序中import nni  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line">   <span class="keyword">import</span> nni  </span><br><span class="line">   <span class="keyword">import</span> os  </span><br><span class="line">   os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"2"</span><span class="comment">#单GPU</span></span><br><span class="line">   <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>,train_epoch):</span><br><span class="line">       每一个batch，在测试集上训练，并反向传播  </span><br><span class="line">       每一个epoch，计算验证集/测试集的loss</span><br><span class="line">       每一个epoch，计算验证集/测试集的评价指标(mae,rmse)</span><br><span class="line">       <span class="comment">#将验证集的评价指标加入到nni中 </span></span><br><span class="line">       <span class="keyword">if</span> epoch &lt; train_epoch:</span><br><span class="line">            nni.report_intermediate_result(valid_mae)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            nni.report_final_result(valid_mae)</span><br><span class="line">   ```  </span><br><span class="line">   在下面的yml文件中，需要指定gpuNum,即需要使用多少张GPU卡。但是nni会自动申请gpu，你也不知道会申请到哪个gpu。为了解决这个问题，需要指定程序只能看见哪些卡，那么就会只申请看见的卡。</span><br><span class="line">   通过以下代码指定：</span><br><span class="line">   ```python    </span><br><span class="line">   os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"2"</span><span class="comment">#单GPU</span></span><br><span class="line">   os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"1,2"</span><span class="comment">#多GPU</span></span><br><span class="line">   ```  </span><br><span class="line">   **注意：如果只指定能看见第<span class="number">2</span>张卡，但是程序中，会给第<span class="number">2</span>张卡编号的为<span class="number">0</span>，即通过ctx=mx.gpu(<span class="number">0</span>)来获取。如果指定能看见<span class="number">1</span>和<span class="number">2</span>卡，那么程序中会分别编号<span class="number">0</span>和<span class="number">1</span>。**</span><br><span class="line"><span class="number">3.</span> nni的配置文件config.yml  </span><br><span class="line">   ```yml   </span><br><span class="line">    authorName: wangbeibei</span><br><span class="line">    experimentName: gru_grid_experiment</span><br><span class="line">    <span class="comment">#并发尝试任务的最大数量，有1张gpu卡就是1，有2张gpu卡就是2</span></span><br><span class="line">    trialConcurrency: <span class="number">1</span></span><br><span class="line">    maxExecDuration: <span class="number">100</span>h</span><br><span class="line">    <span class="comment">#Trial 任务的最大数量，成功和失败的都计算在内</span></span><br><span class="line">    maxTrialNum: <span class="number">10</span></span><br><span class="line">    <span class="comment">#choice: local, remote, pai,在虚拟环境和docker运行时，都写local</span></span><br><span class="line">    trainingServicePlatform: local</span><br><span class="line">    <span class="comment">#在第一步创建的json文件的路径，这里需要写相对路径，因为当前的yml文件和json文件在同一文件夹下</span></span><br><span class="line">    searchSpacePath: lstm_search_space.json</span><br><span class="line">    <span class="comment">#choice: true, false</span></span><br><span class="line">    useAnnotation: false</span><br><span class="line">    <span class="comment"># 存储日志和数据的目录, 默认值是 /data/WangBeibei/nni/experiments</span></span><br><span class="line">    <span class="comment">#如果在虚拟环境中运行该代码，logDir是服务器下的绝对路径，/data/WangBeibei/graduation/Code/nni_save_logs</span></span><br><span class="line">    <span class="comment">#如果在docker下运行该代码，logDir是容器下的绝对路径，/root/Code/nni_save_logs/</span></span><br><span class="line">    logDir: /root/Code/nni_save_logs/</span><br><span class="line">    tuner:</span><br><span class="line">        <span class="comment">#choice: TPE, Random, Anneal, Evolution, BatchTuner, MetisTuner, GPTuner</span></span><br><span class="line">        <span class="comment">#SMAC (SMAC should be installed through nnictl)</span></span><br><span class="line">        builtinTunerName: TPE</span><br><span class="line">        classArgs:</span><br><span class="line">            <span class="comment">#choice: maximize, minimize</span></span><br><span class="line">            <span class="comment">#mae、rmse、mse都是最小化</span></span><br><span class="line">            optimize_mode: minimize</span><br><span class="line">    trial:</span><br><span class="line">    <span class="comment"># 指定了运行 Trial 进程的命令行</span></span><br><span class="line">    command: cd baseline &amp;&amp; python3 lstm_baseline.py</span><br><span class="line">    <span class="comment">#指定了 Trial 代码文件的目录</span></span><br><span class="line">    <span class="comment">#首先从yml目录下，进入到代码的根目录下</span></span><br><span class="line">    codeDir: ../</span><br><span class="line">    <span class="comment">#指定需要使用</span></span><br><span class="line">    gpuNum: <span class="number">1</span></span><br><span class="line">   ```   </span><br><span class="line"><span class="number">4.</span> 启动容器    </span><br><span class="line">   nni网页的默认端口是<span class="number">8080</span>，所以需要和本地映射一下，</span><br><span class="line">   ```  </span><br><span class="line">   docker run -it -p <span class="number">7000</span>:<span class="number">8080</span> -v $PWD:/root --runtime=nvidia --rm -u <span class="number">1018</span> --name wbbnni lin-ai<span class="number">-27</span>:<span class="number">5000</span>/wangbeibei/mxnet:cu_100  </span><br><span class="line"></span><br><span class="line">   docker run -it -p <span class="number">7000</span>:<span class="number">8080</span> -v $PWD:/root --runtime=nvidia --rm -u <span class="number">1018</span> --name wbbnni lin-ai<span class="number">-29</span>:<span class="number">5000</span>/dlspree:latest</span><br><span class="line">   ```   </span><br><span class="line"><span class="number">5.</span> 启动一个nni的experiment    </span><br><span class="line">   进入到yml所在的目录，使用以下命令，启动一个experiment实例，然后就可以在网页上查看</span><br><span class="line">   使用```nnictl create --config config.yml```   </span><br><span class="line">   出现以下提示，说明启动成功。 </span><br><span class="line">   ![](nni/create.png)   </span><br><span class="line"><span class="number">6.</span> 在网页上访问  </span><br><span class="line">   在网页上打开```服务器ip:<span class="number">7000</span>```   </span><br><span class="line">   ![](nni/success.png)   </span><br><span class="line"><span class="number">7.</span> 错误日志    </span><br><span class="line">   如果提交的任务都失败了，可以去看日志文件。日志文件的位置在下图中。在容器中进入到下面的目录中。   </span><br><span class="line">   ![](nni/error1.png)</span><br><span class="line">   ![](nni/error2.png)    </span><br><span class="line">   在容器中进入到日志目录中，找到对应id的文件夹。 </span><br><span class="line">   ![](nni/log.png)  </span><br><span class="line"><span class="number">8.</span> 成功日志  </span><br><span class="line">   如果trial成功运行，那么关于这次trial的</span><br><span class="line">   ![](nni/success1.png)   </span><br><span class="line"><span class="comment"># 3. NNI命令    </span></span><br><span class="line">[NNI命令参考文档](https://github.com/microsoft/nni/blob/master/docs/zh_CN/Tutorial/Nnictl.md)</span><br><span class="line"><span class="number">1.</span> nnictl create  </span><br><span class="line">   （<span class="number">1</span>）在默认端口<span class="number">8080</span>上创建一个新的Experiment</span><br><span class="line">   ```nnictl create --config nni/examples/trials/mnist/config.yml```   </span><br><span class="line">   （<span class="number">2</span>）在指定的端口上<span class="number">8088</span>创建新的Experiment</span><br><span class="line">   ```nnictl create --config nni/examples/trials/mnist/config.yml --port <span class="number">8088</span>```   </span><br><span class="line"><span class="number">2.</span> nnictl stop</span><br><span class="line">   停止正在运行的单个或多个Experiment</span><br><span class="line">   （<span class="number">1</span>）没有指定id，停止所有正在运行的Experiment</span><br><span class="line">   ```nnictl stop```     </span><br><span class="line">   （<span class="number">2</span>）停止指定id的Experiment</span><br><span class="line">   ```nnictl stop [experiment_id]```  </span><br><span class="line"><span class="number">3.</span> nnictl update </span><br><span class="line">   更新 Experiment 的搜索空间，其中`experiment_id`是可选的参数，后面的`--filename`是必填的参数。</span><br><span class="line">   先使用vscode修改搜索空间的json文件，然后再使用下面的命令来更新搜索空间文件。</span><br><span class="line">   ```nnictl update searchspace [experiment_id] --filename examples/trials/mnist/search_space.json```   </span><br><span class="line"><span class="number">4.</span> nnictl view</span><br><span class="line">   如果使用stop结束调参程序，以后还想看一下网页上的调参结果，使用该命令。这个命令只是在前端展示调参的结果，调参程序不会再次启动。</span><br></pre></td></tr></table></figure><p>nnictl view [OPTIONS]<br>其中experiment_id是必填的，port是选填的<br>nnictl view [experiment_id] —port 8088<br>```</p></li><li>nnictl top<br>查看正在运行的Experiment</li><li>nnictl experiment show<br>显示Experiment的信息</li><li>nnictl experiment status<br>显示Experiment的状态</li><li>nnictl experiment list<br>显示正在运行的Experiment的信息</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-简介&quot;&gt;&lt;a href=&quot;#1-简介&quot; class=&quot;headerlink&quot; title=&quot;1. 简介&quot;&gt;&lt;/a&gt;1. 简介&lt;/h1&gt;&lt;p&gt;NN是微软官方出的一个自动调参的第三方库。非常好用。但是用起来还是有一些需要注意的地方。这里记录一下。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="工具" scheme="http://yoursite.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="Docker" scheme="http://yoursite.com/tags/Docker/"/>
    
      <category term="nni" scheme="http://yoursite.com/tags/nni/"/>
    
      <category term="调参工具" scheme="http://yoursite.com/tags/%E8%B0%83%E5%8F%82%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/11/08/Deep-Learning-for-Spatio-Temporal-Data-Mining-A-Survey/"/>
    <id>http://yoursite.com/2019/11/08/Deep-Learning-for-Spatio-Temporal-Data-Mining-A-Survey/</id>
    <published>2019-11-08T07:49:37.713Z</published>
    <updated>2020-01-22T13:23:37.769Z</updated>
    
    <content type="html"><![CDATA[<hr><p>title: ‘Deep Learning for Spatio-Temporal Data Mining: A Survey’<br>date: 2019-11-08T15:49:36.000Z<br>categories: 论文阅读笔记<br>tags:</p><ul><li>时空领域<br>comments: false</li></ul><hr><h1><span id="简介">简介</span></h1><p>&ensp;&ensp;&ensp;&ensp;<a href="https://arxiv.org/pdf/1906.04928.pdf" target="_blank" rel="noopener">论文地址</a><br>这篇论文是时空领域的综述论文，介绍了近几年时空领域的发展。<br><a id="more"></a><br>一些比较好的GitHub<br><a href="https://github.com/xuehaouwa/Awesome-Trajectory-Prediction" target="_blank" rel="noopener">https://github.com/xuehaouwa/Awesome-Trajectory-Prediction</a>   </p><h1><span id="引言">引言</span></h1><p>时空领域的数据的应用很广泛，包括环境和气候预测（风预测，降雨预测等），公共安全预测（crime预测），智能交通预测（交通流量预测），人类活动（人类轨迹模式挖掘）。本文将时空数据的类型，和广泛应用的深度学习模型，以及现有的研究进展。   </p><h1><span id="时空数据分类">时空数据分类</span></h1><ol><li>Even data<br>事件数据由离散的事件组成，有location和time信息，例如cirme事件和traffic accident事件，疾病爆发事件，社会事件。 </li><li>Trajectory data<br>轨迹数据是一系列随着时间变化的经纬度序列组成。有人的轨迹和车的轨迹。  </li><li>Point reference data<br>一般都是气象数据，测量一个区域的温度，植被等。  </li><li>Raster data（栅格数据）<br>有固定的m个区域，每个区域有n个时间段，可以用一个$R^{m \times n}$来表示。例如traffic flow数据。</li><li>Vedio data<br>视频数据和时空数据类似，相邻的像素可以表示相似的RGB，在时间上，特征变化平缓。可以用三维张量表示。  </li></ol><p>以上的5类数据可以用下图的方式表示。</p><p><img src="/2019/11/08/Deep-Learning-for-Spatio-Temporal-Data-Mining-A-Survey/stdata.png" alt=""><br>(1)轨迹和时间序列都可以表示成序列的形式。<br>(2)有时轨迹也可以表示成2维矩阵，矩阵的行和列是网格的长和宽，矩阵的值表示轨迹走的网格。这个表示形式通常使用CNN模型。例如：<a href="https://arxiv.org/pdf/1705.09436.pdf" target="_blank" rel="noopener">（2017NIPS）Human Trajectory Prediction using Spatially aware Deep Attention Models</a><br>(3)空间地图可以表示为Graph和2维矩阵。至于使用图还是2D矩阵根据应用而定。例如在城市交通流预测，交通网络中的交通数据使用Graph表示，例如<a href="https://arxiv.org/pdf/1707.01926.pdf" target="_blank" rel="noopener">(2018ICLR)Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting</a><br>(4)网格数据，通常使用2D或3D张量表示，如果是2D矩阵，行和列分别表示区域和时间。如果是3D张量，分别表示区域的行和列，时间。<br><img src="/2019/11/08/Deep-Learning-for-Spatio-Temporal-Data-Mining-A-Survey/model.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;title: ‘Deep Learning for Spatio-Temporal Data Mining: A Survey’&lt;br&gt;date: 2019-11-08T15:49:36.000Z&lt;br&gt;categories: 论文阅读笔记&lt;br&gt;tags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;时空领域&lt;br&gt;comments: false&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;&lt;a href=&quot;https://arxiv.org/pdf/1906.04928.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文地址&lt;/a&gt;&lt;br&gt;这篇论文是时空领域的综述论文，介绍了近几年时空领域的发展。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/11/05/Enhancing-the-Locality-and-Breaking-the-Memory-Bottleneck-of-Transformer-on-Time-Series-Forecasting/"/>
    <id>http://yoursite.com/2019/11/05/Enhancing-the-Locality-and-Breaking-the-Memory-Bottleneck-of-Transformer-on-Time-Series-Forecasting/</id>
    <published>2019-11-05T01:34:39.486Z</published>
    <updated>2020-01-22T13:24:34.504Z</updated>
    
    <content type="html"><![CDATA[<hr><p>title: &gt;-<br>  Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on<br>  Time Series Forecasting<br>date: 2019-11-05T09:34:39.000Z<br>categories: 论文阅读笔记<br>tags:</p><ul><li>Time Series</li><li>Transformer<br>comments: false</li></ul><hr><h1><span id="简介">简介</span></h1><p>2019NIPS的一篇论文，<br><a href="https://arxiv.org/pdf/1907.00235.pdf" target="_blank" rel="noopener">论文地址</a><br><a id="more"></a>    </p><h1><span id="introduction">Introduction</span></h1><p>本文说Transformer有2个缺点，（1）locality-agnostics：局部不可知性，原先只针对一个点，计算该点和其余所有点的相关性，没有考虑到子序列和子序列的attention。（2）memory bottleneck：内存瓶颈，空间复杂度和输入序列的长度L有关。对于捕获长时间序列不方便。   </p><h1><span id="模型">模型</span></h1><p>本文针对以上2个问题，提出2种解决方案，（1）传统Transformer—&gt;Conv Transformer,（2）使用LogSparse来减少内存的使用。<br><img src="/2019/11/05/Enhancing-the-Locality-and-Breaking-the-Memory-Bottleneck-of-Transformer-on-Time-Series-Forecasting/conv.png" alt=""><br>图b是传统的Transformer，在计算Attention时，计算的是一个点和其余所有点的Attention，在本文中使用一维卷积来生成query和key，在计算Attention时，使用的是子序列之间的Attention，捕获了local上下文信息。   </p><p><img src="/2019/11/05/Enhancing-the-Locality-and-Breaking-the-Memory-Bottleneck-of-Transformer-on-Time-Series-Forecasting/log.png" alt=""><br>在传统Transformer在计算Atterntion时，使用的因果卷积，在第t步捕获前面所有历史时间步的信息，但是这样空间复杂度较大。所以本文提出了LogSparse，即在计算Attention时，对历史时间步的信息使用log函数进行抽样，然后多堆叠几层，也可以捕获前面所有时间步的信息。减少了空间复杂度，又可以捕获历史时间步的所有信息。</p>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;title: &amp;gt;-&lt;br&gt;  Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on&lt;br&gt;  Time Series Forecasting&lt;br&gt;date: 2019-11-05T09:34:39.000Z&lt;br&gt;categories: 论文阅读笔记&lt;br&gt;tags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Time Series&lt;/li&gt;
&lt;li&gt;Transformer&lt;br&gt;comments: false&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;p&gt;2019NIPS的一篇论文，&lt;br&gt;&lt;a href=&quot;https://arxiv.org/pdf/1907.00235.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文地址&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/11/04/DGL/"/>
    <id>http://yoursite.com/2019/11/04/DGL/</id>
    <published>2019-11-04T06:19:34.305Z</published>
    <updated>2020-01-22T13:24:20.129Z</updated>
    
    <content type="html"><![CDATA[<hr><p>title: DGL<br>date: 2019-11-04T14:19:34.000Z<br>categories: Deep Learning<br>tags:</p><ul><li>GCN</li><li>DGL<br>comments: false</li></ul><hr><h1><span id="1-简介">1. 简介</span></h1><p>&ensp;&ensp;&ensp;&ensp;Deep Graph Library(DGL),一款面向图神经网络以及图机器学习的全新框架。DGL基于主流框架进行开发。用户可以使用他们偏爱的框架编写常见的CNN和注意力层，而当遇到图相关的计算时可以切换到DGL。用户和DGL的交互主要通过自定义函数UDF（user-defined function）。目前DGL支持Pytorch和MXNet/Gluon作为系统后端。<br><a id="more"></a><br><!-- TOC --></p><ul><li><a href="#1-简介">1. 简介</a></li><li><a href="#2-dgl">2. DGL</a></li><li><a href="#3-函数介绍">3. 函数介绍</a><ul><li><a href="#31-创建图">3.1. 创建图</a></li><li><a href="#32-获取节点和边的个数">3.2. 获取节点和边的个数</a></li><li><a href="#33-分配节点和边的特征">3.3. 分配节点和边的特征</a></li><li><a href="#34-删除节点和边特征">3.4. 删除节点和边特征</a></li><li><a href="#35-自定义message函数">3.5. 自定义message函数</a></li><li><a href="#36-自定义reduce函数">3.6. 自定义reduce函数</a></li><li><a href="#37-注册message和reduce函数">3.7. 注册message和reduce函数</a></li><li><a href="#38-update_all更新节点特征">3.8. update_all更新节点特征</a></li><li><a href="#39-高级用法">3.9. 高级用法</a></li></ul></li></ul><!-- /TOC --><p><a href="https://archwalker.github.io/blog/2019/07/07/GNN-Framework-DGL-GCN.html" target="_blank" rel="noopener">GNN 教程：DGL框架-消息和GCN的实现</a>     </p><h1><span id="2-dgl">2. DGL</span></h1><p>DGL是基于<strong>消息传递message passing</strong>的编程模型。原因在于图上的计算往往可以表示为2步：</p><ol><li>发送节点：根据自身的特征计算需要向外分发的消息。</li><li>接收节点：对收到的消息进行累加并更新自身的特征。<br>用户需要自定义<strong>消息分发函数</strong>和<strong>消息聚合函数</strong>，来构造新的模型。  </li></ol><ul><li>消息分发函数（message function）：将结点自身的消息传递传递给其邻居。因为对每条边来说，每个源节点将会将自身的Embedding(e.src.data)和边的Embedding(edge.data)传递给目的节点。对于每个目的节点来说，它可能会收到多个源节点传过来的消息，它会将这些消息存储在mailbox中。</li><li>消息聚合函数（reduce function）：聚合函数的目的是根据邻居传过来的消息更新自身节点Embedding，对每个节点来说，它先从邮箱(v.mailbox[‘m’])中汇聚消息函数所传递过来的消息(message)，并清空邮箱(v.mailbox[‘m’])内的消息；然后该节点结合汇聚后的结果和该节点原Embedding，更新节点Embedding。<br><img src="/2019/11/04/DGL/dgl.png" alt=""><br>GCN的公式如下所示：<br><img src="/2019/11/04/DGL/gcn.png" alt=""><br>上面的数学描述可以利用<strong>消息传递</strong>的机制实现：<br>（1）在GCN中，每个节点都有属于自己的表示$h_i$<br>（2）根据消息传递（message passing），每个节点将会收到邻居节点发来的Embedding<br>（3）每个节点将聚合邻居节点的Embedding，得到中间表示$\hat{h_i}$<br>（4）对中间节点表示$\hat{h_i}$进行线性变换，然后利用非线性函数$f$进行计算：$h^{new}_u = f(W_u\hat{h}_u)$<br>（5）利用新的节点表示$h^{new}_u$对该节点的表示$h_u$进行更新。</li></ul><h1><span id="3-函数介绍">3. 函数介绍</span></h1><p><a href="https://docs.dgl.ai/en/latest/api/python/graph.html" target="_blank" rel="noopener">官方文档</a><br><a href="https://docs.dgl.ai/en/latest/tutorials/basics/1_first.html" target="_blank" rel="noopener">实现GCN例子</a></p><h2><span id="31-创建图">3.1. 创建图</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line">g = dgl.DGLGraph()</span><br><span class="line"><span class="comment">#为图添加节点和边</span></span><br><span class="line">g.add_node(<span class="number">34</span>)<span class="comment">#添加34个节点</span></span><br><span class="line"><span class="comment">#一共有78条边</span></span><br><span class="line">edge_list = [(<span class="number">1</span>, <span class="number">0</span>), (<span class="number">2</span>, <span class="number">0</span>), (<span class="number">2</span>, <span class="number">1</span>), (<span class="number">3</span>, <span class="number">0</span>), (<span class="number">3</span>, <span class="number">1</span>), (<span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">        (<span class="number">4</span>, <span class="number">0</span>), (<span class="number">5</span>, <span class="number">0</span>), (<span class="number">6</span>, <span class="number">0</span>), (<span class="number">6</span>, <span class="number">4</span>), (<span class="number">6</span>, <span class="number">5</span>), (<span class="number">7</span>, <span class="number">0</span>), (<span class="number">7</span>, <span class="number">1</span>),</span><br><span class="line">        (<span class="number">7</span>, <span class="number">2</span>), (<span class="number">7</span>, <span class="number">3</span>), (<span class="number">8</span>, <span class="number">0</span>), (<span class="number">8</span>, <span class="number">2</span>), (<span class="number">9</span>, <span class="number">2</span>), (<span class="number">10</span>, <span class="number">0</span>), (<span class="number">10</span>, <span class="number">4</span>),</span><br><span class="line">        (<span class="number">10</span>, <span class="number">5</span>), (<span class="number">11</span>, <span class="number">0</span>), (<span class="number">12</span>, <span class="number">0</span>), (<span class="number">12</span>, <span class="number">3</span>), (<span class="number">13</span>, <span class="number">0</span>), (<span class="number">13</span>, <span class="number">1</span>), (<span class="number">13</span>, <span class="number">2</span>),</span><br><span class="line">        (<span class="number">13</span>, <span class="number">3</span>), (<span class="number">16</span>, <span class="number">5</span>), (<span class="number">16</span>, <span class="number">6</span>), (<span class="number">17</span>, <span class="number">0</span>), (<span class="number">17</span>, <span class="number">1</span>), (<span class="number">19</span>, <span class="number">0</span>), (<span class="number">19</span>, <span class="number">1</span>),</span><br><span class="line">        (<span class="number">21</span>, <span class="number">0</span>), (<span class="number">21</span>, <span class="number">1</span>), (<span class="number">25</span>, <span class="number">23</span>), (<span class="number">25</span>, <span class="number">24</span>), (<span class="number">27</span>, <span class="number">2</span>), (<span class="number">27</span>, <span class="number">23</span>),</span><br><span class="line">        (<span class="number">27</span>, <span class="number">24</span>), (<span class="number">28</span>, <span class="number">2</span>), (<span class="number">29</span>, <span class="number">23</span>), (<span class="number">29</span>, <span class="number">26</span>), (<span class="number">30</span>, <span class="number">1</span>), (<span class="number">30</span>, <span class="number">8</span>),</span><br><span class="line">        (<span class="number">31</span>, <span class="number">0</span>), (<span class="number">31</span>, <span class="number">24</span>), (<span class="number">31</span>, <span class="number">25</span>), (<span class="number">31</span>, <span class="number">28</span>), (<span class="number">32</span>, <span class="number">2</span>), (<span class="number">32</span>, <span class="number">8</span>),</span><br><span class="line">        (<span class="number">32</span>, <span class="number">14</span>), (<span class="number">32</span>, <span class="number">15</span>), (<span class="number">32</span>, <span class="number">18</span>), (<span class="number">32</span>, <span class="number">20</span>), (<span class="number">32</span>, <span class="number">22</span>), (<span class="number">32</span>, <span class="number">23</span>),</span><br><span class="line">        (<span class="number">32</span>, <span class="number">29</span>), (<span class="number">32</span>, <span class="number">30</span>), (<span class="number">32</span>, <span class="number">31</span>), (<span class="number">33</span>, <span class="number">8</span>), (<span class="number">33</span>, <span class="number">9</span>), (<span class="number">33</span>, <span class="number">13</span>),</span><br><span class="line">        (<span class="number">33</span>, <span class="number">14</span>), (<span class="number">33</span>, <span class="number">15</span>), (<span class="number">33</span>, <span class="number">18</span>), (<span class="number">33</span>, <span class="number">19</span>), (<span class="number">33</span>, <span class="number">20</span>), (<span class="number">33</span>, <span class="number">22</span>),</span><br><span class="line">        (<span class="number">33</span>, <span class="number">23</span>), (<span class="number">33</span>, <span class="number">26</span>), (<span class="number">33</span>, <span class="number">27</span>), (<span class="number">33</span>, <span class="number">28</span>), (<span class="number">33</span>, <span class="number">29</span>), (<span class="number">33</span>, <span class="number">30</span>),</span><br><span class="line">        (<span class="number">33</span>, <span class="number">31</span>), (<span class="number">33</span>, <span class="number">32</span>)]</span><br><span class="line"><span class="comment">#添加边的源节点和目的节点  </span></span><br><span class="line">drc,dst = tuple(zip(*edge_list))</span><br><span class="line">g.add_edges(src,dst)</span><br><span class="line"><span class="comment">#边是双向的</span></span><br><span class="line">g.add_edges(dst,src)</span><br><span class="line">```  </span><br><span class="line"><span class="comment">## 3.2. 获取节点和边的个数  </span></span><br><span class="line">```python</span><br><span class="line"><span class="comment">#查看节点和边个数</span></span><br><span class="line">g.number_of_nodes()</span><br><span class="line">g.number_of_edges()  </span><br><span class="line"></span><br><span class="line"><span class="comment">#查看节点和边类型</span></span><br><span class="line">g.node_attr_schemes()</span><br><span class="line"></span><br><span class="line">```   </span><br><span class="line"><span class="comment">## 3.3. 分配节点和边的特征  </span></span><br><span class="line">```python  </span><br><span class="line"><span class="keyword">import</span> torch  </span><br><span class="line"><span class="comment">#分配节点特征</span></span><br><span class="line">g.ndata[<span class="string">'feature'</span>] = torch.eye(<span class="number">34</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取某个节点的特征  </span></span><br><span class="line">G.nodes[<span class="number">2</span>].data[<span class="string">'feature'</span>]</span><br><span class="line">G.nodes[[<span class="number">10</span>,<span class="number">11</span>]].data[<span class="string">'feature'</span>]  </span><br><span class="line"></span><br><span class="line"><span class="comment">#分配边特征,9条边，每条边特征有2个</span></span><br><span class="line">g.edata[<span class="string">'edge_feature'</span>] = torch.randn(<span class="number">9</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#单独为每条边赋值</span></span><br><span class="line">g.edata[<span class="number">1</span>].data[<span class="string">'edge_feature'</span>] = torch.randn(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">g.edata[[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]].data[<span class="string">'edge_feature'</span>] = torch.randn(<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line"><span class="comment">#同时指定起点和终点</span></span><br><span class="line">g.edata[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]].data[<span class="string">'edge_feature'</span>] = torch.randn(<span class="number">3</span>,<span class="number">2</span>)  </span><br><span class="line"></span><br><span class="line"><span class="comment">#查看图的节点特征和边特征</span></span><br><span class="line">g.ndata,g.edata</span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 3.4. 删除节点和边特征 </span></span><br><span class="line">```python</span><br><span class="line">g.ndata.pop(<span class="string">'feature'</span>)</span><br><span class="line">g.edata.pop(<span class="string">'edge_feature'</span>)</span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 3.5. 自定义message函数   </span></span><br><span class="line">```python </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">message_func</span><span class="params">(edges)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    在该函数中，接收一个参数edges，edges有3个成员变量：</span></span><br><span class="line"><span class="string">    edges.src:获取源节点</span></span><br><span class="line"><span class="string">    edges.dst:获取目的节点</span></span><br><span class="line"><span class="string">    edges.data:获取边</span></span><br><span class="line"><span class="string">    主要是向目的节点传递消息，返回的格式是dict</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> &#123; <span class="string">'alpha'</span>: alpha, <span class="string">'state'</span>: edge.src[<span class="string">'state'</span>] &#125;</span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 3.6. 自定义reduce函数  </span></span><br><span class="line">```python</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduce_func</span><span class="params">(nodes)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    源节点通过message函数，将消息发送给目的节点，目的节点接收多个邻居发来的消息，并存储在mailbox中，reduce函数聚合多个邻居发来的消息,并以dict的形式返回。</span></span><br><span class="line"><span class="string">    reduce函数，接收一个参数nodes，nodes有2个成员变量</span></span><br><span class="line"><span class="string">    nodes.data:获取节点的特征</span></span><br><span class="line"><span class="string">    nodes.mailbox:获取message函数返回的值</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    """</span>      </span><br><span class="line">    state = nodes.mailbox[<span class="string">'state'</span>]</span><br><span class="line">    alpha = nodes.mailbox[<span class="string">'alpha'</span>]</span><br><span class="line">    alpha = nd.softmax(alpha, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    new_state = nd.relu(nd.sum(alpha * state, axis=<span class="number">1</span>))  </span><br><span class="line">    <span class="keyword">return</span> &#123; <span class="string">'new_state'</span>: new_state &#125;</span><br><span class="line">```   </span><br><span class="line"><span class="comment">## 3.7. 注册message和reduce函数  </span></span><br><span class="line">```python    </span><br><span class="line"><span class="comment">#自定了message和reduce函数，在graph中注册，以便后续使用 </span></span><br><span class="line">g.register_message_func(message_func)</span><br><span class="line">g.register_reduce_func(reduce_func)   </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pagerank_batch</span><span class="params">(g)</span>:</span></span><br><span class="line">    g.send(g.edges())</span><br><span class="line">    g.recv(g.nodes())</span><br><span class="line"></span><br><span class="line">    <span class="comment">#如果没有将自定义的message和reduce函数注册，使用以下语句</span></span><br><span class="line">    g.send(g.edges(),message_func)</span><br><span class="line">    g.recv(g.nodes(),reduce_func)</span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 3.8. update_all更新节点特征   </span></span><br><span class="line">该方法是上面方法的高级版本</span><br><span class="line">`DGLGraph.update_all(message_func=<span class="string">'default'</span>, reduce_func=<span class="string">'default'</span>, apply_node_func=<span class="string">'default'</span>)`</span><br><span class="line">传入的参数是message函数名，reduce函数名，UDF函数名,如果不传入，使用默认值。</span><br><span class="line">```python    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pagerank_level2</span><span class="params">(g)</span>:</span></span><br><span class="line">    <span class="comment"># g.update_all() </span></span><br><span class="line">    g.update_all(self.message_func,self.reduce_func)</span><br><span class="line"></span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 3.9. 高级用法  </span></span><br><span class="line">[PageRank实现](https://docs.dgl.ai/en/latest/tutorials/basics/<span class="number">3</span>_pagerank.html)  </span><br><span class="line">- `dgl.function.copy_src(src, out)`:需要指定源节点的名称，和message的key值  </span><br><span class="line">  ```python  </span><br><span class="line">  <span class="keyword">import</span> dgl</span><br><span class="line">  message_func = dgl.function.copy_src(<span class="string">'feature'</span>, <span class="string">'state'</span>)</span><br><span class="line">  等价于  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">message_func</span><span class="params">(edges)</span>:</span></span><br><span class="line">      <span class="keyword">return</span> &#123;<span class="string">'state'</span>: edges.src[<span class="string">'feature'</span>]&#125;</span><br></pre></td></tr></table></figure><ul><li><code>dgl.function.sum(msg, out)</code>:用于对目的节点的mailbox进行求和，需要指定message的key值和输出的名称。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line">reduce_func = dgl.function.sum(<span class="string">'state'</span>, <span class="string">'new_state'</span>)</span><br><span class="line">等价于</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduce_func</span><span class="params">(nodes)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'new_state'</span>: torch.sum(nodes.mailbox[<span class="string">'state'</span>], dim=<span class="number">1</span>)&#125;</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl.function <span class="keyword">as</span> fn</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pagerank_builtin</span><span class="params">(g)</span>:</span></span><br><span class="line">    N = <span class="number">100</span>  <span class="comment"># number of nodes</span></span><br><span class="line">    DAMP = <span class="number">0.85</span>  <span class="comment"># damping factor</span></span><br><span class="line">    g.ndata[<span class="string">'pv'</span>] = g.ndata[<span class="string">'pv'</span>] / g.ndata[<span class="string">'deg'</span>]</span><br><span class="line">    g.update_all(message_func=fn.copy_src(src=<span class="string">'pv'</span>, out=<span class="string">'m'</span>,</span><br><span class="line">                reduce_func=fn.sum(msg=<span class="string">'m'</span>,out=<span class="string">'m_sum'</span>))</span><br><span class="line">    g.ndata[<span class="string">'pv'</span>] = (<span class="number">1</span> - DAMP) / N + DAMP * g.ndata[<span class="string">'m_sum'</span>]</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;title: DGL&lt;br&gt;date: 2019-11-04T14:19:34.000Z&lt;br&gt;categories: Deep Learning&lt;br&gt;tags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GCN&lt;/li&gt;
&lt;li&gt;DGL&lt;br&gt;comments: false&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&quot;1-简介&quot;&gt;&lt;a href=&quot;#1-简介&quot; class=&quot;headerlink&quot; title=&quot;1. 简介&quot;&gt;&lt;/a&gt;1. 简介&lt;/h1&gt;&lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;Deep Graph Library(DGL),一款面向图神经网络以及图机器学习的全新框架。DGL基于主流框架进行开发。用户可以使用他们偏爱的框架编写常见的CNN和注意力层，而当遇到图相关的计算时可以切换到DGL。用户和DGL的交互主要通过自定义函数UDF（user-defined function）。目前DGL支持Pytorch和MXNet/Gluon作为系统后端。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/11/02/XGBoost/"/>
    <id>http://yoursite.com/2019/11/02/XGBoost/</id>
    <published>2019-11-02T07:28:18.659Z</published>
    <updated>2020-01-22T13:28:23.574Z</updated>
    
    <content type="html"><![CDATA[<hr><p>title: XGBoost<br>date: 2019-11-02T15:28:18.000Z<br>categories: Machine Learning<br>tags:</p><ul><li>XGBoost</li><li>分类任务<br>comments: false</li></ul><hr><h1><span id="1-简介">1. 简介</span></h1><p>&ensp;&ensp;&ensp;&ensp;最近使用XGBoost做一个二分类的任务。记录XGBoost的主要参数和调参过程。<br><a id="more"></a>   </p><!-- TOC --><ul><li><a href="#1-%e7%ae%80%e4%bb%8b">1. 简介</a></li><li><a href="#2-xgboost">2. XGBoost</a><ul><li><a href="#21-xgboost%e7%9a%84%e4%bc%98%e5%8a%bf">2.1. XGBoost的优势</a></li><li><a href="#22-%e5%8f%82%e6%95%b0">2.2. 参数</a></li><li><a href="#23-%e8%b0%83%e5%8f%82">2.3. 调参</a></li></ul></li></ul><!-- /TOC --><h1><span id="2-xgboost">2. XGBoost</span></h1><p>&ensp;&ensp;&ensp;&ensp;XGBoost是一种十分精致的算法，可以处理各种不规则的数据。<br>构造一个使用XGBoost的模型十分简单。但是，提高这个模型的表现就有些困难，因为涉及到很多参数。所以为了提高模型的表现，参数的调整十分必要。</p><h2><span id="21-xgboost的优势">2.1. XGBoost的优势</span></h2><ul><li>正则化<br>正则化防止过拟合，实际上，XGBoost以“正则化提升(regularized boosting)”技术而闻名。</li><li>缺失值处理<br>XGBoost内置处理缺失值的规则。XGBoost在不同节点遇到缺失值时采用不同的处理方法，并且会学习未来遇到缺失值的处理方法。<h2><span id="22-参数">2.2. 参数</span></h2></li></ul><p>&ensp;&ensp;&ensp;&ensp;XGBoost实际上是很多CART树堆叠起来。传入的特征可以含有None值。XGBoost有很多参数，使用GridSearchCV进行网格搜索时比较耗时。  </p><p>使用pip install xgboost安装<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">XGBClassifier(</span><br><span class="line">        base_score=<span class="number">0.5</span>, </span><br><span class="line">        booster=<span class="string">'gbtree'</span>, </span><br><span class="line">        colsample_bylevel=<span class="number">1</span>,</span><br><span class="line">        colsample_bytree=<span class="number">1</span>, </span><br><span class="line">        gamma=<span class="number">0</span>, </span><br><span class="line">        learning_rate=<span class="number">1</span>, </span><br><span class="line">        max_delta_step=<span class="number">0</span>,</span><br><span class="line">        max_depth=<span class="number">2</span>, </span><br><span class="line">        min_child_weight=<span class="number">1</span>, </span><br><span class="line">        missing=<span class="keyword">None</span>, </span><br><span class="line">        n_estimators=<span class="number">2</span>,</span><br><span class="line">        n_jobs=<span class="number">1</span>, </span><br><span class="line">        nthread=<span class="keyword">None</span>, objective=<span class="string">'binary:logistic'</span>, random_state=<span class="number">0</span>,</span><br><span class="line">        reg_alpha=<span class="number">0</span>, </span><br><span class="line">        reg_lambda=<span class="number">1</span>, </span><br><span class="line">        scale_pos_weight=<span class="number">1</span>, </span><br><span class="line">        seed=<span class="keyword">None</span>,</span><br><span class="line">        silent=<span class="keyword">True</span>, </span><br><span class="line">        subsample=<span class="number">1</span>)</span><br></pre></td></tr></table></figure></p><p>XGBoost参数有3类：<br><a href="https://www.cnblogs.com/wanglei5205/p/8579244.html" target="_blank" rel="noopener">https://www.cnblogs.com/wanglei5205/p/8579244.html</a><br>（1）通用类别：不需要调整，默认就好：</p><ul><li>booster：[默认gbtree]<br>选择每次迭代的模型，有两种选择：<br>gbtree：基于树的模型<br>gbliner：线性模型</li><li>silent[默认0]<br>当这个参数值为1时，静默模式开启，不会输出任何信息。<br>一般这个参数就保持默认的0，因为这样能帮我们更好地理解模型。</li><li>nthread[默认值为最大可能的线程数]<br>这个参数用来进行多线程控制，应当输入系统的核数。<br>如果你希望使用CPU全部的核，那就不要输入这个参数，算法会自动检测它。</li></ul><p>（2）学习目标参数：与任务有关</p><ul><li>objective:损失函数，支持分类/回归<br>[默认reg:linear]，这个参数定义需要被最小化的损失函数。最常用的值有：<br>binary:logistic 二分类的逻辑回归，返回预测的概率(不是类别)。<br>multi:softmax 使用softmax的多分类器，返回预测的类别(不是概率)。<br>在这种情况下，你还需要多设一个参数：num_class(类别数目)。<br>multi:softprob 和multi:softmax参数一样，但是返回的是每个数据属于各个类别的概率。</li><li><p>eval_metric：评价函数，对于回归问题，默认值是rmse，对于分类问题，默认值是error。<br>典型值有：<br>rmse 均方根误差<br>logloss 负对数似然函数值<br>error 二分类错误率(阈值为0.5)<br>merror 多分类错误率<br>mlogloss 多分类logloss损失函数<br>auc 曲线下面积</p></li><li><p>seed：随机数的种子，默认为0<br>设置它可以复现随机数据的结果，也可以用于调整参数</p></li></ul><p>（3）booster参数：弱学习器参数，需要仔细调整，会影响模型性能<br>学习率和n_estimators具有相反的关系，建议学习率设小，通过交叉验证确定n_estimators</p><ul><li>eta[默认0.3]，和GBM中的 learning rate 参数类似。 通过减少每一步的权重，可以提高模型的鲁棒性。 典型值为0.01-0.2。     </li></ul><p><strong>和树有关的参数</strong></p><ul><li>min_child_weight[默认1]，最小样本权重的和，用于避免过拟合。但是如果这个值过高，会导致欠拟合。这个参数需要使用CV来调整。</li><li>max_depth[默认6]，树的最大深度。 用来避免过拟合的。max_depth越大，模型越复杂，学到更具体更局部的样本。 需要使用CV函数来进行调优。 典型值：3-10      </li><li>gamma[默认0]，Gamma指定了节点分裂所需的最小损失函数下降值。这个参数的值越大，算法越保守。这个参数的值和损失函数息息相关，所以是需要调整的。   </li><li>subsample[默认1]<br>和GBM中的subsample参数一模一样。这个参数控制对于每棵树，随机采样的比例。减小这个参数的值，算法会更加保守，避免过拟合。但是，如果这个值设置得过小，它可能会导致欠拟合。<br>典型值：0.5-1  </li><li>colsample_bytree[默认1]<br>和GBM里面的max_features参数类似。用来控制每棵随机采样的列数的占比(每一列是一个特征)。<br>典型值：0.5-1  </li></ul><p><strong>和正则化有关的参数</strong></p><ul><li>lambda[默认1]<br>权重的L2正则化项。(和Ridge regression类似)。<br>这个参数是用来控制XGBoost的正则化部分的。虽然大部分数据科学家很少用到这个参数，但是这个参数在减少过拟合上还是可以挖掘出更多用处的。  </li><li>alpha[默认1]<br>权重的L1正则化项。(和Lasso regression类似)。<br>可以应用在很高维度的情况下，使得算法的速度更快。<br><strong>样本不均衡</strong> </li><li>scale_pos_weight[默认1]<br>正样本占的比重，为1时表示正负样例比重是一样的。当正样本较少时，正样本:负样本=1:9，将scale_pos_weight设置为9，scale_pos_weight=负样本个数/正样本个数。在各类别样本十分不平衡时，把这个参数设定为一个正值，可以使算法更快收敛。   <h2><span id="23-调参">2.3. 调参</span></h2></li></ul><ol><li><p>先给定一个较高的学习率(learning rate)，一般情况下，学习率为0.1，但是对于不同的问题，理想的学习率在0.05~0.3之间波动。先调节决策树的数量n_estimators</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display</span><br><span class="line"></span><br><span class="line">cv_params = &#123;<span class="string">'n_estimators'</span>: [<span class="number">20</span>,<span class="number">40</span>, <span class="number">60</span>, <span class="number">80</span>]&#125;</span><br><span class="line">other_params = &#123;<span class="string">'learning_rate'</span>: <span class="number">0.1</span>, <span class="string">'n_estimators'</span>: <span class="number">500</span>, <span class="string">'max_depth'</span>: <span class="number">5</span>, <span class="string">'min_child_weight'</span>: <span class="number">1</span>, </span><br><span class="line">                <span class="string">'seed'</span>: <span class="number">0</span>,<span class="string">'subsample'</span>: <span class="number">0.8</span>, <span class="string">'colsample_bytree'</span>: <span class="number">0.8</span>, <span class="string">'gamma'</span>: <span class="number">0</span>, <span class="string">'reg_alpha'</span>: <span class="number">0</span>,</span><br><span class="line">                <span class="string">'reg_lambda'</span>: <span class="number">1</span>,<span class="string">'scale_pos_weight'</span>:<span class="number">1</span>,<span class="string">'objective'</span>:<span class="string">'binary:logistic'</span>&#125;</span><br><span class="line">model = XGBClassifier(**other_params)</span><br><span class="line">optimized_GBM = GridSearchCV(estimator=model, param_grid=cv_params, scoring=<span class="string">'accuracy'</span>, cv=<span class="number">5</span>,verbose=<span class="number">1</span>, n_jobs=<span class="number">4</span>)</span><br><span class="line">optimized_GBM.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'参数的最佳取值：&#123;0&#125;'</span>.format(optimized_GBM.best_params_))</span><br><span class="line">print(<span class="string">'最佳模型得分:&#123;0&#125;'</span>.format(optimized_GBM.best_score_))</span><br><span class="line">display(pd.DataFrame(optimized_GBM.cv_results_).T)</span><br></pre></td></tr></table></figure></li><li><p>在给定的learning rate和n_eatimators情况下，对决策树特定参数调优(max_depth,min_child_weight,gamma,subsample,colsample_bytree) </p></li><li><p>max_depth和min_child_weight参数调优</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cv_params = &#123;<span class="string">'max_depth'</span>: list(range(<span class="number">3</span>,<span class="number">10</span>,<span class="number">2</span>)), <span class="string">'min_child_weight'</span>: list(range(<span class="number">1</span>,<span class="number">7</span>,<span class="number">1</span>))&#125;</span><br><span class="line">other_params = &#123;<span class="string">'learning_rate'</span>: <span class="number">0.1</span>, <span class="string">'n_estimators'</span>: <span class="number">60</span>, <span class="string">'max_depth'</span>: <span class="number">5</span>, <span class="string">'min_child_weight'</span>: <span class="number">1</span>, </span><br><span class="line">                <span class="string">'seed'</span>: <span class="number">0</span>,<span class="string">'subsample'</span>: <span class="number">0.8</span>, <span class="string">'colsample_bytree'</span>: <span class="number">0.8</span>, <span class="string">'gamma'</span>: <span class="number">0</span>, <span class="string">'reg_alpha'</span>: <span class="number">0</span>,</span><br><span class="line">                <span class="string">'reg_lambda'</span>: <span class="number">1</span>,<span class="string">'scale_pos_weight'</span>:<span class="number">1</span>,<span class="string">'objective'</span>:<span class="string">'binary:logistic'</span>&#125;</span><br><span class="line">```   </span><br><span class="line"><span class="number">4.</span> gamma参数调优   </span><br><span class="line">Gamma参数取值范围可以很大，我这里把取值范围设置为<span class="number">5</span>了。你其实也可以取更精确的gamma值。  </span><br><span class="line">  ```python</span><br><span class="line">  cv_params = &#123;<span class="string">'gamma'</span>: [<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.5</span>, <span class="number">0.6</span>]&#125;</span><br><span class="line">  other_params = &#123;<span class="string">'learning_rate'</span>: <span class="number">0.1</span>, <span class="string">'n_estimators'</span>: <span class="number">350</span>, <span class="string">'max_depth'</span>: <span class="number">3</span>, <span class="string">'min_child_weight'</span>: <span class="number">5</span>, </span><br><span class="line">                <span class="string">'seed'</span>: <span class="number">0</span>,<span class="string">'subsample'</span>: <span class="number">0.8</span>, <span class="string">'colsample_bytree'</span>: <span class="number">0.8</span>, <span class="string">'gamma'</span>: <span class="number">0</span>, <span class="string">'reg_alpha'</span>: <span class="number">0</span>,</span><br><span class="line">                <span class="string">'reg_lambda'</span>: <span class="number">1</span>,<span class="string">'objective'</span>:<span class="string">'binary:logistic'</span>&#125;</span><br><span class="line">  ```   </span><br><span class="line"><span class="number">5.</span> subsamplehe colsample_bytree参数   </span><br><span class="line">   这链各个参数相当于每个树的样本和特征个数。</span><br><span class="line">  ```python</span><br><span class="line">   cv_params = &#123;  </span><br><span class="line">    <span class="string">'subsample'</span>: [i / <span class="number">10.0</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6</span>, <span class="number">10</span>)],  </span><br><span class="line">    <span class="string">'colsample_bytree'</span>: [i / <span class="number">10.0</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6</span>, <span class="number">10</span>)]  </span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></li><li><p>正则化参数调优<br>下一步应用正则化来降低过拟合。  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv_params = &#123;<span class="string">'reg_alpha'</span>: [<span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], <span class="string">'reg_lambda'</span>: [<span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]&#125;</span><br></pre></td></tr></table></figure></li><li><p>学习率调优<br>最后使用较低的学习率</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;title: XGBoost&lt;br&gt;date: 2019-11-02T15:28:18.000Z&lt;br&gt;categories: Machine Learning&lt;br&gt;tags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;XGBoost&lt;/li&gt;
&lt;li&gt;分类任务&lt;br&gt;comments: false&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&quot;1-简介&quot;&gt;&lt;a href=&quot;#1-简介&quot; class=&quot;headerlink&quot; title=&quot;1. 简介&quot;&gt;&lt;/a&gt;1. 简介&lt;/h1&gt;&lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;最近使用XGBoost做一个二分类的任务。记录XGBoost的主要参数和调参过程。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/11/02/Transformer/"/>
    <id>http://yoursite.com/2019/11/02/Transformer/</id>
    <published>2019-11-02T07:09:45.691Z</published>
    <updated>2020-01-22T13:28:16.673Z</updated>
    
    <content type="html"><![CDATA[<hr><p>title: Transformer<br>date: 2019-11-02T15:09:45.000Z<br>categories: 论文阅读笔记<br>tags:</p><ul><li>Transformer</li><li>NLP<br>comments: false</li></ul><hr><h1><span id="1-简介">1. 简介</span></h1><p>&ensp;&ensp;&ensp;&ensp;《Attention is all you need》是Google Brain在2017年发表在NIPS的一篇文章。虽然在这篇文章之前，也在用Attention，但在这篇文章中，正式提出了Attention的概念，从此Attention在各个领域得到了广泛的应用。<br><a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank" rel="noopener">论文地址</a><br><a id="more"></a><br><!-- TOC --></p><ul><li><a href="#1-%e7%ae%80%e4%bb%8b">1. 简介</a></li><li><a href="#2-transformer%e8%ae%b2%e8%a7%a31">2. Transformer讲解1</a><ul><li><a href="#21-%e4%bd%8d%e7%bd%ae%e5%b5%8c%e5%85%a5">2.1. 位置嵌入</a></li><li><a href="#22-self-attention">2.2. self-attention</a></li><li><a href="#23-%e6%ae%8b%e5%b7%ae%e8%bf%9e%e6%8e%a5%e5%92%8clayernorm">2.3. 残差连接和LayerNorm</a></li><li><a href="#24-transformer%e7%9a%84%e6%95%b4%e4%bd%93%e7%bb%93%e6%9e%84">2.4. transformer的整体结构</a></li></ul></li><li><a href="#3-tramsformer%e8%ae%b2%e8%a7%a32">3. Tramsformer讲解2</a><ul><li><a href="#31-multi-head">3.1. multi-head</a></li></ul></li></ul><!-- /TOC --><p><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650411699&amp;idx=3&amp;sn=83286bfa620ebe7297759fb78c31286c&amp;chksm=becd94e989ba1dff4f933b69d5c74b6cc5c41026e3bed6e5067361a91863b7b6169335ff3326&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">参考资料</a></p><h1><span id="2-transformer讲解1">2. Transformer讲解1</span></h1><p><a href="https://spaces.ac.cn/archives/4765" target="_blank" rel="noopener">Attention is All You Need浅读（简介+代码）</a><br><a href="https://github.com/aespresso/a_journey_into_math_of_ml/blob/master/03_transformer_tutorial_1st_part/transformer_1.ipynb" target="_blank" rel="noopener">transformer教程</a><br><a href="https://www.bilibili.com/video/av58239477/" target="_blank" rel="noopener">transformer视频讲解</a><br>transformer和LSTM的最大区别是：LSTM是迭代的，是一个接一个字，当这个字过完LSTM单元，才可以进下一个字。Transformer的训练是并行的，就是所有的字是全部同时训练的，加快了训练效率。但是这样字之间的顺序是丢失的，transformer引入position embedding来捕获字与字之间的位置关系。<br>transformer的结构分为编码器和解码器：<br><img src="/2019/11/02/Transformer/transformer.png" alt=""><br>先把一个句子输入到编码器，得到一个隐藏层，把隐藏层输入到解码器，得到输出的序列。例如在机器翻译中，输入是why do you work？通过编码器得到一个隐藏层，输入到解码器中，先给解码器一个start符，开始翻译，解码器输出翻译的第一个字‘为’，将‘为’输入到解码器中，输出‘什’，然后再输入到解码器中，直到解码器输出‘结束符’停止。<br><img src="/2019/11/02/Transformer/transformer1.png" alt=""><br>Transformer的编码器分为4部分，分别是：</p><ol><li>位置嵌入</li><li>多头注意力机制</li><li>残差</li><li>Positionwise FFN   </li></ol><p><img src="/2019/11/02/Transformer/transformer-all1.png" alt=""></p><h2><span id="21-位置嵌入">2.1. 位置嵌入</span></h2><p><img src="/2019/11/02/Transformer/PE.png" alt=""><br>其中</p><p> $pos$：字在句子中的位置，比如一句话有10个字，pos从0~9<br>$i$：embedding dimension的维度，比如一个字的字向量有256维，则$i$的取值为0~255。<br>$d_{model}$：总共字向量的维度，即256.<br>如果一句话中有10个字，pos从0至9，一个字向量维度是256，从0~255.则<br>第0个字的position embedding为$PE_{(0,0)},PE_{(0,1)},…,PE_{(0,254)},PE_{(0,255)}$.如果字向量维度的下标是偶数使用$sin$，为奇数使用$cos$。使用以上公式可以区分字与字之间的位置信息。<br>在输入的时候将每个字的词嵌入和位置嵌入相加，作为总体的输入。 </p><h2><span id="22-self-attention">2.2. self-attention</span></h2><ol><li>经过Embedding-lookup查表得到字向量，和position embedding得到位置嵌入，两者相加，得到一个字的最终嵌入表示，输入的维度为<br>$X \in R^{batch_size \quad <em> \quad seq_len \quad </em> \quad embedding_dim}$,<br>比如一个batch中有32个句子，每个句子有10个单词，embedding_dim=100，则输入的维度为$X \in R^{32<em>10</em>100}$  </li><li>然后将$X_{embedding}$进行3次线性变换，$W_QX_{embedding},W_KX_{embedding},W_VX_{embedding}$得到$Q,K,V$,维度都是$R^{batch_size \quad <em> \quad seq_len \quad </em> \quad embedding_dim}$  </li><li>对$Q,K,V进行分割，即多头注意力机制，其中head的个数是一个超参数，$$注意：embedding \quad dimension必须能够整除head。$即一个矩阵变成$h$个矩阵，分割之后$Q,K,V$的维度为$[batch_size,seq_len,h,embedding_dimension/h]$,之后把$Q,K,V的seq_len,h$的维度进行转置，为了方面后面的计算，转置之后的$Q,K,V$的维度为$[batch_size,h,seq_len,embedding_dimension/h]$  </li><li>拿出一个$head$，即$Q*K^T$,得到的维度是$[batch_size,h,seq_len,seq_len]$,每个字与每个字之间的注意力，每一行表示当前这个字和所有字的关系。如果2个字之间的意思越相近，得到的注意力也越大。对每一行做softmax归一化，即每一行的和为1，得到归一化之后的注意力矩阵。</li><li>将注意力矩阵给$V$加权，即让所有字的信息融入到当前字中，得到当前字的一个加权表示。最终让每一个字都融合所有字的信息。得到的$V的维度为[batch_size,h,seq_len,embedding_dimension/h]$.</li><li>在训练的时候，通常多句话进行计算，即形成一个mini-batch。mini-batch中的句子的长度不一样，找出句子的最大长度max_seq_len，将短的句子补成和最大句子一样的长度，使用0padding。假设max_seq_len=10，一个句子的长度为7，即得到的attention矩阵，下面3行和右边3列都是0。在对attention矩阵做softmax会出问题，因为softmax计算涉及到指数计算，$e^0=1$,即经过softmax计算attention不为0，让无效的部分参与了计算。为了解决这个问题，需要用一个mask让这些无效的区域不参与计算，一般给无效的区域加一个很大的负数的偏置，$Z_illegal$表示无效的区域，加上一个很大的负数，变成负数，即通过softmax指数计算结果还是0。  </li><li>不同的head得到的结果concat起来，才能恢复到原来的维度[batch_size,seq_len,embedding_dimension]。不同的head关注的点不一样，可能有的head关注的local的关系，有的head关注的是global的关系。  </li><li>最后一步是PositionwiseFFN，其实就是2层全连接，对输出$[batch_size,seq_len,embedding_dimension]$，经过2次线性变换和一个Relu激活函数。Relu=max(0,x)<br><img src="/2019/11/02/Transformer/FFN.png" alt=""> </li></ol><p><img src="/2019/11/02/Transformer/multi.png" alt=""><br><img src="/2019/11/02/Transformer/multi1.png" alt=""><br><img src="/2019/11/02/Transformer/multi2.png" alt=""><br>Attention的总体架构如下：给出Q，求Q和所有K的attention，然后使用attention和value加权求和，得到加权的value。<br><img src="/2019/11/02/Transformer/qkv.png" alt="">  </p><h2><span id="23-残差连接和layernorm">2.3. 残差连接和LayerNorm</span></h2><p><img src="/2019/11/02/Transformer/res1.png" alt="">     </p><h2><span id="24-transformer的整体结构">2.4. transformer的整体结构</span></h2><p><img src="/2019/11/02/Transformer/transformer-all.png" alt="">   </p><h1><span id="3-tramsformer讲解2">3. Tramsformer讲解2</span></h1><p><a href="https://www.bilibili.com/video/av56239558?from=search&amp;seid=9460464372943296837" target="_blank" rel="noopener">李宏毅视频讲解</a><br>其中<br>$x1,x2,x3,x4表示4个词向量，组成一个sequence,$$每一个a分别乘上3个矩阵，得到q,k,v，然后使用每一个q对每个k做attention，$。<br><img src="/2019/11/02/Transformer/a1.png" alt=""><br>将每一个q对k做attention，然后将结果进行softmax归一化，相加为1.<br><img src="/2019/11/02/Transformer/a2.png" alt=""><br>其中得到的$\hat{a}_{1,1},…\hat{a}_{1,4}$表示每个词对词1的attention，然后将attention和v做点积，再相加得到词1新的加权词向量b1，即b1包含了所有词对词1的影响，产生b1的时候已经看到了所有的词，即global attention，再远的词都可以看到。<br><img src="/2019/11/02/Transformer/a3.png" alt=""><br>同理可以算出b2<br><img src="/2019/11/02/Transformer/a4.png" alt=""><br>即一个序列a1…a4，通过一个self-attention layer得到一个新的序列b1…b4。此时b1…b4可以并行计算。    </p><p><img src="/2019/11/02/Transformer/a5.png" alt=""><br>self-attention的输入看做矩阵$I$,经过self-attention layer变成矩阵$O$。<br><img src="/2019/11/02/Transformer/a6.png" alt="">    </p><h2><span id="31-multi-head">3.1. multi-head</span></h2><p>如果head=2，生成2个$q,k,v$，维度也是原来的一半。经过self-attention操作得到$b^{i,1}和b^{i,2}$,将$b^{i,1}和b^{i,2}进行concat，得到b^i，或者concat之后乘上矩阵W得到b^i.$  </p><p><img src="/2019/11/02/Transformer/a7.png" alt=""><br><img src="/2019/11/02/Transformer/a8.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;title: Transformer&lt;br&gt;date: 2019-11-02T15:09:45.000Z&lt;br&gt;categories: 论文阅读笔记&lt;br&gt;tags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transformer&lt;/li&gt;
&lt;li&gt;NLP&lt;br&gt;comments: false&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&quot;1-简介&quot;&gt;&lt;a href=&quot;#1-简介&quot; class=&quot;headerlink&quot; title=&quot;1. 简介&quot;&gt;&lt;/a&gt;1. 简介&lt;/h1&gt;&lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;《Attention is all you need》是Google Brain在2017年发表在NIPS的一篇文章。虽然在这篇文章之前，也在用Attention，但在这篇文章中，正式提出了Attention的概念，从此Attention在各个领域得到了广泛的应用。&lt;br&gt;&lt;a href=&quot;https://arxiv.org/pdf/1706.03762.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文地址&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/10/18/metrics/"/>
    <id>http://yoursite.com/2019/10/18/metrics/</id>
    <published>2019-10-18T02:48:03.890Z</published>
    <updated>2020-01-22T13:27:05.416Z</updated>
    
    <content type="html"><![CDATA[<hr><p>title: metrics<br>date: 2019-10-18T10:48:03.000Z<br>categories: Deep Learning<br>tags:</p><ul><li>评价指标<br>comments: false</li></ul><hr><h1><span id="1-简介">1. 简介</span></h1><p>介绍在回归问题中的主要评价指标，以及各自的特点</p><a id="more"></a>      <!-- TOC --><ul><li><a href="#1-%e7%ae%80%e4%bb%8b">1. 简介</a></li><li><a href="#2-%e9%97%ae%e9%a2%98">2. 问题</a></li><li><a href="#3-%e5%9b%9e%e5%bd%92%e9%97%ae%e9%a2%98">3. 回归问题</a><ul><li><a href="#31-mae%e5%b9%b3%e5%9d%87%e7%bb%9d%e5%af%b9%e8%af%af%e5%b7%ae">3.1. MAE(平均绝对误差)</a></li><li><a href="#32-mse%e8%af%af%e5%b7%ae%e5%b9%b3%e6%96%b9%e5%b9%b3%e5%9d%87%e5%80%bc">3.2. MSE(误差平方平均值)</a></li><li><a href="#33-rmse%e5%9d%87%e6%96%b9%e6%a0%b9%e8%af%af%e5%b7%ae">3.3. RMSE(均方根误差)</a></li><li><a href="#34-mape%e5%b9%b3%e5%9d%87%e7%bb%9d%e5%af%b9%e7%99%be%e5%88%86%e6%af%94%e8%af%af%e5%b7%ae">3.4. MAPE(平均绝对百分比误差)</a></li><li><a href="#35-%e6%80%bb%e7%bb%93">3.5. 总结</a></li></ul></li><li><a href="#4-%e5%88%86%e7%b1%bb%e9%97%ae%e9%a2%98">4. 分类问题</a><ul><li><a href="#41-micro-f1">4.1. Micro-F1</a></li><li><a href="#42-macro-f1">4.2. Macro-F1</a></li></ul></li></ul><!-- /TOC --><h1><span id="2-问题">2. 问题</span></h1><p>在回归问题中，标签y的分布不均衡，范围在[1,88]，其中70%的值都在1左右。解决的方法：从损失函数入手，设计不同的评价指标，让其更关注一些大的y值。   </p><h1><span id="3-回归问题">3. 回归问题</span></h1><p><a href="https://zhuanlan.zhihu.com/p/74627482" target="_blank" rel="noopener">Metircs参考资料</a>  </p><h2><span id="31-mae平均绝对误差">3.1. MAE(平均绝对误差)</span></h2><p><img src="/2019/10/18/metrics/mae.png" alt=""><br>绝对误差的平均值。</p><ol><li>范围在$[0,\infin]$</li><li>单看MAE并不能看出这个模型的好坏，因为不知道y的平均值。比如MAE=10,y的平均值为1000，则这个模型还不错，但是如果y的平均值为1，那这个模型就非常不好。</li><li>改进：$MAE/y_{mean}$ </li></ol><h2><span id="32-mse误差平方平均值">3.2. MSE(误差平方平均值)</span></h2><p><img src="/2019/10/18/metrics/mse.png" alt="">   </p><ol><li>范围在$[0,\infin]$,  </li><li>很多算法的loss函数都是基于MSE的，因为MSE计算速度快，比RMSE更容易操作。但是我们很少把MAE作为最终的评价指标。</li><li>更关注一些y比较大的值，但是它的代价是对异常点过于敏感。如果预测出的y很不合理，则它的误差比较大，从而对RMSE的值有很大的影响。 </li></ol><h2><span id="33-rmse均方根误差">3.3. RMSE(均方根误差)</span></h2><p><img src="/2019/10/18/metrics/rmse.png" alt=""><br>在MSE上加了根号，误差的结果和数据是一个级别，在数量级上更直观，如果RMSE=10，可以认为回归问题效果与真实结果平均相差10。</p><ol><li>范围在$[0,\infin]$   </li><li>RMSE把更大的注意力放在y更大的值上，只有更大的y值预测准确了，模型的效果才会好。</li></ol><h2><span id="34-mape平均绝对百分比误差">3.4. MAPE(平均绝对百分比误差)</span></h2><p><img src="/2019/10/18/metrics/mape.png" alt="">  </p><ol><li>范围$[0,\infin]$，当MAPE=0%表示完美模型，MAPE大于100%表示劣质模型。</li><li>当真实值有数据等于0时，存在分母为0的情况，该公式不可用</li><li>比如将y1预测为1.5，和100预测为100.5，差值是一样的，。即1的MAPE比100的MAPE大很多。以MAPE作为loss函数时，更加关注y比较小的值。</li><li><p>单看MAPE的大小是没有意义的，因为MAPE是个相对值，而不是绝对值。MAPE只能用来对不同模型同一组数据的评估。比如对于同一组数据，模型A的MAPE比模型B小，可以说明模型A比模型B好。但是如果说MAPE=10%，并不能判断这个模型好还是不好。    </p><h2><span id="35-总结">3.5. 总结</span></h2><p>综上，在选用评价指标时，需要考虑</p></li><li><p>数据中是否有0，如果有0值就不能用MPE、MAPE之类的指标；</p></li><li><p>数据的分布如何，如果是长尾分布可以选择带对数变换的指标，中位数指标比平均数指标更好；</p></li><li><p>是否存在极端值，诸如MAE、MSE、RMSE之类容易受到极端值影响的指标就不要选用；</p></li><li><p>得到的指标是否依赖于量纲(即绝对度量，而不是相对度量)，如果指标依赖量纲那么不同模型之间可能因为量纲不同而无法比较；    </p></li></ol><h1><span id="4-分类问题">4. 分类问题</span></h1><p>在二分类任务中，使用Precison，Recall和F1值来评价分类的效果。<br><img src="/2019/10/18/metrics/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/hun.png" alt=""><br><img src="/2019/10/18/metrics/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/f1.png" alt=""><br>F1是针对二分类的，对于多分类，有2个常用的指标，Marco-F1和Micro-F1.   </p><h2><span id="41-micro-f1">4.1. Micro-F1</span></h2><p><img src="/2019/10/18/metrics/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/micro.png" alt=""><br>假设对于一个多分类问题，有三个类，分别是1，2，3<br>$TP_i$表示分类$i$的TP<br>$FP_i$表示分类$i$的FP<br>$TN_i$表示分类$i$的TN<br>$FN_i$表示分类$i$的FN<br>接下来，我们来计算Micro的Precison<br><img src="/2019/10/18/metrics/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/precison-mi.png" alt=""><br>以及Micro的Recall<br><img src="/2019/10/18/metrics/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/recall-mi.png" alt=""><br>然后计算Micro-F1<br><img src="/2019/10/18/metrics/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/f1-mi.png" alt="">   </p><h2><span id="42-macro-f1">4.2. Macro-F1</span></h2><p>先计算每个类的Precison和Rcall，从而计算出每个类的F1，然后将所有类的F1值平均得到Macro-F1。<br>如果数据集中各个类的分布不均衡的话，建议使用Micro-F1。<br>Macro-F1平等的看待各个类别，它的值更容易受少类别的影响Micro则更容易受常见类别的影响。</p>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;title: metrics&lt;br&gt;date: 2019-10-18T10:48:03.000Z&lt;br&gt;categories: Deep Learning&lt;br&gt;tags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;评价指标&lt;br&gt;comments: false&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&quot;1-简介&quot;&gt;&lt;a href=&quot;#1-简介&quot; class=&quot;headerlink&quot; title=&quot;1. 简介&quot;&gt;&lt;/a&gt;1. 简介&lt;/h1&gt;&lt;p&gt;介绍在回归问题中的主要评价指标，以及各自的特点&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/09/07/keras%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    <id>http://yoursite.com/2019/09/07/keras基础知识/</id>
    <published>2019-09-07T08:21:04.092Z</published>
    <updated>2020-01-22T13:26:40.382Z</updated>
    
    <content type="html"><![CDATA[<hr><p>title: keras基础知识<br>date: 2019-09-07T16:21:04.000Z<br>categories: Deep Learning<br>tags:</p><ul><li>keras<br>comments: false</li></ul><hr><h1><span id="1-简介">1. 简介</span></h1><p>最近看到keras容易上手，封装比较好，学习一下<br><a id="more"></a>    </p><h2><span id="11-基础层的介绍">1.1. 基础层的介绍</span></h2><h3><span id="111-flatten">1.1.1. Flatten</span></h3><p>&ensp;&ensp;&ensp;&ensp;Flatten用来将输入“压平”，把多维的输入变成一维。常用在从卷积层到全连接层的过渡，特征全都变成1维就可以输入到全连接层中。Flatten不影响batch的大小。<br>通过<code>keras.layers.Flatten</code>来引入。<br>比如通过卷积层的输出形状为(batch_size,output_channel,width,height),例如(16,64,32,32),通过<code>Flatten</code>层之后变换成(16,64<em>32\</em>32)=(16,65536)，不改变batch_size的大小。</p><h3><span id="112-dense">1.1.2. Dense</span></h3><p>Dense全连接层。<br>如果Dense是在第一层的话，需要指定output_dim和input_dim，即<code>Dense(output_dim=64,input_dim=44)</code>。在Dense中的API中，看到其实没有input_dim或者input_shape这个参数，查看源码看到，input_dim和input_shape是在<strong>kwargs中，因为并不是所有的Dense层都需要传入输入的形状，只有第一层需要。可以输入<code>input_dim=44</code>,也可以是<code>input_shape=(44,)</code>。一般都是用input_shape     </strong>注意：在input_shape中不包含batch的大小**<br><img src="/2019/09/07/keras基础知识/dense.png" alt=""><br>如果Dense不是在第一层，则只需要指定output_dim，而input_dim则默认为上一层的输出维度。即<code>Dense(output_dim=64)</code><br>如果需要激活函数，则需要再指定激活函数，例如<br><code>Dense(64,avtivation=&#39;relu&#39;)</code></p><h3><span id="113-embedding">1.1.3. Embedding</span></h3><p>Embedding只能作为模型的第一层。基本上用户自然语言处理方面，用来做词嵌入。</p><h3><span id="114-lstm">1.1.4. LSTM</span></h3><p>LSTM传入的参数<br><code>LSTM(batch_input_dim=(batch_size,time_steps,input_size),output_dim=cell_size,return_sequences=True,stateful=True)</code><br>其中LSTM的input_dim是(batch_size，时间步的个数，每个时间步的特征个数)<br>output_dim是LSTM中隐藏层单元的个数<br>return_sequences默认是False，表示一个时间步长为T的序列，只在最后一个时间步输出一个结果，True表示每个时间步都输出一个结果，保留起来。<br>stateful默认是False，表示这个batch与batch之间是不是有联系的，表示这个batch和下一个batch的状态是不是要连起来。 </p><h3><span id="115-merge层">1.1.5. Merge层</span></h3><p>Merge层提供了用于融合<strong>两个层或两个张量</strong>的方法，如果方法以大写字母开头，例如<code>Add()</code>表示融合两个层，如果以小写字母开头，例如<code>add()</code>表示融合两个张量。<br>通过以下来调用<br><code>keras.layers.Add()或keras.layers.add()</code><br>例如<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"></span><br><span class="line">input1 = keras.layers.Input(shape=(<span class="number">16</span>,))</span><br><span class="line">x1 = keras.layers.Dense(<span class="number">8</span>, activation=<span class="string">'relu'</span>)(input1)</span><br><span class="line">input2 = keras.layers.Input(shape=(<span class="number">32</span>,))</span><br><span class="line">x2 = keras.layers.Dense(<span class="number">8</span>, activation=<span class="string">'relu'</span>)(input2)  </span><br><span class="line"><span class="comment"># 相当于added = keras.layers.add([x1, x2])</span></span><br><span class="line">added = keras.layers.Add()([x1, x2])  </span><br><span class="line"></span><br><span class="line">out = keras.layers.Dense(<span class="number">4</span>)(added)</span><br><span class="line">model = keras.models.Model(inputs=[input1, input2], outputs=out)</span><br></pre></td></tr></table></figure></p><h2><span id="12-训练">1.2. 训练</span></h2><pre><code class="lang-python">model = Sequential()model.add()....model.compile(optimizer=&#39;adam&#39;,loss=&#39;mean_squared_error&#39;,metric=[&#39;mse&#39;])model.fit(train_x,train_y,epochs=1000,batch_size=32)#对测试集进行验证loss或metricmodel.evaluate(test_x,test_y,batch_size=16)#对测试集输出预测的结果。model.predict(test_x)</code></pre><p>在训练的时候，有以下3种方法：fit，train_on_batch,fit_gen   </p><ol><li>fit()<br>当使用fit()函数时，首先要保证2个条件：（1）训练数据可以完成的放在内存中，（2）数据已经不需要再做任何处理了，可以直接训练。</li><li>train_on_batch()<br>train_on_batch()函数接收一个batch的输入和标签，然后反向传播，更新参数。大部分情况下都不需要用到train_on_batch()，例如<code>cost = train_on_batch(train_x,train_y)</code>,返回值是误差  </li></ol><h2><span id="13-模型构建">1.3. 模型构建</span></h2><p>在keras中，一些简单的组件可以直接使用def来实现，在这个输入是input，直接使用某些层，得到输出,不使用model。<br>在实现整个模型的框架时，使用<code>model = Model(input=input,output=output)</code>,然后<code>return model</code><br>对于有些层，这个层在<code>keras.layers</code>中没有，这时候就需要自己定义一个层，这个层中的参数需要自己定义。自定义层中的参数也是需要学习的。</p><h2><span id="14-callbacks">1.4. Callbacks</span></h2><p>传入fit()函数中的callbacks必须是一个list，里面是一个或多个callback实例。</p><h3><span id="141-modelcheckpoint">1.4.1. ModelCheckpoint</span></h3><p>回调函数<code>Callbacks</code>是一组在<strong>训练阶段</strong>被调用的函数集，使用回调函数来查看训练过程中网络内部的状态和统计信息。在模型上调用<code>fit()</code>函数时，可以将<code>ModelCheckpoint</code>传递给训练过程。<br>训练深度学习模型时，<code>Checkpoint</code>是模型的权重。<code>ModelCheckpoint</code>回调类运行定义检查模型权重的位置，文件应如何命名，  </p><h3><span id="142-earlystopping">1.4.2. EarlyStopping</span></h3><p>EarlyStopping是Callbacks的一种，用于提前停止训练。停止训练的标准是当val_loss或者val_root_mean_square_error不再减少，或者val_acc不在增加。我们在训练模型时，主要目的是获得最好的泛化性能。模型的泛化能力通常使用验证集来评估。模型在训练的时候，模型在训练集上loss一直在变小，但是在验证集上的loss却是先变小后变大。说明出现了过拟合。解决过拟合的方法有2种方法：权重衰减和早停法。早停法就是模型在验证集上的表现开始下降时，停止训练。这样就可以避免过拟合的问题。</p>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;title: keras基础知识&lt;br&gt;date: 2019-09-07T16:21:04.000Z&lt;br&gt;categories: Deep Learning&lt;br&gt;tags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;keras&lt;br&gt;comments: false&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&quot;1-简介&quot;&gt;&lt;a href=&quot;#1-简介&quot; class=&quot;headerlink&quot; title=&quot;1. 简介&quot;&gt;&lt;/a&gt;1. 简介&lt;/h1&gt;&lt;p&gt;最近看到keras容易上手，封装比较好，学习一下&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/08/21/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    <id>http://yoursite.com/2019/08/21/正则表达式/</id>
    <published>2019-08-21T11:35:25.359Z</published>
    <updated>2020-01-22T13:23:11.842Z</updated>
    
    <content type="html"><![CDATA[<hr><p>title: 正则表达式<br>date: 2019-08-21T19:35:25.000Z<br>categories: Java<br>tags:</p><ul><li>正则表达式<br>comments: false</li></ul><hr><p>&ensp;&ensp;&ensp;&ensp;最近项目中需要用到正则表达式对文件名进行匹配。在上传文件时，如果文件名中含有连续的相同字母或数字，则不允许上传。并且文件名中必须含有设备型号。<br><a id="more"></a><br>正则表达式描述了字符串的匹配模型。</p><ul><li>+：表示前面的字符必须出现至少一次（1次或多次）<br>eg：runoo+b可以匹配runoob、runooob、runoooob</li><li><em>：表示前面的字符可以不出现，也可以出现一次或多次（0次，1次或多次）<br>eg：runoo\</em>b可以匹配runob、runoob、runooob</li><li>？：表示前面的字符出现0次或1次。<br>eg：do(es)?可以匹配”do”或”does”<br>eg：colou?r 可以匹配 color 或者 colour</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;title: 正则表达式&lt;br&gt;date: 2019-08-21T19:35:25.000Z&lt;br&gt;categories: Java&lt;br&gt;tags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;正则表达式&lt;br&gt;comments: false&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;最近项目中需要用到正则表达式对文件名进行匹配。在上传文件时，如果文件名中含有连续的相同字母或数字，则不允许上传。并且文件名中必须含有设备型号。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/08/02/%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/"/>
    <id>http://yoursite.com/2019/08/02/论文总结/</id>
    <published>2019-08-02T02:52:51.522Z</published>
    <updated>2020-01-22T13:22:41.191Z</updated>
    
    <content type="html"><![CDATA[<hr><p>title: 论文总结<br>date: 2019-08-02T10:52:51.000Z<br>categories: 论文阅读笔记<br>tags:</p><ul><li>时空领域</li><li>GCN</li><li>Flow<br>comments: false</li></ul><hr><h1><span id="1-简介">1. 简介</span></h1><p>&ensp;&ensp;&ensp;&ensp;这学期看了很多论文，下面把看过的论文总结一下。<br><a id="more"></a><br><!-- TOC --></p><ul><li><a href="#1-简介">1. 简介</a></li><li><a href="#2-总结">2. 总结</a></li><li><a href="#3-poi推荐">3. POI推荐</a><ul><li><a href="#31-point-of-interest-recommendation-exploiting-self-attentive-autoencoders-with-neighbor-aware-influence---cikm2018">3.1. Point-of-Interest Recommendation Exploiting Self-Attentive Autoencoders with Neighbor-Aware Influence   (CIKM2018)</a></li><li><a href="#32-hst-lstm-a-hierarchical-spatial-temporal-long-short-term-memory-network-for-location-prediction2018ijcai">3.2. HST-LSTM: A Hierarchical Spatial-Temporal Long-Short Term Memory Network for Location Prediction（2018IJCAI）</a></li></ul></li><li><a href="#4-时空数据预测">4. 时空数据预测</a><ul><li><a href="#41-hyperst-net-hypernetworks-for-spatio-temporal-forecasting2019aaai">4.1. HyperST-Net: Hypernetworks for Spatio-Temporal Forecasting（2019AAAI）</a></li><li><a href="#42-restful-resolution-aware-forecasting-of-behavioral-time-series-data2018cikm">4.2. RESTFul: Resolution-Aware Forecasting of Behavioral Time Series Data（2018CIKM）</a></li><li><a href="#43-spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand2019aaai">4.3. Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand（2019AAAI）</a></li><li><a href="#44-revisiting-spatial-temporal-similarity-a-deep-learning-framework-for-traffic-predictionaaai2019">4.4. Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction（AAAI2019）</a></li><li><a href="#45-deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-predictionaaai2017">4.5. Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction（AAAI2017）</a></li><li><a href="#46-attention-based-spatial-temporal-graph-convolutional-networks-for-traffic-flow-forecasting2019aaai">4.6. Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting（2019AAAI）</a></li><li><a href="#47-urbanfm-inferring-fine-grained-urban-flows2019kdd">4.7. UrbanFM: Inferring Fine-Grained Urban Flows（2019KDD）</a></li><li><a href="#48-deep-multi-view-spatial-temporal-network-for-taxi-demand-prediction2018aaai">4.8. Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction（2018AAAI）</a></li><li><a href="#49-urban-traffic-prediction-from-spatio-temporal-data-using-deep-meta-learning2019kdd郑宇">4.9. Urban Traffic Prediction from Spatio-Temporal Data Using Deep Meta Learning（2019KDD郑宇）</a></li></ul></li><li><a href="#5-图卷积">5. 图卷积</a><ul><li><a href="#51-semi-supervised-classification-with-graph-convolutional-networks2017iclr">5.1. Semi-Supervised Classification with Graph Convolutional Networks（2017ICLR）</a></li><li><a href="#52-diffusion-convolutional-recurrent-neural-network-data-driven-traffic-forecasting2018iclr">5.2. Diffusion Convolutional Recurrent Neural Network Data-Driven Traffic Forecasting（2018ICLR）</a></li><li><a href="#53-graph-attention-networks2018iclr">5.3. Graph Attention Networks（2018ICLR）</a></li><li><a href="#54-deeper-insights-into-graph-convolutional-networks-for-semi-supervised-learning2018aaai">5.4. Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning（2018AAAI）</a></li></ul></li><li><a href="#6-time-series-forecasting">6. Time Series Forecasting</a><ul><li><a href="#61-multi-horizon-time-series-forecasting-with-temporal-attention-learning2019kdd">6.1. Multi-Horizon Time Series Forecasting with Temporal Attention Learning（2019KDD）</a></li><li><a href="#62-enhancing-the-locality-and-breaking-the-memory-bottleneck-of-transformer-on-time-series-forecasting2019nips">6.2. Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting（2019NIPS）</a></li></ul></li><li><a href="#7-traffic-accident预测">7. traffic accident预测</a><ul><li><a href="#71-learning-deep-representation-from-big-and-heterogeneous-data-for-traffic-accident-inference2016aaai">7.1. Learning Deep Representation from Big and Heterogeneous Data for Traffic Accident Inference（2016AAAI）</a></li><li><a href="#72-a-deep-learning-approach-to-the-citywide-traffic-accident-risk-prediction2018ieee-itsc">7.2. A Deep Learning Approach to the Citywide Traffic Accident Risk Prediction（2018IEEE-ITSC）</a></li></ul></li></ul><!-- /TOC --><h1><span id="2-总结">2. 总结</span></h1><ul><li>在POI推荐上，考虑考虑用户对不同POI的喜爱程度，对每个POI分配不同的权重，同时对一个POI也要考虑这个POI在不同方面的权重（比如饭店在食物和环境的权重）</li><li>在时空建模上，时间上考虑不同的方面，比如recent，periodic等方面，在空间上考虑neighbor，function similarity等方面，其中功能相似一般通过POI来度量</li><li>考虑不同区域之间的相似性，可以使用2个区域之间的traffic flow，2个区域之间的traffic flow越大，说明这2个区域关联性越强。还可以使用2个区域的POI，2个区域之间的POI越相似，这2个区域的function越相似。</li><li>不管time interval是多少，一般只说预测将来多少个时间段的数据，而不是说预测将来多长时间的数据。比如说预测将来5个时间段的数据。如果time interval=30min，则预测的是将来1.5h的数据，如果time interval=1h，则预测的是将来5h的数据。</li><li>如果是将城市划分成网格，每个网格都有空间特征，比如这个网格的flow或者speed。使用CNN获取这个区域的空间特征，所有区域的形成的矩阵形状为(F,I,J)，其中F表示每个区域的空间特征个数，I和J表示网格的高和宽。如果将不同时间段的网格图拼接起来，比如将t个时间段的网格按照时间拼接起来，则形成的形状为(F*t,I,J),然后通过卷积来捕获空间特征。但是这样有一个问题，将时间拼接起来形成通道，会损失通道信息。如果预测是所有区域下一个时间段的inflow和outflow，则输出为(2,I,J)。如果预测的是所有区域接下来p个时间段的速度，则输出为(p,I,J)。</li><li>比如说网格数据有I*J个网格，每个网格有F个特征，这F个特征都是关于这个网格的特征。一般像外部因素不会放在网格中。因为外部因素，像温度，天气等一般不放在网格中。但也有放在网格中的，比较少。</li><li>比如预测第t天的flow，用到该预测天前hour，day，week数据，同时还要考虑外部因素，这里使用的外部因素只考虑被预测当天的外部因素。</li><li>对于预测flow问题，如果只预测一个区域的flow，在构造样本的时候对于每一个区域都构造一个以该区域为目标区域的样本。训练模型是用所有区域的样本来训练，预测的时候输出一个区域的flow。并不是预测一个区域，只用这个区域的历史数据来训练，而是用所有的区域来训练。</li><li>《2018[AAAI] When will you arrive estimating travel time based on deep neural networks》用户的轨迹数据本来是一个时间序列数据，每个轨迹点使用&lt;经度，纬度&gt;表示，可以使用嵌入将用户的轨迹转换成一个矩阵，使用1D卷积捕获空间关系，然后再送入LSTM中，捕获时间关系。</li></ul><h1><span id="3-poi推荐">3. POI推荐</span></h1><h2><span id="31-point-of-interest-recommendation-exploiting-self-attentive-autoencoders-with-neighbor-aware-influence-cikm2018">3.1. Point-of-Interest Recommendation Exploiting Self-Attentive Autoencoders with Neighbor-Aware Influence   (CIKM2018)</span></h2><p><a href="http://delivery.acm.org/10.1145/3280000/3271733/p697-ma.pdf?ip=218.247.253.241&amp;id=3271733&amp;acc=ACTIVE%20SERVICE&amp;key=BF85BBA5741FDC6E%2EB8E1436BD1CE5062%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1564715146_1e8dd5a9fd9356658c3d093a628ac7c5" target="_blank" rel="noopener">论文地址</a><br>论文题目：邻居感知的自注意自编码器的POI推荐  </p><ul><li>挑战<br>（1）建模用户POI之间的非线性关系，原先都是所有的POI权重一样；<br>（2）结合上下文信息，例如POI地理坐标。<br>（3）用户去过的POI是一小部分，而所有的POI非常多，使得POI矩阵变得非常稀疏</li><li>模型<br><strong>self-attentive encoder and a neighbor-aware decoder（SAE-NAD）</strong><br>&ensp;&ensp;&ensp;&ensp;通过self-attentive encoder区分用户对访问过的POI的喜好程度，用户的访问POI向量中每个POI的权重不同，这样可以学到更好的user hidden representation。<br>&ensp;&ensp;&ensp;&ensp;通过neighbor-aware decoder结合地理上下文信息，使得用户之前到达区域的附近或相似的区域可达性变大。将访问的POI嵌入和未访问的POI嵌入做内积，基于RBF（2个POI的点对点距离） kernel，来计算访问过的POI对未访问POI的影响。<br>&ensp;&ensp;&ensp;&ensp;为了建模稀疏矩阵，我们给未访问的POI分配相同的小权重，给访问过的POI通过访问频率分配不同的大权重。这样对于每个用户就可以区分未访问，少访问，经常访问的POI   </li><li>贡献<br><strong>第一篇使用基于attention的自编码器在POI推荐上</strong></li><li><strong>目标</strong><br><strong>根据用户check-in的记录，向用户推荐一系列从未去过的POIS</strong></li><li><p>Definitoin<br>POI(类型，经纬度)<br>Check-in(用户id，POI ID，时间)     </p><p><img src="/2019/08/02/论文总结/1.png" alt=""><br>&ensp;&ensp;&ensp;&ensp;使用stack autoencoder（堆叠自编码器）学习用户隐藏表示。输出是一个用户去过和没去过的POI，一个n维的0/1向量，其中的$l_2,l_4,l_6$表示去过的POI下标，根据去过POI的下标在POI嵌入矩阵$W^{(1)}$中取出对应的POI向量组成矩阵$W^{(1)_{[L_u]}}$，得到用户已经去过区域的POI嵌入，这n个POI有些POI更能表示用户的喜好，用到self-attentive机制，为$W^{(1)_{[L_u]}}$中的每个POI嵌入学习不同的权重，来构成user hidden representation。一般的attention给每个POI嵌入学习一个分数，这个分数只能反映POI在一方面的重要性。例如饭店，在味道方面这个用户喜欢这家饭店，但是在环境方面用户不喜欢，为了从不同方面捕获用户的喜好，使用multiple-dimension attention，分别对不同方面进行打分。</p></li></ul><p><img src="/2019/08/02/论文总结/2.png" alt=""><br><img src="/2019/08/02/论文总结/3.png" alt=""><br>这n个POI嵌入向量，从$d_a$个方面进行打分，得到的$A_u \in R^{d_a \times n}$ ,然后把n个POI嵌入乘上分数再相加，得到第u个用户隐藏表示$Z^{(1)}_u \in R^{d_a  times H_1}$，从$d_a$个方面来表示这个用户，为了让这个矩阵输入到encoder中，通过全连接将$d_a$个方面整合成一个方面，从一个矩阵变成一个向量。 然后经过2个encoder得到$z^{(3)}_u$<br><img src="/2019/08/02/论文总结/4.png" alt=""><br>&ensp;&ensp;&ensp;&ensp;用户访问过的POI会对没访问过的POI有影响，影响程度有着2个POI的相似性和距离决定。和已访问过的POI相似或邻近的POI用户访问的概率比较大。使用内积的方式求2个POI的相似性，但是这没有考虑到2个POI之间的距离，我们采用RBF kernel根据2个POI之间的距离计算2个POI之间的相关性，得到一个N*N的矩阵。然后把相似性和距离相关性相乘，得到2个POI的最终区域相关性，<br><img src="/2019/08/02/论文总结/6.png" alt=""><br>解码器阶段：将用户隐藏进行解码。其中$z^{(3)}_u$表示根据用户去过的POI得到的用户表示，$p_u$表示去过的POI对未去过的POI的影响。<br><img src="/2019/08/02/论文总结/7.png" alt="">   </p><ul><li>总结<br>根据一个用户之前去过的POI对这个用户进行表示，不同的POI有不同的权重，同一个POI在不同的方面也有不同的权重，得到一个user hidden representation，将用户表示经过2层encoder，然后在解码的时候，用到邻居信息，去过的POI对未去过的POI有影响，影响大小根据这2个POI之间的相似性和距离决定。    </li></ul><h2><span id="32-hst-lstm-a-hierarchical-spatial-temporal-long-short-term-memory-network-for-location-prediction2018ijcai">3.2. HST-LSTM: A Hierarchical Spatial-Temporal Long-Short Term Memory Network for Location Prediction（2018IJCAI）</span></h2><p>这篇论文没怎么看懂<br>弱实时预测，向用户推荐下一分钟或小时要去的地点。 在LSTM中使用时空信息。<br><img src="/2019/08/02/论文总结/8.png" alt="">   </p><ul><li>贡献<br>提出HST-LSTM结合时空影响到LSTM中，来解决位置预测中数据稀疏的问题。<br>HST-LSTM建模用户的历史访问序列，使用encoder-decoder的方式来提高预测性能。</li><li>模型<br><strong>HST-LSTM model</strong><br>AOI:具有一种功能的区域，例如购物中心，工作区<br>Visit Record：用户在一段时间内（几周或几个月）访问的所有AOIS<br>Visit Session：一个用户在在一个时间段（一天）访问的AOI序列，在一个session中的AOI有强烈的相关性，揭示了用户的运动模式。<br>Visit Session Sequence：一个用户连续的visit sessions，可以作为上下文信息预测下一个AOI。<br>多个AOI组成一个visit session，多个visit session组成visit record，</li><li>目标<br>用户在一段时间内访问了N个AOI，这N个AOI按照时间排序（AOI可能有重复），给定前j个用户去过的AOI，预测接下来用户要去的N-j个AOI，是一个多对多的预测。</li></ul><p><img src="/2019/08/02/论文总结/9.png" alt=""><br>在LSTM中3个门控机制中，输入门，遗忘门，输出门加入时空因素。其中s和q都是d维的向量，分别表示空间和时间的影响因素。<br><img src="/2019/08/02/论文总结/10.png" alt=""><br>基于提出的ST-LSTM，对每个visit session建模。使用STLSTM，每一个时间步输入的信息是一个visit session中的AOI嵌入，使用一个STLSTM对一个session进行建模，输出最后一个时间步的隐藏状态$h^i_e$作为第$i$个session的表示。对$n-1$个session进行建模得到n-1个隐藏状态，将这n-1个隐藏状态使用Contextual LSTM建模长期的visit sequence，在global context encoding阶段，每个时间步输入的是上一个STLSTM中session的表示。<br><img src="/2019/08/02/论文总结/11.png" alt=""><br><img src="/2019/08/02/论文总结/12.png" alt=""><br>在Decoding阶段，使用前i-1个session的推断接下来要去的AOI。</p><ul><li>总结<br>在LSTM阶段加入时空信息，提出STLSTM。<br>使用encoder-decoder来实现POI推荐，encoder和decoder都是LSTM</li></ul><h1><span id="4-时空数据预测">4. 时空数据预测</span></h1><h2><span id="41-hyperst-net-hypernetworks-for-spatio-temporal-forecasting2019aaai">4.1. HyperST-Net: Hypernetworks for Spatio-Temporal Forecasting（2019AAAI）</span></h2><p>题目：超时空网络预测<br>以前的方法分别对时间和空间分别建模，没有考虑到时间和空间内在的因果关系。空间的属性（POI或路网）影响空间的特征（工作区或居民区），从而影响时间特征（inflow trend）<br><img src="/2019/08/02/论文总结/13.png" alt="">  </p><ul><li>目标<br>预测一个区域。根据这个区域的空间和时间特征，预测ST数据，例如空气质量预测，交通流量预测。<br>本篇论文提出一个框架，包含3部分：空间模块，时间模块，演绎模块（deduction module）。<br><strong>这是第一篇考虑空间和时间特征内在因果关系的框架。</strong><br>使用spatial module从spatial attribute建模spatial characteristic，然后使用deduction module从spatial characteristic建模temporal characteristic。<br><img src="/2019/08/02/论文总结/14.png" alt=""><br>Spatial module：两阶段模块，在第一阶段，将spatial attribute建模成spatial characteristic。在第二阶段，生成多个独立的因素，deduction module使用它们来建模时间模块中对应神经网络的参数。例如a—》A，b—》B，c—》C。空间模块像一个hypernetwork。<br>Temporal module：应用不同的HyperST层，HyperST层的参数由deduction module计算得到，可以被看做object的时间characteristic。<br>Deduction module：连接空间和时间模块，空间和时间的内在因果关系被考虑进去。<br><img src="/2019/08/02/论文总结/15.png" alt=""> </li></ul><h2><span id="42-restful-resolution-aware-forecasting-of-behavioral-time-series-data2018cikm">4.2. RESTFul: Resolution-Aware Forecasting of Behavioral Time Series Data（2018CIKM）</span></h2><p>基于不同粒度的行为时间序列数据预测<br>行为数据，例如购买行为，邮件行为。<br>现在的预测方法经常仅仅使用一种时间粒度（天或周），然而现在的行为时间数据经常有多重时间粒度模式，每种时间模式之间相互依赖。本篇论文提出RESolution-aware Time series Forecasting（RESTFul），使用循环神经网络来编码不同粒度的时间模式成一个低维表示。不同时间粒度的表示在融合阶段，使用卷积融合框架。最终学到的conclusive embedding向量输入到MLP中用来预测行为时间序列数据。<br><strong>这是第一篇使用多时间粒度来预测时间序列数据。</strong><br>不同粒度的时间序列长度是一样的，比如为5，就表示最近3天，5周。  </p><ul><li>定义<ol><li>Behavioral Time Series：表示一段时间段内的行为数据，$X=[x_1,x_2…x_t,…x_T]，其中t \in [1,2,…T],x_t是一个标量，数值或离散值，表示第t个时间段的行为数据$</li><li>Behavioral Time Series Forecasting：给定历史行为时间序列数据，给定前k个时间段的历史数据$[x_T-k,…x_T],预测x_{T’},其中T’ &gt;= T$  </li><li>Interval Resolution $\alpha$:$s_t和s_{t+1}之间的时间差距$，如果为1天，表示1天测量一次，如果为1周，表示1周测量一次。</li><li>Remporal Resolution $\beta$:如果$\beta=week$表示一次测量1周，如果为1day，表示一次测量1天。</li><li>限制$\alpha &gt;= \beta$  如果$\alpha=1week,\beta=1day,表示1周测量1次，1次测1天。 \alpha=1week,\beta=1week,表示1周测量1次，1次测1周。其中x_t = g(x_t,x_{t+1}…x_{x+\beta})的聚合值，例如一周的平均值或最大值$ </li></ol></li><li>模型<br>RESTFul有2个阶段，第一个阶段，使用循环神经网络来编码不同时间粒度的时间模式。第2个阶段，使用卷积融合模块来融合不同时间粒度的表示。<br><img src="/2019/08/02/论文总结/16.png" alt=""><br>$\alpha,\beta \in {day:1,week:7},这样&lt;\alpha,\beta&gt;就有3种组合，分别是<1,1>,<7,1>,<7,7>$，对于每种组合都有一组行为时间序列数据，对于每组时间序列数据，都使用GRU来这个序列进行时间建模，得到最后一个时间步的隐藏状态向量。将每种组合得到的隐藏状态拼接起来，最终得到一个张量，维度是$R^{|\alpha|\times|\beta|\times d_s}$。然后使用卷积操作，先使用2次2*2的卷积，同时使用padding保证得到的结果大小不变，只改变通道的大小，最终得到的结果是$R^{|\alpha|\times|\beta|\times d_s/4}$,然后展开得到一个$|\alpha|\times|\beta|\times d_s/4$的向量，输入到MLP中，最终可以用来预测回归任务和分类任务。回归任务的损失函数是均方差，分类任务的损失函数是交叉熵。</7,7></7,1></1,1></li><li>总结：<br>考虑不同时间粒度，对不同时间粒度的序列使用GRU建模，将最后一个时间步的隐藏状态拼接起来使用CNN。使用2维卷积对时间数据进行建模，不太合适，可以考虑时间3维卷积。   <h2><span id="43-spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand2019aaai">4.3. Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand（2019AAAI）</span></h2><a href="https://echohhhhhh.github.io/2019/03/05/Spatiotemporal-Multi-Graph-Convolution-Network-for-Ride-hailing-Demand-Forecasting/" target="_blank" rel="noopener">论文总结</a><br>预测出租车流量，对一个区域在空间上考虑neighbor，function similarity，road connectivity。   <h2><span id="44-revisiting-spatial-temporal-similarity-a-deep-learning-framework-for-traffic-predictionaaai2019">4.4. Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction（AAAI2019）</span></h2>&ensp;&ensp;&ensp;&ensp;</li><li>挑战：空间依赖性时动态的，随着时间变化，比如早上居住区和工作区的联系强烈，晚上联系较弱。时间上不是严格的周期性，存在dynamic temporal shifting。比如早高峰在7点值9点，每天可能不一样。</li><li>模型：Spatial-Temporal Dynamic Network（STDN），流量门控机制学习location之间动态相似性，periodically shifting attention机制捕获长期周期时间shifting。</li><li>将一个城市划分成a*b=n个网格，将一个时间段（eg.一个月）划分成m个长度相等的时间段。<br>traffic volume：区域$i$的start流量$y^s_{i,t}$：在第$t$个时间段离开这个区域的trip个数，区域$i$的end流量$y^e_{i,t}$：在第$t$个时间段到达这个区域的trip个数。<br>traffic flow：从在第$t$个时间段从区域$i$出发，在第$\tau$个时间段到达$j$区域的traffic flow使用$f^{j,\tau}_{i,t}$表示。</li><li>目标：给定时间段t及其之前的traffic volume和traffic flow，预测第$t+1$个时间段的start and end traffic volume。</li><li>模型：使用Local CNN和LSTM捕获时间和空间关系。<br><img src="/2019/08/02/论文总结/STDN.png" alt=""><br>在提出本文的组件之前，先介绍一下2个base model。</li><li>空间 Local CNN<br>使用traffic volume来获取空间相关性，使用local CNN得到区域表示。<br><img src="/2019/08/02/论文总结/volume.png" alt=""></li><li>Short-term 时间依赖，短期比如说预测今天9:00~9:30的traffic volume，输入是今天7:00~8:30。<br>使用LSTM来获取短期时间依赖。<br><img src="/2019/08/02/论文总结/short-term.png" alt="">  </li><li>下面提取本文的改进，<br><strong>Local CNN—》Flow Gate Mechanism<br>Short-term temporal—》Periodically Shifted Attention Mechanism</strong></li></ul><p><strong>Spatial Dynamic Similarity: Flow Gating Mechanism(空间动态相似性)</strong><br>在local CNN中，local spatial dependency主要是traffic volume。Y表示traffic volume。  但是traffic volume是静态的，不能完全反映目标区域和周围邻居的关系，traffic flow可以更加直接的反应区域之间的联系。两个区域之间的flow越多表示2个区域联系越强（eg.这2个区域越相似）。设计Flow Gating Mechanism(FGM)捕获区域间的dynamic spatial dependency。<br>traffic flow分为2种：inflow和outflow。<br>给定一个目标区域$i$，获取该区域历史$l$个时间段的traffic flow(从$t-l+1到t$),将历史$l$个时间段的inflow和outflow拼接在一起，形成一个三维张量$F_{i,t} \in \mathbb{R}^{S \times S \times 2l}$，其中$S$表示邻近区域，使用CNN建模区域之间的空间相关性。其中$F_{i,j}$作为第一层的输入。  </p><p><img src="/2019/08/02/论文总结/cnn.png" alt=""><br>在每一个卷积层，<strong>使用traffic flow信息来捕获区域之间的动态相似性</strong>，通过一个流量门来限制空间信息。每一层的输出是空间表示$Y^{i,k}_t$，受流量门调整。<br>即对上式的traffic volume，通过traffic flow来控制。 $\sigma$的取值是[0,1]，对traffic volume起到门控机制。  </p><p><img src="/2019/08/02/论文总结/gate.png" alt=""><br><strong>Temporal Dynamic Similarity：Periodically Shifted Attention Mechanism(时间动态相似性)</strong><br>以前的LSTM没有考虑长期依赖(例如：周期)，比如预测第$t$天9点的volume，考虑昨天或前天这个时间段的数据。但是traffic volume并不是严格周期的，在时间上会有平移，图a显示了在天之间的时间平移，图b显示了在周之间的时间平移。<br><img src="/2019/08/02/论文总结/shifting.png" alt=""><br>因为时间具有shifting，因此设计了Periodically Shifted Attention Mechanism（PSAM），这里只考虑天周期性，不考虑周周期。从前P天对应时间段的数据来预测，为了解决time shifting，获取每一天的$Q$个时间段,假设预测的时间段是9:00~9:30，$Q=5$,则获取该时间段前后1个小时的数据8:00~10:30。<br>即获取前P天的数据，并且从每天中获取Q个时间段。如模型图所示，对于每一天都有Q个时间段，可以获取每个时间段的traffic volume和traffic flow，然后使用图卷积，即可以得到一个区域每个时间段的表示。每一天都有一个自己的LSTM，每个LSTM都有Q个时间步，每个时间步都会得到一个隐藏状态向量，即会得到Q个隐藏状态，使用Attention，将Q个隐藏状态整合成一个隐藏状态，用$h^p_{i,t}$表示。其中attention中的$\alpha^{p,q}_{i,t}$表示在第$p$天，第$q$个时间段的重要性。$\alpha^{p,q}_{i,t}$根据长期的隐藏状态和被预测天的短期隐藏状态$h_{i,t}$计算得到。 </p><p><img src="/2019/08/02/论文总结/lstm.png" alt=""><br><img src="/2019/08/02/论文总结/attention.png" alt=""><br>经过attention之后，P天会得到P个隐藏状态，然后再经过一个LSTM来保存周期的序列信息，最终得到长期依赖表示$\hat{h}^p_{i,t}$。  </p><p><img src="/2019/08/02/论文总结/periodic.png" alt=""><br><strong>Joint Traning</strong><br>将短期表示$h_{i,t}$和长期依赖$\hat{h}^p_{i,t}$拼接得到$h^c_{i,t}$，送到一个全连接神经网络中，得到最终的输出，表示为$y^i_{s,t+1}$$y^i_{e,t+1}$作为start volume和end volume。<br><img src="/2019/08/02/论文总结/output.png" alt=""></p><h2><span id="45-deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-predictionaaai2017">4.5. Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction（AAAI2017）</span></h2><p>预测flow of crowd，提出ST-ResNet，使用残差网络来建模traffic crowd的时间邻近，周期，区域属性，对每一种属性，设计一个残差卷积单元，建模traffic crowd的空间属性。ST-ResNet对3个残差神经网络的输出分配不同的权重，动态地结合3个输出，在整合3个输出的时候同时考虑外部因素，例如天气，day of week。在这篇论文中，预测2种crowd flow：inflow和outflow。inflow是在一个时间段内从其他区域进行到目标区域的crowds。outflow是在一个时间段内离开目标区域的corwds。inflow和outflow是行人数量、车的数据、公共交通系统上的人数量或者3个的总和。</p><ul><li>gloal：给定历史t个时间段所有区域的inflow和outflow，预测第t+1个时间段所有区域的inflow和outflow。<br>将一个city网格划分成$I<em>J$，下面定义inflow和outflow<br><img src="/2019/08/02/论文总结/inflow.png" alt=""><br>inflow：从其他区域进入到(i,j)<br>outflow：从(i,j)出发到其他区域<br>其中$Tr:g1—&gt;g2…—&gt;g_{|Tr|}$<br><img src="/2019/08/02/论文总结/X.png" alt=""><br>其中X是所有区域的inflow和outflow矩阵。<br><img src="/2019/08/02/论文总结/problem.png" alt=""><br><img src="/2019/08/02/论文总结/ST-ResNet.png" alt=""><br>这个模型由4个组件构成：temporal closeness，period，trend和external。<br>每个时间段内都有一个网格图，2通道，表示所有区域的inflow和outflow。多个时间段按照时间排列会有多个图。在时间段上划分为3部分：recnet、near、distant，分别送到3个模块中：closeness，period，trend，然后对三个模块的输出分配不同的权重融合，再和external信息融合送到Tanh中。<br><strong>Conv-ResNet</strong><br>前3个模块内部是相同的结构，由2部分组成：卷积和残差单元<br><img src="/2019/08/02/论文总结/conv-resnet.png" alt=""><br>拿closeness模块举例，首先使用Conv来捕获near和distant区域的关系。  将closeness的图拼接在一起，closeness一共有$l_c$个时间段，每个时间段有2个通道，将这$l_c$时间段的图拼接在一起，变成$2</em>l_c <em> I </em> J$的数据送入到第一层卷积层。<br><img src="/2019/08/02/论文总结/closeness.png" alt=""><br><img src="/2019/08/02/论文总结/resnet.png" alt=""><br>根据上述结构分别对period和trend进行编码<br><strong>External Component</strong><br>主要考虑以下的外部因素，使用2层全连接提取外部因素。第一层是嵌入层，第二层是转换低维到高维，和$X_t$的维度一样。<br><img src="/2019/08/02/论文总结/external.png" alt=""><br><strong>Fusion</strong><br>所有的区域都被closeness，period，trend影响，但是不同的区域影响程度不同，<br><img src="/2019/08/02/论文总结/fusion.png" alt=""><br><strong>Fusion the external component</strong><br>将3个closeness，period，trend的输出融合，然后再和被预测时间段t的外部因素融合。<br><img src="/2019/08/02/论文总结/fusion-external.png" alt=""> </li></ul><h2><span id="46-attention-based-spatial-temporal-graph-convolutional-networks-for-traffic-flow-forecasting2019aaai">4.6. Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting（2019AAAI）</span></h2><p>&ensp;&ensp;&ensp;&ensp;使用时空图卷积预测所有节点在未来n个时间步的traffic flow。将traffic flow分为3个时间粒度级别：recent，daily，weekly，3个时间粒度的数据使用3个相同的module来建模，每个module有2个submodule：时空Attention和时空GCN    </p><h2><span id="47-urbanfm-inferring-fine-grained-urban-flows2019kdd">4.7. UrbanFM: Inferring Fine-Grained Urban Flows（2019KDD）</span></h2><p>从粗粒度级的flow推断细粒度级的flow。比如给出的是3<em>3区域的flow，需要推断6\</em>6区域的flow.大的区域称为superregion，划分的小区域称为subregion，同时考虑superregion和subregion的flow约束关系，加起来和superregion的flow相等。<br><img src="/2019/08/02/论文总结/fine-grain.png" alt=""><br>模型的总体框架如下：<br>主要分为2个部分：inference network和external factor subnet。其中推断网络由2个模块组成，特征提取模块和分布上采样模块。<br>在推断网络中，输入是I*J的flow，先经过卷积和M个残差块，捕获空间相关性。在分布上采样模块，每个网格区域需要划分为N<em>N个区域，所以分布上采样主要是改变特征图的大小，从原来的$F</em>I<em>J变成F</em>NI<em>NJ$，对于每个网格区域，经过分布上采样模块，输出的$N</em>N$的flow分布概率。原始的输入$X_c的维度是I<em>J$，经过近邻上采样，会将原始的输入$变成维度为NI</em>NJ$,就是将每个区域的$flow复制N<em>N份$，然后和分布上采样输出的概率相乘，得到每个细粒度区域的flow。<br>**需要注意外部因素，输入是一个向量，经过特征提取模块，输出也是一个向量，为了将外部因素和粗粒度级的flow和细粒度级的flow拼接，也需要将外部因素reshape成$I</em>J或NI<em>NJ$的形状。我原先以为是将外部因素复制$I</em>J或NJ<em>NJ$份，其实并不是，是使用reshape函数。*</em>  </p><p><img src="/2019/08/02/论文总结/urbanFM.png" alt=""></p><h2><span id="48-deep-multi-view-spatial-temporal-network-for-taxi-demand-prediction2018aaai">4.8. Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction（2018AAAI）</span></h2><p>将一个城市进行网格划分，时间段：30min。预测一个网格区域的taxi demand。<br><strong>注意：根据多个区域，多个时间段，预测一个区域，一个区域的taxi demand</strong><br>根据前$t-h,….t$个时间段的taxi demand和外部因素，预测第$t+1$个时间段的taxi demand。<br><img src="/2019/08/02/论文总结/taxi-demand.png" alt=""><br>文章的标题是multi-view分别是spatial view、temporal view和semantic view(城市功能)，其中spatial view考虑的是target的邻近区域，但是有些区域离target很远，但是城市功能（居民区、商业区）和target相似，通过semantic view来捕获。<br><strong>1. Spatial view：Local CNN</strong><br>仅考虑空间近邻的区域，邻居区域大小$S<em>S,例如7</em>7$，通道数为1，表示taxi demand，表示为$Y^{i,0}_t \in R^{S \times S \times 1}$，经过K个卷积层，输出变成$Y^{i,K}_t \in R^{S \times S \times \lambda}$，然后reshape成一个向量维度为$S^2\lambda$，输入到全连接$FC中，输出一个d维的向量$。时间段有$t-h,….t$，每个时间段的$S<em>S</em>1$的网格都输入到Conv中，然后再经过全连接$FC$,所以最终输出$t-h,….t$个时间步，每个时间步是$d维。$<br><strong>细节：对于城市的边界区域，使用0来填充邻居。</strong><br><strong>2. Temporal view：LSTM</strong><br>经过spatial view输出每个时间步的表示，再和每个时间步的外部信息(天气，hour of day，day of week)拼接，共同输入到LSTM中，最终输出最后一个时间步的隐藏状态。<br><strong>3. Semantic View：Structural Embedding</strong><br>根据区域之间的城市功能相似性来构建graph，图中的节点是所有的区域，共$L个$，边：2个区域之间的相似性。相似性的计算是通过$Dynamic \quad Time \quad Warping \quad (DTW)$。 下图中给出了2个区域相似性的计算公式。根据区域$i 和 j$在工作日的taxi demand的时间序列，计算2个时间序列的相似性，即2个区域的相似性。根据区域间的相关性构建了一个全连接图$G$,使用$Embed$嵌入层,本文使用$LINE对图中的节点进行嵌入$，得到每个节点的低维特征表示，然后再次送入全连接中。<br><strong>注意：构建的是一个全连接图，即任意2个节点之间都有边，因为任意2个节点都可以达到。</strong><br><img src="/2019/08/02/论文总结/DTW.png" alt=""><br><strong>4. Prediction Component</strong><br>将LSTM中最后一个时间步的隐藏状态和target区域的节点表示$m^i$拼接，送入到全连接中，经过$sigmoid函数，$最终输出的值在[0,1]之间，然后再反归一化得到真实的taxi demand。<br><img src="/2019/08/02/论文总结/prediction.png" alt="">     </p><p><strong>5. Loss Function</strong><br><strong>注意：损失函数有参考意义。</strong>   </p><p>损失函数中包含2部分，一个是输出的taxi demand的均方差，一个是MAPE，前面更关注一些大的值，为了避免模型被一些大的值控制，后面加入MAPE。<br><img src="/2019/08/02/论文总结/loss.png" alt=""> </p><p><img src="/2019/08/02/论文总结/DMVST-Net.png" alt=""><br><strong>6. 数据集</strong><br>使用广州2个月的taxi数据，$区域划分20<em>20，每个区域700m</em>700m$，<br>（1）使用$Min-Max归一化为[0,1]之间，同时也对y进行归一化到[0,1]之间。$模型预测的输出也在$[0,1]之间，$然后对$y$使用反归一化得到真实的taxi demand。<br>（2）邻居大小设置为$9*9$<br>（3）时间段：30min，根据前8个时间段(4h)预测下一个时间段<br>（4）最后FC的激活函数是$Sigmoid$，其余FC的激活函数是$Relu$</p><h2><span id="49-urban-traffic-prediction-from-spatio-temporal-data-using-deep-meta-learning2019kdd郑宇">4.9. Urban Traffic Prediction from Spatio-Temporal Data Using Deep Meta Learning（2019KDD郑宇）</span></h2><p>通过时空数据，使用深度元学习，进行城市交通预测<br>论文代码：<a href="https://github.com/panzheyi/ST-MetaNet" target="_blank" rel="noopener">https://github.com/panzheyi/ST-MetaNet</a><br><strong>Abstract</strong><br>&ensp;&ensp;&ensp;&ensp;预测城市traffic有以下挑战：（1）复杂的时空相关性，（2）时空相关性的多样性，每个location的POI和路网信息都不一样。提出deep-meta-learning模型（深度元学习），叫做ST-MetaNet，同时预测所有location的traffic，使用seq2seq架构，包含encoder来学习历史信息，decoder来一步接一步的预测，encoder和decoder有相同的架构，都包含RNN来编码历史traffic数据，一个meta graph attention来捕获各种的空间关系，一个meta RNN来考虑各种的时间相关性。     </p><p><strong>Introduction</strong>   </p><ol><li><p>ST相关性的Complex：<br>&ensp;&ensp;&ensp;&ensp;traffic随着location变化，不同的location，traffic也不同。同一个location，不同的时间点的traffic也不一样。构建一个geo-graph表示空间结构，节点：location，边：location之间的关系。<br>&ensp;&ensp;&ensp;&ensp;在空间上，一些location会相互影响，例如图1(a)中的$S3$发生了accident，那么$S1,S2,S4$可能会发生交通阻塞。<br>&ensp;&ensp;&ensp;&ensp;在时间上，一个location的traffic会受到recent或far时间的影响。例如$S4$举办一个演唱会，$S4$的inflow变大，并且会持续一段时间。  </p></li><li><p>ST相关性的Diversity：<br>&ensp;&ensp;&ensp;&ensp;在上面构建的geo-graph中，有节点特征和边特征。节点：location，节点特征：这个location的POI、路的密度。边：location之间的关系。边特征：location的连通性和距离。比如图1(b)和(c)中，$R1和R3$有相同的POI，都是商业区，$R2$是住宅区，所以它们的flow的时间模式也不一样。  </p></li></ol><p><img src="/2019/08/02/论文总结/Urban-Traffic-Prediction-from-Spatio-Temporal-Data-Using-Deep-Meta-Learning-1.png" alt="">     </p><p>&ensp;&ensp;&ensp;&ensp;为了解决以上的挑战，提出<strong>ST-MetaNet</strong>,首先从geo-graph中的节点和边的特征中提取meta knowledge，从中生成预测网络的权重。<br><img src="/2019/08/02/论文总结/Urban-Traffic-Prediction-from-Spatio-Temporal-Data-Using-Deep-Meta-Learning-2.png" alt=""><br>文章的贡献有4个：<br>（1）提出一个新颖的deep meta learning模型，预测城市traffic，ST-MetaNet利用从geo-graph中提取的meta knowledge，生成graph attention network和RNN seq2seq的权重。<br>（2）提出一个meta graph attention网络来建模空间相关性，Attention机制可以捕获location之间的动态关系，attention网络中的权重是从geo-graph的meta knowledge中提取出来的。<br>（3）提出meta gated RNN，生成<br>（4）在traffic flow和traffic speed做实验<br><strong>Preliminaries</strong><br>&ensp;&ensp;&ensp;&ensp;一共有$N_l个location，每个location有N_t个时间步，traffic一共有D_t类$<br>Ubran Traffic：可以表示为以下的张量</p><script type="math/tex; mode=display">X=\left(X_{1}, \ldots, X_{N_{t}}\right) \in \mathbb{R}^{N_{t} \times N_{l} \times D_{t}}</script><p>其中$X_{t}=\left(x_{t}^{(1)}, \ldots, x_{t}^{\left(N_{l}\right)}\right)$表示在时间步$t$所有区域的traffic信息。<br>&ensp;&ensp;&ensp;&ensp;Geo-Graph 特征：分为节点特征和边特征，其中 $G=\{\mathcal{V}, \mathcal{E}\}$ 表示一个有向图，$\mathcal{V} = \{v^{(1)},\ldots,v^{(N_l)}\}$表示所有节点，$\mathcal{E} = \{e^{(ij)} | 1 \leq i, j \leq N_l\}$表示所有的边，使用$\mathcal{N}_i表示节点i的邻居。$<br>&ensp;&ensp;&ensp;&ensp;问题定义：给定前$\tau_{in}$个时间段的$\left(X_{t-\tau_{i n}+1}, \ldots, X_{t}\right)$所有location在所有时间段的traffic特征，和geo-graph特征$\mathcal{G}$，预测在接下来$\tau_{out}$个时间段所有节点的traffic信息，表示为$\left(\hat{Y}_{t+1}, \ldots, \hat{Y}_{t+\tau_{o u t}}\right)$。<br><strong>Methodologies</strong><br>&ensp;&ensp;&ensp;&ensp;ST-MetaNet是Seq2Seq结构，由encoder(蓝色)和decoder(绿色)组成, encoder编码输入序列$\left(X_{t-\tau_{i n}+1}, \ldots, X_{t}\right)$，生成隐藏状态$\{H_{RNN},H_{Meta-RNN}\}$,用来初始化decoder的状态，预测输出序列$\left(\hat{Y}_{t+1}, \ldots, \hat{Y}_{t+\tau_{o u t}}\right)$。<br>&ensp;&ensp;&ensp;&ensp;encoder和decoder有相同的网络架构，包含以下4个组件。<br>（1）RNN：使用RNN来对历史traffic进行嵌入，捕获长期的时间依赖。<br>（2）Meta-knowledge learner：使用2个全连接FCNs，分分别叫做NMK-Learner和EMK-Learner，从节点特征(POI和GPS位置)和边特征(location的道路连通性和距离)学习meta-knowledge，得到的meta-knowledge用来学习GAT和RNN的权重。<br>（3）Meta-GAT：由Meta-Learner和GAT组成，使用FCN作为Meta-Learner，它的输入是所有节点和边的meta knowledge，输出是GAT的权重。Meta-GAT可以捕获多样的空间相关性。<br>（4）Meta-RNN：由Meta-Learner和RNN组成，Meta-Learner是FCN，输入是所有节点的meta knowledge，输出是每一个节点在RNN的权重，Meta-RNN可以捕获多样的时间相关性。</p><p><img src="/2019/08/02/论文总结/Urban-Traffic-Prediction-from-Spatio-Temporal-Data-Using-Deep-Meta-Learning-3.png" alt="">      </p><ol><li>RNN(GRU)组件<br>编码所有的location的traffic信息，RNN网络对所有的location共享相同的参数，每次GRU输入的是一个location所有时间步的traffic信息，输出这个location的隐藏状态，下一次再输入另一个location所有时间步的traffic，所有的location共享GRU的参数。GRU输出所有location的隐藏状态$H_{t}=\left(h_{t}^{(1)}, \ldots, h_{t}^{\left(N_{l}\right)}\right)$  <script type="math/tex; mode=display"> h_{t}^{(i)}=\operatorname{GRU}\left(z_{t}^{(i)}, h_{t-1}^{(i)} | W_{\Omega}, U_{\Omega}, b_{\Omega}\right), \quad \forall i \in\left\{1, \ldots, N_{l}\right\}</script></li><li>Meta-Knowledge Learner<br>提出2个meta-knowledge learner：NMK-Learner和EMK-Learner，就是2个FCN，输入是一个节点或一条边的特征，输出是节点或边的向量嵌入表示，这些嵌入表示被用来生成GAT和RNN的权重，捕获时空相关性。使用NMK$(v^{(i)})$和EMK$(e^{(ij)})$表示节点和边的嵌入表示。</li></ol><h1><span id="5-图卷积">5. 图卷积</span></h1><p><a href="https://echohhhhhh.github.io/2019/03/03/%E5%9B%BE%E5%8D%B7%E7%A7%AF/" target="_blank" rel="noopener">图卷积总结</a>   </p><h2><span id="51-semi-supervised-classification-with-graph-convolutional-networks2017iclr">5.1. Semi-Supervised Classification with Graph Convolutional Networks（2017ICLR）</span></h2><h2><span id="52-diffusion-convolutional-recurrent-neural-network-data-driven-traffic-forecasting2018iclr">5.2. Diffusion Convolutional Recurrent Neural Network Data-Driven Traffic Forecasting（2018ICLR）</span></h2><h2><span id="53-graph-attention-networks2018iclr">5.3. Graph Attention Networks（2018ICLR）</span></h2><h2><span id="54-deeper-insights-into-graph-convolutional-networks-for-semi-supervised-learning2018aaai">5.4. Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning（2018AAAI）</span></h2><h1><span id="6-time-series-forecasting">6. Time Series Forecasting</span></h1><h2><span id="61-multi-horizon-time-series-forecasting-with-temporal-attention-learning2019kdd">6.1. Multi-Horizon Time Series Forecasting with Temporal Attention Learning（2019KDD）</span></h2><h2><span id="62-enhancing-the-locality-and-breaking-the-memory-bottleneck-of-transformer-on-time-series-forecasting2019nips">6.2. Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting（2019NIPS）</span></h2><h1><span id="7-traffic-accident预测">7. traffic accident预测</span></h1><h2><span id="71-learning-deep-representation-from-big-and-heterogeneous-data-for-traffic-accident-inference2016aaai">7.1. Learning Deep Representation from Big and Heterogeneous Data for Traffic Accident Inference（2016AAAI）</span></h2><p>&ensp;&ensp;&ensp;&ensp;在这篇论文中，使用数据：7个月的accident数据和1.6 million的用户GPS数据。使用堆叠降噪自编码器SDA来学习用户GPS的层次特征。这些特征被用来accidentrisk level的预测。这个模型一旦训练好，给定用户的移动轨迹，就可以模拟对应的accident risk地图。但是导致accident的因素很多。例如司机行为，天气，道路情况等。其他的研究尽管考虑到这些因素，但是没有揭示accidentrisk随着这些因素的变化。这篇论文的问题就是：能否通过实时的位置数据来评accident risk。商业和娱乐区有较高的accident risk，因为这些区域有较高的人流密度和人流量。<strong>accident因为受到很多因素的影响使得仅仅给定人类的移动情况，变得不好预测。因此我们推断一个accident的risk，而不是这次accident会不会发生。因为这是一个回归问题，而不是分类问题。</strong><br>&ensp;&ensp;&ensp;&ensp;我们的模型利用降噪自编码器来学习人类移动的层次特征表示。在预测accident risk任务中，经过自编码器学出来的人类移动特征比原始数据更有效。最终，根据人类移动数据的实时输入，我们的模型可以仿真大规模的accident risk地图。有high risk的区域会高亮显示。    </p><p>这篇论文的贡献有3个：  </p><ol><li>第一篇在城市级别上预测accident risk。  </li><li>构造深度学习框架  </li><li>在accident risk上的模拟是非常有效的。  </li></ol><p><strong>使用的数据：</strong></p><ul><li>traffic accident 数据。收集了三十万日本从2013.1.1~2013.7.31的traffic accident数据。每条记录包括事故发生的地点和小时，严重程度。其中严重程度被划分为3级，轻度受伤：1，重度受伤：2，致命：3</li><li>人类移动数据。收集了大约1.6million用户的GPS记录，在日本2013.1.1~2013.7.31。  </li></ul><p>accident的risk可以通过事故的频率和严重程度计算。定义risk level=每一个accident的严重程度的和。  时间划分：1个时间作为一个时间段，一天划分24个时间段。空间划分：每个区域500m*500m。时间索引t，空间索引r表示一个区域。即每1个小时统计一次risk level。 同时每小时统计一次该区域的人流密度density。risk level使用$g_{r,t}$表示，人流密度使用$d_{r,t}$表示。问题是通过$d_{r,t}$来预测$g_{r,t}$。每个区域每个时间段的(d,g)作为一个样本。  </p><p><strong>总结</strong>  </p><ul><li>没有考虑时间和空间特征，没有考虑外部因素</li><li>使用的特征太单一，只考虑区域的人流密度</li></ul><h2><span id="72-a-deep-learning-approach-to-the-citywide-traffic-accident-risk-prediction2018ieee-itsc">7.2. A Deep Learning Approach to the Citywide Traffic Accident Risk Prediction（2018IEEE-ITSC）</span></h2><p>traffic risk受很多因素的影响。例如不同的区域有不同的accident rate，天气因素，交通量，时间因素。本文结合<br>accident，traffic flow，天气，空气质量的历史短期和周期特征本文提出的模型用来预测短期的accident risk。和AAAI2016一样，本文是回归问题，预测accident risk。将accident分为3级。模型输入的特征是最近的traffic accident，traffic flow，weather，和air quality。最近指的是前几个小时或者昨天或者上星期。<br>将城市网格划分，每个网格区域1000m*1000m，每个时间段是30min或者60min。  </p><p>这篇文章是预测一个区域未来n天的accident平均发生频率。输入有2个，第1个是这个区域历史n个时间段发生的accident的次数，第2个是这个区域的经纬度坐标。<br>这篇论文的前身《A Deep Learning Approach to the Prediction of Short-term Traffic Accident Risk》比这篇传入的特征更多，但是不明白为啥没中。<br>这篇文章说traffic accident具有day和week周期性。所以考虑了hour，day，week共3个级别的数据。这篇文章是预测1个区域的risk level，和上一篇不同，上一篇是预测frequency。这篇文章使用的特征有，accident risk，traffic flow，holiday，time period（处于1天的哪个时段，论文中将1天分为7个时段），weather，air quality。将这个区域的以上这6个特征拼接在一起，表示为$I_r(t)$。分别获取这个区域hour，day，week共3个级别的$I_r$,作为LSTM的时间步，每个时间步的特征个数是6个特征拼接起来形成的$I_r$。</p>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;title: 论文总结&lt;br&gt;date: 2019-08-02T10:52:51.000Z&lt;br&gt;categories: 论文阅读笔记&lt;br&gt;tags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;时空领域&lt;/li&gt;
&lt;li&gt;GCN&lt;/li&gt;
&lt;li&gt;Flow&lt;br&gt;comments: false&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&quot;1-简介&quot;&gt;&lt;a href=&quot;#1-简介&quot; class=&quot;headerlink&quot; title=&quot;1. 简介&quot;&gt;&lt;/a&gt;1. 简介&lt;/h1&gt;&lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;这学期看了很多论文，下面把看过的论文总结一下。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/07/21/traffic-accident/"/>
    <id>http://yoursite.com/2019/07/21/traffic-accident/</id>
    <published>2019-07-21T10:35:32.893Z</published>
    <updated>2020-01-22T13:28:10.509Z</updated>
    
    <content type="html"><![CDATA[<hr><p>title: Traffic Accident相关论文<br>date: 2019-07-21T18:35:32.000Z<br>categories: 论文阅读笔记<br>tags:</p><ul><li>时空领域</li><li>accident预测<br>comments: false</li></ul><hr><h1><span id="1-简介">1. 简介</span></h1><p>以下是关于event prediction的相关论文，主要是traffic accident这一类的事件预测。<br><a id="more"></a><br><!-- TOC --></p><ul><li><a href="#1-%e7%ae%80%e4%bb%8b">1. 简介</a></li><li><a href="#2-%e8%ae%ba%e6%96%87">2. 论文</a><ul><li><a href="#21-learning-deep-representation-from-big-and-heterogeneous-data-for-traffic-accident-inference2016aaai">2.1. Learning Deep Representation from Big and Heterogeneous Data for Traffic Accident Inference(2016AAAI)</a></li><li><a href="#22-combining-satellite-imagery-and-open-data-to-map-road-safety2017aaai">2.2. Combining Satellite Imagery and Open Data to Map Road Safety(2017AAAI)</a></li><li><a href="#23-a-deep-learning-approach-to-the-prediction-of-short-term-traffic-accident-risk%e6%9c%aa%e4%b8%ad">2.3. A Deep Learning Approach to the Prediction of Short-term Traffic Accident Risk(未中)</a></li><li><a href="#24-a-deep-learning-approach-to-the-citywide-traffic-accident-risk-prediction2018ieee-itsc">2.4. A Deep Learning Approach to the Citywide Traffic Accident Risk Prediction(2018IEEE-ITSC)</a></li></ul></li></ul><!-- /TOC --><h1><span id="2-论文">2. 论文</span></h1><h2><span id="21-learning-deep-representation-from-big-and-heterogeneous-data-for-traffic-accident-inference2016aaai">2.1. Learning Deep Representation from Big and Heterogeneous Data for Traffic Accident Inference(2016AAAI)</span></h2><p>论文地址：<br><a href="https://shiba.iis.u-tokyo.ac.jp/song/wp-content/uploads/2017/02/AAAI2016.pdf" target="_blank" rel="noopener">Learning Deep Representation from Big and Heterogeneous Data for Traffic Accident Inference</a><br>目标：使用real-time GPS data 预测所有区域的traffic risk level，回归问题，预测risk的大小，而不是accident会不会发生 。<br><strong>数据集：</strong><br>Traffic accident data和Human mobility data throughout Japan from 2013.1.1~2013.7.31。<br><strong>模型：</strong><br><img src="/2019/07/21/traffic-accident/1.png" alt="traffic-accident/1.png"><br>对Japan的区域进行网格划分，获取每个网格的risk和mobility。使用Denoise Autoencoder模型对mobility进行编码representation，然后输入到Logistic regression层作为预测。<br><strong>总结：</strong></p><ul><li>第一个使用深度学习来预测traffic accident的模型，使用real-time GPS data作为输入。 </li><li>没有考虑到时间和空间的关系；</li><li>特征单一。只考虑了human mobility，可以考虑weather，POI，population，land use等信息。</li></ul><h2><span id="22-combining-satellite-imagery-and-open-data-to-map-road-safety2017aaai">2.2. Combining Satellite Imagery and Open Data to Map Road Safety(2017AAAI)</span></h2><p>论文地址：<br><a href="https://pdfs.semanticscholar.org/ef28/efaa43a05be548ed61d52a6bd590b88e7782.pdf" target="_blank" rel="noopener">Combining Satellite Imagery and Open Data to Map Road Safety</a>   </p><p>直接从原始的satellie image来预测road safety。相同的safety在图像视觉上有一些相同的特点，比如颜色(grey/greed)，路段等。所以图像的特点是road safety的一种体现。<br><img src="/2019/07/21/traffic-accident/2.png" alt="traffic-accident/1.png"><br>traffic accident被分为3类：slight，heavy，fatal。<br><strong>数据集：</strong><br>NYC：收集了14000张卫星图像，每个图像图片的标签是3类accident中的一类<br>Denver：收集了21406张卫星图像，标签是3类中的一类。<br>每张图片是256*256，使用ConvNet来对图像进行分类。使用NYC的卫星图像训练模型，使用训练好的模型对NYC的测试卫星图像进行测试。<br>使用Denver的traffic accident映射到地图上，形成traffic 热力图。使用从NYC训练得到的模型，输入是Denver的卫星图片，输出区域的traffic accident severity。即可以生成地图来表示区域的risk。</p><p><strong>总结：</strong></p><ul><li>第一个使用satellite image来预测city-scale road safety的模型</li><li>仅仅使用satellite image来预测traffic accident，没有考虑时间和空间信息，外部信息。    </li></ul><h2><span id="23-a-deep-learning-approach-to-the-prediction-of-short-term-traffic-accident-risk未中">2.3. A Deep Learning Approach to the Prediction of Short-term Traffic Accident Risk(未中)</span></h2><p>论文地址：<br><a href="https://www.researchgate.net/publication/320627131_A_Deep_Learning_Approach_to_the_Prediction_of_Short-term_Traffic_Accident_Risk" target="_blank" rel="noopener">A Deep Learning Approach to the Prediction of Short-term Traffic Accident Risk</a></p><p>这篇论文首先指出了《Learning Deep Representation from Big and Heterogeneous Data for Traffic Accident Inference》AAAI2016的缺点：（1）只考虑了human mobility data，像traffic flow，weather，air quality，regional characteristic这些重要的信息没有考虑。（2）没有考虑traffic的周期pattern。<br>本篇论文收集了big and heterogeneous data related traffic accident。<br><strong>数据集：</strong><br>traffic accident：北京2016年的accident数据，每条记录包含时间，地点，严重程度，分为三类，slight、heavy、fatal<br>traffic flow data：北京2016.8所有的taxi的GPS信息和speed信息。<br>air quality：北京的daily PM2.5信息。<br>weather information：cloudy，sunny…<br>每个区域的risk level是这个区域所有的accident severity的总和。<br>将traffic accident按照时间和空间划分，时间1h为一个slot，空间每个gird大小为1000m<em>1000m。<br>在给定时间t，定义所有区域的时间相关性，<br>从以上这些数据集提取出6个矩阵，分别是<br><img src="/2019/07/21/traffic-accident/4.png" alt="traffic-accident/1.png"><br>将这6个矩阵进行整合成一个矩阵，每个区域每个时间得到一个多源数据的表示。<br><em>*模型：Traffic Accident Risk Prediction Method based on LSTM (TARPML)</em></em><br><img src="/2019/07/21/traffic-accident/5.png" alt="traffic-accident/1.png"><br>有2个input layer，隐藏层有4个LSTM layer和3个fully connected layer，1个output layer，输出risk level。<br>使用LSTM是因为LSTM可以捕捉periodic信息。<br>输入层中的Short-term features是预测时间槽t的前几个小时的特征I，Periodic feature是预测时间槽t的daily和weekly特征。将这三种特征拼接起来，输入到first input layer中。区域的经纬度信息输入到second input layer中， 直接和fully connected layer相连。<br>输入的短期特征是预测时间t前n个小时的特征，n=4.输入的周期特征是预测时间t昨天和上周该时间段前后3个小时的特征。所以输入的特征维度为$(n+2n_d+2n_w+2,6)$。对于一个区域预测时间t的risk level，需要输入的数据是$(n+2n_d+2n_w+2,6)$<br><img src="/2019/07/21/traffic-accident/7.png" alt="traffic-accident/1.png"></p><p><strong>整体架构</strong><br><img src="/2019/07/21/traffic-accident/3.png" alt="traffic-accident/1.png"><br><strong>总结</strong></p><ul><li>使用到的数据集是北京：traffic accident，traffic flow，weather，holiday，air quality数据</li><li>分三种时间模式，recent，daily，weekly，直接concatenate输入到LSTM中。并且把region的经纬度输入到全连接中，相当于位置embedding。</li><li>没有考虑不同区域之间的关系</li><li>想法：（1）回归问题，预测区域的risk level，但是是一个区域还是所有区域，没有想好（2）考虑recent，daily，weekly，使用Attention机制计算三种之间的重要性.（3）对区域进行embedding，（4）考虑不同区域之间的关系.   </li></ul><h2><span id="24-a-deep-learning-approach-to-the-citywide-traffic-accident-risk-prediction2018ieee-itsc">2.4. A Deep Learning Approach to the Citywide Traffic Accident Risk Prediction(2018IEEE-ITSC)</span></h2><p>论文地址：<br><a href="https://arxiv.org/pdf/1710.09543.pdf" target="_blank" rel="noopener">A Deep Learning Approach to the Citywide Traffic<br>Accident Risk Prediction</a><br>这篇论文是上篇论文的修改版本。<br>和上文的改进之处是加入了很多图表对现象进行解释。解释了为什么预测traffic accident分类比回归要难的原因。<br>这里只使用了北京Traffic accident数据，没有使用其他外部数据。<br>在给定时间t，计算所有区域的空间相关性，然后再计算时空相关性。 计算下面2个公式，主要是为了说明traffic accident具有day周期性。所以在本论文中一个time slot=24h。<strong>计算一个区域每天的traffic accident发生的频率作为risk。</strong><br><img src="/2019/07/21/traffic-accident/8.png" alt="traffic-accident/1.png"><br><img src="/2019/07/21/traffic-accident/9.png" alt="traffic-accident/1.png"><br><img src="/2019/07/21/traffic-accident/10.png" alt="traffic-accident/1.png"></p><p>输入序列长度为100，输入每个区域100h的traffic accident frequency，输出是每个区域未来3天的mean frequency，使用所有的区域样本进行训练。测试时，输入是所有区域100h的traffic accident frequency，输出所有区域未来3天的平均frequency。<br><img src="/2019/07/21/traffic-accident/11.png" alt="traffic-accident/1.png"><br><strong>总结：</strong></p><ul><li>只使用了traffic accident数据，没有使用traffic flow，weather，road network等外部信息</li><li>没有考虑空间信息</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;title: Traffic Accident相关论文&lt;br&gt;date: 2019-07-21T18:35:32.000Z&lt;br&gt;categories: 论文阅读笔记&lt;br&gt;tags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;时空领域&lt;/li&gt;
&lt;li&gt;accident预测&lt;br&gt;comments: false&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&quot;1-简介&quot;&gt;&lt;a href=&quot;#1-简介&quot; class=&quot;headerlink&quot; title=&quot;1. 简介&quot;&gt;&lt;/a&gt;1. 简介&lt;/h1&gt;&lt;p&gt;以下是关于event prediction的相关论文，主要是traffic accident这一类的事件预测。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/07/17/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%B8%A9%E5%9D%91/"/>
    <id>http://yoursite.com/2019/07/17/神经网络踩坑/</id>
    <published>2019-07-17T08:08:21.126Z</published>
    <updated>2020-01-22T13:22:49.047Z</updated>
    
    <content type="html"><![CDATA[<hr><p>title: 神经网络踩坑<br>date: 2019-07-17T16:08:20.000Z<br>categories: Deep Learning<br>tags:</p><ul><li>训练经验</li><li>踩坑<br>comments: false</li></ul><hr><p>参考资料:<br><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729285&amp;idx=1&amp;sn=8f78edc716bbd2198cd7b14f62a93298&amp;chksm=871b2f3bb06ca62d60632da0faebbee63068405a5841934ebec300dc4bbace4b5e6f79daaeed&amp;mpshare=1&amp;scene=1&amp;srcid=07263lmMeeAcHLPSZpJXJI3L#rd" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729285&amp;idx=1&amp;sn=8f78edc716bbd2198cd7b14f62a93298&amp;chksm=871b2f3bb06ca62d60632da0faebbee63068405a5841934ebec300dc4bbace4b5e6f79daaeed&amp;mpshare=1&amp;scene=1&amp;srcid=07263lmMeeAcHLPSZpJXJI3L#rd</a>   </p><a id="more"></a>   <ol><li><strong>Suffle数据集</strong><br><strong>先划分数据集再shuffle</strong>。先将数据集划分成训练集、验证集、测试集。然后在DataLoader划分mini-batch时对训练集进行shuffle得到batch。<strong>对验证集和测试集不需要shuffle</strong>。不对训练集进行shuffle容易造成过拟合。<br><strong>只对train进行shuffle，对val和test不进行shuffle</strong></li><li><strong>归一化</strong><br>先划分数据集，再归一化。将数据划分成训练集，验证集，测试集，然后计算<strong>训练集的平均值和标准差</strong>。使用训练集的平均值和标准差对验证集和测试集进行归一化。模型不应该知道关于测试集的任何信息，所以要用训练集的均值和标准差对训练集归一化。<br><strong>划分数据集—&gt;归一化—&gt;对训练集shuffle</strong>   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line">   <span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">   X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = <span class="number">0.7</span>) <span class="comment">#train 70%, test 30%</span></span><br><span class="line">   ss = StandardScaler()</span><br><span class="line">   ss.fit(X_train)</span><br><span class="line">   <span class="comment">#X_val_std = ss.transform(X_val)#如果有验证集</span></span><br><span class="line">   X_test_std = ss.transform(X_test)</span><br><span class="line">   ```       </span><br><span class="line">   一般都是把数据归一化成[<span class="number">0</span>,<span class="number">1</span>]或者减去均值除以标准化。默认是对每一列进行归一化，即axis=<span class="number">0</span>。很少用sklearn的标准化方法，都是自己写一个方法用来标准化。</span><br><span class="line">   ![](神经网络踩坑/norm.png)      </span><br><span class="line">   在实际中对train，val，test归一化有<span class="number">2</span>种方法，  </span><br><span class="line">   方法<span class="number">1</span>：同时传入train，val，test参数，返回归一化后的trian，val，test和训练集的mean、std。</span><br><span class="line">   ```python</span><br><span class="line">   </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">normalize</span><span class="params">(x)</span>:</span></span><br><span class="line">        mean = x.mean(axis=<span class="number">0</span>, keepdims=<span class="keyword">True</span>)</span><br><span class="line">        std = x.std(axis=<span class="number">0</span>, keepdims=<span class="keyword">True</span>)</span><br><span class="line">        <span class="keyword">return</span> (x - mean) / std  </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">normalization</span><span class="params">(train, val, test)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    train, val, test: np.ndarray</span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    stats: dict, two keys: mean and std</span></span><br><span class="line"><span class="string">    train_norm, val_norm, test_norm: np.ndarray,</span></span><br><span class="line"><span class="string">                                     shape is the same as original</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> train.shape[<span class="number">1</span>:] == val.shape[<span class="number">1</span>:] <span class="keyword">and</span> val.shape[<span class="number">1</span>:] == test.shape[<span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">        <span class="comment">#求出训练集的mean和std</span></span><br><span class="line">        <span class="comment">#假设train的维度是(3,6,9),mean和std的维度为(1,6,9)</span></span><br><span class="line">        mean = train.mean(axis=<span class="number">0</span>, keepdims=<span class="keyword">True</span>)</span><br><span class="line">        std = train.std(axis=<span class="number">0</span>, keepdims=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">normalize</span><span class="params">(x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> (x - mean) / std</span><br><span class="line"></span><br><span class="line">    train_norm = normalize(train)</span><br><span class="line">    val_norm = normalize(val)</span><br><span class="line">    test_norm = normalize(test)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'mean'</span>: mean, <span class="string">'std'</span>: std&#125;, train_norm, val_norm, test_norm</span><br><span class="line">   ```     </span><br><span class="line">   方法<span class="number">2</span>：    </span><br><span class="line">   如果使用(data-mean)/std进行标准化，需要计算train的平均值和标准差，但是怎么将train的平均值和标准差保留用在val和test上呢？下面自定义一个标准化的类   </span><br><span class="line">   ```python</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Scaler</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data)</span>:</span></span><br><span class="line"><span class="comment">#计算train的平均值和标准差</span></span><br><span class="line">        <span class="comment">#假如data的维度是(2880, 1024, 2)</span></span><br><span class="line">        <span class="comment">#下面的平均值是mean所有的数相加/总个数</span></span><br><span class="line">    self.mean = np.mean(data)<span class="comment">#实数</span></span><br><span class="line">    self.std = np.std(data)<span class="comment">#实数</span></span><br><span class="line">    <span class="comment">#归一化：(数据-平均值)/标准差</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, data)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> (data - self.mean) / self.std</span><br><span class="line"></span><br><span class="line">    <span class="comment">#反归一化：(数据*标准差)+平均值</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inverse_transform</span><span class="params">(self, data)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> data * self.std + self.mean</span><br><span class="line">   ```  </span><br><span class="line">   然后在用到`Scaler`这个类时，`scaler = utils.Scaler(train)`,则scaler对象则保留了train的平均值和标准差，使用`scaler.mean和scaler.std`即可以获得train的平均值和标准差。  </span><br><span class="line">   ```python   </span><br><span class="line">   scaler = utils.Scaler(train)</span><br><span class="line">   <span class="comment">#对train，val，test进行标准化   </span></span><br><span class="line">   train_new = scaler.transform(train)</span><br><span class="line">   val_new = scaler.transform(val)</span><br><span class="line">   test_new = scaler.transform(test)</span><br><span class="line">   ```    </span><br><span class="line">   在计算loss时，不需要反归一化。在计算评价指标时需要反归一化。在计算评价指标时，比如RMSE,MAE等，首先根据归一化后的test_new得到预测结果predict，然后将predict根据scaler的inverse_transform反归一化，然后使用真实量级的predict和label再计算评价指标。</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> **batch_size**   </span><br><span class="line">   当数据量较大时，向网络中传入所有的数据来计算loss和梯度，更新参数会造成内存溢出。所以每次向网络中值传入一个batch的数据，说过这一个batch的数据来更新权重，输出这个batch里面所有样本的平均loss。下次再使用另一个batch，更新网络参数，直到所有的数据全都输入，完成一个epoch。</span><br><span class="line"><span class="number">4.</span> **划分数据集**</span><br><span class="line">   如果数据充足的情况下，通常采用均匀随机抽样的方法将数据集划分为<span class="number">3</span>部分，训练集，验证集和测试集，这三个集合不能有交集，常见的比例是<span class="number">8</span>:<span class="number">1</span>:<span class="number">1</span>，<span class="number">6</span>:<span class="number">2</span>:<span class="number">2</span>。需要注意的是，通常都会给定训练集和测试集，而不会给验证集，一般的做法是从训练集中抽取一部分数据作为验证集。   </span><br><span class="line"><span class="number">5.</span> **验证集的使用**  </span><br><span class="line">   在训练时，仅使用训练集的数据进行训练，使用验证集评价模型。当选中最好的模型超参数之后，再使用训练集+验证集来训练模型，以充分利用所有的标注数据，然后再测试集上测试</span><br><span class="line"></span><br><span class="line">   训练模型时，使用一个bacth来训练模型更新模型参数，记录下batch的loss。当训练完一个epcoh时，记录下模型的参数和梯度。并在验证集上计算验证集的误差，在测试集上计算测试集的MAE和MSE。     </span><br><span class="line">   **在训练的时候，每个batch记录训练的时间，**  </span><br><span class="line">   **使用 tensorboard，训练模型时，每一个batch记录一下train_loss，每一个epoch记录一下模型梯度，在验证集上的loss和评价指标，在测试集上的loss和评价指标，和模型的参数(只保存在val上效果最好的那组参数，其余的删掉)。至于使用val的loss还是评价指标来选择最好的模型，这个需要自己选择**   </span><br><span class="line">   在模型训练的时候记录训练集/验证集/测试集的loss，以及验证集/测试集的评价指标。  </span><br><span class="line">   为训练集，验证集，测试集创建<span class="number">3</span>个SummaryWriter。    </span><br><span class="line">   mxboard中log文件夹下的目录结构为：</span><br><span class="line">   --logs  </span><br><span class="line">   $\qquad$--时间<span class="number">1</span>文件夹</span><br><span class="line">   $\qquad\qquad$--train文件夹</span><br><span class="line">   $\qquad\qquad$--valid文件夹</span><br><span class="line">   $\qquad\qquad$--test文件夹</span><br><span class="line">   $\qquad$--时间<span class="number">2</span>文件夹</span><br><span class="line">   $\qquad\qquad$--train文件夹</span><br><span class="line">   $\qquad\qquad$--valid文件夹</span><br><span class="line">   $\qquad\qquad$--test文件夹</span><br><span class="line">   ```python   </span><br><span class="line">   timestamp = datetime.now().strftime(<span class="string">"%Y%m%d%H%M%S"</span>)</span><br><span class="line">    mxboard_log = <span class="string">'./logs/%s_%s/'</span> % (<span class="string">'GRU'</span>,timestamp)</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(mxboard_log):</span><br><span class="line">        shutil.rmtree(mxboard_log)</span><br><span class="line">    os.makedirs(mxboard_log)   </span><br><span class="line"></span><br><span class="line">    train_sw = SummaryWriter(logdir=mxboard_log+<span class="string">'/train'</span>,flush_secs=<span class="number">2</span>)</span><br><span class="line">    val_sw = SummaryWriter(logdir=mxboard_log+<span class="string">'/val'</span>,flush_secs=<span class="number">2</span>)</span><br><span class="line">    test_sw = SummaryWriter(logdir=mxboard_log+<span class="string">'/test'</span>,flush_secs=<span class="number">2</span>)  </span><br><span class="line"></span><br><span class="line">    <span class="comment">#为了让loss显示在一张图上，tag需要一样，但是使用不同的sw，即3个loss会分别写入train,valid,test文件夹中，但是在tensorboard网页上会显示在同一张图中，</span></span><br><span class="line">    train_sw.add_scalar(tag=<span class="string">'loss'</span>,value=training_loss,global_step=global_step)  </span><br><span class="line">    val_sw.add_scalar(tag=<span class="string">'loss'</span>,value=loss_mean,global_step=global_step)</span><br><span class="line">    test_sw.add_scalar(tag=<span class="string">'loss'</span>,value=loss_mean,global_step=global_step)  </span><br><span class="line">    <span class="comment">#评价指标的显示，同理。</span></span><br><span class="line">    val_sw.add_scalar(tag=<span class="string">'MAE'</span>,value=mae,global_step=global_step)</span><br><span class="line">    test_sw.add_scalar(tag=<span class="string">'MAE'</span>,value=mae,global_step=global_step)</span><br></pre></td></tr></table></figure></li></ol><p>   <a href="https://github.com/panzheyi/ST-MetaNet" target="_blank" rel="noopener">ST-MetaNet</a>这篇论文的代码在使用验证集验证的过程是：</p><ol><li>在for循环中遍历所有的的epoch</li><li>在每个epoch中，使用训练集训练模型，使用该epoch训练的模型对val进行验证，记录当前模型在val的metric(eg. MAE,MSE)和该模型的参数。</li><li>进行下一个epoch，重复步骤2</li><li>等到所有的epoch都结束了，选出在val上MAE或MSE最好的那个epoch的模型参数，重新给model加载这个epoch的参数，对测试集进行测试，输出metrics。     </li><li><p>即这篇的val是用来早停的，选出效果最好的epoch的模型参数。  </p><p><a href="https://github.com/Davidham3/ASTGCN" target="_blank" rel="noopener">ASTGCN</a>这篇论文的代码在使用没有选出最好效果的epoch，而是每个epoch在val上计算loss。  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> train_loader:</span><br><span class="line">        start_time = time()</span><br><span class="line">        output = model(input)</span><br><span class="line">        loss = loss_funtion(output,label)</span><br><span class="line">        loss.backward()</span><br><span class="line">        trainer.step(batch_size)</span><br><span class="line">        train_loss = loss.mean().asscalar()</span><br><span class="line">        <span class="comment">#一个batch,使用sw记录train_loss</span></span><br><span class="line">        sw.add_scalar(train_loss)</span><br><span class="line">        print(<span class="string">'每个batch需要的时间和train_loss'</span>)</span><br><span class="line">    <span class="comment">#一个epoch，使用sw记录model的梯度</span></span><br><span class="line">    sw.add_histogram(param.grad())</span><br><span class="line">    <span class="comment">#一个epoch，使用val进行验证，并使用sw记录val的loss</span></span><br><span class="line">    compute_val_loss(net, val_loader)</span><br><span class="line">    <span class="comment">#一个epoch，计算test的metric，并使用sw记录test的MAE等值</span></span><br><span class="line">    compute_metrics(net,test_loader) </span><br><span class="line">    <span class="comment">#一个epoch保存模型参数</span></span><br><span class="line">    net.save_param()</span><br></pre></td></tr></table></figure><p>完整代码  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line">   global_step = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, epochs + <span class="number">1</span>):</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> train_w, train_d, train_r, train_t <span class="keyword">in</span> train_loader:</span><br><span class="line"></span><br><span class="line">            start_time = time()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">with</span> autograd.record():</span><br><span class="line">                output = net([train_w, train_d, train_r])</span><br><span class="line">                l = loss_function(output, train_t)</span><br><span class="line">            l.backward()</span><br><span class="line">            trainer.step(train_t.shape[<span class="number">0</span>])</span><br><span class="line">            training_loss = l.mean().asscalar()</span><br><span class="line"></span><br><span class="line">            sw.add_scalar(tag=<span class="string">'training_loss'</span>,</span><br><span class="line">                          value=training_loss,</span><br><span class="line">                          global_step=global_step)</span><br><span class="line"></span><br><span class="line">            print(<span class="string">'global step: %s, training loss: %.2f, time: %.2fs'</span></span><br><span class="line">                  % (global_step, training_loss, time() - start_time))</span><br><span class="line">            global_step += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># logging the gradients of parameters for checking convergence</span></span><br><span class="line">        <span class="keyword">for</span> name, param <span class="keyword">in</span> net.collect_params().items():</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                sw.add_histogram(tag=name + <span class="string">"_grad"</span>,</span><br><span class="line">                                 values=param.grad(),</span><br><span class="line">                                 global_step=global_step,</span><br><span class="line">                                 bins=<span class="number">1000</span>)</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                print(<span class="string">"can't plot histogram of &#123;&#125;_grad"</span>.format(name))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute validation loss</span></span><br><span class="line">        compute_val_loss(net, val_loader, loss_function, sw, epoch)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># evaluate the model on testing set</span></span><br><span class="line">        evaluate(net, test_loader, true_value, num_of_vertices, sw, epoch)</span><br><span class="line"></span><br><span class="line">        params_filename = os.path.join(params_path,</span><br><span class="line">                                       <span class="string">'%s_epoch_%s.params'</span> % (model_name,</span><br><span class="line">                                                               epoch))</span><br><span class="line">        net.save_parameters(params_filename)</span><br><span class="line">        print(<span class="string">'save parameters to file: %s'</span> % (params_filename))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># close SummaryWriter</span></span><br><span class="line">    sw.close()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="string">'prediction_filename'</span> <span class="keyword">in</span> training_config:</span><br><span class="line">        prediction_path = training_config[<span class="string">'prediction_filename'</span>]</span><br><span class="line"></span><br><span class="line">        prediction = predict(net, test_loader)</span><br><span class="line"></span><br><span class="line">        np.savez_compressed(</span><br><span class="line">            os.path.normpath(prediction_path),</span><br><span class="line">            prediction=prediction,</span><br><span class="line">            ground_truth=all_data[<span class="string">'test'</span>][<span class="string">'target'</span>]</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">   ```  </span><br><span class="line"></span><br><span class="line"><span class="number">6.</span> **交叉验证**  </span><br><span class="line">   原先对交叉验证使用的数据集一直都理解错了。  </span><br><span class="line">   [参考资料](https://blog.csdn.net/qq_24753293/article/details/<span class="number">79970997</span>)</span><br><span class="line">   交叉验证使用的数据集是训练集，而不是全部的数据集。在交叉验证的时候把训练集分成K个集合，其中K<span class="number">-1</span>份用来训练，<span class="number">1</span>份用来验证。    </span><br><span class="line">   ![](神经网络踩坑/cross.png)</span><br><span class="line">   比如使用<span class="number">5</span>折交叉验证，使用不同的<span class="number">5</span>个训练集和测试集，训练得到<span class="number">5</span>个模型，但是我们最后使用的模型并不是这<span class="number">5</span>个模型中的一个。我们仍然认为这<span class="number">5</span>个模型是一个模型，虽然参数不同，只是它们的输入不同而已。交叉验证只是为了验证这个模型的性能，交叉验证的目的并不是为了得到最终的模型。</span><br><span class="line">   假设我们有<span class="number">2</span>个模型：线性回归和MLP。怎么说哪个模型更好呢？我们可以使用K折交叉验证来证明哪个模型更好，一旦我们选择了更好模型，例如MLP,那我们就用全部的数据来训练这个模型。</span><br><span class="line">   先使用网格搜索选择超参数，然后使用交叉验证输出这个模型的预测结果。</span><br><span class="line">   交叉验证有<span class="number">2</span>个用处：</span><br><span class="line">   - 准确的调整模型的超参数。超参数不同模型就不同。使用交叉验证来选出最好的超参数。</span><br><span class="line">   - 比如分类问题，有多个算法，逻辑回归，决策树，聚类等方法，不确定使用哪个方法时，可以使用交叉验证。  </span><br><span class="line"><span class="number">7.</span> **数据输入和输出**  </span><br><span class="line">   （<span class="number">1</span>）在gloun中Dense的输入是二维的，(batch_size,feature)，比如输入是(<span class="number">64</span>,<span class="number">120</span>)表示一个batch有<span class="number">64</span>个样本，每个样本有<span class="number">120</span>个特征。如果训练集中的X不是二维的，可以使用reshape()将X变换成(<span class="number">-1</span>,全连接输入单元个数)</span><br><span class="line">   （<span class="number">2</span>）卷积神经网络，卷积的输入和输出形状是(batch_size,通道,高,宽)，如果后面接的是全连接，就要转换成二维(batch_size,每个样本特征=通道\*高*宽)，但是不需要人去手动转换形状，Dense会自动转换。如果是keras，从卷积层到全连接层，形状不会自动转变，所以需要自己加一个`Flatten()`层。  </span><br><span class="line">   （<span class="number">3</span>）如果是一个分类问题，比如mnist数字识别，最后一层是一个神经单元个数为<span class="number">10</span>的全连接层，然后把输送入到softmax，将每一行的<span class="number">10</span>个值都变成在[<span class="number">0</span>,<span class="number">1</span>]之间小数。损失函数是交叉熵损失损失。在gluon中，最后一层Dense只需要指定输出神经单元个数即可，即`Dense(<span class="number">10</span>)`，在预测的时候，输出predict，这时的predict并没有归一化到[<span class="number">0</span>,<span class="number">1</span>]的范围内，我们直接把predict和true_label输入到loss中，在loss函数中，才会对predict进行softmax计算，将predict归一化到[<span class="number">0</span>,<span class="number">1</span>]范围内。   </span><br><span class="line">   在keras中，和gluon不同，会在最后一层的输出指定softmax激活函数，即`Dense(<span class="number">10</span>,activation=<span class="string">'softmax'</span>)`。</span><br><span class="line"></span><br><span class="line">   ![](神经网络踩坑/conv.png)  </span><br><span class="line">   （<span class="number">3</span>）循环神经网络的输入形状为(时间步数，batch_size，特征个数)   </span><br><span class="line">   [通俗易懂的RNN图解](https://www.zhihu.com/question/<span class="number">41949741</span>)</span><br><span class="line"><span class="number">8.</span> **激活函数**   </span><br><span class="line">   在使用激活函数的时候，一般都是</span><br><span class="line">   net.add(nn.Dense(<span class="number">10</span>,activation=<span class="string">'relu'</span>)),在定义层的时候直接加上activation，</span><br><span class="line">   也可以使用,但是不常用</span><br><span class="line">   net.add(nn.Dense(<span class="number">10</span>),</span><br><span class="line">           nn.Activation(<span class="string">'relu'</span>) </span><br><span class="line">    )</span><br><span class="line">    或者net.add(nn.Conv2D(channels=<span class="number">6</span>, kernel_size=<span class="number">5</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">    只有当在该层和激活函数之间有其余的操作时，才会分开写，例如在卷积计算之后，激活函数之前加上批量归一化层，写成</span><br><span class="line">    ```python   </span><br><span class="line">    net.add(nn.Conv2D(<span class="number">6</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">        BatchNorm(),</span><br><span class="line">        nn.Activation(<span class="string">'sigmoid'</span>))  </span><br><span class="line">        或者  </span><br><span class="line">        n.Dense(<span class="number">120</span>),</span><br><span class="line">        BatchNorm(),</span><br><span class="line">        nn.Activation(<span class="string">'sigmoid'</span>)</span><br></pre></td></tr></table></figure></li></ol><ol><li>什么时候用激活函数<ul><li>如果是回归问题，最后一层不需要激活函数（当然，如果数据归一化，可以加激活函数，也可以不加）</li><li>如果是分类问题，最后一层的激活函数使用sigmoid(二分类)，softmax(多分类)</li><li>大部分问题上，使用Relu会得到较好的性能。现在已经很少使用sigmoid激活函数了，sigmoid函数的输出范围在[0,1]之间，x轴在[-5,5]之间的梯度非常高，当x在该范围之外时，梯度很好，接近于0，在反向传播时，容易出现梯度消失问题，无法完成深层网络的训练。<br><img src="/2019/07/17/神经网络踩坑/sigmoid.png" alt="">  </li><li>由于梯度消失问题，尽量避免使用sigmoid和tanh激活函数</li><li>Relu是一个通用的激活函数，在大多数情况下都可以使用</li><li><strong>注意：Relu只能在隐藏层中使用，不可以在输出层使用</strong>  </li><li>使用softmax作为最后一层的激活函数时，前一层最好不要使用relu激活，而是使用tanh代替，否则最终的loss很可能变成nan</li><li></li></ul></li></ol><ol><li><p><strong>GPU运行程序</strong><br>ctx=mx.gpu(2)，下标从0开始<br><strong>需要用到ctx的地方：</strong></p><ul><li>数据集需要放到gpu上。有2种方法。<br>（1）在创建数据的时候，指定ctx，在gpu上创建数据。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">   train_loader = gluon.data.DataLoader(</span><br><span class="line">                        gluon.data.ArrayDataset(</span><br><span class="line">                            nd.array(all_data[<span class="string">'train'</span>][<span class="string">'week'</span>], ctx=ctx),</span><br><span class="line">                            nd.array(all_data[<span class="string">'train'</span>][<span class="string">'day'</span>], ctx=ctx),</span><br><span class="line">                            nd.array(all_data[<span class="string">'train'</span>][<span class="string">'recent'</span>], ctx=ctx),</span><br><span class="line">                            nd.array(all_data[<span class="string">'train'</span>][<span class="string">'target'</span>], ctx=ctx)</span><br><span class="line">                        ),</span><br><span class="line">                        batch_size=batch_size,</span><br><span class="line">                        shuffle=<span class="keyword">True</span></span><br><span class="line">    )</span><br><span class="line">   ```   </span><br><span class="line">   （<span class="number">2</span>）在训练的时候，使用as_in_context()将train_loader,val_loader,test_loader,数据拷贝到gpu上   </span><br><span class="line">   ![](神经网络踩坑/gpu.png)         </span><br><span class="line">   - 模型初始化的时候，通过ctx指定gpu设备，将模型参数初始化在gpu上。</span><br><span class="line">   ```python  </span><br><span class="line">    net = nn.Sequential()</span><br><span class="line">    net.add(nn.Dense(<span class="number">1</span>))</span><br><span class="line">    net.initialize(ctx=mx.gpu())</span><br><span class="line">   ```   </span><br><span class="line"><span class="number">10.</span> **使用多GPU运行**    </span><br><span class="line">    假设`ctx=[mx.gpu(<span class="number">1</span>),mx.gpu(<span class="number">2</span>)]`，则需要调整以下内容    </span><br><span class="line">    (<span class="number">1</span>)模型初始化，使用  </span><br><span class="line">    `net.initialize(init=init.Normal(sigma=<span class="number">0.01</span>), ctx=ctx)`   </span><br><span class="line">    (<span class="number">2</span>)split_and_load函数，将一个batch_size的数据再次划分成子集，并复制到各个GPU上，比如batch_size=<span class="number">6</span>，有<span class="number">2</span>个GPU，那么每个GPU上有<span class="number">3</span>个样本，  </span><br><span class="line">    ```python     </span><br><span class="line">    x = nd.random.uniform(shape=(<span class="number">4</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>))  </span><br><span class="line">    gpu_x = gutils.split_and_load(x, ctx)</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>NDArray和numpy</strong><br>使用gluon运行程序，gluon中的数据结构是NDArray，普通的python程序中的数据是numpy。什么时候用nd.array？什么时候用np.array?</p><ul><li><strong>nd.array</strong><br>（1）在模型内部的运算，使用的都是nd。比如模型的数据输入，在创建DataLoader时，数据需要转换成nd.array()类型。<br>（2）自定义的compute_val_loss()计算验证集的loss时，传入的数据是val_loader，是nd.array类型，但是在返回loss的时候，需要转换成np.array()，<br>（3）自定义的evaluate计算数据，返回的值是np.array()</li><li><strong>np.array</strong><br>（1）在metrics.py中计算MSE，RMSE，MAE等指标时，输出和输出都是np.array类型。</li><li><strong>nd.array和np.array转换</strong><br>（1）nd.array—&gt;np.array:<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = np.arange(<span class="number">10</span>)</span><br><span class="line">b = a.asnumpy()</span><br></pre></td></tr></table></figure></li></ul><p>（2）np.array—&gt;nd.array</p><pre><code class="lang-python">c = nd.array(b)</code></pre></li><li><strong>tensorboard使用</strong>   <ul><li>在训练集上每次epoch之后，验证模型在验证集上的平均loss，对验证集上的每个batch中的每个样本都求出一个loss，将所有样本的loss放在list中，最后求list的平均值得到验证集的平均loss。</li><li>在训练集上每次epoch之后，写一个evaluate函数，验证模型在测试集上的RMSE或MSE等指标。<br>tensorboard中tag相同的会被显示在同一张图中。为了显示训练集，验证集和测试集的loss，tag都被设置为loss，但是SummaWriter的logdir不同。  </li></ul></li><li><strong>Dropout的使用</strong><br>丢弃层会将隐藏单元中的值以一定的概率丢弃，即被设置为0，起到正则化的作用，用来应对过拟合。在测试模型时，为了拿到更加确定的结果，一般不使用丢弃法，只在训练模型下才使用dropout。在训练模型时，将靠近输入层的丢弃概率设的小一点。dropout一般放在全连接层后面。   </li><li>调参经验<br><a href="https://www.cnblogs.com/kamekin/p/10163743.html" target="_blank" rel="noopener">调参经验</a><br><a href="https://mp.weixin.qq.com/s/whbQ3b7NcA9Ifvb9aymkbQ" target="_blank" rel="noopener">33 个神经网络「炼丹」技巧</a></li><li>EarlyStopping<br><a href="https://github.com/dmlc/dgl/tree/master/examples/mxnet/gat" target="_blank" rel="noopener">GAT官方实现EarlyStopping的完整代码</a><br>早停是在模型在val_loss，或者val_acc,val_mae等指标上进行。传入2个参数，patience和delta。<ul><li>如果val_loss在连续patience epoch内，val_loss都大于最好的val_loss，即val_loss在增大，模型出现过拟合。</li><li>当前val_loss&gt;最好的val_loss-delta，有2种情况，<br>  （1）当前val_loss上升，counter+1<br>  （2）val_loss虽然减少，但是减少很小，基本可以视为不变，counter+1，</li><li>当前val_loss &lt;= 最好的val_loss-delta,说明val_loss一直在下降，即更新最高的val_loss</li><li>总结：即val_loss在连续patience内，都没有显著下降(current_loss &lt;= best_loss - delta)，则停止训练</li></ul></li><li>卷积尺寸大小变化<br>（1）2D卷积，输入和输出形状一样：一般kernel_size=(3,3),padding=1,stride=1，输入和输出的形状一样<br>（2）2D卷积，输入和输出高和宽减半：kernel_size=(3,3),padding=1,stride=2，输出的形状是输入一半<br>（3）3D卷积，一般kernel_size=(3,3,3),padding=1,stride=1，输入和输出的形状一样<br>（4）3D卷积，一般kernel_size=(1,1,1),padding=0,stride=1，输入和输出的形状一样</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;title: 神经网络踩坑&lt;br&gt;date: 2019-07-17T16:08:20.000Z&lt;br&gt;categories: Deep Learning&lt;br&gt;tags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;训练经验&lt;/li&gt;
&lt;li&gt;踩坑&lt;br&gt;comments: false&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;参考资料:&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650729285&amp;amp;idx=1&amp;amp;sn=8f78edc716bbd2198cd7b14f62a93298&amp;amp;chksm=871b2f3bb06ca62d60632da0faebbee63068405a5841934ebec300dc4bbace4b5e6f79daaeed&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=07263lmMeeAcHLPSZpJXJI3L#rd&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650729285&amp;amp;idx=1&amp;amp;sn=8f78edc716bbd2198cd7b14f62a93298&amp;amp;chksm=871b2f3bb06ca62d60632da0faebbee63068405a5841934ebec300dc4bbace4b5e6f79daaeed&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=07263lmMeeAcHLPSZpJXJI3L#rd&lt;/a&gt;   &lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/07/16/%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E5%92%8C%E8%A1%B0%E5%87%8F/"/>
    <id>http://yoursite.com/2019/07/16/梯度爆炸和衰减/</id>
    <published>2019-07-16T03:14:49.985Z</published>
    <updated>2020-01-22T13:22:53.353Z</updated>
    
    <content type="html"><![CDATA[<hr><p>title: 梯度爆炸和衰减<br>date: 2019-07-16T11:14:49.000Z<br>categories: Deep Learning<br>tags:</p><ul><li>反向传播</li><li>梯度爆炸</li><li>梯度衰减<br>comments: false</li></ul><hr><a id="more"></a>    <p>参考资料：<a href="https://zhuanlan.zhihu.com/p/33006526" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/33006526</a><br><a href="http://wangxin123.com/2019/01/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/#什么是梯度消失和梯度爆炸，分别会引发什么问题" target="_blank" rel="noopener">http://wangxin123.com/2019/01/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/#什么是梯度消失和梯度爆炸，分别会引发什么问题</a></p><h1><span id="为什么使用梯度更新规则">为什么使用梯度更新规则</span></h1><p>&ensp;&ensp;&ensp;&ensp;现在，神经网络的参数都是通过反向传播更新的。深层神经网络由很多分线性层堆叠，每一个非线性层都可以看做是一个非线性函数。神经网络就是一个复合的非线性函数，将输入映射成输出。损失函数就是使关于真实值与预测值之间的误差。通过损失函数对参数求导，得到梯度，梯度的含义就是这个参数对整个网络的影响程度大小。使用梯度下降更新参数。<br>梯度决定了网络（参数）的学习速率。如果梯度出现异常，参数更新出现异常，即神经元失去了学习的能力。<br>如果权重的值都小于1，最终的输出很小，<br>如果权重的值都大于1，最终的输出很大，</p><ul><li>在反向求导时，假设对$W^1$求梯度，如果其他的权重都小于1，求得的梯度很小，出现梯度消失，使用$W-\alpha \Delta W$，权重更新的很慢，训练的难度大大增加。<strong>梯度消失比梯度爆炸更常见</strong>   </li><li>在反向求导时，如果权重大于1，梯度大幅度更新，网络变得很不稳定。较好的情况是网络无法利用训练数据学习，最差的情况是梯度或权重增大溢出，变成网络无法更新的Nan值。<br>不用层的参数更新速率不一样，一般靠近网络输出层的参数更新速度加快，学习的情况较好。靠近网络输入层的参数更新速度慢，学习的很慢，有时候训练了很久，前几层的权重参数值和刚开始初始化的值差不多。因此，梯度消失和爆炸的根本原因在于反向传播法则。<br><img src="/2019/07/16/梯度爆炸和衰减/1.png" alt="">       <h1><span id="激活函数">激活函数</span></h1>（1）在权重更新的时候，需要计算前层的偏导信息，因此如果激活函数选择的不合适，比如sigmoid，梯度消失的很明显。因为sigmoid的导数不会超过0.25，经过链式求导，很容易出现梯度消失。<br><img src="/2019/07/16/梯度爆炸和衰减/sigmoid.png" alt=""><br>（2）tanh比sigmoid好一些，但是它的导数仍然小于1<br><img src="/2019/07/16/梯度爆炸和衰减/tanh.png" alt="">    <h1><span id="初始化缓解梯度消失和爆炸">初始化缓解梯度消失和爆炸</span></h1>使用Xavier初始化：基本思想是通过网络层时，输出和输出的方差相同。Xavier在tanh中表现很好，但在Relu激活函数中表现很差。<br>何凯明提出了针对Relu的初始化方法<br>Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification He, K. et al. (2015)<br>该方法集合He initialization，简单思想是：在Relu网络中，假定每一层有一半的神经元被激活，另一半为0，所有，要保持方差不变，只需要在Xavier的基础上再除以2。<br>针对Relu的激活函数，基本使用He initialization。   </li><li>Xavier初始化：tanh，sigmoid激活函数</li><li>He初始化：Relu激活函数<h1><span id="如何判断出现梯度爆炸">如何判断出现梯度爆炸</span></h1>当出现以下信号时，说明出现了梯度爆炸：</li></ul><ol><li>训练过程中，每个节点和层的权重梯度连续大于1</li><li>模型不稳定，梯度显著变化，快速变大</li><li>训练过程中，权重变成了Nan</li><li>权重无法从训练数据中更新</li></ol><h1><span id="如何解决梯度爆炸">如何解决梯度爆炸</span></h1><ol><li>梯度剪切<br>此方法针对梯度爆炸提出来的，基本思想是设置一个梯度剪切阈值，然后更新梯度的时候，如果梯度超过了这个阈值，就强制限制在这个范围之，这可以防止梯度爆炸。</li><li>权重正则化<br>比较常见的是L1正则化和L2正则化。正则化是通过对网络权重做正则化限制过拟合<br><img src="/2019/07/16/梯度爆炸和衰减/reg.png" alt="">    </li><li>Relu，LeakRelu激活函数<br>如果激活函数的导数为1，就不存在梯度爆炸的问题了。每层网络都可以得到相同的更新速度。在深层网络中使用relu激活函数不会导致梯度消失和爆炸的情况。<br><img src="/2019/07/16/梯度爆炸和衰减/relu.png" alt=""><br>relu的主要贡献在于：<ul><li>解决了梯度消失、爆炸的问题</li><li>计算方便，计算速度快</li><li>加速了网络的训练<br>同时也存在一些缺点：由于负数部分恒为0，会导致一些神经元无法激活（可通过设置小学习率部分解决）；输出不是以0为中心的</li></ul></li><li>BatchNorm </li><li>RestNet</li><li>LSTM，可以解决梯度消失的问题</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;title: 梯度爆炸和衰减&lt;br&gt;date: 2019-07-16T11:14:49.000Z&lt;br&gt;categories: Deep Learning&lt;br&gt;tags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;反向传播&lt;/li&gt;
&lt;li&gt;梯度爆炸&lt;/li&gt;
&lt;li&gt;梯度衰减&lt;br&gt;comments: false&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Dataset</title>
    <link href="http://yoursite.com/2019/07/12/Dataset/"/>
    <id>http://yoursite.com/2019/07/12/Dataset/</id>
    <published>2019-07-12T06:22:25.000Z</published>
    <updated>2020-01-22T13:23:33.782Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="数据">数据</span></h1><a id="more"></a>  <p>滴滴数据集：<a href="https://outreach.didichuxing.com/app-vue/dataList" target="_blank" rel="noopener">https://outreach.didichuxing.com/app-vue/dataList</a><br>京东城市计算：<a href="http://urban-computing.com/index-40.htm" target="_blank" rel="noopener">http://urban-computing.com/index-40.htm</a><br>NYC crash数据：<a href="https://data.cityofnewyork.us/Public-Safety/Vision-Zero-View-Data/v7f4-yzyg" target="_blank" rel="noopener">https://data.cityofnewyork.us/Public-Safety/Vision-Zero-View-Data/v7f4-yzyg</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;数据&quot;&gt;&lt;a href=&quot;#数据&quot; class=&quot;headerlink&quot; title=&quot;数据&quot;&gt;&lt;/a&gt;数据&lt;/h1&gt;
    
    </summary>
    
      <category term="Dataset" scheme="http://yoursite.com/categories/Dataset/"/>
    
    
      <category term="交通领域数据源" scheme="http://yoursite.com/tags/%E4%BA%A4%E9%80%9A%E9%A2%86%E5%9F%9F%E6%95%B0%E6%8D%AE%E6%BA%90/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/07/01/Deep-Spatio-Temporal-Residual-Networks-for-Citywide-Crowd-Flows-Prediction/"/>
    <id>http://yoursite.com/2019/07/01/Deep-Spatio-Temporal-Residual-Networks-for-Citywide-Crowd-Flows-Prediction/</id>
    <published>2019-07-01T13:02:12.664Z</published>
    <updated>2020-01-22T13:24:08.308Z</updated>
    
    <content type="html"><![CDATA[<hr><p>title: Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction<br>date: 2019-07-01T21:02:12.000Z<br>categories: 论文阅读笔记<br>tags:</p><ul><li>spatial-temporal</li><li>ResNet</li><li>Crowd Flows Prediction<br>comments: false</li></ul><hr><h1><span id="简介">简介</span></h1><p>参考资料<br><a href="https://www.microsoft.com/en-us/research/publication/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/" target="_blank" rel="noopener">https://www.microsoft.com/en-us/research/publication/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/</a><br>城市计算，郑宇发表的论文：<br><a href="https://www.microsoft.com/en-us/research/project/urban-computing/#!publications" target="_blank" rel="noopener">https://www.microsoft.com/en-us/research/project/urban-computing/#!publications</a><br><a id="more"></a>   </p><h1><span id="abstract">Abstract</span></h1><p>&ensp;&ensp;&ensp;&ensp;预测人群流量对于公共安全是非常重要的，同时也有挑战，因为涉及到很多复杂的因素。例如区域间交通、时间、以及天气。我们提出了一个基于深度学习的方法：ST-ResNet，预测城市中每个区域的inflow和outflow。基于时空数据，我们设计了端到端结构的ST-ResNet。我们应用残差神经网络框架来建模时间closeness、period和trend的属性。对每一个属性，设计一个残差卷积单元分支，每个残差卷积单元对空间进行建模。三个残差神经网络对每个区域分配不同的权重。残差神经网络的输出再和外部因素（天气）整合，最终预测每个区域的人流量。在北京和NYC2种数据集上做了实验。</p><h1><span id="instruction">Instruction</span></h1><p>&ensp;&ensp;&ensp;&ensp;在这篇论文中，预测2种流量：inflow和outflow。inflow：在给定一个时间间隔中，从其他区域进入到一个区域的所有流量。outflow：在给定时间间隔中，从这个区域离开的流量。这2种流量都标识人迁移的变化。inflow/outflow可以由行人的数量、周围路上车的数量、公共交通系统（bus,metro）上的人数量或者它们的总和（如果都可以获取到）。 例如图1中的(b)，可以通过手机信号来推测人inflow/outflow分别是(3,1)，使用车辆的GPS轨迹，推测处inflow/outflow分别是(0,3)。<br><img src="/2019/07/01/Deep-Spatio-Temporal-Residual-Networks-for-Citywide-Crowd-Flows-Prediction/figure1.png" alt=""><br>&ensp;&ensp;&ensp;&ensp;预测城市中每个区域的inflow和outflow有以下3个复杂的因素：</p><ol><li>空间依赖。例如图1中(2)，r2的inflow会受到邻近区域(r1)和偏远区域的outflow影响，相反，r2的outflow也会影响其他区域的inflow。同时r2的inflow也会影响自身的outflow。</li><li>时间依赖。一个区域的流量受到邻近和较远时间段的影响。例如，在上午8点发生交通阻塞将会影响9点的traffic。并且，早上高峰时的交通情况可能其连续工作日的同一时刻相似。当温度变得越来越低，太阳升的越来越晚，人们也起的越来越晚。</li><li>外部因素影响。一些外部因素，像天气，事故可能会影响不同区域的flow。<br>&ensp;&ensp;&ensp;&ensp;为了处理这些挑战，提出ST-RestNet，模型的贡献主要如下：</li></ol><ul><li>ST-ResNet使用基于卷积的残差网络，来建模周围和较远任意2个地区的空间依赖。同时保证模型的准确率不包含在神经网络的深层架构中（？？？）  </li><li>将流量的时间属性总结为3类，分别是closeness、period、trend。ST-ResNet使用3个残差网络分别对这3个属性建模</li><li>ST-ResNet为不同的分支和区域分配不同的权重，动态整合以上3个网络的输出。然后再和外部因素进行整合。</li><li>使用北京出租车轨迹数据和NYC自行车轨迹数据来做实验。有6个baseline。<h1><span id="preliminaries">Preliminaries</span></h1></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;title: Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction&lt;br&gt;date: 2019-07-01T21:02:12.000Z&lt;br&gt;categories: 论文阅读笔记&lt;br&gt;tags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;spatial-temporal&lt;/li&gt;
&lt;li&gt;ResNet&lt;/li&gt;
&lt;li&gt;Crowd Flows Prediction&lt;br&gt;comments: false&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;p&gt;参考资料&lt;br&gt;&lt;a href=&quot;https://www.microsoft.com/en-us/research/publication/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.microsoft.com/en-us/research/publication/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/&lt;/a&gt;&lt;br&gt;城市计算，郑宇发表的论文：&lt;br&gt;&lt;a href=&quot;https://www.microsoft.com/en-us/research/project/urban-computing/#!publications&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.microsoft.com/en-us/research/project/urban-computing/#!publications&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/07/01/Tomcat/"/>
    <id>http://yoursite.com/2019/07/01/Tomcat/</id>
    <published>2019-07-01T00:55:23.474Z</published>
    <updated>2020-01-22T13:28:07.355Z</updated>
    
    <content type="html"><![CDATA[<hr><p>title: Tomcat<br>date: 2019-07-01T08:55:23.000Z<br>categories: Java<br>tags:</p><ul><li>JVM</li><li>Tomcat<br>comments: false</li></ul><hr><h1><span id="简介">简介</span></h1><p>&ensp;&ensp;&ensp;&ensp;<br>参考资料<a href="https://www.cnblogs.com/centos2017/p/9956432.html" target="_blank" rel="noopener">https://www.cnblogs.com/centos2017/p/9956432.html</a><br><a id="more"></a>   </p><h1><span id="内存溢出">内存溢出</span></h1><p>在Tomcat时，常常会遇到内存溢出的错误，主要是以下2种：</p><ul><li>java.lang.OutOfMemoryError: Java heap space   </li><li>java.lang.OutOfMemoryError: PermGen space       </li></ul><h1><span id="原理">原理</span></h1><ul><li>-Xms 为jvm启动时分配的初始内存      比如-Xms200m，表示分配200M</li><li>-Xmx 为jvm运行分配的最大内存        比如-Xms500m，表示jvm进程最多只能够占用500M内存</li><li>-Xss 每个线程堆栈的大小             一般情况下256K是足够了。影响了此进程中并发线程数大小</li><li>-XX  PermSize=64M JVM初始分配的非堆内存</li><li>-XX  MaxPermSize=128M JVM最大允许分配的非堆内存，按需分配<br>首先了解一下JVM内存管理的机制，然后解释每个参数的含义。<br>按照官方的说法：Java虚拟机具有一个堆，堆是运行时数据区域，所有类实例和数组的内存均从此处分配。堆是在Java虚拟机启动时创建的。<br>在JVM中堆之外的内存称为非堆内存（Non-heap memory）。<br>简单来说，堆就是Java代码可及的内存，是留给开发人员使用的，非堆就是JVM留给自己用的。<h2><span id="堆heap内存">堆Heap内存</span></h2></li><li>JVM初始分配的堆内存由-Xms指定，默认是物理内存的1/64；</li><li>JVM最大分配的堆内存由-Xmx指定，默认是物理内存的1/4。<br>默认空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制；<br>空余堆内存大于70%时，JVM会减少堆直到-Xms的最小限制。<br><strong>因此服务器一般设置-Xms、-Xmx 相等，以避免在每次GC 后调整堆的大小</strong>。<br>说明：如果-Xmx 不指定或者指定偏小，应用可能会导致java.lang.OutOfMemoryError: Java heap space错误，此错误来自JVM，不是Throwable的，无法用try…catch捕捉。   <h2><span id="非堆内存分配">非堆内存分配</span></h2></li><li>JVM使用-XX:PermSize设置非堆内存初始值，默认是物理内存的1/64；</li><li>由XX:MaxPermSize设置最大非堆内存的大小，默认是物理内存的1/4。<br>XX:MaxPermSize设置过小会导致java.lang.OutOfMemoryError: PermGen space 就是内存益出。<br>为什么会内存益出：<br>（1）这一部分内存用于存放Class和Meta的信息，Class在被 Load的时候被放入PermGen space区域，它和存放Instance的Heap区域不同。<br>（2）GC(Garbage Collection)不会在主程序运行期对PermGen space进行清理，所以如果你的APP会LOAD很多CLASS 的话,就很可能出现PermGen space错误。<br>这种错误常见在web服务器对JSP进行pre compile的时候。   <h1><span id="解决方案">解决方案</span></h1>(1) 进入到tomcat的/bin目录下<br>在bin目录下，创建一个新的文件，<br>如果是Linxu或Mac系统，创建setenv.sh<br>如果是Windows系统，创建setenv.bat<br>(2) 添加配置（Linux/Mac）<br>在这个文件中添加以下内容  <figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">CATALINA_OPTS</span>=<span class="string">"<span class="variable">$CATALINA_OPTS</span> -Xms2048m"</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">CATALINA_OPTS</span>=<span class="string">"<span class="variable">$CATALINA_OPTS</span> -Xmx2048m"</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">CATALINA_OPTS</span>=<span class="string">"<span class="variable">$CATALINA_OPTS</span> -XX:MaxPermSize=512m"</span></span><br><span class="line">```       </span><br><span class="line"></span><br><span class="line">如果是Windows系统，使用以下配置</span><br></pre></td></tr></table></figure></li></ul><p>set “JAVA_OPTS=%JAVA_OPTS% -Xms2048m -Xmx2048m-XX:MaxPermSize=512m -server”<br><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">(<span class="number">3</span>) 完成以上配置后，启动Tomcat服务可以使用以下<span class="number">2</span>种命令(Linux/Mac)：</span><br></pre></td></tr></table></figure></p><p>cd apache/bin<br>./catalina.sh run或者./startup.sh<br>```        </p><p>如果是Windows系统，使用catalina.bat启动Tomcat服务<br>(4) 查看log日志<br>在日志中，启动Tomcat时，可以看到刚刚配置的参数。</p>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;title: Tomcat&lt;br&gt;date: 2019-07-01T08:55:23.000Z&lt;br&gt;categories: Java&lt;br&gt;tags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;JVM&lt;/li&gt;
&lt;li&gt;Tomcat&lt;br&gt;comments: false&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;&lt;br&gt;参考资料&lt;a href=&quot;https://www.cnblogs.com/centos2017/p/9956432.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.cnblogs.com/centos2017/p/9956432.html&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/06/24/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/"/>
    <id>http://yoursite.com/2019/06/24/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/</id>
    <published>2019-06-24T00:43:06.723Z</published>
    <updated>2020-01-22T13:27:15.172Z</updated>
    
    <content type="html"><![CDATA[<hr><p>title: &gt;-<br>  MiST-A Multiview and Multimodal Spatial-Temporal Learning Framework for<br>  Citywide Abnormal Event Forecasting<br>date: 2019-06-24T08:43:06.000Z<br>categories: 论文阅读笔记<br>tags:</p><ul><li>Abnomaly Event Forecasting<br>comments: false</li></ul><hr><h1><span id="1-简介">1. 简介</span></h1><p><a href="http://delivery.acm.org/10.1145/3320000/3313730/p717-huang.pdf?ip=218.247.253.153&amp;id=3313730&amp;acc=ACTIVE%20SERVICE&amp;key=BF85BBA5741FDC6E%2EB8E1436BD1CE5062%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1561380383_40e3bd8d678088e9b04173b89f85c49c" target="_blank" rel="noopener">论文出处</a><br><a id="more"></a><br><!-- TOC --></p><ul><li><a href="#1-简介">1. 简介</a></li><li><a href="#2-keywords">2. Keywords</a></li><li><a href="#3-abstract">3. Abstract</a></li><li><a href="#4-introduction">4. Introduction</a></li><li><a href="#5-problem-formulation">5. Problem Formulation</a><ul><li><a href="#51-preliminaries">5.1. Preliminaries</a></li><li><a href="#52-framework-overview">5.2. Framework Overview</a></li></ul></li><li><a href="#6-methodology">6. Methodology</a><ul><li><a href="#61-context-aware-recurrent-framework">6.1. Context-aware Recurrent Framework</a></li><li><a href="#62-multi-modal-pattern-fusion-module">6.2. Multi-Modal Pattern Fusion Module</a></li><li><a href="#63-conclusive-recurrent-network">6.3. Conclusive Recurrent Network</a></li><li><a href="#64-forecasting-and-model-inference">6.4. Forecasting and Model Inference</a></li></ul></li><li><a href="#7-evaluation">7. Evaluation</a><ul><li><a href="#71-data-description">7.1. Data Description</a><ul><li><a href="#711-data-statistics">7.1.1. Data Statistics</a></li></ul></li><li><a href="#72-experimental-setting">7.2. Experimental Setting</a><ul><li><a href="#721-parameter-setting">7.2.1. Parameter Setting</a></li><li><a href="#722-baseline-methods">7.2.2. Baseline Methods</a></li><li><a href="#723-evaluation-protocols">7.2.3. Evaluation Protocols</a></li></ul></li><li><a href="#73-performance-comparison">7.3. Performance Comparison</a><ul><li><a href="#731-overall-comparisonq1">7.3.1. Overall Comparison(Q1)</a></li><li><a href="#732-forecasting-accuracy-vs-time-periodq2">7.3.2. Forecasting Accuracy v.s Time Period(Q2)</a></li><li><a href="#733-forecasting-accuracy-vs-categoriesq3">7.3.3. Forecasting Accuracy v.s Categories(Q3)</a></li></ul></li><li><a href="#74-component-wise-evaluation-of-mistq4">7.4. Component-Wise Evaluation of MiST(Q4)</a></li><li><a href="#75-effect-of-spatial-and-temporal-scaleq5">7.5. Effect of Spatial and Temporal Scale(Q5)</a></li><li><a href="#76-hyperparameters-studiesq6">7.6. Hyperparameters Studies(Q6)</a></li><li><a href="#77-case-studyq7">7.7. Case Study(Q7)</a></li></ul></li><li><a href="#8-conclusion">8. Conclusion</a></li><li><a href="#9-该作者其他论文">9. 该作者其他论文</a></li><li><a href="#10-anomaly检测领域的其他论文">10. Anomaly检测领域的其他论文：</a></li></ul><!-- /TOC --><h1><span id="2-keywords">2. Keywords</span></h1><p><strong>异常事件预测、深度神经网络、时空数据挖掘</strong> </p><h1><span id="3-abstract">3. Abstract</span></h1><p>&ensp;&ensp;&ensp;&ensp;<font color="#FF0000">[应用]</font>城市异常事件，比如犯罪、事故，如果不及时处理的话，会造成人员和财产的损失。如果异常事件能在发生之前自动被预测出来，对很多领域都有重要意义，比如公共秩序维护、灾难控制和人的活动建模。<font color="#FF0000">[挑战]</font>然而，预测不同类型的城市异常事件是非常有挑战的，因为它被很多复杂的因素影响。(i)区域内动态的时间关系；(ii)区域间复杂的空间关系；(iii)潜在的类别之间的关系。<font color="#FF0000">[模型]</font>在这篇论文中，我们研究了一个<strong>Multi-View and Multi-Modal Spatial-Temporal learning多视角和多模态的时空学习框架(MiST)</strong> 来解决以上的挑战，通过增强不同视角（空间、时间和语义）的相关性，和将多模态单元映射到相同的潜在空间。特别的，将多模态模式融合架构和分层循环框架进行整合，MiST可以保留多视角异常事件数据的潜在的结果信息，和自动地学习特定视角表示的重要性。在三个真实数据集上的实验，例如：犯罪数据和城市异常数据，表明我们MiST模型比其他先进的模型效果都好。   </p><h1><span id="4-introduction">4. Introduction</span></h1><p>&ensp;&ensp;&ensp;&ensp;城市异常事件，比如犯罪(抢劫、袭击)和城市异常(道路封锁、噪声)如果不及时处理，对公共安全有很大的风险。据统计，异常造成了很大的损失，因为准确和可靠的预测异常事件是数据驱动的决策者用于减少人和经济的损失迫切的需求。<font color="#FF0000">[应用]</font>例如，在灾难控制中，通过预测未来的异常事件，当地政府可以设计更好的交通规划和移动管理策略来防止严重的社会骚乱。此外，在公共秩序维护上，了解城市每个区域的异常事件潜在的发生模式对人们活动建模和地方推荐任务是非常重要的。在这篇论文中，我们旨在提前预测城市中不同区域不同类型的异常事件，为社会福利给予重大的提高。<br>&ensp;&ensp;&ensp;&ensp;<font color="#FF0000">[前人工作]</font>前人已经有一些研究关于使用时空数据检测地理异常。大部分这些研究都是通过分析被研究对象的历史轨迹和移动模式，使用统计和数据挖掘的方法来发现异常事件。然而，这些方法并不是预测将来的时间，而是在它们发生之后鉴定是不是异常事件，这会造成信息延迟和缺乏异常处理的提前准备。<br>&ensp;&ensp;&ensp;&ensp;从多个角度，我们确定了建模这种异常事件数据的三个挑战。<font color="#FF0000">[挑战]</font><br>&ensp;&ensp;&ensp;&ensp;<font color="#FF0000">[考虑空间关系]</font>第一，在城市中异常事件的分布是变化的，并且不同区域异常事件的分布是不同的。在这种情况下，异常事件的发生不再是区域独立的，在预测异常事件时，考虑不同区域的空间关系是非常重要的。并且，当建模动态空间关系对时，概率图模型将不再有效，由于概率图模型基于先验假设分布有很多的参数，涉及大量的计算。<br>&ensp;&ensp;&ensp;&ensp;<font color="#FF0000">[时间动态依赖]</font>第二，异常事件的发生模式经常涉及到随时间变化的潜在因素。例如，工作日的犯罪因果性和周末可能不同。传统的时间序列预测技术，像ARIMA和SVR被限制在线性模型，它仅依赖于单级周期模式。因此，这些方法很难在时间动态上预测异常事件。<br>&ensp;&ensp;&ensp;&ensp;<font color="#FF0000">[不同类别的异常事件间相互影响]</font>第三，不同类别的异常事件有着显示和隐示的影响。例如，一个区域的抢劫可能会引发该区域的交通堵塞，由于人群的聚集和巡逻的增加。因此，一种类别异常事件的发生不仅仅来源于不同区域之间的空间关系和时间槽之间的时间依赖，还可能来源于不同类别异常事件的相互影响。<br>&ensp;&ensp;&ensp;&ensp;<font color="#FF0000">[模型3个阶段]</font>受以上挑战的启发，该工作提出了一个通用且灵活的框架：Multi-View Deep Spatial-Temporal Networks(MiST)，从多视角异常事件数据的关系中学习预测结构。特别的，在第一阶段，我们提出了上下文感知context-aware的循环框架从不同的角度来捕获异常事件数据的时间动态性，并且自动提供了某个视角的表示。在第二阶段，为了将区域间的关系、不同类别间的影响和已编码的多维度数据的时间模式整合起来，我们基于attention机制提出了一个模式融合模块，来促进不同视角的融合，并且在预测模型的相应视角，自动地捕获关联区域、时间槽、类别的贡献。为了增强MisT模型的时间序列结构信息和非线性，在最后阶段设计了一个总结性的循环网络模块，对融合嵌入向量的序列模式进行建模。最终的总结潜在表示被喂入一个全连接神经网络来预测未来时间槽的异常事件。<br>&ensp;&ensp;&ensp;&ensp;综上所述，我们贡献主要是：</p><ul><li>我们引入了一个新的多视角和多模态时空学习框架MiST来预测一个城市每个区域不同类型的异常事件。MiST映射所有的空间时间和语义单元到一个潜在空间来保留它们跨模态的相关性。</li><li>我们提出了一个多模态融合模型，和分层循环框架，学习共享在多视角数据中潜在的区域-时间-类别关系，并且自动地调整每个视角中的相关性，以协助预测任务。</li><li>在三个真实世界异常事件数据集，从NYC和Chicago收集的数据集进行试验，MiST一直比其他state-of-the-art方法效果好。     </li></ul><h1><span id="5-problem-formulation">5. Problem Formulation</span></h1><p>&ensp;&ensp;&ensp;&ensp;在这一节，首先引出preliminary和problem。</p><h2><span id="51-preliminaries">5.1. Preliminaries</span></h2><ul><li>定义1 Geographical Region(地理区域)<br>把城市进行网格分区。划分成$I \times J$,有$I$行$J$列，带有经纬度信息。每一个网格被视为一个地理区域，表示为$r_{i,j}$，其中$i和j$是分别是行和列的索引。在这篇论文中，我们使用区域作为最小单元来研究异常事件预测问题。<br>&ensp;&ensp;&ensp;&ensp;我们定义地理区域集合$R=(r_{1,1},…,r_{i,j},…,r_{I,J})$,并且假设有$L$个异常事件类别，$C=(c_1,…,c_l,…,c_L)$,其中$C$表示异常事件类别集合，下标为$l$。给定一个时间窗口$T$,我们分割$T$为不重叠且连续的时间槽$(T=(t_1,…,t_k,…,t_K))$,其中$K$表示时间槽的个数，索引是$k$.<br><strong><script type="math/tex">区域R是I \times J;异常事件类别C，有L个值;     时间T，有K个时间槽</script></strong></li><li>定义2 Abnormal Event Data Source(异常事件数据源)<br>假设一个区域$r_{i,j}$，使用$Y_{i,j}=(y^1_{i,j},…,y^l_{i,j},…,y^L_{i,j}) \in \mathbb{R}^{L \times K}$来表示在区域$r_{i,j}$过去$K$个时间槽发生的所有类型的异常事件。对于$y^l_{i,j} \in \mathbb{R}^K$表示区域$r_{i,j}$在类别$c_l$上从时间$t_1到t_K$的值。在$y^l_{i,j}$中，每一个元素$y^{l,k}_{i,j}$为1如果在区域$r_{i,j}$在时间$t_k$中有类别$c_l$异常事件发生，否则为0。<br>即$Y_{i,j}$是一个矩阵，一共有$L行K列$，每一个元素非0即1，其中每一行表示一种类别，每一列表示一个时间段。</li><li><strong>Problem Statement</strong><br><font color="#FF0000">[任务]</font>给定一个城市区域$R$时间从$t1到t_K$,所有异常事件类别的数据源$Y$，其中$Y$有$I \times J$个矩阵，每个矩阵都是$\mathbb{R}^{L \times K}$。目标是学习一个预测框架来推断一个区域$r_{i,j}$在未来$h$个时间槽，异常事件类别$c_l$是否发生。即计算$(y^{l,(K+h)}_{i,j}|Y_{i,j}=(y^1_{i,j},…,y^L_{i,j}));i,j \in [1,…,I],[1,…,J]$。即给定一个区域历史$K$个时间槽所有类别异常事件发生地数据，来预测这个区域在未来第$K+h$个时间槽，类别$l$事件是否发生，即输出结果是0/1。 </li></ul><h2><span id="52-framework-overview">5.2. Framework Overview</span></h2><p>&ensp;&ensp;&ensp;&ensp;我们提出的MiST模型是一个多层表示学习框架，如figure1所示。在详细介绍模型之前，首先介绍一下模型的输入，然后详细介绍设计的动机。</p><ul><li>定义3 Event Context Tensor(事件上下文张量)<br>给定一个目标区域$r_{i,j}$，使用event context tensor$\mathcal{A}^k_{i,j} \in \mathbb{R}^{I \times J \times L}$，对这个区域的邻近区域在时间段$t_k$中不同类别的异常事件进行建模。$\mathcal{A}^k_{i,j} \in \mathbb{R}^{I \times J \times L}$，有3个维度，分别表示$I行J列L个类别$。给定一个时间槽$t_k,\mathcal{A}^k_{i,j,l}$为1如果？？？？？,</li><li><strong>Context-aware Recurrent Framework</strong><br>为了从时间角度，就异常事件分布的动态属性方面表示区域内的相关性，我们提出了基于LSTM的context encoder，将每个时间槽的$\mathcal{A}$展开形成的向量中的每个元素，学习一个潜在表示。从我们的LSTM encoder中学习到的表示，可以对异常事件的时间依赖特性建模，还可以捕获异常事件的局部时间上下文和多层周期模式。  </li><li><strong>Multi-Modal Pattern Fusion Mudule</strong><br>为了捕获异常事件分布，在区域间和不同类别的关系，我们提出了深度融合模块，用于同时对周围地理区域和不同类别的异常事件的固有发生模式进行建模。我们将$K(表示K个时间槽)$个张量$\mathcal{A}^k_{i,j} \in \mathbb{R}^{I \times J \times L}$按照时间进行排序，然后对于每一个时间槽$t_k$都有一个张量$\mathcal{A}^k_{i,j}$,将它的隐藏向量表示，应用attention机制，从空间-类别视图生成summarized嵌入向量。</li><li><strong>Conclusive Recurrent Networks</strong><br>依赖从空间-时间-类别视图生成的隐藏表示，我们提出一个conclusive recurrent networks来有效地捕获位置、时间、类别多模态的序列模式。最终的spatial-temporal-categorical多视图序列表示被保存在conclusive recurrent network单元格的最终状态，在解码阶段为预测异常发生的概率提供了指导。<br><img src="/2019/06/24/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/figure1.png" alt=""><br>输入的数据A是非0即1的张量，表示目标区域和邻居发生异常事件的情况。先选中一个目标区域$r_{i,j}$，找出这个区域的邻居$r_{i\prime,j\prime} \in G(i,j)$。flatten得到的是目标区域和邻居的值，就是0或1值，然后选中一个区域，有K个时间段，得到一个区域在一个异常类别上的时间序列，例如0110…，然后输入到LSTM中，每一步都可以得到一个隐藏状态。所以第一个时间段第一个异常类别，会有很多个隐藏状态，假设目标区域和其邻域共有9个区域，则第一个时间步第一个类别会输出9个隐藏状态。这样每个区域在每个类别上，每个时间步上都会得到一个隐藏状态。只是对一个区域进行建模，没有涉及到邻居和类别。在第二步使用Attention，获取每个区域的得到，就是把这个区域所有的特征全都塞到一个全连接神经网络中，一个区域的特征有3个，LSTM输出的隐藏状态，这个区域的嵌入表示，异常类别的嵌入表示，根据这3个特征得到这个区域的得分，然后将每个区域的得分使用softmax归一化。然后将得分再乘上一个隐藏状态得到每个时间步的表示。再将每个时间步的表示作为一个序列传入到LSTM中，将最终的隐藏状态传入到MLP中。最后预测的值是一个概率，表示这个区域在这个时间段发生这个类别的异常事件的概率。<h1><span id="6-methodology">6. Methodology</span></h1><h2><span id="61-context-aware-recurrent-framework">6.1. Context-aware Recurrent Framework</span></h2>&ensp;&ensp;&ensp;&ensp;在MiST架构中，在异常事件在时间槽$t_1到t_k$的分布，我们首先采用LSTM网络来编码复杂的的区域内相关性。特别，LSTM包含1个记忆细胞状态和3个控制门通过分别执行写、读、重置操作来更新记忆细胞状态。用公式表示，区域$r_{i,j}$和异常类别$c_l$在第$t$个时间槽的隐藏状态$h^t_{i,j,l}$和记忆细胞状态$c^t_{i,j,l}$计算公式如下：<br><img src="/2019/06/24/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/1.png" alt=""><br>&ensp;&ensp;&ensp;&ensp;其中$W_<em> \in \mathbb{R}^{d_s \times d_s}$表示前一个状态$(i.e., c^{t-1}_{i,j,l} \quad and \quad h^{t-1}_{i,j,l})$到当前状态的转换矩阵，$V_</em> \in \mathbb{R}^{d_x \times d_s}$是从输入到当前状态的转换矩阵，$d_x和d_s$分别表示输入向量的维度和隐藏状态的维度，且$b_<em> \in \mathbb{R}^{d_s}$是偏置向量，$\sigma(.)和\phi(.)$分别表示sigmoid和tanh函数。$\odot$表示元素相乘。分别使用$i^t_{i,j,l},o^t_{i,j,l},f^t_{i,j,l}$表示输入门、输出门、遗忘门。为了简单起见，我们用$h^t_{i,j,l}=LSTM(</em>,c^{t-1}_{i,j,l},h^{t-1}_{i,j,l})$表示上面的式1。当然也存在RNN的一些变体，例如GRU。<h2><span id="62-multi-modal-pattern-fusion-module">6.2. Multi-Modal Pattern Fusion Module</span></h2>&ensp;&ensp;&ensp;&ensp;然后直接或间接地应用RNN来解决异常事件预测问题是直观的。一般的RNN不能处理来自其他地理区域和时间类别的影响因素。因此我们进一步使用attention机制来自适应地捕获空间和类别的动态相关性。Attention机制用来推断训练集不同部分的重要性，让学习算法更加关注重要的部分。Attention机制引入一个context vector建模相关性，让编码器-解码器摆脱定长的内部表示。并且，在融合过程中，为了区分区域和类别，用$e_{r_{i,j}} \in \mathbb{R}^{d_e}$表示区域嵌入，用$e_{c_j} \in \mathbb{R}^{d_e}$表示类别嵌入，这两种嵌入在attention机制中会用到。attention的计算公式如下：<br><img src="/2019/06/24/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/2.png" alt=""><br>&ensp;&ensp;&ensp;&ensp;在attention网络中将隐藏表示向量的大小作为attention dimensionality，用$S$表示，其中$d_s$表示LSTM中隐藏状态的维度。$W^k \in \mathbb{R}^{d_s \times S} \quad b^k \in \mathbb{R}^{d_s}$分别表示权重矩阵和偏置向量，将输入映射到隐藏层，得到$\eta^k_{i,j,l}$作为$h^k_{i,j,l}$的隐藏表示。然后我们度量了每个区域$r_{i,j}$每种类别$c_l$的隐藏表示$\eta^k_{i,j,l}$的重要性，归一化得到$\alpha^k_{i,j,l}$。attention中的权重由输入的空间-类别特征$e_{r_{i,j}} \in \mathbb{R}^{d_e},e_{c_j} \in \mathbb{R}^{d_e}$联合决定，在Context-LSTM编码器中编码历史隐藏状态$h^k_{i,j,k}$。在获取attention权重后，在时间段k的输出隐藏表示向量计算如下：<script type="math/tex; mode=display">q^k = \sum_{i,j \in G}\sum_{l=1}^{L} \alpha^k_{i,j,l}h^k_{i,j,l} \tag{3}</script>&ensp;&ensp;&ensp;&ensp;其中$q^k$是$h^k_{i,j,l}$的summarized拼接表示，描述了在区域$r_{i,j}$异常事件的发生，哪个因素更重要。在MiST的训练过程中，带有attention机制的深度融合模块被参数化为前向神经网络，和整个神经网络一起训练。我们提出的方法是非常通用的，可以自动学习不同视图的相关性权重。<h2><span id="63-conclusive-recurrent-network">6.3. Conclusive Recurrent Network</span></h2>&ensp;&ensp;&ensp;&ensp;目前为止，我们已经研究了MiST到的2个组件，(i)从temporal角度，使用context-LSTM建模区域内动态的相关性；(ii)从spatial-categorical角度，使用深度融合模块捕获复杂的区域间和类别见的相关性。经过以上步骤，得到了summarized representation $q^k$，从不同角度使用不同的权重$\alpha^k_{i,j,l}$计算组合表示。<br>&ensp;&ensp;&ensp;&ensp;为了将空间-类别的编码pattern和时间pattern整合在一起，我们提出了用循环神经网络编码多维模式，用潜在空间的表示建模location-time-category之间的关系。在这篇论文中，我们采用LSTM作为循环神经单元，公式如下：<script type="math/tex; mode=display">\xi_k = LSTM(q_{k-1},\xi_{k-1}) \tag{4}</script>&ensp;&ensp;&ensp;&ensp;联合嵌入$\xi$将所有的空间、时间、类别单元映射到一个共同的潜在空间中。提出的conclusive循环神经网络提供了一种灵活的方式让不同的视图彼此合作。将空间、类别上下文信号和时间状态结合，MiST框架可以预测将来异常事件，不仅仅根据时间序列关系，还根据区域间的空间关系和不同类别的共现关系。<h2><span id="64-forecasting-and-model-inference">6.4. Forecasting and Model Inference</span></h2>&ensp;&ensp;&ensp;&ensp;最终，我们利用MLP来解码异常事件出现的概率，通过捕获隐藏向量元素之间的非线性依赖。公式如下：<br><img src="/2019/06/24/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/5.png" alt=""><br>&ensp;&ensp;&ensp;&ensp;其中，$N$表示隐藏层的个数，对于层$\psi_n$，$W_n$和$b_n$表示权重矩阵和偏置向量。我们使用$ReLU,\phi(.)$为全连接层的激活函数。使用$\sigma(.)sigmoid$作为输出层的激活函数，值域在(0,1),输出异常事件发生的概率，在区域$r_{i,j}$时间槽$t_k$异常事件类别$c_l$，例如$y^{l,k}_{i,j}$。<br>&ensp;&ensp;&ensp;&ensp;综上所述，我们的异常事件发生预测可以被看做是一个分类问题。我们利用叫啥上作为损失函数。<br><img src="/2019/06/24/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/6.png" alt=""><br>&ensp;&ensp;&ensp;&ensp;其中，$\hat{y}^{l,k}_{i,j}$表示预测的在区域$r_{i,j}$第$k$个时间段发生第$l$个异常类别事件的概率，$S$是训练集中异常事件的集合。使用Adam优化器来学习参数。<br>算法流程如下：<br><img src="/2019/06/24/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/algo.png" alt="">  <h1><span id="7-evaluation">7. Evaluation</span></h1>在三个真实异常事件数据集上做了实验，数据从NYC和Chicago收集，验证模型的有效性和准确率和其他baseline，通过实验回答以下几个问题</li><li>Q1：和其他state-of-the-art预测方法，在预测全市犯罪和不同城市的异常情况时，MiST可以达到与之媲美的准确率吗？</li><li>Q2：在不同的时间段中，MiST一直比其他的算法表现好吗？</li><li>Q3：和其他state-of-the-art技术相比，MiST模型怎么预测不同种类的异常事件</li><li>Q4：MiST使用不同关键组件的组合形成的变体效果怎么样？</li><li>Q5：MiST在不同的空间和时间范围上表现怎么样？</li><li>Q6：不同的参数设置怎么影响MiST的预测效果？</li><li>Q7：当预测城市异常事件时，怎么解释MiST框架捕获的空间和类别维度的动态重要性权重？<h2><span id="71-data-description">7.1. Data Description</span></h2><h3><span id="711-data-statistics">7.1.1. Data Statistics</span></h3>&ensp;&ensp;&ensp;&ensp;我们从NYC和Chicago收集了2种类型的3个异常事件数据，有2个犯罪数据和1个城市异常数据，通过做实验，预测城市的每个区域发生每种城市犯罪和异常事件的可能性。数据集基本统计如下：<br><img src="/2019/06/24/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/table1.png" alt=""><br>在我们的实验中，我们重点关注了一些关键类别，把其他的类别看做外部类别。我们也给了不同类型和时间周期的异常事件在地理上的分布，如Figure2所示。</li><li>NYC Crime Data(NYC-C)：这个数据集中有多个类别的犯罪记录。每一个犯罪记录有犯罪类别、经纬度、时间。时间跨度为2015.1~2015.12</li><li>NYC Urban Anomaly Data(NYC-A)：这个数据集时间跨度为2014.1~2014.12，从NYC311个非紧急服务中心收集来的，这里记录了不同类别的城市异常。每个记录都有异常类别、经纬度、时间。</li><li>Chicago Crime Data(CHI-C)：从芝加哥收集的2015.1~2015.12不同种类的犯罪记录，记录的个数和NYC类似。<br><img src="/2019/06/24/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/figure2.png" alt=""> <h2><span id="72-experimental-setting">7.2. Experimental Setting</span></h2><h3><span id="721-parameter-setting">7.2.1. Parameter Setting</span></h3>&ensp;&ensp;&ensp;&ensp;在我们的试验中，利用Adam作为优化器，使用Tensorflow实现MiST架构。在LSTM中设置隐藏状态维度$d_s=32$，区域嵌入向量$e_{r_{i,j}}$和类别嵌入向量$e_{c_j}$的维度$d_e=32$，attention的维度$S=32$，MLP的层数为3。batch size=64，学习率=0.001。<h3><span id="722-baseline-methods">7.2.2. Baseline Methods</span></h3></li></ul><p>(i)传统的时间序列预测方法：SVR、ARIMA<br>(ii)传统的有监督学习算法：LR<br>(iii)循环神经网络和它的变体for时空数据预测：ST-RNN 、GRU<br>(iv)先进的神经网络模型for 时间序列和序列模型：RDN、HRN、ARM</p><h3><span id="723-evaluation-protocols">7.2.3. Evaluation Protocols</span></h3><p>&ensp;&ensp;&ensp;&ensp;在实验中，按照时间顺序将数据集划分为训练集(6.5个月)、验证集(0.5个月)和测试集(1个月)。验证集被用来调整超参数，在测试集上进行性能比较。我们把NYC和Chicago划分为248和189个互不相交的区域，每个区域的大小$2km \times 2km$，根据区域划分的结果，我们可以映射每个异常事件(犯罪或城市异常)到一个地理区域中，作为MiST的输入。我们采用2种评价指标来衡量所有的方法。</p><ul><li>(i)使用Macro-F1 和Micro-F1来衡量不同种类犯罪的预测准确率。这2个指标表示了不同类别之间的整体效果。这2个指标的数据定义如下：<br><img src="/2019/06/24/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/micro.png" alt=""><br><img src="/2019/06/24/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/macro.png" alt=""><br>其中$J$是异常事件的种类数。这2个值越高效果越好</li><li>(ii) 使用F1-score和$AUC$来衡量预测一个类别的异常事件发生的准确率。F1和AUC越高，说明预测效果越好。<br>&ensp;&ensp;&ensp;&ensp;为了确保所有方法的性能公平比较，在测试集中预测一段时间连续几天异常事件发生的概率。在评估结果中，一段时间所有天的平均性能作为最终的结果。<h2><span id="73-performance-comparison">7.3. Performance Comparison</span></h2><h3><span id="731-overall-comparisonq1">7.3.1. Overall Comparison(Q1)</span></h3><img src="/2019/06/24/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/table2.png" alt=""></li></ul><p>&ensp;&ensp;&ensp;&ensp;表2显示了不同城市犯罪和城市异常的预测准确率。总结以下3点：<br>&ensp;&ensp;&ensp;&ensp;第一：MiST比其他神经网络方法效果都好。例如，在预测Chicago犯罪时，MiST比最好的模型RDN Macro-F1和Micrl-F1高9.6%和30.9%。<br>&ensp;&ensp;&ensp;&ensp;第二：神经网络方法比传统的时间序列和有监督学习方法效果好。这是由于（1）传统的时间序列预测方法仅仅强调一个固定的时间模式，而不是时间依赖的演变。（2）神经网络方法使用非线性方法捕获多维空间-时间数据的内在结构，这非常有用。<br>&ensp;&ensp;&ensp;&ensp;第三：在循环神经网络中(ST-LSTM和GRU)和深度序列数据模型方法(RDN、HRN、ARM)效果不分上下。这再一次验证了仅仅考虑时间维度的数据依赖在预测犯罪和城市异常发生时不够的。相反，MiST动态关联潜在的空间、时间、类别的关系，表现了很好的灵活性和优越性。</p><h3><span id="732-forecasting-accuracy-vs-time-periodq2">7.3.2. Forecasting Accuracy v.s Time Period(Q2)</span></h3><p>&ensp;&ensp;&ensp;&ensp;对于MiST和其他的baseline，在不同的训练和测试时间段上做了实验。我们发现MiST在不同的测试时间段上一直保持最好的效果。并且也可以发现在MiST和起亚baseline相比，当滑动训练集和测试集的时间窗口时，MiST的效果更稳定，这说明MiST在学习随着时间动态的异常事件分布时更健壮。</p><h3><span id="733-forecasting-accuracy-vs-categoriesq3">7.3.3. Forecasting Accuracy v.s Categories(Q3)</span></h3><p>&ensp;&ensp;&ensp;&ensp;我们测试了MiST在预测单个异常类别事件的有效性，在NYC的犯罪和异常数据、Chicago的犯罪数据集上，结果如figure3和4所示。发现MiST在所有的类别上都取得了最好的效果。另一个发现是MiST在预测building/Use时效果比ST-RNN高了84.1%左右，这说明MiST在预测稀疏异常类别时表现也很好，解决了数据稀疏问题。<br><img src="/2019/06/24/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/figure3.png" alt=""><br><img src="/2019/06/24/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/figure4.png" alt=""></p><h2><span id="74-component-wise-evaluation-of-mistq4">7.4. Component-Wise Evaluation of MiST(Q4)</span></h2><p>为了更的理解MiST，对MiST的不同组件进行组合做了实验。</p><ul><li><strong>Spatial-View+Temporal View</strong> $MiST-st$<br>这个变体捕获了空间和时间依赖，不考虑类别的影响</li><li><strong>Category-view+Temporal View</strong>$MiST-ct$<br>这个变体考虑了累呗和时间依赖，不考虑区域间的空间相关性</li><li><strong>Temporal View</strong>$MiST-t$<br>这个变体仅仅使用LSTM和时间attention机制，不考虑空间和类别。      </li></ul><p>&ensp;&ensp;&ensp;&ensp;结果显示使用全部的组件效果最好，这说明使用一个联合框架是很有必要的，同时捕获空间视图（区域间的空间相关性）、时间视图（区域内的时间相关性）、类别视图（类别间的依赖）。<br><img src="/2019/06/24/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/figure5.png" alt="">   </p><h2><span id="75-effect-of-spatial-and-temporal-scaleq5">7.5. Effect of Spatial and Temporal Scale(Q5)</span></h2><p>&ensp;&ensp;&ensp;&ensp;进一步研究了空间和时间范围的影响。在event context tensor$\mathcal{A}$中，网格地图的地理范围$G=I \times J$，在我们的实验中$I=J$，循环框架中时间序列长度为$T$。 在十月份的Crime上做了实验，实验结果如图6所示：2个结论，（1） 随着I和J的增大，实验效果也变好。因为每个网格是$2km \times 2km$，I和J增大，说明考虑了更大的地理区域在学习表示时，当I和J为11时，准确率趋于稳定。另一个可能的原因是当考虑更大的地理区域时，需要学习更多的参数，训练MiST更加困难。（2）当时间序列长度$T$变大时，准确率也变得更好。当T=10时趋于稳定。<br><img src="/2019/06/24/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/figure6.png" alt="">   </p><h2><span id="76-hyperparameters-studiesq6">7.6. Hyperparameters Studies(Q6)</span></h2><p>&ensp;&ensp;&ensp;&ensp; 为了检验MiST模型的健壮性，设置不同的超参数看预测效果。除了被测试的参数外，其余参数都被设置为默认值。 总体上，发现MiST在两个任务上（预测NYC犯罪和异常事件）对参数不敏感，并且都能达到很好的效果，说明MiST模型的健壮性。并且发现当表示的维度为32时，效果最好。这是因为刚开始，潜在表示的维度变大能够为循环框架和Attention框架提供一个更好的表示，随着参数的增加，可能会造成过拟合。在我们的实验中，为了权衡有效性和计算代价，将表示维度设置为32。<br><img src="/2019/06/24/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/figure7.png" alt=""><br><img src="/2019/06/24/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/figure8.png" alt=""> </p><h2><span id="77-case-studyq7">7.7. Case Study(Q7)</span></h2><p>&ensp;&ensp;&ensp;&ensp;MiST除了有很好的预测性能，并且在预测一个区域特定类别的异常事件时，能很好的解释空间和类别相关性的重要性。为了说明这点，我们做了实验说明模型的可解释性，在预测NYC盗窃事件时，在一个$5\times 5$的网格中，中间的区域表示目标区域，将attention权重可视化。说明MiST能够动态建模目标区域和其他区域的相关性，并且可以动态建模目标区域的异常类别事件（盗窃）和其他类别的关系。<br><img src="/2019/06/24/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/figure9.png" alt="">   </p><h1><span id="8-conclusion">8. Conclusion</span></h1><p>&ensp;&ensp;&ensp;&ensp;这篇论文提出了一个新的神经网络架构MiST，从空间-事件-类别维度对城市异常事件的动态模式进行建模。我们整合了循环神经网络和多模态融合模块来建模空间-事件的相关性。在不同的真实数据集上评测模型，结果显示MiST比其他baseline效果都好。<font color="#FF0000">[未来方向]</font>关于我们工作的未来方向。第一，检测不同类别的异常事件发生的因果关系，这对公共政策的制定有用。发现异常事件发生的潜在因素，以及不同类别的异常事件在时空上怎么传播。第二，由于数据的限制，我们只在3个真实数据集上做了实验，实际上，MiST通用且灵活，可以应用到其他多维且有时间戳的序列数据上。</p><h1><span id="9-该作者其他论文">9. 该作者其他论文</span></h1><p>除了这篇论文之外，作者还发表了3篇关于anomaly方向的论文：</p><ul><li><p>[2016 CIKM]《Crowdsourcing-based urbananomaly prediction system for smart cities》<br>数据集：311 is NYC’s non-emergency service platform.人们可以在这个平台上抱怨周围发生的事情，通过文字、电话或者app，在NYC OpenData可以获取到。<br>Crodsourcing-bases Urban Anomaly Prediction Scheme(CUAPS)给定一个区域，在异常发生之前进行预测。在crowdsourcing data中，结合空间和时间信息进行预测。首先使用贝叶斯推理模型，根据区域的异常分布来鉴别区域之间的依赖性。然后应用一个最优的异常状态预测方案来预测一个区域的异常事件，从这个区域本身的数据和它依赖的区域。<br><img src="/2019/06/24/MiST-A-Multiview-and-Multimodal-Spatial-Temporal-Learning-Framework-for-Citywide-Abnormal-Event-Forecasting/CUAPS.png" alt=""></p></li><li><p>[2017 ECML] 《Uapd: Predicting urban anomalies from spatial-temporal data》<br>数据集：311 is NYC’s non-emergency service platform（作者提供了整理好的数据和源码）<a href="https://bitbucket.org/xianwu9/uapd/src/master/" target="_blank" rel="noopener">https://bitbucket.org/xianwu9/uapd/src/master/</a><br>和Pittsburgh OpenData portal<br>挑战：时间动态，多维相关，空间、时间、类别。提出模型Urban Anomaly PreDection(UAPD)。首先提出一个概率模型，模型参数通过马尔科夫连推导出来，来检测历史异常记录的变化点，然后最相关的记录被用来预测将来的异常。在第二阶段，从被检测出的变化点开始，使用3维张量建模异常数据，每一维表示区域、时间、类别。然后，分解张量，将每个维度之间的潜在关系合并到张量对应的固有因子上。随后，预测下一时间段的异常变成了一个时间序列预测问题。在第三阶段，利用向量自回归来捕获多个时间序列之间的相互依赖性，从而生成预测结果。</p></li><li>[2018 CIKM] 《DeepCrime:Attentive Hierarchical Recurrent Networks for Crime Prediction》和郑宇联合发表<br>数据集：NYC的Crime记录，<br>DeepCrime，a deep neural network architecture。编码空间、时间、类别到隐藏向量表示中。通过分层循环神经网络捕获异常的动态信息。</li></ul><h1><span id="10-anomaly检测领域的其他论文">10. Anomaly检测领域的其他论文：</span></h1><ul><li>[2013 Ubicomp] 《Flead: Online frequency<br>likelihood estimation anomaly detection for mobile sensing》<br>数据集：手机收集的数据</li><li>[2015 CIKM] 《Profiling pedestrian distribution and anomaly detection in a dynamic environment》<br>数据集：没有说</li><li>[2015 SIGSPATIAL] 郑宇《Detecting collective anomalies from multiple spatio-temporal datasets across different domains》<br>提供了数据集和代码<a href="https://www.microsoft.com/en-us/research/publication/detecting-collective-anomalies-from-multiple-spatio-temporal-datasets-across-different-domains/?from=http%3A%2F%2Fresearch.microsoft.com%2Fapps%2Fpubs%2F%3Fid%3D255670" target="_blank" rel="noopener">链接</a><br>数据描述：<br>（1）POI数据：NYC有24031个POI，共14中类别<br>（2）Road network data：在NYC的862个区域中的路段，每个路段有2个终点和一些中间点，还有一些属性，比如级别，速度限制等<br>（3）311data：NYC<br>（4）Taxicab data：在NYC的14000个出租车产生的数据，包括费用和行程数据，行程数据包括：上下车地点和时间，行程的距离和持续时间，出租车ID，乘客个数等。<br>（5）Bike tenting data：自行车租赁数据，NYC的340个自行车站点，大约7000辆车，每一条记录包括时间，车辆ID，站点ID，返还记录。</li><li>[2017 CIKM] 《Spatiotemporal event forecasting from incomplete hyper-local price data》<br>数据集：有6个数据集，来自6个不同的城市，其中2个是商品价格数据，数据从<a href="https://www.premise.com/" target="_blank" rel="noopener">https://www.premise.com/</a>获取。其中4个是美国4个城市房地产短租的价格数据，数据从Airbnb获取</li><li>[2017 KDD] 《Contextual spatial outlier detection with metric learning》<br>一部分数据来源：<a href="http://archive.ics.uci.edu/ml/index.php" target="_blank" rel="noopener">http://archive.ics.uci.edu/ml/index.php</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;title: &amp;gt;-&lt;br&gt;  MiST-A Multiview and Multimodal Spatial-Temporal Learning Framework for&lt;br&gt;  Citywide Abnormal Event Forecasting&lt;br&gt;date: 2019-06-24T08:43:06.000Z&lt;br&gt;categories: 论文阅读笔记&lt;br&gt;tags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Abnomaly Event Forecasting&lt;br&gt;comments: false&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&quot;1-简介&quot;&gt;&lt;a href=&quot;#1-简介&quot; class=&quot;headerlink&quot; title=&quot;1. 简介&quot;&gt;&lt;/a&gt;1. 简介&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;http://delivery.acm.org/10.1145/3320000/3313730/p717-huang.pdf?ip=218.247.253.153&amp;amp;id=3313730&amp;amp;acc=ACTIVE%20SERVICE&amp;amp;key=BF85BBA5741FDC6E%2EB8E1436BD1CE5062%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;amp;__acm__=1561380383_40e3bd8d678088e9b04173b89f85c49c&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文出处&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
