<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Echo&#39;s blog</title>
  
  <subtitle>远方到底有多远</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-03-03T08:26:13.192Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Echo</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>深度学习优秀代码示例</title>
    <link href="http://yoursite.com/2020/03/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BC%98%E7%A7%80%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B/"/>
    <id>http://yoursite.com/2020/03/03/深度学习优秀代码示例/</id>
    <published>2020-03-03T03:30:18.000Z</published>
    <updated>2020-03-03T08:26:13.192Z</updated>
    
    <content type="html"><![CDATA[<p>&ensp;&ensp;&ensp;&ensp;曾经一段时间很苦恼，对于深度学习算法不知道怎么上手，看了很多深度学习教程，依然不会写。后来就看论文公开的源代码，对照着论文模型，一点点看，多看几篇代码，逐渐有种开窍的感觉。其次是看Mxnet和Pytorch的源代码(我主要用这2个框架)，Mxnet和Pytorch的Github上给了很多示例代码，写的非常规范，从中可以学到用法，从而也可以规范自己的代码。<br>&ensp;&ensp;&ensp;&ensp;下面整理一下，在我学习过程中，对我帮助很大的教程和代码。</p><a id="more"></a><ol><li><a href="http://zh.gluon.ai/" target="_blank" rel="noopener">《动手学深度学习》Mxnet版</a><br>Mxnet的入门教程，沐神写的，来来回回看了2~3遍，每次看都有新的收货</li><li><a href="https://tangshusen.me/Dive-into-DL-PyTorch/#/" target="_blank" rel="noopener">《动手学深度学习》Pytorch版</a><br>将Mxnet改写为Pytorch版本，非常好的Pytorch入门教程</li><li><a href="https://github.com/Davidham3/ASTGCN" target="_blank" rel="noopener">ASTGCN</a><br>AAAI2019论文公开代码，用Mxnet写的</li><li><a href="https://yjucho1.github.io/spatio-temporal%20data/deep%20learning%20paper/ST-resnet/" target="_blank" rel="noopener">ST-ResNet</a><br>AAAI2017论文公开代码，用Keras，看这篇代码主要是学习模型架构，然后自己用mxnet复现了一下</li><li><a href="https://github.com/panzheyi/ST-MetaNet" target="_blank" rel="noopener">ST-MetaNet</a><br>KDD2019论文公开代码，用Mxnet写的，学到了很多高级用法，例如EarlyStopping，Encoder和Decoder，getattr，DGL</li><li><p><a href="https://github.com/pytorch/examples/tree/master/word_language_model" target="_blank" rel="noopener">Pytorch Transformer</a><br>学习怎么使用Transformer，Dropout和BN在训练和测试的不同，PositionEmbedding，getattr等用法。学习Transformer最好去看Pytorch关于Tranformer的源代码。</p></li><li><p><a href="https://github.com/pytorch/examples" target="_blank" rel="noopener">Pytorch示例代码</a><br>Pytorch Github中的示例代码</p></li><li><a href="https://github.com/apache/incubator-mxnet/tree/master/example" target="_blank" rel="noopener">Mxnet示例代码</a><br>Mxnet Github中的示例代码</li></ol><p>觉得自己最大的变化是喜欢去读源代码了，遇到问题去官网看教程，读源码，帮助很大。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;曾经一段时间很苦恼，对于深度学习算法不知道怎么上手，看了很多深度学习教程，依然不会写。后来就看论文公开的源代码，对照着论文模型，一点点看，多看几篇代码，逐渐有种开窍的感觉。其次是看Mxnet和Pytorch的源代码(我主要用这2个框架)，Mxnet和Pytorch的Github上给了很多示例代码，写的非常规范，从中可以学到用法，从而也可以规范自己的代码。&lt;br&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;下面整理一下，在我学习过程中，对我帮助很大的教程和代码。&lt;/p&gt;
    
    </summary>
    
      <category term="Deep Learning" scheme="http://yoursite.com/categories/Deep-Learning/"/>
    
    
      <category term="Pyotrch" scheme="http://yoursite.com/tags/Pyotrch/"/>
    
      <category term="Mxnet" scheme="http://yoursite.com/tags/Mxnet/"/>
    
  </entry>
  
  <entry>
    <title>时空论文阅读笔记</title>
    <link href="http://yoursite.com/2020/02/27/%E6%97%B6%E7%A9%BA%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2020/02/27/时空论文阅读笔记/</id>
    <published>2020-02-27T12:03:53.000Z</published>
    <updated>2020-03-02T15:15:52.118Z</updated>
    
    <content type="html"><![CDATA[<p>因为疫情推迟开学，在家把以前看的论文又看了一遍，每重新看一次都有新的收获，在此整理下。</p><a id="more"></a><!-- TOC --><ul><li><a href="#1-deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-predictionaaai2017">1. Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction(AAAI2017)</a></li><li><a href="#2-deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolisaaai2019">2. DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis(AAAI2019)</a></li><li><a href="#3-attention-based-spatial-temporal-graph-convolutional-networks-for-traffic-flow-forecastingaaai2019">3. Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting(AAAI2019)</a></li><li><a href="#4-deep-multi-view-spatial-temporal-network-for-taxi-demand-predictionaaai2018">4. Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction(AAAI2018)</a></li><li><a href="#5-revisiting-spatial-temporal-similarity-a-deep-learning-framework-for-traffic-predictionaaai2019">5. Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction(AAAI2019)</a></li><li><a href="#6-spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecastingaaai2019">6. Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting(AAAI2019)</a></li><li><a href="#7-passenger-demand-forecasting-with-multi-task-convolutional-recurrent-neural-networkspakdd2019">7. Passenger Demand Forecasting with Multi-Task Convolutional Recurrent Neural Networks(PAKDD2019)</a></li><li><a href="#8-hyperst-net-hypernetworks-for-spatio-temporal-forecasting2019aaai">8. HyperST-Net: Hypernetworks for Spatio-Temporal Forecasting(2019AAAI)</a></li><li><a href="#9-restful-resolution-aware-forecasting-of-behavioral-time-series-data2018cikm">9. RESTFul: Resolution-Aware Forecasting of Behavioral Time Series Data(2018CIKM)</a></li><li><a href="#10-stepdeep-a-novel-spatial-temporal-mobility-event-prediction-framework-based-on-deep-neural-networkkdd2018">10. StepDeep: A Novel Spatial-temporal Mobility Event Prediction Framework based on Deep Neural Network(KDD2018)</a></li><li><a href="#11-stgrat-a-spatio-temporal-graph-attention-network-for-traffic-forecastingaaai2020">11. STGRAT: A Spatio-Temporal Graph Attention Network for Traffic Forecasting(AAAI2020)</a></li><li><a href="#12-%e6%80%bb%e7%bb%93">12. 总结</a><ul><li><a href="#121-%e6%a0%b9%e6%8d%ae%e7%bd%91%e6%a0%bc%e6%9e%84%e5%bb%ba%e5%9b%be">12.1. 根据网格构建图</a></li><li><a href="#122-%e8%ae%a1%e7%ae%972%e4%b8%aa%e5%8c%ba%e5%9f%9f%e7%9a%84%e7%9b%b8%e5%85%b3%e6%80%a7">12.2. 计算2个区域的相关性</a></li><li><a href="#123-poi">12.3. POI</a></li><li><a href="#124-%e6%97%b6%e9%97%b4">12.4. 时间</a></li></ul></li></ul><!-- /TOC --><h1><span id="1-deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-predictionaaai2017">1. Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction(AAAI2017)</span></h1><blockquote><p>张钧波(京东)<br>郑宇(京东)</p></blockquote><ul><li>给定所有区域历史T个时间段的inflow和outflow，预测下一个时间段所有区域的inflow和outflow</li></ul><p><img src="/2020/02/27/时空论文阅读笔记/ST-ResNet.png" alt=""></p><ul><li>每个时间段所有区域的输入是$I<em>J</em>2$,将输入分为recent，daily，weekly周期，预测第t个时间段的infow和outflow：<ul><li>recent：当天前r个时间段</li><li>daily：前d天该时间段</li><li>weekly：前w周该天该时间段</li></ul></li><li>外部特征包括：天气，节假日，dayOfWeek。用2层FCN对外部特征进行嵌入，第一层FCN作为嵌入层，第二层FCN转换维度和$X_{Res}$一致。</li><li>在融合阶段，先将3个时间周期的输出融合，再和外部因素拼接。</li><li>数据集：北京出租车和NYC自行车流量</li><li>将flow使用Max-Min归一化到[-1,1]，FCN最后一层使用tanh激活函数</li></ul><h1><span id="2-deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolisaaai2019">2. DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis(AAAI2019)</span></h1><blockquote><p>Ziqian Lin(清华大学)<br>Jie Feng(清华大学)<br>Ziyang Lu(清华大学)<br>Yong Li(清华大学)<br>Depeng Jin(清华大学)</p></blockquote><ul><li>crowd flow预测是给定历史T个时间段，预测区域的inflow和outflow</li><li>现有研究的缺点：<ul><li>不能捕获长距离空间依赖</li><li>忽略区域功能对人流的影响(POI)</li></ul></li><li>提出DeeoSTN+，有3个组件<ul><li>ConvPlus：解决长距离区域的空间依赖</li><li>SemanticPlus：解决区域POI对人流的影响</li><li>early-fusuion模块</li></ul></li></ul><p><img src="/2020/02/27/时空论文阅读笔记/DeepSTN+.png" alt=""></p><ul><li><strong>计算POI在时间上的分布权重</strong></li><li>crowd flow使用Max-Min归一化到[-1,1]，最后一层使用Tanh，范围[-1,1]</li><li>POI使用Max-Min归一化到[0,1]</li></ul><h1><span id="3-attention-based-spatial-temporal-graph-convolutional-networks-for-traffic-flow-forecastingaaai2019">3. Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting(AAAI2019)</span></h1><p>根据所有节点历史T个时间段traffic flow，occupy，speed，预测所有节点未来T_p个时间段的traffic flow。</p><p><img src="/2020/02/27/时空论文阅读笔记/ASTGCN.png" alt=""></p><ul><li>三个独立的组件，分别对recent，daily，weekly周期进行建模</li><li>比如说预测6.14 8:00-8:55的flow，传入的样本是<br>时：6.14号6:00~7:55（前2个小时）的数据，<br>天：6.13和6.12（前2天）的8:00-8:55，<br>周：上周6.17，上上周5.31（前2周）的8:00-8:55</li></ul><h1><span id="4-deep-multi-view-spatial-temporal-network-for-taxi-demand-predictionaaai2018">4. Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction(AAAI2018)</span></h1><blockquote><p>姚骅修(Pennsylvania State University)<br>吴飞(Pennsylvania State University)<br>柯金涛(香港科技大学)<br>Xianfeng Tang(Pennsylvania State University)<br>叶杰平(滴滴出行)</p></blockquote><ul><li><strong>出租车需求预测</strong>，根据S<em>S的小区域，历史T个时间段的出租车订单数据，预测下一个时间段中心区域的订单。<em>*空间和时间都是多预测一</em></em></li></ul><p><img src="/2020/02/27/时空论文阅读笔记/DMVST_Net.png" alt=""></p><ul><li>现有的研究都是使用CNN对空间建模，LSTM对时间建模，时间和空间分开建模，本文的模型是对时间和空间同时建模</li><li>本文提出DMVST-Net，有3个view：<strong>时间view</strong>（通过LSTM建模时间关系），<strong>空间view</strong>（使用local CNN建模邻近空间关系），<strong>语义view</strong>（建模功能相似的区域）</li><li>local CNN只考虑空间邻近的区域，但是不能考虑离得较远，但出租车需求模型相似的区域，所以又加了语义view</li><li><img src="/2020/02/27/时空论文阅读笔记/DMVST_Net-1.jpg" alt=""></li><li><strong>输入是S*S的邻居区域，如果是边界区域，其邻居用0填充</strong></li><li>在LSTM每个时间步的特征中拼接天气等外部因素</li><li>local CNN和LSTM对时间和空间建模，然后再构建图，表示区域之间需求相似性(功能相似性)。求出2个区域每周的需求量，形成一个时间序列，使用DTW计算2个序列的相似性，即<strong>2个区域的相似性，作为图中的边，创建一个全连接图(任意2个区域都相连)</strong>,使用LINE对图中节点进行嵌入。</li><li><img src="/2020/02/27/时空论文阅读笔记/DMVST_Net-2.png" alt=""><br>损失函数由MSE和MAPE组成，MSE更关注大值，为了避免模型偏向大值的方向训练，又添加了MAPE，但是使用MAPE时，真实值中不能有0</li><li>Max-Min激活，最终输出值在[0,1]之间，反归一化</li><li>最后一层FCN用sigmoid激活，其余的FCN用ReLU激活</li></ul><h1><span id="5-revisiting-spatial-temporal-similarity-a-deep-learning-framework-for-traffic-predictionaaai2019">5. Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction(AAAI2019)</span></h1><blockquote><p>姚骅修(Pennsylvania State University)<br>Xianfeng Tang(Pennsylvania State University)</p></blockquote><ul><li>主要问题是：原先研究中的空间相关性都是静态的，本次建模<strong>动态的空间相关性</strong>。<strong>时间有天和周周期，且有时间偏移</strong>。</li><li>提出模型<strong>S</strong>patial-<strong>T</strong>emporal <strong>D</strong>ynamic <strong>N</strong>etwork(<strong>STDN</strong>)来traffic prediction</li><li>根据S<em>S小区域历史T个时间段的volume和flow，预测下一个时间段中心区域的volume，<em>*空间和时间都是多预测一</em></em></li></ul><p><img src="/2020/02/27/时空论文阅读笔记/STDN.png" alt=""></p><ul><li>将交通量分为2种<ul><li>traffic volume：无方向，一个区域进来和出去的流量。</li><li>traffic flow：有方向，从区域i到区域j的流量</li></ul></li><li>flow-gated local CNN每次输入S*S区域的volume和flow，其中flow起到门控作用，值在[0,1]之间，如果2个区域之间flow大，即门控的值大，2个区域的相关性强。每个时间段经过local CNN输出的值，再拼接上该时间段的天气等外部因素送入LSTM中</li><li><strong>时间偏移Attention</strong>：比如预测第t+1个时间段的volume，用到当天前t=7个时间段的数据(短期依赖)，前P=3天(长期依赖)，每天Q=3个时间段(解决时间偏移问题)。</li><li>先将短期的t个时间段数据输入LSTM中，得到隐藏状态h做Attention。前P天，每天Q个时间段输入到LSTM中，每天得到Q个隐藏状态，和h做attention，将Q个整合成1个，最终生成P个隐藏状态，再输入到LSTM，得到长期依赖的隐藏状态，然后再和短期的隐藏状态h拼接，输入到FCN中。</li><li><strong>短期的隐藏状态和长期的隐藏状态做Attention</strong></li><li><strong>短期的隐藏状态和长期的隐藏状态拼接</strong></li><li>数据集：出租车流量和自行车流量</li></ul><blockquote><ul><li>STDN和DMVST-Net是同一作者发的</li><li>两者都是：空间和时间<strong>多预测一</strong></li><li><strong>STDN</strong>：local CNN + LSTM</li><li><strong>DMVST-Net</strong>：flow-gated local CNN + Periodically Shifted Attention LSTM</li></ul></blockquote><h1><span id="6-spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecastingaaai2019">6. Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting(AAAI2019)</span></h1><blockquote><p>Xu Geng(香港大学)<br>Yaguang Li(南加利福尼亚)<br>Lingyu Zhang(滴滴AI)<br>杨强(香港大学)<br>叶杰平(滴滴)</p></blockquote><p><img src="/2020/02/27/时空论文阅读笔记/ST_MGCN.png" alt=""></p><ul><li>问题：根据所有区域历史T个时间段的订单数，预测所有区域下一个时间段的订单数</li><li>将研究区域划分为网格，根据网格构建3个图，这3个图的图信号矩阵一样，只是邻接矩阵不一样。分别<ul><li><strong>邻居图</strong>（3*3网格，每个区域有8个邻居，2个区域是邻居，邻接矩阵为1，否则为0）；</li><li><strong>区域功能相似图</strong>（根据每个区域的POI，计算相似性，值在0&lt;=sim&lt;=1）；</li><li><strong>交通连通图</strong>（看2个区域是否在高速公路，公共交通等方式相连，相连为1，否则为0）</li></ul></li><li><strong>Channel-wise attention</strong>参考CV领域，图像输入$X \in \mathbb{R}^{W\times H \times C}$，计算每一个通道的权重$s$,然后再把输入和通道权重相乘$\tilde{\boldsymbol{X}}_{:,:,c}=\boldsymbol{X}_{:,:, c} \circ s_{c} \quad for \quad c=1,2, \cdots C$</li><li>一共有3类图，每类图的邻接矩阵不一样，图信号矩阵一样，表示该区域的订单数，图信号矩阵是动态的，每个时间段的图信号矩阵都不一样，一共有T个时间段。拿一个图距离，输入为(T,V,P),根据通道维的attention，<strong>这里将时间维作为通道维，对T个时间段做Attention</strong>，最终得到attention后的输入(T,V,P),然后输入到RNN中，因为RNN一次只能输入一个节点T个时间段的数据，但是这里有V个节点，这里V个节点共享一个RNN，最终得到隐藏状态，然后在把3个图的输出融合，得到最终的预测结果(所有区域下一个时间段的订单数)</li><li>T为5，根据ST_ResNet，其中3个邻近，1个天周期，1个周周期。</li></ul><h1><span id="7-passenger-demand-forecasting-with-multi-task-convolutional-recurrent-neural-networkspakdd2019">7. Passenger Demand Forecasting with Multi-Task Convolutional Recurrent Neural Networks(PAKDD2019)</span></h1><blockquote><p>Lei Bai1(University of New South Wales)<br>Lina Yao(University of New South Wales)<br>Salil S. Kanhere(University of New South Wales)</p></blockquote><ul><li>根据历史T个时间段<strong>相似区域</strong>出租车demand和人流量，预测下一个时间段中心区域的出租车demand。<strong>时间和空间都是多预测一</strong></li></ul><p><img src="/2020/02/27/时空论文阅读笔记/MT-CRNN.png" alt=""></p><ul><li>根据路网来划分区域</li><li>多任务预测：<ul><li><strong>主任务(回归)</strong>：预测中心区域的订单需求数</li><li><strong>辅助任务(分类)</strong>：预测中心区域的订单需求等级(高、中、低)</li></ul></li><li>主任务输入的是相似区域的订单数据和人流量数据，其中<strong>根据POI和taxi demand来计算2个区域的相似性</strong>，为中心区域选择m=3个最相似区域</li><li>使用外部信息(天气等)来预测订单需求等级(辅助任务)</li></ul><h1><span id="8-hyperst-net-hypernetworks-for-spatio-temporal-forecasting2019aaai">8. HyperST-Net: Hypernetworks for Spatio-Temporal Forecasting(2019AAAI)</span></h1><blockquote><p>潘哲逸(上海交通大学)<br>梁宇轩(西安电子科技大学)<br>张钧波(京东)<br>易修文(京东)<br>郑宇(京东)</p></blockquote><p>论文声称第一个考虑<strong>空间和时间内在因果关系</strong>的深度框架。</p><p><img src="/2020/02/27/时空论文阅读笔记/HyperST_Net.png" alt=""></p><ul><li>该论文提出的只是一个HyperNetwork框架，并不是一个具体的模型。</li><li><strong>HyperNetwork</strong>：和以往不同，以前都是一个网络的输出，输入到下一个网络中，<strong>超网络是一个网络的输出作为另一个网络的参数</strong>。</li><li>该模型有3个模块：空间模块，时间模块，推理模块。将空间模块的输出经过推理模块，得到的输出作为时间模块的权重参数，以此捕获时间和空间的内在因果关系。</li><li>这只是一个框架，可以变换成多种模型。在空间模块中如果使用全连接就是HyperST-Dense，使用卷积就是HyperST-Conv。</li></ul><h1><span id="9-restful-resolution-aware-forecasting-of-behavioral-time-series-data2018cikm">9. RESTFul: Resolution-Aware Forecasting of Behavioral Time Series Data(2018CIKM)</span></h1><blockquote><p>吴宪(University of Notre Dame)<br>史宝旭(University of Notre Dame)<br>Yuxiao Dong(微软)<br>黄超(University of Notre Dame)</p></blockquote><p>本文使用<strong>多种时间粒度</strong>的<strong>时间序列数据</strong>来预测。<br>模型为<strong>RES</strong>olution-aware <strong>T</strong>ime <strong>S</strong>eries Forecasting (RESTFul)<br>第一个使用多种时间粒度来进行行为时间序列预测</p><p><img src="/2020/02/27/时空论文阅读笔记/RESTFul.png" alt=""></p><ul><li>有2个参数$\alpha和\beta$，取值{day,week}，限制α&gt;=β，<br>$\alpha$=1week,$\beta$=1day,表示1周测量1次，1次测1天。<br>$\alpha$=1week,$\beta$=1week,表示1周测量1次，1次测1周。<br>有一个完整的时间序列，要从中隔抽取不同时间粒度的时间序列。$X=\left[x_{1}, \ldots, x_{t}, \ldots, x_{T-1}, x_{T}\right]$，不同的$\alpha和\beta$就构成不同时间粒度的序列，序列长度为k，这里设置为5。</li><li>对于每一个时间序列都用GRU来捕获时间相关性，得到一个隐藏状态，那么n个时间序列就有n个隐藏状态</li><li>将所有的隐藏状态reshape成$\alpha <em> \beta </em> d$的张量，然后使用卷积融合不同粒度。</li><li>使用数据集：销售数据，311投诉数据</li></ul><h1><span id="10-stepdeep-a-novel-spatial-temporal-mobility-event-prediction-framework-based-on-deep-neural-networkkdd2018">10. StepDeep: A Novel Spatial-temporal Mobility Event Prediction Framework based on Deep Neural Network(KDD2018)</span></h1><blockquote><p>Bilong Shen(清华大学)<br>梁晓丹(卡耐基梅隆)</p></blockquote><ul><li><strong>S</strong>patial-<strong>T</strong>emporal mobility <strong>E</strong>vent <strong>P</strong>rediction framework based on <strong>Deep</strong> neural network (<strong>StepDeep</strong>)同时考虑时间和空间模式，给定所有区域历史T个时间段的出租车流量和外部因素，预测所有区域在下一个时间段出租车的inflow和outflow。</li><li>网格区域中的flow随时间变化，可以看做一个视频(T,C,W,H)，进而看做是视频预测任务</li><li>数据集NYC出租车轨迹数据，将NYC网格划分，计算每个区域的inflow和outflow，</li></ul><p><img src="/2020/02/27/时空论文阅读笔记/StepDeep.png" alt=""></p><p><img src="/2020/02/27/时空论文阅读笔记/StepDeep1.png" alt=""></p><ul><li>提出3种卷积：时间卷积，空间卷积，时空卷积。将输入(T,C,H,W)输入到以上7层卷积中，最终输出(C,H,W)表示下一个时间段所有区域的inflow和outflow，</li></ul><h1><span id="11-stgrat-a-spatio-temporal-graph-attention-network-for-traffic-forecastingaaai2020">11. STGRAT: A Spatio-Temporal Graph Attention Network for Traffic Forecasting(AAAI2020)</span></h1><blockquote><p>Cheonbok Park(韩国大学)<br>Chunggi Lee(韩国大学)<br>Hyojin Bahng(韩国大学)</p></blockquote><ul><li>根据所有节点历史T个时间段的交通速度，预测所有节点未来T个时间段的交通速度(T=12)，时间多预测多，Seq2Seq架构</li></ul><p><img src="/2020/02/27/时空论文阅读笔记/STGRAT.png" alt=""></p><ul><li>Encoder layer中有3个sublayer：空间Attention层，时间Attention层和point-wise FCN。<ul><li>空间Attention：关注每个时间步上空间邻近的节点</li><li>时间Attention：关注单个节点，输入时间序列的不同时间步</li></ul></li><li>整个Encoder = 1个嵌入层 + 4个Encoder layer，使用LINE对图节点进行嵌入</li></ul><p><img src="/2020/02/27/时空论文阅读笔记/STGRAT1.png" alt=""></p><ul><li>空间Attention层：参考Transformer，中心结点作为query，其邻居作为key和value，计算每个节点新的表示。</li><li>时间Attention==Transformer，输入维度(batch_size,T,N,D),计算时间步之间的attention分数，输出维度(batch_size,T,N,D)</li><li>Point-wise FFN和Transformer中一样，使用2层FCN，中间使用GELU激活函数，Transformer使用的是ReLU激活函数。</li><li>Decoder layer有4个sublayer：空间Attention层，mask时间Attention层，Encoder-Decoder Attention层，point-wise FFN层。整个Decoder层=1个嵌入层+4个Decoder层。</li><li><strong>本模型比Transformer多了一个空间Attention层，其余都一样，因为时间Attention层、FFN和Transformer的一样</strong></li></ul><h1><span id="12-总结">12. 总结</span></h1><h2><span id="121-根据网格构建图">12.1. 根据网格构建图</span></h2><p>图用2个矩阵表示：图信号矩阵和邻接矩阵。由网格构建图时，节点表示区域，图信号矩阵就是区域的特征。重点是怎么构建邻接矩阵。</p><ul><li>《Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting》(AAAI2019)这篇文章构建了3个图：邻居图，POI功能相似图，交通连通图</li></ul><h2><span id="122-计算2个区域的相关性">12.2. 计算2个区域的相关性</span></h2><ul><li>用出租车需求量计算2个区域的<strong>相似性</strong>，用2个区域的出租车需求量组成时间序列<ul><li>使用DTW计算2个序列的相似性，2个时间序列越相似，说明2个区域越相似。例如：《Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting》(AAAI2019)</li><li>使用皮尔森系数，例如《Passenger Demand Forecasting with Multi-Task Convolutional Recurrent Neural Networks》(2019PAKDD)</li></ul></li><li>计算2个区域之间的<strong>相关性</strong>，使用区域之间的traffic flow，如果2个区域之间的traffic flow越大，说明这2个区域越相关。但是《Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction》(AAAI2019)说这种相关性也是相似性。我觉得有问题，例如工作区和住宅区，2个区域的traffic flow很大，有很强的相关性，但是相似性并不强。</li><li>根据POI计算2个区域的相似性，例如《Passenger Demand Forecasting with Multi-Task Convolutional Recurrent Neural Networks》(2019PAKDD)</li></ul><h2><span id="123-poi">12.3. POI</span></h2><p>很多论文中都习惯将POI成为Semantic</p><ul><li>《Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction》(AAAI2018)</li><li>《DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis》(AAAI2019)</li></ul><h2><span id="124-时间">12.4. 时间</span></h2><p>像dayOfWeek，monthOfYear等时间信息，在论文中称作<strong>time meta feature</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;因为疫情推迟开学，在家把以前看的论文又看了一遍，每重新看一次都有新的收获，在此整理下。&lt;/p&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="时空领域" scheme="http://yoursite.com/tags/%E6%97%B6%E7%A9%BA%E9%A2%86%E5%9F%9F/"/>
    
  </entry>
  
  <entry>
    <title>VSCode连接服务器太慢</title>
    <link href="http://yoursite.com/2020/02/26/VSCode%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%A4%AA%E6%85%A2/"/>
    <id>http://yoursite.com/2020/02/26/VSCode连接服务器太慢/</id>
    <published>2020-02-26T09:59:55.000Z</published>
    <updated>2020-02-26T12:26:38.519Z</updated>
    
    <content type="html"><![CDATA[<p>使用VSCode远程连接服务器太慢，是因为需要远程下载vscode-server-linux-x64.tar.gz，下载太慢，下面是解决方案</p><a id="more"></a><p><img src="/2020/02/26/VSCode连接服务器太慢/vscode.png" alt=""></p><p><a href="https://blog.csdn.net/bcfd_yundou/article/details/96135456" target="_blank" rel="noopener">vscode搭建远程开发</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">先将vscode-server-linux-x64.tar.gz拷贝到/data/WangBeibei/.vscode-server/bin/xxx下面，并解压</span></span><br><span class="line">tar -xzvf vscode-server-linux-x64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">删掉压缩包</span></span><br><span class="line">rm -r vscode-server-linux-x64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">将vscode-server-linux-x64目录中所有内容移到/data/WangBeibei/.vscode-server/bin/xxx下面</span></span><br><span class="line">mv /data/WangBeibei/.vscode-server/bin/xxx/vscode-server-linux-x64/* /data/WangBeibei/.vscode-server/bin/xxx</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">删掉vscode-server-linux-x64</span></span><br><span class="line">rm -r vscode-server-linux-x64</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用VSCode远程连接服务器太慢，是因为需要远程下载vscode-server-linux-x64.tar.gz，下载太慢，下面是解决方案&lt;/p&gt;
    
    </summary>
    
      <category term="工具" scheme="http://yoursite.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="VSCode" scheme="http://yoursite.com/tags/VSCode/"/>
    
  </entry>
  
  <entry>
    <title>对loss进行mask</title>
    <link href="http://yoursite.com/2020/02/25/%E5%AF%B9loss%E8%BF%9B%E8%A1%8Cmask/"/>
    <id>http://yoursite.com/2020/02/25/对loss进行mask/</id>
    <published>2020-02-25T05:37:12.000Z</published>
    <updated>2020-02-25T06:50:43.513Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="简介">简介</span></h1><p>在计算loss和评价指标时，对一些不关注的值进行mask。下面介绍mask的使用。</p><a id="more"></a><h1><span id="对输入进行mask">对输入进行mask</span></h1><h1><span id="对loss进行mask">对loss进行mask</span></h1><p>在NLP中的Seq2Seq中经常会对loss进行mask，因为一个batch中句子的长度通常不一样，一个batch中不足长度的位置用0填充，最后生成句子计算loss时需要忽略掉原先那些padding的值，即只保留mask中值为1的位置，忽略值为0的位置。在计算loss时，将那些本不应该计算的mask掉，使其loss为0，这样就不会反向传播了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">masked_predicts = torch.masked_select(predicts, mask)</span><br><span class="line">masked_targets = torch.masked_select(targets, mask)</span><br><span class="line">loss = my_criterion(masked_predicts, masked_targets)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">diff2 = (torch.flatten(input) - torch.flatten(target)) ** <span class="number">2.0</span> * torch.flatten(mask)</span><br><span class="line">loss = torch.sum(diff2) / torch.sum(mask)</span><br><span class="line">out.backward()</span><br></pre></td></tr></table></figure><h1><span id="pytorch的mask_select函数">Pytorch的mask_select函数</span></h1><p><code>torch.masked_select(input, mask, out=None) → Tensor</code><br>返回1-D的Tensor</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">tensor([[ <span class="number">0.3552</span>, <span class="number">-2.3825</span>, <span class="number">-0.8297</span>,  <span class="number">0.3477</span>],</span><br><span class="line">        [<span class="number">-1.2035</span>,  <span class="number">1.2252</span>,  <span class="number">0.5002</span>,  <span class="number">0.6248</span>],</span><br><span class="line">        [ <span class="number">0.1307</span>, <span class="number">-2.0608</span>,  <span class="number">0.1244</span>,  <span class="number">2.0139</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mask = x.ge(<span class="number">0.5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mask</span><br><span class="line">tensor([[<span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">False</span>],</span><br><span class="line">        [<span class="keyword">False</span>, <span class="keyword">True</span>, <span class="keyword">True</span>, <span class="keyword">True</span>],</span><br><span class="line">        [<span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">True</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.masked_select(x, mask)</span><br><span class="line">tensor([ <span class="number">1.2252</span>,  <span class="number">0.5002</span>,  <span class="number">0.6248</span>,  <span class="number">2.0139</span>])</span><br></pre></td></tr></table></figure><p>【参考资料】</p><p><a href="http://www.linzehui.me/2018/10/12/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%B5%85%E8%B0%88mask%E7%9F%A9%E9%98%B5/" target="_blank" rel="noopener">浅谈mask矩阵</a><br><a href="https://github.com/xlwang233/pytorch-DCRNN/blob/master/lib/metrics.py" target="_blank" rel="noopener">pytorch-DCRNN</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;p&gt;在计算loss和评价指标时，对一些不关注的值进行mask。下面介绍mask的使用。&lt;/p&gt;
    
    </summary>
    
      <category term="Deep Learning" scheme="http://yoursite.com/categories/Deep-Learning/"/>
    
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch之知识点汇总</title>
    <link href="http://yoursite.com/2020/02/24/Pytorch%E4%B9%8B%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/"/>
    <id>http://yoursite.com/2020/02/24/Pytorch之知识点汇总/</id>
    <published>2020-02-24T09:08:12.000Z</published>
    <updated>2020-03-03T14:40:08.165Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="1-简介">1. 简介</span></h1><p>汇总Pytorch的一些知识点</p><a id="more"></a><!-- TOC --><ul><li><a href="#1-%e7%ae%80%e4%bb%8b">1. 简介</a></li><li><a href="#2-%e6%9f%a5%e7%9c%8b%e7%bd%91%e7%bb%9c%e5%8f%82%e6%95%b0">2. 查看网络参数</a></li><li><a href="#3-%e5%88%86%e7%b1%bb%e9%97%ae%e9%a2%98">3. 分类问题</a></li><li><a href="#4-crossentropyloss%e5%92%8cnllloss-%e5%8c%ba%e5%88%ab">4. CrossEntropyLoss()和NLLLoss() 区别</a></li><li><a href="#5-%e6%a8%a1%e5%9e%8b%e8%ae%ad%e7%bb%83%e7%a4%ba%e4%be%8b">5. 模型训练示例</a></li><li><a href="#6-%e5%85%b3%e9%97%ad%e6%a2%af%e5%ba%a6">6. 关闭梯度</a></li><li><a href="#7-gpu">7. GPU</a></li><li><a href="#8-%e5%a4%9agpu%e8%bf%90%e8%a1%8c%e7%a8%8b%e5%ba%8f">8. 多GPU运行程序</a></li><li><a href="#9-tensor">9. Tensor</a></li><li><a href="#bn%e5%92%8cdropout%e5%9c%a8%e8%ae%ad%e7%bb%83%e5%92%8c%e6%b5%8b%e8%af%95%e7%9a%84%e4%b8%8d%e5%90%8c">BN和Dropout在训练和测试的不同</a></li><li><a href="#linear">Linear</a></li></ul><!-- /TOC --><h1><span id="2-查看网络参数">2. 查看网络参数</span></h1><ul><li><p>方法1</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> network.parameters():</span><br><span class="line">  print(param.shape)</span><br></pre></td></tr></table></figure></li><li><p>方法2<br>可以查看参数的名称</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> network.named_parameters():</span><br><span class="line">  print(name, <span class="string">'\t\t'</span>, param.shape)</span><br></pre></td></tr></table></figure></li></ul><h1><span id="3-分类问题">3. 分类问题</span></h1><p>例如Fashion-MNIST分类任务中，一共有10类。假设batch_size=16,每个batch的feature维度为(16,1,28,28)，label的维度(16,)，经过模型最终输出的预测结果维度(16,10)，然后我们使用<code>argmax()</code>来得出最终的预测类别。然后可以和真实label比较，看预测结果的正确性,计算预测正确的个数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&gt; preds.argmax(dim=<span class="number">1</span>)</span><br><span class="line">tensor([<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">&gt; labels</span><br><span class="line">tensor([<span class="number">9</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">7</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">&gt; preds.argmax(dim=<span class="number">1</span>).eq(labels)</span><br><span class="line">tensor([<span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">True</span>, <span class="keyword">False</span>], dtype=torch.bool)</span><br><span class="line"></span><br><span class="line">&gt; preds.argmax(dim=<span class="number">1</span>).eq(labels).sum()</span><br><span class="line">tensor(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">&gt; preds.argmax(dim=<span class="number">1</span>).eq(labels).sum().item()</span><br><span class="line"><span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#得到每个batch预测正确的样本</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_num_correct</span><span class="params">(preds, labels)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> preds.argmax(dim=<span class="number">1</span>).eq(labels).sum().item()</span><br></pre></td></tr></table></figure><h1><span id="4-crossentropyloss和nllloss-区别">4. CrossEntropyLoss()和NLLLoss() 区别</span></h1><p><a href="https://blog.csdn.net/zwqjoy/article/details/96282788" target="_blank" rel="noopener">Pytorch nn.CrossEntropyLoss()和nn.NLLLoss() 区别</a></p><p><a href="https://www.cnblogs.com/marsggbo/p/10401215.html" target="_blank" rel="noopener">Pytorch里的CrossEntropyLoss详解</a>  </p><p><a href="https://www.zhihu.com/question/66782101" target="_blank" rel="noopener">PyTorch 中，nn 与 nn.functional 有什么区别</a></p><h1><span id="5-模型训练示例">5. 模型训练示例</span></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">network = Network()</span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_set, batch_size=<span class="number">100</span>)</span><br><span class="line">optimizer = optim.Adam(network.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    </span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    total_correct = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> train_loader: <span class="comment"># Get Batch</span></span><br><span class="line">        images, labels = batch </span><br><span class="line"></span><br><span class="line">        preds = network(images) <span class="comment"># Pass Batch</span></span><br><span class="line">        loss = F.cross_entropy(preds, labels) <span class="comment"># Calculate Loss</span></span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward() <span class="comment"># Calculate Gradients</span></span><br><span class="line">        optimizer.step() <span class="comment"># Update Weights</span></span><br><span class="line"></span><br><span class="line">        total_loss += loss.item()</span><br><span class="line">        total_correct += get_num_correct(preds, labels)</span><br><span class="line"></span><br><span class="line">    print(</span><br><span class="line">        <span class="string">"epoch"</span>, epoch, </span><br><span class="line">        <span class="string">"total_correct:"</span>, total_correct, </span><br><span class="line">        <span class="string">"loss:"</span>, total_loss</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><h1><span id="6-关闭梯度">6. 关闭梯度</span></h1><p>关闭梯度有2种方法</p><ul><li><p>方法1：在模型训练的时候，需要计算梯度，但是在测试的时候不需要计算梯度，那我们就可以使用<code>@torch.no_grad()</code>。下面代码示例求所有的预测结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@torch.no_grad()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_all_preds</span><span class="params">(model, loader)</span>:</span></span><br><span class="line">    all_preds = torch.tensor([])</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> loader:</span><br><span class="line">        images, labels = batch</span><br><span class="line">        preds = model(images)</span><br><span class="line">        all_preds = torch.cat(</span><br><span class="line">            (all_preds, preds),dim=<span class="number">0</span>)</span><br><span class="line">  <span class="keyword">return</span> all_preds</span><br></pre></td></tr></table></figure></li></ul><p>使用<code>@torch.no_grad()</code>就不用再记录梯度的轨迹(不用再保存动态图的计算轨迹)，省内存。</p><ul><li><p>方法2：<br>使用<code>with torch.no_grad()</code>在函数内部</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">  prediction_loader = torch.utils.data.DataLoader(train_set, batch_size=<span class="number">10000</span>)</span><br><span class="line">  train_preds = get_all_preds(network, prediction_loader)</span><br></pre></td></tr></table></figure></li></ul><h1><span id="7-gpu">7. GPU</span></h1><p>在这里原先一直有个误区，误认为<code>device = torch.device(&quot;cuda&quot;)</code>获取所有的GPU，<code>device = torch.device(&quot;cuda:0&quot;)</code>获取第一个GPU。下面是正解：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#程序只能看到1,2,3序号的GPU，然后重新给它们编号为：0,1,2</span></span><br><span class="line">&gt; os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">'1,2,3'</span></span><br><span class="line"></span><br><span class="line">&gt; device = torch.device(<span class="string">"cuda:0"</span>)<span class="comment">#获取下标为0的GPU</span></span><br><span class="line">device(type=<span class="string">'cuda'</span>, index=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#如果不指定cuda编号，其实有一个默认编号，</span></span><br><span class="line"><span class="comment">#默认为torch.cuda.current_device()，该值默认为0</span></span><br><span class="line">&gt; device = torch.device(<span class="string">"cuda"</span>)</span><br><span class="line">device(type=<span class="string">'cuda'</span>)</span><br><span class="line"></span><br><span class="line">&gt; torch.cuda.current_device()</span><br><span class="line"><span class="number">0</span></span><br></pre></td></tr></table></figure><p>也就是说<code>device = torch.device(&quot;cuda&quot;)</code>还是1个GPU，等价于<code>device = torch.device(&quot;cuda:X&quot;)</code>,其中<code>X = torch.cuda.current_device()</code>  </p><p>【<strong>参考资料</strong>】</p><p><a href="https://pytorch.apachecn.org/docs/1.0/tensor_attributes.html" target="_blank" rel="noopener">torch.device</a></p><p><a href="https://pytorch.org/docs/stable/notes/cuda.html" target="_blank" rel="noopener">CUDA SEMANTICS</a></p><h1><span id="8-多gpu运行程序">8. 多GPU运行程序</span></h1><p><a href="https://echohhhhhh.github.io/2020/01/06/Pytorch%E4%B9%8BGPU%E7%A8%8B%E5%BA%8F/" target="_blank" rel="noopener">Pytorch之GPU程序</a></p><p><a href="https://echohhhhhh.github.io/2019/12/29/%E8%BF%90%E8%A1%8CGPU%E7%A8%8B%E5%BA%8F/" target="_blank" rel="noopener">运行GPU程序</a></p><h1><span id="9-tensor">9. Tensor</span></h1><p><a href="https://echohhhhhh.github.io/2020/02/17/Pytorch%E4%B9%8BTensor%E5%AD%A6%E4%B9%A0/" target="_blank" rel="noopener">Pytorch之Tensor学习</a></p><h1><span id="bn和dropout在训练和测试的不同">BN和Dropout在训练和测试的不同</span></h1><p><code>model.train()</code>:启用 BatchNormalization 和 Dropout<br><code>model.eval()</code>:不启用 BatchNormalization 和 Dropout<br>训练完train样本后，生成的模型model要用来测试样本。在model(test)之前，需要加上model.eval()，否则的话，有输入数据，即使不训练，它也会改变权值。这是model中含有batch normalization层所带来的的性质。</p><p>参考资料<br><a href="https://zhuanlan.zhihu.com/p/54986509" target="_blank" rel="noopener">Pytorch model.train 与 model.eval</a><br><a href="https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615/19" target="_blank" rel="noopener">‘model.eval()’ vs ‘with torch.no_grad()’</a><br><a href="https://github.com/pytorch/examples/blob/master/word_language_model/main.py" target="_blank" rel="noopener">https://github.com/pytorch/examples/word_language_model</a></p><h1><span id="linear">Linear</span></h1><p>原先误以为Pytorch中的Linear的输入只能接受二维数据，实际上Linear的输入数据可以是三维、四维等更多维。但是<strong>输入数据的最后一维一定要和<code>in_dim</code>一致，输出数据维度就是把<code>in_dim</code>换成了<code>out_dim</code>，前面所有的维度都不变</strong>。<br>例如定义一个全连接<code>nn.Linear(10,5)</code>，输入数据维度为(3,6,10),输出维度为(3,6,5)。即输入数据最后一个维度一定要和<code>in_dim</code>一致，也不用纠结到底3是batch_size,还是6是batch_size，因为最终输出的数据只有最后一个维度变化，前面维度都不变。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dense = nn.Linear(in_dim,out_dim)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-简介&quot;&gt;&lt;a href=&quot;#1-简介&quot; class=&quot;headerlink&quot; title=&quot;1. 简介&quot;&gt;&lt;/a&gt;1. 简介&lt;/h1&gt;&lt;p&gt;汇总Pytorch的一些知识点&lt;/p&gt;
    
    </summary>
    
      <category term="Deep Learning" scheme="http://yoursite.com/categories/Deep-Learning/"/>
    
    
      <category term="Pytorch" scheme="http://yoursite.com/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>RiskOracle-A Minute-level Citywide Traffic Accident Forecasting Framework</title>
    <link href="http://yoursite.com/2020/02/18/RiskOracle-A-Minute-level-Citywide-Traffic-Accident-Forecasting-Framework/"/>
    <id>http://yoursite.com/2020/02/18/RiskOracle-A-Minute-level-Citywide-Traffic-Accident-Forecasting-Framework/</id>
    <published>2020-02-18T03:34:20.000Z</published>
    <updated>2020-02-21T05:56:50.817Z</updated>
    
    <content type="html"><![CDATA[<p>AAAI2020原文链接：<a href="https://github.com/zzyy0929/AAAI2020-RiskOracle" target="_blank" rel="noopener">RiskOracle-A Minute-level Citywide Traffic Accident Forecasting Framework</a><br>中国科大发<br><a id="more"></a></p><!-- TOC --><ul><li><a href="#1-%e6%91%98%e8%a6%81">1. 摘要</a></li><li><a href="#2-%e4%bb%8b%e7%bb%8d">2. 介绍</a></li><li><a href="#%e8%b4%a1%e7%8c%ae">贡献</a></li><li><a href="#3-%e9%97%ae%e9%a2%98%e5%ae%9a%e4%b9%89">3. 问题定义</a></li><li><a href="#4-minute-level-real-time-traffic-accident-forecasting">4. Minute-level Real-time Traffic Accident Forecasting</a><ul><li><a href="#41-framework-overview">4.1. Framework Overview</a></li><li><a href="#42-data-preprocessing">4.2. Data Preprocessing</a></li><li><a href="#43-multi-task-dtgn-for-accident-risk-prediction">4.3. Multi-task DTGN for Accident Risk Prediction</a></li></ul></li><li><a href="#5-%e5%ae%9e%e9%aa%8c">5. 实验</a><ul><li><a href="#51-%e6%95%b0%e6%8d%ae%e5%87%86%e5%a4%87">5.1. 数据准备</a></li><li><a href="#52-%e5%ae%9e%e7%8e%b0%e7%bb%86%e8%8a%82">5.2. 实现细节</a></li><li><a href="#53-%e8%af%84%e4%bb%b7%e6%8c%87%e6%a0%87">5.3. 评价指标</a></li><li><a href="#54-baseline">5.4. Baseline</a></li><li><a href="#55-%e5%ae%9e%e9%aa%8c%e7%bb%93%e6%9e%9c">5.5. 实验结果</a></li><li><a href="#56-%e8%b6%85%e5%8f%82%e6%95%b0">5.6. 超参数</a></li><li><a href="#57-%e6%a1%88%e4%be%8b%e5%88%86%e6%9e%90">5.7. 案例分析</a></li></ul></li><li><a href="#6-%e6%80%bb%e7%bb%93">6. 总结</a></li><li><a href="#7-%e7%9f%a5%e8%af%86%e8%a1%a5%e5%85%85">7. 知识补充</a></li></ul><!-- /TOC --><h1><span id="1-摘要">1. 摘要</span></h1><p>&ensp;&ensp;&ensp;&ensp;实时交通事故预测对公共安全和城市管理意义重大（例如.实时路径规划和应急响应部署）。之前的事故预测是在小时级别上，利用神经网络和静态的区域关系。然而，随着道路网络的高度动态性和交通师傅的稀有性，提高预测的粒度仍然是一个挑战，这将会导致结果偏差和零膨胀问题。在这篇论文中，我们提出一个新颖的RiskOracle框架，提高预测的粒度到分钟级别。具体来说，我们首先将0风险值转换为适合网络训练的值，然后，我们提出差分时变图神经网络(DTGN)来捕获交通状态的即时变化和子区间之间的动态相关性，并且，我们采用多任务和区域选择方案来突出显示全市范围内最可能发生事故的子区域，弥合了偏差的风险值和稀疏的事故分布。在2个真实数据集上做了大量实验证明了我们的RiskOracle框架的有效性和可扩展性。</p><h1><span id="2-介绍">2. 介绍</span></h1><p>&ensp;&ensp;&ensp;&ensp;交通事故预测对城市安全非常重要。构建一个细粒度级的事故预测模型，为乘客提供及时的安全路径规划，为新兴应用(智能交通和自动驾驶)提供准确的应急响应的需求越来越大。<br>&ensp;&ensp;&ensp;&ensp;关于事故预测周期的长短，现有的工作主要分为2类：长期（天级别预测）和中期（小时级别预测）。我们在表1中总结了所有相关的工作。即使最近关于天级别的预测模型通过建模时空异质数据取得了很好的效果，但是对于紧急的情况并没有意义。<br>&ensp;&ensp;&ensp;&ensp;在小时级别上的中期事故预测可以进一步划分为：传统方法和深度学习。传统方法包括：基于聚类，基于频率树，基于非负矩阵分解。但是，这些方法忽略了时间关系，不能建模复杂非线性的时空关系。深度学习方法例如，仅仅将历史交通事故数据输入到模型中，利用LSTM学习时间相关性，缺少了多源实时交通数据，效果不好。还有一些工作利用深度学习框架SDAE/SDCAE和ConvLSTM，结合人类实时移动数据，来学习交通事故模式，但是它们都不能提取区域间和区域内随时间变化的关系。<br>&ensp;&ensp;&ensp;&ensp;即使深度学习模型的进展为小时级别的事故预测带了可喜的结果，但是我们认为其忽略了3个重要的问题，使得在分钟级别的预测效果较差。第一，在2019中提到的，当预测任务的时空分辨率提高时，会出现零膨胀问题，将预测所有的结果都为0。由于没有方法来解决这个问题，稀少的非零值在训练时使模型无法生效。第二，尽管CNNC可以学习静态的子区域相关性，但是随时间变化的子区域相关性在城市短期事故预测有着重要的作用，例如，由于潮汐流，2个子区域在早上相关性强，在下午相关性弱。第三，在同一子区域相邻时间段内交通状况的异常变化通常会诱发交通事故或其他事件。没有考虑以上3个时空因素，小时级别的预测模型能力将受到严重阻碍。</p><p><img src="/2020/02/18/RiskOracle-A-Minute-level-Citywide-Traffic-Accident-Forecasting-Framework/Summarization.png" alt=""></p><p>表中的论文<br><a href="https://echohhhhhh.github.io/2019/07/21/traffic-accident/#11-learning-deep-representation-from-big-and-heterogeneous-data-for-traffic-accident-inference2016aaai" target="_blank" rel="noopener">Learning Deep Representation from Big and Heterogeneous Data for Traffic Accident Inference(2016AAAI)</a></p><p><a href="https://echohhhhhh.github.io/2019/07/21/traffic-accident/#14-a-deep-learning-approach-to-the-citywide-traffic-accident-risk-prediction2018ieee-itsc" target="_blank" rel="noopener">A Deep Learning Approach to the Citywide Traffic Accident Risk Prediction(2018IEEE-ITSC)</a></p><p><a href="http://tony.9shi.cf/index.php?q=aHR0cHM6Ly93d3cua2RkLm9yZy9rZGQyMDE4L2FjY2VwdGVkLXBhcGVycy92aWV3L2hldGVyby1jb252bHN0bS1hLWRlZXAtbGVhcm5pbmctYXBwcm9hY2gtdG8tdHJhZmZpYy1hY2NpZGVudC1wcmVkaWN0aW9uLW9uLQ" target="_blank" rel="noopener">Hetero-ConvLSTM: A Deep Learning Approach to Traffic Accident Prediction on Heterogeneous Spatio-Tem(2018KDD)</a></p><p>&ensp;&ensp;&ensp;&ensp;这篇论文，我们研究了分钟级别的全市交通事故预测，提出了三阶段RiskOracle框架，该框架基于多任务差分时变图卷积(Multi-task DTGN)。三个阶段分别是：数据预处理阶段，训练阶段，预测阶段。在数据预处理阶段，我们提出一个感知策略以最大程度地推断全球交通状况，然后设计基于数据增强的先验知识来解决短期预测中的零膨胀问题。在训练阶段，我们提出Multi-task DTGN，其中时变总体上建模了短期子区域的动态相关性，差分特征生成器在交通状态即时变化和交通事故之间建立了高级联系。正如我们所知，交通事故和交通量在城市中通常分布不均衡，因此多任务方案旨在解决事故预测中的空间异质性，然后在预测阶段，我们利用学到的多尺度事故分布，获取到一组离散的最可能发生事故的子区域。在2个真实数据集上的实验证明了我们的框架在10-min和30-min级别的预测任务上都超过了state-of-the-art。</p><h1><span id="贡献">贡献</span></h1><ul><li>提升实时事故预测的时间粒度，从小时—&gt;分钟</li><li>提出多任务STDN来解决短期事故预测的挑战。这是第一篇使用图卷积来解决事故预测问题</li><li>距离远但是有潜在关系的区域在图中可以被动态连接</li><li>通过差分特征生成器，交通状况的异常变化可以被捕获</li><li>多任务学习用来解决稀疏和空间异质性问题。多尺度的事故分布可以突出强调最可能发生交通事故的子区域</li><li>提出数据增强策略来解决零膨胀问题</li><li>提出协同感知策略来处理稀疏的感知数据</li></ul><h1><span id="3-问题定义">3. 问题定义</span></h1><p>&ensp;&ensp;&ensp;&ensp;在这一节，介绍基本定义，使用公式定义问题。<br>&ensp;&ensp;&ensp;&ensp;在我们的工作中，如果直接将整个研究区域作为方形区域，使用CNN进行时空特征提取，尤其在实时事故预测中，则会导致不必要的冗余，因为城市轮廓通常是不规则的。如图2(a)所示，我们首先将路网中研究区域划分为<code>q</code>个中等大小的矩形区域，每一个矩形区域包含一些小的方形子区域。一共有<code>m</code>个子区域(subregion)，我们通过城市图对<code>m</code>个子区域建模。</p><p><strong>定义1：Urban Graph</strong>：研究区域可以定义成无向图，用$G(\mathcal{V},\mathcal{E})$表示。顶点集$\mathcal{V}=\{v_1,v_2,…,v_m\}$，其中$v_i$表示第$i$个方形子区域，给定2个节点$v_i,v_j\in \mathcal{V}$,边$e_{ij} \in \mathcal{E}$表示2个subregion的连接，边非0即1。</p><script type="math/tex; mode=display">e_{i j}=\left\{\begin{array}{ll}{1} & {\text { iff the traffic elements within two }} \\ {} & {\text { subregions have strong correlations }} \\ {0} & {\text { otherwise }}\end{array}\right.</script><p>&ensp;&ensp;&ensp;&ensp;在该论文中，1个节点的<code>traffic element</code>包括2方面，静态的道路特征和动态的traffic特征。$\rho$来控制<code>affinity matrix</code>$\mathcal{A}_s$和$\mathcal{A}^{\Delta t}_o$的稀疏性，表示整个<code>urban graph</code>的连通性，在<code>affinity matrix</code>中的非0值表示subregion之间有很强的相关性。<br>&ensp;&ensp;&ensp;&ensp;在一个时间段$\Delta t$中<code>subregion</code> $v_i$的动态traffic特征包括3部分，(a)人流量，用<code>traffic volume</code>$TV_{v_i}(\Delta t)$表示;(b)交通状况，用平均交通速度$a_{v_i}(\Delta t)$表示;(c)交通事故风险等级$r_{v_i}(\Delta t)$。动态交通特征的正式定义如下所示。</p><p><strong>定义2：Static Road Network Features</strong>：一个城市<code>subregion</code>节点$v_i \in \mathcal{V}$,它的静态路网特征包括道路个数，道路类型，道路长度和宽度，除雪等级，红绿灯个数，<code>subregion</code> $v_i$中的所有道路使用一个固定长度的向量$s_i$表示。整个<code>urban graph</code>的静态道路特征使用$S=\{s_1,s_2,…,s_m\}$表示。静态特征，不随着时间变化，没有时间下标。</p><p><strong>定义3：Dynamic Traffic Features</strong>：对一个<code>subregion</code>节点$v_i \in \mathcal{V}$,在时间段$\Delta t$中，它的动态交通特征被表示为$f_{v_i}(\Delta t)=\left\{T V_{v_{i}}(\Delta t), a_{v_{i}}(\Delta t), r_{v_{i}}(\Delta t)\right\}$，$r_{v_i}(\Delta t)$是交通事故的risk求和，将交通事故分为3类：轻度，中度，重度，risk值分别是1,2,3.所有子区域在时间段$\Delta t$的交通事故风险分布表示为$\mathcal{R}(\Delta t)=\left\{r_{v_{1}}(\Delta t), r_{v_{2}}(\Delta t), \cdots, r_{v_{m}}(\Delta t)\right\}$，动态交通特征表示为$\mathcal{F}(\Delta t)=\left\{f_{v_{1}}(\Delta t), f_{v_{2}}(\Delta t), \cdots, f_{v_{m}}(\Delta t)\right\}$。动态交通特征随着时间变化，所以有区域和时间2个变量，动态特征包括：人流量，交通平均速度，事故风险</p><p><strong>定义4:Traffic Accident Prediction</strong>：给定所有子区域的静态道路特征$S$和所有子区域历史$T$个时间段的动态交通特征$\mathcal{F}(\Delta t)(\Delta t=1,2,…,T)$,目标是预测下一个时间段全市的事故风险$\mathcal{R}(T+1)$和选出高风险的子区域$\mathcal{V}_{acc}(T+1)$</p><blockquote><p>总结：根据m个子区域构建无向图，节点表示子区域，边表示2个子区域特征之间的相关性。2个子区域之间的特征有强相关性，边为1，否则为0。即无向图的边非1即0。子区域的特征包括2类：静态道路特征和动态交通特征。静态道路特征包括：道路个数，道路类型，长宽，道路除雪等级，红绿灯个数。动态交通特征包括：在该时间段内的车流量，车平均速度，该子区域事故风险。</p></blockquote><h1><span id="4-minute-level-real-time-traffic-accident-forecasting">4. Minute-level Real-time Traffic Accident Forecasting</span></h1><p>&ensp;&ensp;&ensp;&ensp;在这一节，先整体看一下我们的<code>RiskOracle</code>框架，然后再详细介绍。</p><p><img src="/2020/02/18/RiskOracle-A-Minute-level-Citywide-Traffic-Accident-Forecasting-Framework/RiskOracle.png" alt=""></p><h2><span id="41-framework-overview">4.1. Framework Overview</span></h2><p>&ensp;&ensp;&ensp;&ensp;如图1所示，<code>RiskOracle</code>框架包括3个阶段：数据预处理阶段，训练阶段，预测阶段。</p><h2><span id="42-data-preprocessing">4.2. Data Preprocessing</span></h2><p><strong>解决事故预测中的空间异质</strong>。高风险的值通常出现在城市区域，由于市中心发生事故多且车流量大，导致风险值在空间上不均衡，会忽略农村地区相对高风险的区域。为了实现全市预测，选择最有可能发生事故的区域来解决空间异质性是非常必要的。如图2(a)所示,按照层次结构组织这个子区域，中等大小区域用来收集粗粒度的事故分布，小的子区域用来收集细粒度的事故分布，然后进一步突出显示每个中等区域中的子区域。多尺度分布也可以看做分层事故分布。<br><strong>解决零膨胀问题</strong>。深度神经网络在训练中，如果非零值非常少的话，受到零膨胀的影响，将会预测出无效的值。如图2(b)所示，在选定的10min中，整个NYC只有6个交通事故，说明在短期事故的内在稀有性。为了解决这个问题实现实时事故预测，我们设计基于先验知识的数据增强(PKDE)策略来区分训练数据集中标签的风险值。具体来说，对时间段$\Delta t$,我们将所有区域在该时间段内的风险值$\mathcal{R}(\Delta t)$中的0转换为具有区分度的负值。转换分为2步：a)风险中的0值通过等式2转换为事故风险指标；b)指标值通过等式3转换为静态事故强度。给定子区域$v_i$，我们计算它的事故风险指标$\varepsilon_{v_i}$  </p><script type="math/tex; mode=display">\varepsilon_{v_{i}}=\frac{1}{N_{\text {week}}} \sum_{j=1}^{N_{\text {week}}} \frac{r_{v_{i}}(j)}{\sum_{k=1}^{m} r_{v_{k}}(j)}</script><p>其中$N_{week}$是训练集中总共的周数，$r_{v_{i}}(j)$是区域$v_i$在第$j$周总的风险值。然后，根据该子区域的事故风险指标$\varepsilon_{v_i}$,我们通过以下公式计算子区域$v_i$的统计事故强度。  </p><script type="math/tex; mode=display">\pi_{v_{i}}=b_{1} \log _{2} \varepsilon_{v_{i}}+b_{2}</script><blockquote><p>总结：给定时间段$\Delta t$，将子区域中的riks 0值转换为负值，先计算事故风险指标，再计算事故强度。</p></blockquote><p>其中$b_1$和$b_2$是算子，用来保持绝对值$\pi_{v_{i}}$的范围和真实风险值的范围对称。我们通过对数在0和1之间的区分性质，可以使转换后的数据易于区分并适合于训练网络。转换的方式为：1)事故风险为0的子区域的事故强度为负，小于非零风险的子区域，反映了零风险子区域有较低的事故风险;2)具有较低事故风险指标的子区域有较低的事故概率，保留了实际事故风险的等级。<br>事故风险指数$\varepsilon_{v_{i}}$值在[0,1]之间，取对数值在$(-\infin,0]%$，如果一个子区域的风险值为0，则事故风险指数为0，则事故强度$\pi_{v_{i}}$为负。</p><p><img src="/2020/02/18/RiskOracle-A-Minute-level-Citywide-Traffic-Accident-Forecasting-Framework/nyc-map.png" alt=""></p><p><strong>补充稀疏的传感数据</strong>。实时交通信息的通常收集不足来进行事故预测，动态交通信息通常和静态空间路网结构相互影响，因此，我们提出了一个协同感知策略，利用FM的交互操作，修改<code>xDeepFM</code>为时空深度因式分解(ST-DFM)。<br>我们首先通过静态关联矩阵$\mathcal{A}_s$来提取2个子区域间的路网相似性和连接性。其中关联矩阵affinity matrix中的元素$\alpha_s(i,j)$表示子区域$v_i和v_j$见的静态相关性。</p><script type="math/tex; mode=display">\alpha_{s}(i, j)=\left\{\begin{array}{cc}{1} & {\text { if subregion } v_{i} \text { and }} {v_{j}} {\text { are adjacent }} \\{e^{-J S\left(s_{i} \| s_{j}\right)}} & {\text { otherwise }}\end{array}\right.</script><p>其中，$JS$函数是Jensen-Shannon divergence（散度），$s_{i}和s_{j}$是子区域$i,j$的静态道路特征，包括道路个数，类型，长宽，除雪等级，红绿灯个数。</p><script type="math/tex; mode=display">J S\left(s_{i} \| s_{j}\right)=\frac{1}{2} \sum_{k}\left(\begin{array}{c}{s_{i}(k) \log \frac{2 s_{i}(k)}{s_{i}(k)+s_{j}(k)}+} \\{s_{j}(k) \log \frac{2 s_{j}(k)}{s_{i}(k)+s_{j}(k)}}\end{array}\right)</script><p>和xDeepFM一样，ST-DFM包含压缩交互网络模块和DNN模块。在ST-DFM中嵌入了3个时空字段，即静态空间特征，动态交通特征和时间戳。然后ST-DFM通过CIN模块学习矢量级别不同时空特征间的交互关系，通过DNN模块学习特征的高级表示，最后获取高级特征的组合。我们将对应子区间的交通量输入到ST-DFM中来推断速度值，反之亦然。然后通过训练2个实时交通数据的交集数据，来最大程度推断交通信息，以此获取全局交通状态。</p><blockquote><p>补充：JS散度是一个衡量距离的函数，JS散度的值域在[0,1]之间，相同为0，反之为1。静态affinity matrix $\mathcal{A}_s \in R^{m \times m}$，如果2个子区域相邻，值为1，不相邻则计算2个子区域的静态道路特征的相似度，值在$[\frac{1}{e},1]$之间，越相似，值越靠近1，越不相似，值越靠近$\frac{1}{e}$</p></blockquote><h2><span id="43-multi-task-dtgn-for-accident-risk-prediction">4.3. Multi-task DTGN for Accident Risk Prediction</span></h2><p><strong>时空DTGN</strong>.事故和交通拥堵在路网中通常相互影响，特别是节假日和高峰。由于GCN对非欧式空间很好的建模，我们提出了DTGN，通过time-varying overall affinity和differential feature generator来修改GCN，解决分钟级别预测事故的挑战。</p><p><strong>Time-varying overall affinity matrix with dynamic traffic features involved</strong>. 不同城市分区之间的交通状况有很强的时变相关性。并且，交通事故和交通状况有很强的时空相关性。因此，对于分钟级别的事故预测，需要通过动态affinity matrix $\mathcal{A}^{\Delta t}_o$捕获子区域间在时间段$\Delta t$的时间交通相关性。在$\mathcal{A}^{\Delta t}_o$中的元素$\alpha^{\Delta t}_o(i,j)$表示子区域$i,j$的动态相似性。</p><script type="math/tex; mode=display">\alpha_{O}^{\Delta t}(i, j)=e^{-J S\left(s_{i}^{*} \| s_{j}^{*}\right)}+\gamma * e^{-J S\left(C_{i}^{\Delta t} \| C_{j}^{\Delta t}\right)}</script><p>其中$C_{i}^{\Delta t}$表示子区域$v_i$上周每一天相同时间段的交通量$TV_{v_i}(\Delta t)$和平均速度$a_{v_i}(\Delta t)$。注意我们使用Attention机制，根据子区域的静态空间特征对事故的影响，修改了子区域静态空间特征的权重。并且子区域基于事故的静态的静态特征可以表示为$s^*_i$.权重$\gamma$用来调节动态交通affinity占overall affinity matrix的比例。通过overall affinity matrix，距离较远但有潜在事故相关的子区域可以被动态连接。为了在谱域运行GCN，我们需要计算动态affinity matrix $\mathcal{A}^{\Delta t}_o$的拉普拉斯矩阵$L^{\Delta t}$，其中$\mathcal{A}^{\Delta t}_o$可以被看做邻接矩阵。首先定义$\mathcal{B}^{\Delta t}$</p><script type="math/tex; mode=display">\mathcal{B}^{\Delta t}=\mathcal{A}_{o}^{\Delta t}+I_{m}</script><p>其中$I_{m}$是维度$m \times m$的单位矩阵。然后计算$\Phi^{\Delta t}$</p><script type="math/tex; mode=display">\Phi^{\Delta t}=\left[\begin{array}{cccc}{\varphi_{11}} & {0} & {\cdots} & {0} \\{0} & {\varphi_{22}} & {\cdots} & {0} \\{\vdots} & {\vdots} & {\ddots} & {\vdots} \\{0} & {0} & {\cdots} & {\varphi_{m m}}\end{array}\right]</script><p>其中$\varphi_{i i}=\sum_{j=1}^{m} b_{i j}$,$b_{i j}$是矩阵$\mathcal{B}^{\Delta t}$中的元素。然后获取时间段$\Delta t$的拉普拉斯矩阵。</p><script type="math/tex; mode=display">L^{\Delta t}=\left(\Phi^{\Delta t}\right)^{-\frac{1}{2}} \mathcal{B}^{\Delta t}\left(\Phi^{\Delta t}\right)^{-\frac{1}{2}}</script><blockquote><p>补充：原始GCN中，拉普拉斯矩阵为$\hat{D}^{-\frac{1}{2}}\hat{A}\hat{D}^{-\frac{1}{2}}$，其中$\hat{A}=A+I$</p><p>总结：文中提到的affinity matrix有2类：静态affinity matrix $\mathcal{A}_s$和动态overall affinity matrix $\mathcal{A}_o^{\Delta t}$，这2个矩阵的维度都是$R^{m \times m}$，其中静态affinity matrix不随着时间变化，根据子区域的静态道路特征计算得到。动态overall affinity matrix随着时间变化，由子区域的静态道路特征和上周每一天同时间段的动态交通特征(车流量和车平均速度)计算得来。这里将动态overall affinity matrix看做邻接矩阵，计算拉普拉斯矩阵，每个时间段都有一个拉普拉斯矩阵，用在GCN中。</p></blockquote><p><strong>Differential GCN for extracting spatiotemporal features</strong>和常规的交通状况相比，事故或事件预测和交通状况的异常变化更相关。因此，我们引入了差分特征生成器来计算相邻时间段的差分图片。将差分动态交通特征输入到GCN中，可以对交通状况的异常变化的传播和相互作用进行建模，并且可以学习即时的交通状态变化和事故之间的高层关系，可以更好地用来分钟级的事故预测。给定时间段$\Delta t$,差分向量$\vec{\Theta}^{\Delta t}$计算如下：</p><script type="math/tex; mode=display">\vec{\Theta}^{\Delta t}=\mathcal{D}(\Delta t)-\mathcal{D}(\Delta t-1)</script><p>其中$\mathcal{D}(\Delta t)=\left\{d_{v_{1}}(\Delta t), d_{v_{2}}(\Delta t), \cdots, d_{v_{m}}(\Delta t)\right\}$,$d_{v_{i}}(\Delta t)=\left\{T V_{v_{i}}(\Delta t), a_{v_{i}}(\Delta t)\right\}$，差分不涉及到事故风险的计算。在时间段$\Delta t$中所有的子区域通过结合它们的动态交通特征和对应的差分向量，生成了统一的特征元组$\mathcal{U}(\Delta t)=\left\{\mathcal{F}(\Delta t), \vec{\Theta}^{\Delta t}\right\}$,在郑宇AAAI2017 ST-ResNet文中提到的，城市交通有3个时间周期：小时，天，长期趋势。所以，给定时间段$\Delta t$，我们选取$\mathcal{k}$个统一特征元组，按照ST-ResNet，设置$\mathcal{k}=3$,作为DTGN的输入。具体来说，选取时间段$\Delta t$的前$\mathcal{k}$个时间段作为小时周期，选取连续前$\mathcal{k}$天中相同的时间段作为天周期，至于长期趋势，向前每10天取1天，一共取$\mathcal{k}$天,在这$\mathcal{k}$天种，取相同的时间段作为长期趋势。即hour周期有$\mathcal{k}$个时间段,天周期有$\mathcal{k}$个时间段，长期区域有$\mathcal{k}$个时间段。如图1所示，将这3个时间周期的二元组分别输入到3个DTGN中。其中DTGN的模型细节在图3(a)中。对于每一个时间周期，将它的特征二元组用$\mathbb{U}_{<em>} \Delta t$表示，将$\mathbb{U}_{</em>} \Delta t$输入到FCN中，将特征嵌入成低维特征，然后输入到GCN中。</p><script type="math/tex; mode=display">\mathcal{H}^{n+1}=\text{Leaky-ReLU}(L^*  \mathcal{H}^{n} \mathcal{W}^{n}),\text { where } \mathcal{H}^{0}=\mathbb{U}_{*}^{\Delta t}</script><p>其中$\mathcal{H}^{n}$表示第n层GCN输入的特征，$\mathcal{W}^{n}$表示第n层GCN的卷积核参数。因为每个时间周期会输出多个时间段的数据，在做GCN操作时，需要用到拉普拉斯矩阵，这里的$L^*$是输入所有时间段的拉普拉斯矩阵$L^{\Delta t}$的平均。每2个GCN后使用1次BN，防止梯度爆炸。考虑到转换后的risk中有负值，使用Leaky_ReLU激活。同时，对应时间段的外部数据(时间戳和天气)经过嵌入层变成定长的向量，再和GCN的输入融合。因为有3个时间周期，DTGN有3个输出，分别用$\mathcal{O}_{h c}^{\Delta t}, \mathcal{O}_{d p}^{\Delta t}$ and $\mathcal{O}_{d t}^{\Delta t}$表示。</p><p><img src="/2020/02/18/RiskOracle-A-Minute-level-Citywide-Traffic-Accident-Forecasting-Framework/DTGN.png" alt=""></p><blockquote><p>总结：每一个时间段有一个差分向量，是该时间段所有区域的车流量和车平均速度减去上一时间段的值，得到差分向量。然后将该时间段所有子区域的动态交通特征$\mathcal{F}(\Delta t)$和该时间段的差分向量$\vec{\Theta}^{\Delta t}$组成一个统一的特征元组$\mathcal{U}(\Delta t)$。那么每个时间段都有一个特征元组，存储所有子区域的特征。受郑宇2017AAAI ST-ResNet的启发，事故的发生有小时，天，长期的周期性，如果当前时间段是t，为其找出小时，天，长期的时间段。小时周期：[t,t-1,t-2]，天周期：[昨天t,前天t,大前天t]，长期周期[10天前t,20天前t,30天前t],然后分别输入到3个DTGN中。这个拿1个DTGN举例。输入的图信号矩阵维度是(batch_size,N,T*D),将时间维度乘到特征上，先经过FCN对特征进行嵌入，变成低维特征。然后输入到GCN中，GCN操作需要使用拉普拉斯矩阵。上节中提到拉普拉斯矩阵是动态的，每一个时间段都有一个L，这里每个周期都有3个时间段，使用的拉普拉斯矩阵是3个时间段拉普拉斯矩阵的平均值。</p></blockquote><p><strong>多任务学习来事故风险预测</strong>设计多任务学习方案，不仅可以增强深度学习的表示能力，还可以学到分层事故分布，为最可能发生事故区域的选取提供指导。为了预测子区域的事故风险，我们首先将事故风险分布作为主任务。考虑到交通事故和人类活动强度有关，我们将区域交通量预测作为第一个辅助任务，用来提高深度学习的表示能力，。为了给分层事故区域的选取提供指导，将预测中等区域发生的事故总数作为第二个辅助任务。<br>具体地，我们将DTGN的3个输出$\mathcal{O}_{h c}^{\Delta t}, \mathcal{O}_{d p}^{\Delta t}$ and $\mathcal{O}_{d t}^{\Delta t}$输入到卷积融合模块中，融合成1个输出，然后进行多任务学习，如图3(b)所示。首先生成预测风险分布特征图$\mathcal{O}_{\text {risk}}^{\Delta t}$,使用$Leaky_ReLU$激活是因为label中的risk值有负值，其余都使用$ReLU$激活。</p><script type="math/tex; mode=display">\mathcal{O}_{r i s k}^{\Delta t}=\text { Leaky } \operatorname{ReLU}\left(\mathcal{W}_{risk}^{\Delta t} *\left[\mathcal{O}_{h c}^{\Delta t}, \mathcal{O}_{d p}^{\Delta t}, \mathcal{O}_{d t}^{\Delta t}\right]\right)</script><script type="math/tex; mode=display">\mathcal{O}_{v o l}^{\Delta t}=\operatorname{ReLU}\left(\mathcal{W}_{v o l}^{\Delta t} *\left[\mathcal{O}_{h c}^{\Delta t}, \mathcal{O}_{d p}^{\Delta t}, \mathcal{O}_{d t}^{\Delta t}\right]\right)</script><script type="math/tex; mode=display">\mathcal{O}_{\text {count}}^{\Delta t}=\operatorname{ReLU}\left(\mathcal{W}_{f c}^{\Delta t} *\left(\mathcal{W}_{\text {count}}^{\Delta t} *\left[\mathcal{O}_{h c}^{\Delta t}, \mathcal{O}_{d p}^{\Delta t}, \mathcal{O}_{d t}^{\Delta t}\right]\right)\right)</script><p>使用一个全连接学习每个中等区域发生事故的总数。<br>其中$\mathcal{W}_{risk}^{\Delta t},\mathcal{W}_{vol}^{\Delta t},\mathcal{W}_{count}^{\Delta t}$表示三个任务中：细粒度事故风险，交通流量，中等区域发生事故总数的训练权重。$\mathcal{W}_{fc}^{\Delta t}$是全连接网络中的融合权重。$\mathcal{O}_{\text {count}}^{\Delta t}$是粗粒度的事故分布，将其输入到另一个全连接中，reshape成和$\mathcal{O}_{\text {risk}}^{\Delta t}$相同维度，和原先的细粒度事故分布相加，迫使学习粗粒度和细粒度的事故分布之间的关系。最终$\mathcal{O}_{\text {risk}}^{\Delta t}$被更新为</p><script type="math/tex; mode=display">\mathcal{O}_{risk*}^{\Delta t}=\text { Leaky } \operatorname{ReLU}\left(\mathcal{W}_{f c *} * \mathcal{O}_{c o u n t}^{\Delta t}+\mathcal{O}_{r i s k}^{\Delta t}\right)</script><p>其中$\mathcal{O}_{risk*}^{\Delta t}$是最终主任务的输出。</p><blockquote><p>疑问：3个DTGN输出的维度应该是(batch_size,N,D),怎么使用卷积对其进行融合？</p></blockquote><p>多任务的总loss如下：</p><script type="math/tex; mode=display">\operatorname{Loss}(\theta)=m s e_{r i s k}+\lambda_{1} * m s e_{v o l}+\lambda_{2} * m s e_{c o u n t}+\lambda_{3} * L_{2}</script><p>其中$m s e_{r i s k}, m s e_{v o l},m s e_{c o u n t}$是主任务和2个辅助任务的loss，这里使用L2正则化来避免过拟合。$\lambda_{1},\lambda_{2},\lambda_{3}$是损失函数的超参数。</p><p><strong>分层最可能发生事故区域选择</strong>.交通事故和交通量在城市和农村经常不均衡，导致空间异质性问题。因此，用统一的风险阈值来选择最可能发生事故的区域是不合理的，我们基于多任务中的分层事故分布，提出一个分层的最可能发生事故区域选择的方法。<br>对每个中等区域$i$，我们都从中选出$k_i(i=1,2,…,q)$个风险最高的子区域，其中参数$k_i$等于第二个辅助任务学到的$\mathcal{O}_{\text {count}}^{\Delta t}$中对应的值。因此，我们获得了一组最可能发生事故的子区域。并且通过这种方式获得的$k_i$可以减少区域的过度预测，并且模型符合时间和天气的变化。</p><h1><span id="5-实验">5. 实验</span></h1><p>分钟级别的事故预测模型，设置时间段分别为10min和30min</p><h2><span id="51-数据准备">5.1. 数据准备</span></h2><p>在2个真实数据集上做实验：NYC Opendata和苏州工业园区(SIP)。对于NYC数据集，由于缺少实时的交通流量数据，这里利用每个子区域的出租车流量来代表人流量。对于SIP数据集，它包含交通流量和速度。我们将其从新浪收集的交通事故数据集集成。2个数据集的统计信息在表2中。</p><p><img src="/2020/02/18/RiskOracle-A-Minute-level-Citywide-Traffic-Accident-Forecasting-Framework/dataset.png" alt=""></p><h2><span id="52-实现细节">5.2. 实现细节</span></h2><p>训练集:验证集:测试集=6:1:3，划分子区域参照AAAI2019<a href="https://echohhhhhh.github.io/2019/03/05/Spatiotemporal-Multi-Graph-Convolution-Network-for-Ride-hailing-Demand-Forecasting/" target="_blank" rel="noopener">Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting</a>和实际情况。堆叠9层GCN，每层有384个filter。损失函数中$\lambda_{1}=0.8,\lambda_{2}=1,\lambda_{3}=1e-4$。优化器使用Adam。</p><p>在训练阶段，动态交通数据和affinity matrix被划分为小时，天，长期共3组，2种scale的事故分布输入到多任务DTGN中。在测试阶段，将数据组织成以上格式并输入到模型中，最有可能发生事故的子区域可以从主任务和辅助任务2中得到。高风险子区域被突出显示，并与实际的事故记录比较。</p><h2><span id="53-评价指标">5.3. 评价指标</span></h2><p>从2个角度验证RiskOracle模型，回归角度：MSE，分类角度：a)Acc@M，常用于时空排名任务中，表示预测的前M个风险最高的子区域中正确的比例。NYC数据集中，在30min预测时，M=20，在10min预测时，M=6。在SIP数据集中，M=5。b)Acc@K,其中K是第二个辅助任务学到的$k_i$的总和。其中Acc1表示发生事故频率较高时间段的准确率，例如早上7~9点，下午12~4点。</p><h2><span id="54-baseline">5.4. Baseline</span></h2><ol><li>ARIMA，用于时间序列预测</li><li>Hetero-ConvLSTM(2018KDD),调整超参数为4,blocks with 16 filters, and a size of 12x12 moving window with step=6.</li><li>ST-ResNet(2017AAAI郑宇)用来预测车流量</li><li>SDAE(2016AAAI)使用人流量来预测risk</li><li>SDCAE最新的小时级别风险预测模型</li></ol><h2><span id="55-实验结果">5.5. 实验结果</span></h2><p><strong>性能比较</strong><br>实验结果如表3.RiskOracle获得了最高的准确率，且MSE优于大部分baseline。使用分层事故区域选择HARS，我们的模型解决了空间异质性和过渡预测的问题。尤其在NYC数据集上，我们模型在Acc@20比最好的模型高22.49%。对于稀疏的传感数据和短期的时空预测，可扩展性高。并且，我们的模型在高峰期的预测更好，在现实应用中有用。所有的指标NYC的都比SIP的要好，可能因为SIP数据中事故标签不完整。<br>总体上，随着时间粒度变小，我们的模型性能稍微下降，而其他的模型急剧下降因为遇到零膨胀问题。这表明我们的模型在短期事故预测中的有效性和可扩展性。在实际应用中有很少的事故记录时，2个数据集上的提升验证了我们模型的健壮性和普适性。</p><p><img src="/2020/02/18/RiskOracle-A-Minute-level-Citywide-Traffic-Accident-Forecasting-Framework/result.png" alt=""></p><p><strong>Acc@K和消融实验</strong>.如图4所示。Acc@20和Acc@6的结果略高于Acc@K，这是合理的，因为统一阈值无法适应实时条件，并且往往会高估事故率。相反，我们的框架具有使用多尺度事故分布预测，近似估计每个矩形区域中事故数量，具有灵活性。与表3中的结果相比，我们的框架胜过其他baseline，并在Acc@K达到可接受的准确性水平。<br>为了验证哪个组件起作用，做了消融实验，从模型中去掉一些组件。</p><ul><li>RO-1：去掉基于先验知识的数据增强PKDE，无法解决零膨胀问题。priori knowledge-based data enhancement</li><li>RO-2：去掉ST-DFM，无法解决实时交通数据缺失问题</li><li>RO-3：去掉overall affinity，无法实现时变的GCN</li><li>RO-4：去掉差分特征生成器，在输入到GCN中没有差分特征</li><li>RO-5：去掉带有HARS的多任务</li><li>Integrated model：完整模型<br>其中最重要的组件是overall affinity和PKED，说明零膨胀和时变GCN是重要的。</li></ul><p><img src="/2020/02/18/RiskOracle-A-Minute-level-Citywide-Traffic-Accident-Forecasting-Framework/ablation.png" alt=""></p><h2><span id="56-超参数">5.6. 超参数</span></h2><p>在NYC数据集的30min展示超参数实验。</p><ul><li>9层GCN，每层有384个filter</li><li>损失函数中$\lambda_{1}=0.8,\lambda_{2}=1,\lambda_{3}=1e-4$</li><li>计算overall affinity时动态元素占的比重$\gamma=0.5$</li><li>中等区域个数$q=18$</li></ul><h2><span id="57-案例分析">5.7. 案例分析</span></h2><p>可视化NYC2017.5.22这一天中选取的3个30min时间段。上面是预测值，下面是真实值。可以看到预测的高风险子区域和真实值相似。由于在周日上午很少人外出，因此早晨7:00预测发生的事故很少。但是，下午事故数量会增加，而到了晚上，事故更加严重，由于当晚大雨，路况易发生事故。结果证明，辅助任务和HARS通过捕获外部因素，来学习事故分布的动态模式，调整推理，比统一阈值解决方案具有更好的适应性。</p><p><img src="/2020/02/18/RiskOracle-A-Minute-level-Citywide-Traffic-Accident-Forecasting-Framework/case.png" alt=""></p><h1><span id="6-总结">6. 总结</span></h1><p>在这篇论文中，我们提出了基于多任务DTGN的RiskOracle框架，解决分钟级的事故预测问题。首先提出2个方法来解决零膨胀和稀疏感知的问题。在多任务DTGN中，结合差分特征生成器和时间overall affinity，模型可以建模稀疏的时空数据，捕获短期的子区域相关性。学习多尺度事故分布，突出显示最可能发生事故的子区域来解决空间异质性。在2个真实数据集上的实验验证模型的优越性。</p><h1><span id="7-知识补充">7. 知识补充</span></h1><p><strong>【Factorization Machine】</strong> FM (Factorization Machine) 主要是为了解决数据稀疏的情况下，特征怎样组合的问题。<br><a href="https://zhuanlan.zhihu.com/p/80726100" target="_blank" rel="noopener">【推荐系统】Factorization Machine</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;AAAI2020原文链接：&lt;a href=&quot;https://github.com/zzyy0929/AAAI2020-RiskOracle&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;RiskOracle-A Minute-level Citywide Traffic Accident Forecasting Framework&lt;/a&gt;&lt;br&gt;中国科大发&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="时空领域" scheme="http://yoursite.com/tags/%E6%97%B6%E7%A9%BA%E9%A2%86%E5%9F%9F/"/>
    
  </entry>
  
  <entry>
    <title>时空论文列表</title>
    <link href="http://yoursite.com/2020/02/18/%E6%97%B6%E7%A9%BA%E8%AE%BA%E6%96%87%E5%88%97%E8%A1%A8/"/>
    <id>http://yoursite.com/2020/02/18/时空论文列表/</id>
    <published>2020-02-17T16:17:25.000Z</published>
    <updated>2020-02-18T08:32:08.173Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="简介">简介</span></h1><p>以下列出AAAI2020和ICLR2020关于时空领域的论文<br><a id="more"></a></p><h1><span id="aaai2020">AAAI2020</span></h1><p><strong>[1]. RiskOracle: A Minute‐level Citywide Traffic Accident Forecasting Framework</strong><br><a href="https://github.com/zzyy0929/AAAI2020-RiskOracle" target="_blank" rel="noopener">https://github.com/zzyy0929/AAAI2020-RiskOracle</a></p><blockquote><p>Zhengyang Zhou (University of Science and Technology of China); Yang Wang (University of Science and<br>Technology of China)*; Xike Xie (University of Science and Technology of China); Lianliang Chen (University of<br>Science and Technology of China); Hengchang Liu (USTC)</p></blockquote><p><strong>[2]. GMAN: A Graph Multi-­Attention Network for Traffic Prediction</strong><br><a href="https://github.com/zhengchuanpan/GMAN" target="_blank" rel="noopener">https://github.com/zhengchuanpan/GMAN</a></p><blockquote><p>Chuanpan Zheng (Xiamen University); Xiaoliang Fan (Xiamen University)*; Cheng Wang (Xiamen University);<br>Jianzhong Qi (The University of Melbourne)</p></blockquote><p><strong>[3]. Multi-­Range Attentive Bicomponent Graph Convolutional Network for Traffic Forecasting</strong><br><a href="https://github.com/naganandy/graph-based-deep-learning-literature/blob/master/conference-publications/folders/publications_aaai20/mrabgcn_aaai20/README.md" target="_blank" rel="noopener">https://github.com/naganandy/graph-based-deep-learning-literature/blob/master/conference-publications/folders/publications_aaai20/mrabgcn_aaai20/README.md</a><br><a href="https://arxiv.org/abs/1911.12093?context=cs" target="_blank" rel="noopener">https://arxiv.org/abs/1911.12093?context=cs</a></p><blockquote><p>Weiqi Chen (Zhejiang University); Ling Chen (Zhejiang University)*; Yu Xie (Alibaba Cloud); Wei Cao (Alibaba);<br>Yusong Gao (Alibaba Cloud); Xiaojie Feng (Alibaba Cloud)</p></blockquote><p><strong>[4]. Spatio­‐Temporal Graph Structure Learning for Traffic Forecasting</strong></p><blockquote><p>Qi Zhang (institute of automation, Chinese academy of science)*; Jianlong Chang (National Laboratory of Pattern<br>Recognition, Institute of Automation, Chinese Academy of Sciences); Gaofeng Meng (Chinese Academy of<br>Sciences); SHIMING XIANG (Chinese Academy of Sciences, China); Chunhong Pan (Institute of Automation, Chinese<br>Academy of Sciences)</p></blockquote><p><strong>[5]. Pay Your Trip for Traffic Congestion: Dynamic Pricing in Traffic­‐Aware Road Networks</strong></p><blockquote><p>Lisi Chen (HKBU)*; Shuo Shang (KAUST); Bin Yao (“Shanghai Jiaotong University, China”); Jing Li (Inception Institute<br>of Artificial Intelligence)</p></blockquote><p><strong>[6]. Self­‐Attention ConvLSTM for Spatiotemporal Prediction</strong></p><blockquote><p>Zhihui Lin (Tsinghua University)*; Maomao Li (Tsinghua university); Zhuobin Zheng ( Tsinghua University);<br>Yangyang Cheng (Tsinghua University); Chun Yuan (Tsinghua University)</p></blockquote><p><strong>[7]. An Attentional Recurrent Neural Network for Personalized Next Location Recommendation</strong></p><blockquote><p>Qing Guo (Nanyang Technological University)*; Zhu Sun (Nanyang Technological University); Jie Zhang (Nanyang<br>Technological University); Yin-­‐Leng Theng (Nanyang Technological University)</p></blockquote><p><strong>[8]. Spatial­‐Temporal Synchronous Graph Convolutional Networks: A New Framework for Spatial-­‐Temporal Network Data Forecasting</strong><br><a href="https://github.com/Davidham3/STSGCN" target="_blank" rel="noopener">https://github.com/Davidham3/STSGCN</a></p><blockquote><p>Chao Song (Beijing Jiaotong University)*; Youfang Lin (Beijing Jiaotong University); Shengnan Guo (Beijing Jiaotong<br>University); Huaiyu Wan (Beijing Jiaotong University)</p></blockquote><p><strong>[9]. STGRAT: A Spatio-Temporal Graph Attention Network for Traffic Forecasting</strong><br><a href="https://arxiv.org/abs/1911.13181" target="_blank" rel="noopener">https://arxiv.org/abs/1911.13181</a></p><blockquote><p>Cheonbok Park1, Chunggi Lee2, Hyojin Bahng1, Taeyun won1,<br>Kihwan Kim2, Seungmin Jin2, Sungahn Ko2, Jaegul Choo1<br>1 Korea University , 2 UNIST</p></blockquote><p><strong>[10]. Semi-Supervised Hierarchical Recurrent Graph Neural Network for City-Wide Parking Availability Prediction</strong><br><a href="https://arxiv.org/abs/1911.10516" target="_blank" rel="noopener">https://arxiv.org/abs/1911.10516</a></p><blockquote><p>Weijia Zhang (University of Science and Technology of China); Hao LIU (Business Intelligence Lab, Baidu<br>Research)*; Yanchi Liu (Rutgers University); Jingbo Zhou (Baidu Inc.); Hui Xiong (Rutgers University)</p></blockquote><p><strong>[11]. RoadTagger: Robust Road Attribute Inference with Graph Neural Networks</strong><br><a href="https://arxiv.org/abs/1912.12408" target="_blank" rel="noopener">https://arxiv.org/abs/1912.12408</a></p><blockquote><p>Songtao He (MIT CSAIL)*; Favyen Bastani (MIT CSAIL); Satvat Jagwani (MIT CSAIL); Edward Park (MIT CSAIL);<br>Sofiane Abbar (Qatar Computing Research Institute); Mohammad Alizadeh (MIT CSAIL); Dr.Hari Balakrishnan<br>(Massachusetts institute of technology); Sanjay Chawla (QCRI); Samuel Madden (MIT); Mohammad Amin Sadeghi<br>(MIT)  </p></blockquote><h1><span id="iclr2020">ICLR2020</span></h1><p><a href="http://tony.9shi.cf/index.php?q=aHR0cHM6Ly93d3cuZW5kdG9lbmQuYWkvYmxvZy9pY2xyMjAyMC8" target="_blank" rel="noopener">ICLR2020 Accepted Papers</a></p><p><strong>[1]. Geom-gcn: Geometric Graph Convolutional Networks</strong><br>Spotlight paper<br><a href="https://github.com/graphdml-uiuc-jlu/geom-gcn" target="_blank" rel="noopener">https://github.com/graphdml-uiuc-jlu/geom-gcn</a></p><blockquote><p>Hongbin Pei, Bingzhe Wei, Kevin Chen-Chuan Chang, Yu Lei, Bo Yang<br>Jilin University</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;p&gt;以下列出AAAI2020和ICLR2020关于时空领域的论文&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="时空领域" scheme="http://yoursite.com/tags/%E6%97%B6%E7%A9%BA%E9%A2%86%E5%9F%9F/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch之Tensor学习</title>
    <link href="http://yoursite.com/2020/02/17/Pytorch%E4%B9%8BTensor%E5%AD%A6%E4%B9%A0/"/>
    <id>http://yoursite.com/2020/02/17/Pytorch之Tensor学习/</id>
    <published>2020-02-17T14:56:16.000Z</published>
    <updated>2020-02-24T08:02:56.237Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="1-简介">1. 简介</span></h1><p>最近发现一个学习Pytorch的教程，有视频版和文字版<a href="https://deeplizard.com/" target="_blank" rel="noopener">deeplizard</a>,这里面详细介绍了关于Tensor的知识，真的讲得超级好，解决了我很多关于Tensor运算的疑惑，在此记录下。</p><a id="more"></a>  <!-- TOC --><ul><li><a href="#1-%e7%ae%80%e4%bb%8b">1. 简介</a></li><li><a href="#2-%e5%88%9b%e5%bb%batensor">2. 创建Tensor</a></li><li><a href="#3-tensor%e7%9a%844%e7%b1%bb%e6%93%8d%e4%bd%9c">3. Tensor的4类操作</a><ul><li><a href="#31-reshape%e6%93%8d%e4%bd%9c">3.1. Reshape操作</a><ul><li><a href="#311-reshape">3.1.1. reshape</a></li><li><a href="#312-squeeze%e5%92%8cunsqueeze%e5%87%bd%e6%95%b0">3.1.2. squeeze和unsqueeze函数</a></li><li><a href="#313-cat%e5%87%bd%e6%95%b0">3.1.3. cat函数</a></li><li><a href="#314-stack%e5%87%bd%e6%95%b0">3.1.4. stack函数</a></li><li><a href="#315-cat%e5%92%8cstack%e7%9a%84%e5%8c%ba%e5%88%ab">3.1.5. cat和stack的区别</a></li></ul></li><li><a href="#32-element-wise%e6%93%8d%e4%bd%9c">3.2. Element-wise操作</a></li><li><a href="#33-reduction%e6%93%8d%e4%bd%9c">3.3. Reduction操作</a><ul><li><a href="#331-%e6%b2%bf%e7%9d%80%e6%9f%90%e4%b8%aaaxis%e8%81%9a%e5%90%88">3.3.1. 沿着某个axis聚合</a></li><li><a href="#332-argmax%e5%87%bd%e6%95%b0%e4%bb%8b%e7%bb%8d">3.3.2. Argmax函数介绍</a></li></ul></li><li><a href="#34-access%e6%93%8d%e4%bd%9c">3.4. Access操作</a></li></ul></li></ul><!-- /TOC --><h1><span id="2-创建tensor">2. 创建Tensor</span></h1><p>创建Tensor有四种方式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建Tensor</span></span><br><span class="line">&gt; data = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">&gt; o1 = torch.Tensor(data)</span><br><span class="line">&gt; o2 = torch.tensor(data)</span><br><span class="line">&gt; o3 = torch.as_tensor(data)</span><br><span class="line">&gt; o4 = torch.from_numpy(data)</span><br><span class="line"></span><br><span class="line">&gt; print(o1)</span><br><span class="line">&gt; print(o2)</span><br><span class="line">&gt; print(o3)</span><br><span class="line">&gt; print(o4)</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>])</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=torch.int32)</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=torch.int32)</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=torch.int32)</span><br><span class="line"></span><br><span class="line">&gt; print(o1.dtype)</span><br><span class="line">&gt; print(o2.dtype)</span><br><span class="line">&gt; print(o3.dtype)</span><br><span class="line">&gt; print(o4.dtype)</span><br><span class="line">torch.float32</span><br><span class="line">torch.int32</span><br><span class="line">torch.int32</span><br><span class="line">torch.int32</span><br><span class="line"></span><br><span class="line"><span class="comment">#内存是否共享</span></span><br><span class="line">&gt; print(<span class="string">'old:'</span>, data)</span><br><span class="line">old: [<span class="number">1</span> <span class="number">2</span> <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">&gt; data[<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">&gt; print(<span class="string">'new:'</span>, data)</span><br><span class="line">new: [<span class="number">0</span> <span class="number">2</span> <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">&gt; print(o1)</span><br><span class="line">&gt; print(o2)</span><br><span class="line">&gt; print(o3)</span><br><span class="line">&gt; print(o4)</span><br><span class="line"></span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>])</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=torch.int32)</span><br><span class="line">tensor([<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=torch.int32)</span><br><span class="line">tensor([<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=torch.int32)</span><br></pre></td></tr></table></figure><ul><li><code>torch.Tensor()</code>和<code>torch.tensor()</code>区别<br><code>torch.Tensor()</code>是<code>Tensor</code>类的构造函数，<code>torch.tensor()</code>是factory function，该函数将传入的参数构造成一个<code>Tensor</code>对象并返回。<br>以上4个函数中，<code>torch.Tensor()</code>是构造函数，其余都是factory function。</li><li>这4个函数的主要区别是:<code>torch.Tensor()</code>返回的<code>Tensor</code>默认是<code>float32</code>类型，而其他3个函数返回的<code>Tensor</code>数据类型根据传入的数据而定。并且其他3个函数可以传入<code>dtype</code>来指定数据的类型，但是<code>torch.Tensor()</code>不能传入<code>dtype</code>参数。</li><li><p>通过<code>np.array</code>来创建<code>Tensor</code>，然后改变data的值，可以看到，前2个<code>Tensor</code>的值并没有改变，后2个<code>Tensor</code>的值改变。这是因为<code>torch.Tensor()</code>和<code>torch.tensor()</code>是copy输入数据的值，而<code>torch.as_tensor()</code>和<code>torch.from_numpy()</code>是share输入数据的memory</p><p>Shara Data | Copy Data<br>-|-|-|<br>torch.as_tensor() | torch.tensor()|<br>torch.from_numpy() |     torch.Tensor()|</p></li><li><p><code>torch.as_tensor()</code>和<code>torch.from_numpy()</code>都是factory function，且都是share data，那这2个函数有什么区别？<code>torch.from_numpy()</code>仅仅接受<code>np.array</code>的参数，然而<code>torch.as_tensor()</code>接受<a href="https://docs.scipy.org/doc/numpy/user/basics.creation.html#converting-python-array-like-objects-to-numpy-arrays" target="_blank" rel="noopener">array-like objects</a>类型的参数</p></li><li>综上所述，下面2个方法是创建Tensor的推荐方法：<ul><li><code>torch.tensor()</code></li><li><code>torch.as_tensor()</code></li></ul></li></ul><h1><span id="3-tensor的4类操作">3. Tensor的4类操作</span></h1><h2><span id="31-reshape操作">3.1. Reshape操作</span></h2><h3><span id="311-reshape">3.1.1. reshape</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; t = torch.tensor([</span><br><span class="line">    [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>],</span><br><span class="line">    [<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>]</span><br><span class="line">], dtype=torch.float32)</span><br></pre></td></tr></table></figure><p>有2种方式获取Tensor的shape:<code>t.size()和t.shape</code></p><h3><span id="312-squeeze和unsqueeze函数">3.1.2. squeeze和unsqueeze函数</span></h3><ol><li><code>torch.squeeze(input, dim=None, out=None) → Tensor</code><br>将维度中的1去掉，如果不指定dim，则去掉所有维度上的1；如果指定dim，则只去掉该维度上的1。<strong>dim是可选项</strong></li></ol><ul><li>输入维度是(A×1×B×C×1×D),不指定dim，输出维度(A×B×CxD)</li><li>输入维度是(A×1×B×C×1×D),不指定dim=1，输出维度(A×B×C×1×D)</li></ul><ol><li><code>torch.unsqueeze(input, dim, out=None) → Tensor</code><br>在指定维度上增加1个维度。<strong>dim是必填项</strong><br><code>torch.unsqueeze(x, 0)</code><h3><span id="313-cat函数">3.1.3. cat函数</span></h3></li></ol><p><code>torch.cat(tensors, dim=0, out=None) → Tensor</code><br>如果要拼接多个Tensor，需要将多个Tensor包装成tuple，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cat((t1,t2,t3),dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><strong>cat不改变数据维度个数</strong></p><h3><span id="314-stack函数">3.1.4. stack函数</span></h3><p><code>torch.stack(tensors, dim=0, out=None) → Tensor</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.stack((t1,t2,t3),dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><strong>stack改变数据维度个数,增加一个维度</strong></p><h3><span id="315-cat和stack的区别">3.1.5. cat和stack的区别</span></h3><p>cat和stack的区别可以用一句话描述：</p><ul><li>cat不会改变数据维度个数，原先是3维数据，n个tensor进行cat之后还是3维数据。</li><li>stack会增加维度个数，原先是3维，n个tensor进行stack会变成4维数据</li></ul><h2><span id="32-element-wise操作">3.2. Element-wise操作</span></h2><p><a href="https://deeplizard.com/learn/video/QscEWm0QTRY" target="_blank" rel="noopener">Broadcasting and Element-wise Operations with PyTorch</a><br><a href="https://deeplizard.com/learn/video/6_33ulFDuCg" target="_blank" rel="noopener">Broadcasting Explained</a></p><p>逐元素有以下4种叫法，意思都一样：</p><ul><li>Element-wise</li><li>Component-wise</li><li>Point-wise</li></ul><p>逐元素操作有以下几种:</p><ol><li><p><strong><code>t1+t2</code>维度相同</strong><br>其中t1和t2维度相同</p></li><li><p><strong><code>t1+2, t1-2, t1*2, t1/2</code></strong><br>实际上是对2进行了<code>broadcasting</code>，然后再和t1运算</p></li><li><p><strong><code>t1+t2</code>，rank相同，维度不同</strong><br>这种情况比较复杂。</p><ul><li><p>首先我们先看这2个Tensor在所有维度上是否兼容。判断2个Tensor在维度上是否兼容有2个条件，只要满足其中的一个条件就兼容，否则不兼容。</p><ul><li>相等</li><li><p>有一个值维1 </p><p>例如：t1维度(1,3)，t2维度(3,1)，<strong>从后往前对比</strong>，我们先看第二个维度的值，分别是3和1，不相等但是满足第二个条件，即第二个维度上兼容。再看第一个维度，分别是1和3，满足第二个条件，即第一个维度上兼容。所以2个Tensor在所有维度上兼容，可以进行下一步的操作。如果不兼容，则这2个Tensor无法进行逐元素运算。</p></li></ul></li><li><p>决定最终结果的输出维度。还是要看2个Tensor的维度。<strong>从后往前对比</strong>, t1维度(1,3)，t2维度(3,1)，先看第二维度是3和1，取最大值作为输出的第一个维度，即3，再看第一维度1和3，也是3作为输出的第二个维度。即输出的维度是(3,3)。</p></li><li>分别将t1维度(1,3)，t2维度(3,1)进行广播成(3,3)，然后再进行相加，得到最终的结果。</li></ul></li><li><p><strong><code>t1+t2</code>，rank不同</strong></p><ul><li>例子1：t1的维度(2,4),t2的维度是(4,)，这2个Tensor也可以进行，实际是先将低rank的t2最后一维和t1的最后一维相等，都等于4，但是t2只有一维，那就在缺失的维度上补1，变成(1,4),然后再广播成(2,4)维度，然后再和t1计算。</li><li>例子2：t1的维度(2,4),t2的维度是(2,)，这2个Tensor不可以进行。因为t1和t2的最后一维分别是4和2，不相等也不等于1，不兼容，无法进行下一步。</li><li>例子3：t1维度(1,2,3)，t2维度(3,3)，这个Tensor就不能做逐元素操作。先看所有维度是否兼容。最后一个维度3和3，相等即兼容，再看前一个维度2和3，既不相等也不等于1，不兼容。则不能进行逐元素操作</li></ul></li></ol><p><strong>以上2，3，4情况都涉及到了broadcasting的知识。</strong>  </p><ol><li><p>比较操作<br>比较也是逐元素操作的一种，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]) &lt; torch.tensor([<span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">tensor([<span class="keyword">True</span>, <span class="keyword">False</span>, <span class="keyword">False</span>])</span><br></pre></td></tr></table></figure></li></ol><h2><span id="33-reduction操作">3.3. Reduction操作</span></h2><p>聚合操作：减少Tesnor中元素的个数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; t = torch.tensor([</span><br><span class="line">    [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">2</span>,<span class="number">0</span>,<span class="number">2</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">3</span>,<span class="number">0</span>]</span><br><span class="line">], dtype=torch.float32)</span><br><span class="line">&gt; t.sum()</span><br><span class="line">tensor(<span class="number">8.</span>)</span><br></pre></td></tr></table></figure><p><code>sum()</code>返回的结果是scalar类型(0维的Tensor)，只包含1个元素</p><h3><span id="331-沿着某个axis聚合">3.3.1. 沿着某个axis聚合</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; t = torch.tensor([</span><br><span class="line">    [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>],</span><br><span class="line">    [<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>]</span><br><span class="line">], dtype=torch.float32)</span><br><span class="line">&gt; t.sum(dim=<span class="number">0</span>)</span><br><span class="line">tensor([<span class="number">6.</span>, <span class="number">6.</span>, <span class="number">6.</span>, <span class="number">6.</span>])</span><br></pre></td></tr></table></figure><h3><span id="332-argmax函数介绍">3.3.2. Argmax函数介绍</span></h3><p>当一个Tensor变量a调用<code>argmax()</code>函数时，返回只包含1个元素的Tensor，该元素表示a中最大值的下标。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">t = torch.tensor([</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">2</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">4</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">5</span>]</span><br><span class="line">], dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">&gt; t.max()</span><br><span class="line">tensor(<span class="number">5.</span>)</span><br><span class="line"></span><br><span class="line">&gt; t.argmax()</span><br><span class="line">tensor(<span class="number">11</span>)</span><br><span class="line"></span><br><span class="line">&gt; t.flatten()</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">2.</span>, <span class="number">0.</span>, <span class="number">3.</span>, <span class="number">3.</span>, <span class="number">0.</span>, <span class="number">4.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">5.</span>])</span><br></pre></td></tr></table></figure><p>如果<code>argmax()</code>没有指定axis，则返回整个Tensor最大值的下标。如果指定axis，则返回指定轴上最大值下标。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&gt; t.max(dim=<span class="number">0</span>)</span><br><span class="line">(tensor([<span class="number">4.</span>, <span class="number">3.</span>, <span class="number">3.</span>, <span class="number">5.</span>]), tensor([<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>]))</span><br><span class="line"></span><br><span class="line">&gt; t.argmax(dim=<span class="number">0</span>)</span><br><span class="line">tensor([<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">&gt; t.max(dim=<span class="number">1</span>)</span><br><span class="line">(tensor([<span class="number">2.</span>, <span class="number">3.</span>, <span class="number">5.</span>]), tensor([<span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>]))</span><br><span class="line"></span><br><span class="line">&gt; t.argmax(dim=<span class="number">1</span>)</span><br><span class="line">tensor([<span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><p>当调用<code>max()</code>函数时，返回2个Tensor，第一个Tensor表示返回轴上最大的值，第2个Tensor返回最大值的下标，也就是<code>argmax()</code>的返回值。<br>通常<code>argmax()</code>通常用在分类任务的输出上，决定哪类有最高的预测值。</p><h2><span id="34-access操作">3.4. Access操作</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&gt; t = torch.tensor([</span><br><span class="line">    [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line">    [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],</span><br><span class="line">    [<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]</span><br><span class="line">], dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">&gt; t.mean()</span><br><span class="line">tensor(<span class="number">5.</span>)</span><br><span class="line"></span><br><span class="line">&gt; t.mean().item()</span><br><span class="line"><span class="number">5.0</span></span><br><span class="line"></span><br><span class="line">&gt; t.mean(dim=<span class="number">0</span>).tolist()</span><br><span class="line">[<span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>]</span><br><span class="line"></span><br><span class="line">&gt; t.mean(dim=<span class="number">0</span>).numpy()</span><br><span class="line">array([<span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>], dtype=float32)</span><br></pre></td></tr></table></figure><p>如果返回的结果是scalar，只有1个元素，使用item()来获取其中的值。<br>如果返回的结果有多个值，可以将Tensor转换为pyhton中的list和array.</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-简介&quot;&gt;&lt;a href=&quot;#1-简介&quot; class=&quot;headerlink&quot; title=&quot;1. 简介&quot;&gt;&lt;/a&gt;1. 简介&lt;/h1&gt;&lt;p&gt;最近发现一个学习Pytorch的教程，有视频版和文字版&lt;a href=&quot;https://deeplizard.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;deeplizard&lt;/a&gt;,这里面详细介绍了关于Tensor的知识，真的讲得超级好，解决了我很多关于Tensor运算的疑惑，在此记录下。&lt;/p&gt;
    
    </summary>
    
      <category term="Deep Learning" scheme="http://yoursite.com/categories/Deep-Learning/"/>
    
    
      <category term="Pytorch" scheme="http://yoursite.com/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>openpai</title>
    <link href="http://yoursite.com/2020/01/10/openpai/"/>
    <id>http://yoursite.com/2020/01/10/openpai/</id>
    <published>2020-01-10T02:34:27.000Z</published>
    <updated>2020-03-05T07:54:49.383Z</updated>
    
    <content type="html"><![CDATA[<p>&ensp;&ensp;&ensp;&ensp;最近实验室安装了openpai平台，可以在上面提交程序运行。下面记录怎么使用OpenPai提交NNI程序，进行调参。<br><a id="more"></a><br><!-- TOC --></p><ul><li><a href="#1-%e4%bd%bf%e7%94%a8%e6%ad%a5%e9%aa%a4">1. 使用步骤</a><ul><li><a href="#11-%e7%bc%96%e5%86%99%e7%a8%8b%e5%ba%8f">1.1. 编写程序</a></li><li><a href="#12-%e5%87%86%e5%a4%87%e9%95%9c%e5%83%8f">1.2. 准备镜像</a></li><li><a href="#13-%e7%bc%96%e5%86%99nni%e7%9a%84yml%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6">1.3. 编写NNI的yml配置文件</a></li><li><a href="#14-%e5%ae%89%e8%a3%85nni">1.4. 安装NNI</a></li><li><a href="#15-%e5%90%af%e5%8a%a8nni">1.5. 启动NNI</a></li><li><a href="#16-nni%e6%b5%8f%e8%a7%88%e5%99%a8%e6%9f%a5%e7%9c%8b">1.6. NNI浏览器查看</a></li><li><a href="#17-%e5%9c%a8%e6%b5%8f%e8%a7%88%e5%99%a8%e4%b8%ad%e6%9f%a5%e7%9c%8bopenpai">1.7. 在浏览器中查看OpenPai</a></li><li><a href="#18-%e5%85%b3%e9%97%adnni">1.8. 关闭NNI</a></li></ul></li><li><a href="#%e5%86%85%e5%ad%98%e6%8c%87%e6%a0%87%e8%a7%a3%e8%af%bb">内存指标解读</a></li></ul><!-- /TOC --><h1><span id="1-使用步骤">1. 使用步骤</span></h1><h2><span id="11-编写程序">1.1. 编写程序</span></h2><p>   先在VSCode中完成代码，先在VSCode的虚拟环境中运行，如果可以运行，再使用OpemPai运行。<br>   <strong>注：在OpenPai上运行程序，不需要指定使用哪块GPU，因为OpenPai会自动申请需要使用的GPU。即以下代码注释掉</strong></p>   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># os.environ["CUDA_VISIBLE_DEVICES"] = "1,2,3"</span></span><br></pre></td></tr></table></figure><h2><span id="12-准备镜像">1.2. 准备镜像</span></h2><p>   准备一个包含hdfs的镜像，将需要用的镜像push到实验室服务器的仓库。<br>   下面是我本人的镜像：</p><ul><li>运行环境mxnet<br> <code>lin-ai-27:5000/wangbeibei/mxnet:cu100_hdfs</code></li><li>运行环境是pytorch<br> <code>172.31.246.45:5000/dlspree:hdfs_pyg</code></li></ul><h2><span id="13-编写nni的yml配置文件">1.3. 编写NNI的yml配置文件</span></h2><p>   使用<code>pip install nni==1.2</code>安装1.2版本的nni，如果不指定版本，默认安装最新版，目前最新是1.3，1.3版本的nni其yml配置文件和1.2有所区别<br>   <a href="https://nni.readthedocs.io/zh/latest/Tutorial/ExperimentConfig.html#openpai" target="_blank" rel="noopener">OpenPai模式</a><br>   1.3版本的nni的yml配置文件和1.2有所不同,<a href="https://nni.readthedocs.io/zh/latest/TrainingService/PaiMode.html" target="_blank" rel="noopener">最新版本的配置文件</a>，其中多了<code>nniManagerNFSMountPath,containerNFSMountPath,paiStoragePlugin</code>三个必填的键。<br>   下面使用的是1.2版本的nni配置文件</p>   <figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">authorName:</span> <span class="string">wangbeibei</span></span><br><span class="line"><span class="attr">experimentName:</span><span class="string">hetero_convlstm_grid_experiment</span></span><br><span class="line"><span class="comment">#并发尝试任务的最大数量，有1张gpu卡就是1，有2gpu卡就是2</span></span><br><span class="line"><span class="attr">trialConcurrency:</span> <span class="number">6</span></span><br><span class="line"><span class="attr">maxExecDuration:</span> <span class="number">100</span><span class="string">h</span></span><br><span class="line"><span class="comment">#Trial 任务的最大数量，成功和失败的都计算在内</span></span><br><span class="line"><span class="attr">maxTrialNum:</span> <span class="number">600</span></span><br><span class="line"><span class="comment">#choice: local, remote, pai</span></span><br><span class="line"><span class="attr">trainingServicePlatform:</span> <span class="string">pai</span></span><br><span class="line"><span class="comment"># 指定nni管理器ip 为29号服务器</span></span><br><span class="line"><span class="attr">nniManagerIp:</span> <span class="number">202.205</span><span class="number">.99</span><span class="number">.174</span></span><br><span class="line"><span class="attr">searchSpacePath:</span><span class="string">hetero_convlstm_search_space.json</span></span><br><span class="line"><span class="comment">#choice: true, false</span></span><br><span class="line"><span class="attr">useAnnotation:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># 存储日志和数据的目录, 默认值是 /dataWangBeibei/nni/  experiments</span></span><br><span class="line"><span class="comment">#如果在虚拟环境中运行该代码，logDir是服务器下绝对路径，/data/ WangBeibei/graduation/Codenni_save_logs</span></span><br><span class="line"><span class="comment">#如果在docker下运行该代码，logDir是容器下的绝路径，/root/ Code/nni_save_logs/</span></span><br><span class="line"><span class="attr">logDir:</span> <span class="string">/data/WangBeibei/graduation/Codenni_save_logs</span></span><br><span class="line"><span class="attr">tuner:</span></span><br><span class="line">  <span class="comment">#choice: TPE, Random, Anneal, Evolution,BatchTuner,  MetisTuner, GPTuner</span></span><br><span class="line">  <span class="comment">#SMAC (SMAC should be installed throughnnictl)</span></span><br><span class="line"><span class="attr">  builtinTunerName:</span> <span class="string">TPE</span></span><br><span class="line"><span class="attr">  classArgs:</span></span><br><span class="line">    <span class="comment">#choice: maximize, minimize</span></span><br><span class="line"><span class="attr">    optimize_mode:</span> <span class="string">minimize</span></span><br><span class="line"><span class="attr">trial:</span></span><br><span class="line">  <span class="comment"># 指定了运行 Trial 进程的命令行</span></span><br><span class="line"><span class="attr">  command:</span> <span class="string">cd</span> <span class="string">baseline</span> <span class="string">&amp;&amp;</span> <span class="string">python3</span>  <span class="string">hetero_convlstm_baseline.py</span></span><br><span class="line">  <span class="comment">#指定了 Trial 代码文件的目录,../会进入到Cod目录下</span></span><br><span class="line"><span class="attr">  codeDir:</span> <span class="string">../</span></span><br><span class="line"><span class="attr">  gpuNum:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  cpuNum:</span> <span class="number">8</span></span><br><span class="line"><span class="attr">  memoryMB:</span> <span class="number">14000</span></span><br><span class="line">  <span class="comment"># docker 镜像地址</span></span><br><span class="line">  <span class="comment">#pytorch镜像：172.31.246.45:5000dlspree:hdfs_pyg</span></span><br><span class="line">  <span class="comment">#mxnet镜像：lin-ai-27:5000/wangbeibeimxnet:cu100_hdfs</span></span><br><span class="line"><span class="attr">  image:</span> <span class="number">172.31</span><span class="number">.246</span><span class="number">.45</span><span class="string">:5000/dlspree:hdfs_pyg</span></span><br><span class="line"><span class="comment"># 配置访问的 OpenPAI 集群</span></span><br><span class="line"><span class="attr">paiConfig:</span></span><br><span class="line">  <span class="comment">#OpenPai网页的用户名和密码，也是53号服务器用户名和密码</span></span><br><span class="line"><span class="attr">  userName:</span> <span class="string">user</span></span><br><span class="line">  <span class="comment"># 密码如果是全数字需要 ""</span></span><br><span class="line"><span class="attr">  passWord:</span> <span class="string">psw</span></span><br><span class="line">  <span class="comment">#OpenPai集群的主节点</span></span><br><span class="line"><span class="attr">  host:</span> <span class="number">172.31</span><span class="number">.246</span><span class="number">.52</span></span><br></pre></td></tr></table></figure><p>   <strong>这里资源的配置都是针对一个trail的，memoryMB也是针对一个trail的。</strong><br>   <strong>注意：</strong> pai 模式下，NNIManager 会启动 RESTful 服务，监听端口为 NNI 网页服务器的端口加1。 例如，如果网页端口为<code>8080</code>，那么 RESTful 服务器会监听在 <code>8081</code>端口，来接收运行在 Kubernetes 中的 Trial 作业的指标。 因此，需要在防火墙中启用端口 <code>8081</code> 的 TCP 协议，以允许传入流量。</p><p>通常在服务器中8080端口无法使用，我们需要在启动NNI管理器时手动通过 —port 指定端口。</p><h2><span id="14-安装nni">1.4. 安装NNI</span></h2><p>   由于NNI并不依赖于任何环境，因此当我们使用OpenPAI提交NNI任务时，为了方便（需要解决ip和端口映射问题），<strong>不需要在docker中启动NNI，直接在服务器环境下安装NNI，启动即可</strong>。<br>   使用<code>pip install nni==1.2</code>安装nni</p><h2><span id="15-启动nni">1.5. 启动NNI</span></h2><p>   使用<code>nnictl create --port 6688 --config xxx.yml</code>来启动一个Experiment,如果端口被占用，换别的端口</p><h2><span id="16-nni浏览器查看">1.6. NNI浏览器查看</span></h2><p>   在浏览器中输入<code>服务器ip:6688</code></p><h2><span id="17-在浏览器中查看openpai">1.7. 在浏览器中查看OpenPai</span></h2><p>   在浏览器中登录OpenPai，可以查看启动的trail，在代码中的print输出的内容在stdout中查看。<br>   <strong>注：有时候print语句输出的内容在stdout显示不出来，添加<code>flush=True</code>就可以了</strong></p>   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"************进入main函数"</span>,flush=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p>   <img src="/2020/01/10/openpai/logs.png" alt=""></p><h2><span id="18-关闭nni">1.8. 关闭NNI</span></h2><p>直接在服务器中使用<code>nnictl stop</code>即可关闭nni的Experiment</p><h1><span id="内存指标解读">内存指标解读</span></h1><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">trial:</span></span><br><span class="line">    <span class="comment"># 指定了运行 Trial 进程的命令行</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">cd</span> <span class="string">baseline</span> <span class="string">&amp;&amp;</span> <span class="string">python3</span>  <span class="string">hetero_convlstm_baseline.py</span></span><br><span class="line">    <span class="comment">#指定了 Trial 代码文件的目录,../会进入到Cod目录下</span></span><br><span class="line"><span class="attr">    codeDir:</span> <span class="string">../</span></span><br><span class="line"><span class="attr">    gpuNum:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">    cpuNum:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">    memoryMB:</span> <span class="number">20000</span></span><br></pre></td></tr></table></figure><p><strong>【gpuNum】</strong>：设置为2，表示该程序使用2张GPU，即该程序独占2张GPU卡，<strong>独占2张卡的显存和计算力</strong><br><strong>【cpuNum】</strong>：设置为3，占用3块CPU来计算<br><strong>【memoryMB】</strong>：设置为20000MB，表示该程序总共占2000MB的内存，在openpai上内存是共享的，显存是独享的。</p><p>当我设置如上资源来跑程序时，可以看到程序的资源占用情况如下所示：<br><img src="/2020/01/10/openpai/指标示意图.png" alt=""></p><p><strong>【指标解读】</strong></p><p>上面从左到右一共有6张图，我们只关注<code>CPU,memory usage,GPU Utilization,GPU Memory</code>这4张图。</p><ul><li><strong>CPU</strong>：CPU的占用率稳定在300%，说明程序分配的3张CPU卡都用来做计算，CPU一直是满载状况，这时候可以适当增加cpuNum的个数</li><li><strong>memory usage</strong>：内存占用率稳定在12G，我们分配给该程序的资源是20G，分配的有点多，可以适当减少些。内存分配的资源也不是越多越好，因为openpai在跑程序时，当有足够的GPU但是却没有足够的内存，程序依然不能运行，会一直处于waiting状态</li><li><strong>GPU Utilization和GPU Memory</strong>：GPU的占用率稳定在25%，给该程序分配了2张GPU卡，一张卡有11G显存，但是程序只占了25%，也就是大约3G，2张卡对该程序有点多，可以改为1张卡</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;最近实验室安装了openpai平台，可以在上面提交程序运行。下面记录怎么使用OpenPai提交NNI程序，进行调参。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="工具" scheme="http://yoursite.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="openpai" scheme="http://yoursite.com/tags/openpai/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch之GPU程序</title>
    <link href="http://yoursite.com/2020/01/06/Pytorch%E4%B9%8BGPU%E7%A8%8B%E5%BA%8F/"/>
    <id>http://yoursite.com/2020/01/06/Pytorch之GPU程序/</id>
    <published>2020-01-06T06:35:30.000Z</published>
    <updated>2020-02-24T08:24:54.101Z</updated>
    
    <content type="html"><![CDATA[<p>介绍Pytorch的一些使用方法<br><a id="more"></a></p><h1><span id="gpu">GPU</span></h1><p><a href="https://zhuanlan.zhihu.com/p/71566775" target="_blank" rel="noopener">转载出处</a></p><p><a href="https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter04_DL_computation/4.6_use-gpu" target="_blank" rel="noopener">GPU计算</a></p><h2><span id="查看-gpu-信息">查看 GPU 信息</span></h2><p>更多接口，参考 <a href="https://pytorch.org/docs/stable/cuda.html" target="_blank" rel="noopener">torch.cuda</a></p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">torch</span><span class="selector-class">.cuda</span><span class="selector-class">.is_available</span>()       # 判断 <span class="selector-tag">GPU</span> 是否可用</span><br><span class="line"><span class="selector-tag">torch</span><span class="selector-class">.cuda</span><span class="selector-class">.device_count</span>()       # 判断有多少 <span class="selector-tag">GPU</span></span><br><span class="line"><span class="selector-tag">torch</span><span class="selector-class">.cuda</span><span class="selector-class">.get_device_name</span>(0)   # 返回 <span class="selector-tag">gpu</span> 名字，设备索引默认从 0 开始</span><br><span class="line"><span class="selector-tag">torch</span><span class="selector-class">.cuda</span><span class="selector-class">.current_device</span>()     # 返回当前设备索引</span><br></pre></td></tr></table></figure><h2><span id="torchdevice">torch.device</span></h2><p><code>torch.device</code> 表示 <code>torch.Tensor</code> 分配到的设备的对象。其包含一个设备类型（<code>cpu</code> 或 <code>cuda</code>），以及可选的设备序号。如果设备序号不存在，则为当前设备，即 <code>torch.cuda.current_device()</code> 的返回结果。</p><p>可以通过如下方式创建 <code>torch.device</code> 对象：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过字符串</span></span><br><span class="line"><span class="attr">device</span> = torch.device(<span class="string">'cpu'</span>)</span><br><span class="line"><span class="attr">device</span> = torch.device(<span class="string">'cuda:1'</span>)  # 指定类型及编号。注意，代码不会检查编号是否合法</span><br><span class="line"><span class="attr">device</span> = torch.device(<span class="string">'cuda'</span>)    # 默认为当前设备，如果是多GPU，默认使用全部GPU</span><br></pre></td></tr></table></figure><p>还可以通过设备类型加上编号，来创建 <code>device</code> 对象：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">device</span> = torch.device(<span class="string">'cuda'</span>, <span class="number">0</span>)</span><br><span class="line"><span class="attr">device</span> = torch.device(<span class="string">'cpu'</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure><h2><span id="配置-cuda-访问限制">配置 CUDA 访问限制</span></h2><p>可以通过如下方式，设置当前 <code>Python</code> 脚本可见的 <code>GPU</code>。</p><h3><span id="在命令行设置">在命令行设置</span></h3><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">CUDA_VISIBLE_DEVICES</span>=<span class="number">1</span> python my_script.py</span><br></pre></td></tr></table></figure><p><strong>实例</strong></p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Environment Variable Syntax      Results</span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">1</span>           Only device <span class="number">1</span> will be seen</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span>         Devices <span class="number">0</span> <span class="keyword">and</span> <span class="number">1</span> will be visible</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="string">"0,1"</span>       Same as above, quotation marks are optional</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>       Devices <span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span> will be visible; device <span class="number">1</span> <span class="keyword">is</span> masked</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="string">""</span>          No GPU will be visible</span><br></pre></td></tr></table></figure><h3><span id="在-python-代码中设置">在 Python 代码中设置</span></h3><figure class="highlight moonscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="built_in">os</span></span><br><span class="line"><span class="built_in">os</span>.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"0, 2"</span></span><br></pre></td></tr></table></figure><h3><span id="使用函数-set_device">使用函数 set_device</span></h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">torch<span class="selector-class">.cuda</span><span class="selector-class">.set_device</span>(id)</span><br></pre></td></tr></table></figure><blockquote><p>官方建议使用 <code>CUDA_VISIBLE_DEVICES</code>，不建议使用 <code>set_device</code> 函数。</p></blockquote><h2><span id="用-gpu-训练">用 GPU 训练</span></h2><p>默认情况下，使用 <code>CPU</code> 训练模型。可以通过如下方式，通过 <code>GPU</code> 进行训练。<strong>使用 GPU 时，模型和输入必须位于同一张 GPU 上。</strong></p><p><code>.to(device)</code> 和 <code>.cuda()</code> 的区别如下：</p><p><a href="https://stackoom.com/question/3bltP/Pytorch-%E5%9C%A8CUDA%E8%AE%BE%E5%A4%87%E4%B8%8A%E6%9C%89%E4%B8%89%E7%A7%8D%E6%96%B9%E6%B3%95%E5%8F%AF%E4%BB%A5%E5%88%9B%E5%BB%BA%E5%BC%A0%E9%87%8F-%E5%AE%83%E4%BB%AC%E4%B9%8B%E9%97%B4%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%E5%90%97" target="_blank" rel="noopener">to和cuda的区别</a><br><img src="/2020/01/06/Pytorch之GPU程序/pytorch-学习/to和cuda区别.png" alt="to和cuda区别"></p><ol><li><code>.to()</code> 中的参数必不可少</li><li>对于 <code>module</code> 而言，<code>.to()</code> 是 <code>inplace</code> 的，而 <code>.cuda()</code> 不是；而对于 <code>tensor</code> 而言，两者一致。</li></ol><blockquote><p><strong>注</strong>：实测，两者时间消耗持平。推荐使用<code>.to()函数</code></p></blockquote><p><strong>方式 1 ：使用cuda</strong></p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">device</span> = torch.device(<span class="string">"cuda:1"</span>)   <span class="comment"># 指定模型训练所在 GPU</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 CPU 转移至 GPU</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available() <span class="literal">and</span> use_gpu:</span><br><span class="line">    <span class="attr">net</span> = net.cuda(device)    <span class="comment"># 默认在第一块 GPU 上训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 同时将数据转移至 GPU,注意cuda有返回值</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available() <span class="literal">and</span> use_gpu:</span><br><span class="line">    <span class="attr">inputs</span> = inputs.cuda(device)</span><br><span class="line">    <span class="attr">labels</span> = labels.cuda(device)</span><br></pre></td></tr></table></figure><p><strong>方法 2 ：使用to</strong></p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">device</span> = torch.device(<span class="string">"cuda:1"</span>)   <span class="comment"># 指定模型训练所在 GPU</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 CPU 转移至 GPU</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available() <span class="literal">and</span> use_gpu:</span><br><span class="line">    <span class="attr">net</span> = net.to(device)    <span class="comment"># 默认在第一块 GPU 上训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 同时将数据转移至 GPU</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available() <span class="literal">and</span> use_gpu:</span><br><span class="line">    <span class="attr">inputs</span> = inputs.to(device)</span><br><span class="line">    <span class="attr">labels</span> = labels.to(device)</span><br></pre></td></tr></table></figure><h2><span id="存在的问题">存在的问题</span></h2><h3><span id="batch-size-太大">batch size 太大</span></h3><p>当想要用大批量进行训练，但是 <code>GPU</code> 资源有限，此时可以通过<strong>梯度累加</strong>（<code>accumulating gradients</code>）的方式进行。</p><p>梯度累加的基本思想在于，在优化器更新参数前，也就是执行 <code>optimizer.step()</code> 前，进行多次反向传播，使得梯度累计值自动保存在 <code>parameter.grad</code> 中，最后使用累加的梯度进行参数更新。</p><p>这个在 <code>PyTorch</code> 中特别容易实现，因为 <code>PyTorch</code> 中，梯度值本身会保留，除非我们调用 <code>model.zero_grad()</code> 或 <code>optimizer.zero_grad()</code>。</p><p>修改后的代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model.zero_grad() <span class="comment"># 重置保存梯度值的张量</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, (inputs, labels) <span class="keyword">in</span> enumerate(training_set):</span><br><span class="line">    predictions = model(inputs)<span class="comment"># 前向计算</span></span><br><span class="line">    loss = loss_function(predictions, labels)<span class="comment"># 计算损失函数</span></span><br><span class="line">    loss.backward()<span class="comment"># 计算梯度</span></span><br><span class="line">    <span class="keyword">if</span> (i + <span class="number">1</span>) % accumulation_steps == <span class="number">0</span>:<span class="comment">#重复多次前面的过程</span></span><br><span class="line">        optimizer.step()<span class="comment">#更新梯度</span></span><br><span class="line">        model.zero_grad()<span class="comment">#重置梯度</span></span><br></pre></td></tr></table></figure><h3><span id="model-太大">model 太大</span></h3><p>当模型本身太大，以至于不能放置于一个 <code>GPU</code> 中时，可以通过<strong>梯度检查点</strong> (<code>gradient-checkpoingting</code>) 的方式进行处理。</p><p>梯度检查点的基本思想是<strong>以计算换内存</strong>。具体来说就是，在反向传播的过程中，把梯度切分成几部分，分别对网络上的部分参数进行更新。如下图所示：</p><p><img src="http://tankzhou.cn/images/%E6%A2%AF%E5%BA%A6%E6%A3%80%E6%9F%A5%E7%82%B9.gif" alt=""></p><p>梯度检查点图示</p><p>这种方法速度很慢，但在某些例子上很有用，比如训练长序列的 RNN 模型等。</p><p>具体可参考：<a href="https://medium.com/huggingface/from-zero-to-research-an-introduction-to-meta-learning-8e16e677f78a" target="_blank" rel="noopener">From zero to research — An introduction to Meta-learning</a></p><p>单机多卡训练，即<strong>并行训练</strong>。并行训练又分为<strong>数据并行</strong> (<code>Data Parallelism</code>) 和<strong>模型并行</strong>两种。</p><p>数据并行指的是，多张 <code>GPU</code> 使用相同的模型副本，但是使用不同的数据批进行训练。而模型并行指的是，多张<code>GPU</code> 分别训练模型的不同部分，使用同一批数据。</p><p>两者对比如下图所示：</p><p><img src="/2020/01/06/Pytorch之GPU程序/pytorch-学习/多GPU.jpg" alt=""></p><p>模型并行 VS 数据并行</p><h2><span id="数据并行">数据并行</span></h2><p><a href="https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html" target="_blank" rel="noopener">Pytorch多GPU官方实例</a></p><h3><span id="pytorch-api">Pytorch API</span></h3><p>【<strong>Class 原型</strong>】</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.DataParallel(module, <span class="attribute">device_ids</span>=None, <span class="attribute">output_device</span>=None, <span class="attribute">dim</span>=0)</span><br></pre></td></tr></table></figure><p>【<strong>参数</strong>】</p><ul><li><strong>module</strong> ：要进行并行的 <code>module</code>。这里隐含了一点 ，即网络中的某一层也是可以进行数据并行的，但是一般不会这么使用。</li><li><strong>device_ids</strong> : <code>CUDA</code> 列表，可以为 <code>torch.device</code> 类型，也可以是编号组成的 <code>int</code> 列表。<strong>默认使用全部 GPU</strong></li><li><strong>output_device</strong> : 某一 <code>GPU</code> 编号或 <code>torch.device</code> 。指定输出的 <code>GPU</code>，默认为第一个，即 <code>device_ids[0]</code></li></ul><p>【<strong>返回值</strong>】</p><p>要进行并行的模型。</p><p>【<strong>基本使用方式</strong>】</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; net = torch.nn.DataParallel(model, device_ids=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; output = net(input_var)  <span class="comment"># input_var can be on any device, including CP</span></span><br></pre></td></tr></table></figure><h3><span id="数据并行的原理">数据并行的原理</span></h3><p>数据并行的具体原理流程为：</p><p><img src="/2020/01/06/Pytorch之GPU程序/pytorch-学习/数据并行.png" alt=""></p><ol><li><p>将模型加载至主设备上，作为 <code>controller</code>，一般设置为 <code>cuda:0</code></p></li><li><p>在每次迭代时，执行如下操作：</p><ol><li><p>将 <code>controller</code> 模型复制（<code>broadcast</code>）到每一个指定的 <code>GPU</code> 上</p></li><li><p>将总输入的数据 <code>batch</code>，进行均分，分别作为各对应副本的输入 (<code>scatter</code>)</p></li><li><p>每个副本独立进行前向传播，并进行反向传播，但只是求取梯度，每个GPU上的loss都要进行<code>loss.backward()</code>,得到各自的梯度</p></li><li><p>将各副本的梯度汇总（<code>gather</code>）到 <code>controller</code> 设备，并进行求和 (<code>reduced add</code>)</p><blockquote><p>During the backwards pass, gradients from each replica are summed into the original module.</p></blockquote></li><li><p>更具总体度，更新 <code>controller</code> 设备上的参数</p></li></ol></li></ol><h3><span id="注意事项">注意事项</span></h3><p>【<strong>警告 1</strong>】</p><ul><li>设置的 <code>batch size</code> 为总的批量尺寸，其必须大于 <code>GPU</code> 数量。</li><li>在 <code>parallelized module</code> 运行之前，必须保证其在 <code>controller</code> 设备上，存在参数和 <code>buffers</code>。</li><li>并行的 <code>GPU</code> 列表中，必须包含主 <code>GPU</code></li><li>当 <code>forward()</code> 中，<code>module</code> 返回一个标量，那么并行的结果将返回一个 <code>vector</code>，其长度等于 <code>device</code> 的数量，对应于各个设备的结果。</li></ul><p>【<strong>警告 2</strong>】</p><p>在每次前向传播过程中，<code>module</code> 都先会被复制到每一个 <code>device</code> 上。因此，在前向传播中，任何对该运行的 <code>module</code> 的副本的更新，在此后都将会丢失。</p><p>比方说，如果 <code>module</code> 有一个 <code>counter</code> 属性，每次前向传播都会进行累加，则它将会保持为初始值。因为更新是发生在模型的副本（在其他 <code>device</code> 上的副本）上的，并且这些更新在前向传播结束之后将会被销毁。</p><p>然而，<code>DataParallel</code> 保证 <code>controller</code> 设备上的副本的参数和 <code>buffers</code> 与其他并行的 <code>modules</code> 之间共享存储。因此，如若对 <code>controller device</code> 的 参数和 <code>buffers</code> 的更改，将会被记录。例如，<code>BatchNorm2d</code> 和 <code>spectral_norm()</code> 依赖于这种行为来更新 <code>buffers</code>。</p><p>【<strong>警告 3</strong>】</p><p>定义于 <code>module</code> 及其子 <code>module</code> 上的前向传播和反向传播 <code>hooks</code>，将会被调用 <code>len(device_ids)</code> 次，每个设备对应一次。</p><p>具体来说，<code>hooks</code> 只能保证按照正确的顺序执行对应设备上的操作，即在对应设备上的 <code>forward()</code> 调用之前执行，但是不能保证，在所有 <code>forward)()</code> 执行之前，通过 <code>register_forward_pre_hook()</code> 执行完成所有的 <code>hooks</code>。</p><p>【<strong>警告 4</strong>】</p><p>任何位置和关键字 (<code>positional and keyword</code>) 输入都可以传递给 <code>DataParallel</code>，处理一些需要特殊处理的类型。</p><p><code>tensors</code> 将会在指定维度（默认为 <code>0</code>）上被 <code>scattered</code>。 <code>tuple</code>， <code>list</code> 和 <code>dict</code> 类型则会被浅拷贝。其他类型则会在不同的线程之间进行共享，且在模型前向传播过程中，如果进行写入，则可被打断。</p><p>【<strong>警告 5</strong>】</p><p>当对 <code>pack sequence -&gt; recurrent network -&gt; unpack sequence</code> 模式的 <code>module</code> 使用 <code>DataParallel</code> 或 <code>data_parallel</code> 时，有一些小的问题。</p><p>每个设备上的 <code>forward</code> 的对应输入，将仅仅是整个输入的一部分。因为默认的 <code>unpack</code> 操作 <code>torch.nn.utils.rnn.pad_packed_sequence()</code> 只会将该设备上的输入 <code>padding</code> 成该设备上的最长的输入长度，因此，将所有设备的结构进行汇总时，可能会发生长度的不匹配的情况。</p><p>因此，可以利用 <code>pad_packed_sequence()</code> 的 <code>total_length</code> 参数来保证 <code>forward()</code> 调用返回的序列长度一致。代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.nn.utils.rnn <span class="keyword">import</span> pack_padded_sequence, pad_packed_sequence</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModule</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="comment"># ... __init__, other methods, etc.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># padded_input is of shape [B x T x *] (batch_first mode) and contains</span></span><br><span class="line">    <span class="comment"># the sequences sorted by lengths</span></span><br><span class="line">    <span class="comment">#   B is the batch size</span></span><br><span class="line">    <span class="comment">#   T is max sequence length</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, padded_input, input_lengths)</span>:</span></span><br><span class="line">        total_length = padded_input.size(<span class="number">1</span>)  <span class="comment"># get the max sequence length</span></span><br><span class="line">        packed_input = pack_padded_sequence(padded_input, input_lengths,</span><br><span class="line">                                            batch_first=<span class="keyword">True</span>)</span><br><span class="line">        packed_output, _ = self.my_lstm(packed_input)</span><br><span class="line">        output, _ = pad_packed_sequence(packed_output, batch_first=<span class="keyword">True</span>,</span><br><span class="line">                                        total_length=total_length)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">m = MyModule().cuda()        <span class="comment"># 设置 controller 模型</span></span><br><span class="line">dp_m = nn.DataParallel(m)    <span class="comment"># 进行副本拷贝</span></span><br></pre></td></tr></table></figure><h3><span id="示例程序">示例程序</span></h3><p>下面是使用 <code>DataParrel</code> 的核心代码，其余部分与一般的训练流程一致。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置当前脚本可见的 GPU 列表</span></span><br><span class="line"><span class="comment"># 这里设置 0 号和 1 号 GPU 对当前脚本可见。</span></span><br><span class="line"><span class="comment"># 此时，若 DataParallel 中指定使用其他 GPU 资源，额外的编号将会被忽略</span></span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"0, 1"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用数据并行</span></span><br><span class="line"><span class="comment"># 1. 将 model 转移到某 GPU 上 -- net.cuda()</span></span><br><span class="line"><span class="comment"># 2. 指定并行训练要用到的 GPU -- device_ids=[0, 1]</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.device_count() &gt; <span class="number">1</span>:</span><br><span class="line">    print(<span class="string">"Let's use"</span>, torch.cuda.device_count(), <span class="string">"GPUs!"</span>)</span><br><span class="line">    net = nn.DataParallel(net.cuda(), device_ids=[<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据转移到 controller 所在 GPU</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">and</span> use_gpu:</span><br><span class="line">    inputs = inputs.cuda(device)</span><br><span class="line">    labels = labels.cuda(device)</span><br></pre></td></tr></table></figure><h3><span id="模型的加载">模型的加载</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_Single2Parallel</span><span class="params">(self, origin_state)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    将串行的权值参数转换为并行的权值参数</span></span><br><span class="line"><span class="string">    :param origin_state : 原始串行权值参数</span></span><br><span class="line"><span class="string">    :return             : 并行的权值参数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">  converted = OrderedDict()</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> origin_state.items():</span><br><span class="line">      name = <span class="string">"module."</span> + k</span><br><span class="line">      converted[name] = v</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> converted</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_Parallel2Single</span><span class="params">(self, origin_state)</span>:</span></span><br><span class="line">  <span class="string">"""</span></span><br><span class="line"><span class="string">  将并行的权值参数转换为串行的权值参数</span></span><br><span class="line"><span class="string">  :param origin_state : 原始串行权值参数</span></span><br><span class="line"><span class="string">  :return             : 并行的权值参数</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">    </span><br><span class="line">    converted = OrderedDict()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> origin_state.items():</span><br><span class="line">      name = k[<span class="number">7</span>:]</span><br><span class="line">      converted[name] = v</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">return</span> converted</span><br></pre></td></tr></table></figure><h2><span id="模型并行">模型并行</span></h2><p>如果模型本身较大，一张 <code>GPU</code> 放置不下时，要通过模型并行来处理。模型并行指的是，将模型的不同部分，分别放置于不同的 <code>GPU</code> 上，并将中间结果在 <code>GPU</code> 之间进行传递。</p><p>尽管从执行时间上来看，将模型的不同部分部署在不同设备上确实有好处，但是它通常是出于避免内存限制才使用。具有特别多参数的模型会受益于这种并行策略，因为这类模型需要很高的内存占用，很难适应到单个系统。</p><h3><span id="基本使用">基本使用</span></h3><p>下面，我们以一个 <code>toy</code> 模型为例，讲解模型并行。模型并行的实现方式如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.features_1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels=<span class="number">3</span>, out_channels=<span class="number">16</span>, kernel_size=<span class="number">3</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">16</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="keyword">True</span>),  <span class="comment"># 30</span></span><br><span class="line">            ......</span><br><span class="line">            nn.Conv2d(in_channels=<span class="number">64</span>, out_channels=<span class="number">128</span>, kernel_size=<span class="number">3</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="keyword">True</span>),  <span class="comment"># 12</span></span><br><span class="line">        ).to(<span class="string">'cuda:0'</span>)</span><br><span class="line"></span><br><span class="line">        self.features_2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels=<span class="number">128</span>, out_channels=<span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="keyword">True</span>),  <span class="comment"># 5</span></span><br><span class="line">            ......).to(<span class="string">'cuda:1'</span>)  <span class="comment"># 1</span></span><br><span class="line"></span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            ......</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, class_num)).to(<span class="string">'cuda:1'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        out = self.features_1(x.to(<span class="string">'cuda:0'</span>))</span><br><span class="line">        out = self.features_2(out.to(<span class="string">'cuda:1'</span>))</span><br><span class="line">        out = out.view(<span class="number">-1</span>, <span class="number">384</span>)</span><br><span class="line">        out = self.classifier(out)</span><br><span class="line">        out = F.softmax(out, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>上面的 <code>toy</code> 模型看起来和在单个 <code>GPU</code> 上运行的模型没什么区别，只不过用 <code>to(device)</code> 来将模型内的不同层分散到不同的 <code>GPU</code> 上进行运行，并且将中间结果转移到对应的 <code>GPU</code> 上即可。</p><p><code>backward()</code> 和 <code>torch.optim</code> 将会自动考虑梯度，与在一个 <code>GPU</code> 上没有区别。</p><blockquote><p><strong>注意</strong>：在调用 <code>loss</code> 函数时，<code>labels</code> 与 <code>output</code> 必须在同一个 <code>GPU</code> 上。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此时，不在此需要使用 model = model.cuda()</span></span><br><span class="line">model = ToyModel()</span><br><span class="line"></span><br><span class="line">loss_fn = nn.MSELoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> trainloader:</span><br><span class="line">    images, labels = data</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 要处理的部分</span></span><br><span class="line">    images = images.to(<span class="string">'cuda:0'</span>)</span><br><span class="line">    labels = labels.to(<span class="string">'cuda:1'</span>)   <span class="comment"># 必须与输出所在 GPU 一致</span></span><br><span class="line">    </span><br><span class="line">    outputs = net(images)</span><br><span class="line">    loss = criterion(outputs, labels)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure><h3><span id="模型并行的性能分析">模型并行的性能分析</span></h3><p>以上的实现解决了单个模型太大，不能存放于一个 <code>GPU</code> 的情况。然而，需要注意的是，相较于在单个 <code>GPU</code> 上运行，其速度更慢。因为任何时候，只有一个 <code>GPU</code> 在工作，而另一个则闲置。而当中间结果在 <code>GPU</code> 之间进行转移时，速度会进一步下降。</p><p>下面同时实例分析。以 <code>resnet50</code> 为例，用随机生成的数据输入，比较两个版本的运行时间。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision.models.resnet <span class="keyword">import</span> ResNet, Bottleneck</span><br><span class="line"></span><br><span class="line">num_classes = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ModelParallelResNet50</span><span class="params">(ResNet)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, *args, **kwargs)</span>:</span></span><br><span class="line">        super(ModelParallelResNet50, self).__init__(</span><br><span class="line">            Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], num_classes=num_classes, *args, **kwargs)</span><br><span class="line"></span><br><span class="line">        self.seq1 = nn.Sequential(</span><br><span class="line">            self.conv1,</span><br><span class="line">            self.bn1,</span><br><span class="line">            self.relu,</span><br><span class="line">            self.maxpool,</span><br><span class="line"></span><br><span class="line">            self.layer1,</span><br><span class="line">            self.layer2</span><br><span class="line">        ).to(<span class="string">'cuda:0'</span>)</span><br><span class="line"></span><br><span class="line">        self.seq2 = nn.Sequential(</span><br><span class="line">            self.layer3,</span><br><span class="line">            self.layer4,</span><br><span class="line">            self.avgpool,</span><br><span class="line">        ).to(<span class="string">'cuda:1'</span>)</span><br><span class="line"></span><br><span class="line">        self.fc.to(<span class="string">'cuda:1'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.seq2(self.seq1(x).to(<span class="string">'cuda:1'</span>))</span><br><span class="line">        <span class="keyword">return</span> self.fc(x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"></span><br><span class="line">num_batches = <span class="number">3</span></span><br><span class="line">batch_size = <span class="number">120</span></span><br><span class="line">image_w = <span class="number">128</span></span><br><span class="line">image_h = <span class="number">128</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(model)</span>:</span></span><br><span class="line">    model.train(<span class="keyword">True</span>)</span><br><span class="line">    loss_fn = nn.MSELoss()</span><br><span class="line">    optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">    one_hot_indices = torch.LongTensor(batch_size) \</span><br><span class="line">                           .random_(<span class="number">0</span>, num_classes) \</span><br><span class="line">                           .view(batch_size, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(num_batches):</span><br><span class="line">        <span class="comment"># generate random inputs and labels</span></span><br><span class="line">        inputs = torch.randn(batch_size, <span class="number">3</span>, image_w, image_h)</span><br><span class="line">        labels = torch.zeros(batch_size, num_classes) \</span><br><span class="line">                      .scatter_(<span class="number">1</span>, one_hot_indices, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># run forward pass</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = model(inputs.to(<span class="string">'cuda:0'</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># run backward pass</span></span><br><span class="line">        labels = labels.to(outputs.device)</span><br><span class="line">        loss_fn(outputs, labels).backward()</span><br><span class="line">        optimizer.step()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.switch_backend(<span class="string">'Agg'</span>)</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> timeit</span><br><span class="line"></span><br><span class="line">num_repeat = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">stmt = <span class="string">"train(model)"</span></span><br><span class="line"></span><br><span class="line">setup = <span class="string">"model = ModelParallelResNet50()"</span></span><br><span class="line"><span class="comment"># globals arg is only available in Python 3. In Python 2, use the following</span></span><br><span class="line"><span class="comment"># import __builtin__</span></span><br><span class="line"><span class="comment"># __builtin__.__dict__.update(locals())</span></span><br><span class="line">mp_run_times = timeit.repeat(</span><br><span class="line">    stmt, setup, number=<span class="number">1</span>, repeat=num_repeat, globals=globals())</span><br><span class="line">mp_mean, mp_std = np.mean(mp_run_times), np.std(mp_run_times)</span><br><span class="line"></span><br><span class="line">setup = <span class="string">"import torchvision.models as models;"</span> + \</span><br><span class="line">        <span class="string">"model = models.resnet50(num_classes=num_classes).to('cuda:0')"</span></span><br><span class="line">rn_run_times = timeit.repeat(</span><br><span class="line">    stmt, setup, number=<span class="number">1</span>, repeat=num_repeat, globals=globals())</span><br><span class="line">rn_mean, rn_std = np.mean(rn_run_times), np.std(rn_run_times)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot</span><span class="params">(means, stds, labels, fig_name)</span>:</span></span><br><span class="line">    fig, ax = plt.subplots()</span><br><span class="line">    ax.bar(np.arange(len(means)), means, yerr=stds,</span><br><span class="line">           align=<span class="string">'center'</span>, alpha=<span class="number">0.5</span>, ecolor=<span class="string">'red'</span>, capsize=<span class="number">10</span>, width=<span class="number">0.6</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">'ResNet50 Execution Time (Second)'</span>)</span><br><span class="line">    ax.set_xticks(np.arange(len(means)))</span><br><span class="line">    ax.set_xticklabels(labels)</span><br><span class="line">    ax.yaxis.grid(<span class="keyword">True</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.savefig(fig_name)</span><br><span class="line">    plt.close(fig)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plot([mp_mean, rn_mean],</span><br><span class="line">     [mp_std, rn_std],</span><br><span class="line">     [<span class="string">'Model Parallel'</span>, <span class="string">'Single GPU'</span>],</span><br><span class="line">     <span class="string">'mp_vs_rn.png'</span>)</span><br></pre></td></tr></table></figure><p>结果如下所示。模型并行相较于单 <code>GPU</code> 训练的模型，训练时间开销多出 <code>4.02/3.75-1=7%</code> 左右。当然，这存在优化空间，因为多 <code>GPU</code> 中，每一时刻只有一个 <code>GPU</code> 进行训练，其他闲置。而在中间数据转移过程中，又消耗一定的时间。</p><p><img src="/2020/01/06/Pytorch之GPU程序/pytorch-学习/模型并行.jpg" alt=""></p><p>模型并行 VS 单 GPU</p><h3><span id="输入流水线">输入流水线</span></h3><p>解决上面的问题的最直接的方式就是使用流水线技术，即 <code>GPU-0</code> 输出到 <code>GPU-1</code> 之后，在 <code>GPU-1</code> 训练的同时，<code>GPU-0</code> 接收下一批数据，这样就可以多 <code>GPU</code> 同时执行了。</p><p>下面，我们将 <code>120</code> 个样本的 <code>batch</code> 再次细分，分为 <code>20</code> 张样本每份的小 <code>batch</code>。由于 <code>Pytorch</code> 同步启动 <code>CUDA</code> 操作，因此，该操作不需要使用额外的多线程来处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PipelineParallelResNet50</span><span class="params">(ModelParallelResNet50)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, split_size=<span class="number">20</span>, *args, **kwargs)</span>:</span></span><br><span class="line">        super(PipelineParallelResNet50, self).__init__(*args, **kwargs)</span><br><span class="line">        self.split_size = split_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        splits = iter(x.split(self.split_size, dim=<span class="number">0</span>))</span><br><span class="line">        s_next = next(splits)</span><br><span class="line">        s_prev = self.seq1(s_next).to(<span class="string">'cuda:1'</span>)</span><br><span class="line">        ret = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> s_next <span class="keyword">in</span> splits:</span><br><span class="line">            <span class="comment"># A. s_prev runs on cuda:1</span></span><br><span class="line">            s_prev = self.seq2(s_prev)</span><br><span class="line">            ret.append(self.fc(s_prev.view(s_prev.size(<span class="number">0</span>), <span class="number">-1</span>)))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># B. s_next runs on cuda:0, which can run concurrently with A</span></span><br><span class="line">            s_prev = self.seq1(s_next).to(<span class="string">'cuda:1'</span>)</span><br><span class="line"></span><br><span class="line">        s_prev = self.seq2(s_prev)</span><br><span class="line">        ret.append(self.fc(s_prev.view(s_prev.size(<span class="number">0</span>), <span class="number">-1</span>)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> torch.cat(ret)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">setup = <span class="string">"model = PipelineParallelResNet50()"</span></span><br><span class="line">pp_run_times = timeit.repeat(</span><br><span class="line">    stmt, setup, number=<span class="number">1</span>, repeat=num_repeat, globals=globals())</span><br><span class="line">pp_mean, pp_std = np.mean(pp_run_times), np.std(pp_run_times)</span><br><span class="line"></span><br><span class="line">plot([mp_mean, rn_mean, pp_mean],</span><br><span class="line">     [mp_std, rn_std, pp_std],</span><br><span class="line">     [<span class="string">'Model Parallel'</span>, <span class="string">'Single GPU'</span>, <span class="string">'Pipelining Model Parallel'</span>],</span><br><span class="line">     <span class="string">'mp_vs_rn_vs_pp.png'</span>)</span><br></pre></td></tr></table></figure><p>需要注意的是，<code>device-to-device</code> 的 <code>tensor copy</code> 操作是同步的。如果创建多个数据流，则需要保证 <code>copy</code> 操作以合适的同步方式进行。</p><p>在完成 <code>tensor</code> 拷贝之前，对 <code>source tensor</code> 进行写入，或者对 <code>target tensor</code> 进行读写，都可能会导致不可预期的行为。上面的实现中，在源和目标设备中，均只使用了默认的 <code>stream</code>，因此无需额外的强化同步操作。</p><p><img src="/2020/01/06/Pytorch之GPU程序/pytorch-学习/模型并行2.jpg" alt=""><br>模型并行 VS 单 GPU VS 流水线模型并行</p><p>如上图所示，流水线输入确实加速了训练进程，大约 <code>3.75/2.51-1=49%</code>，但距离 <code>100%</code> 的加速相去甚远。由于我们在流水线并行实现中，引入了一个新的参数 <code>split_sizes</code>，但是并不知晓其对训练时间的影响。</p><p>直觉上来说，使用一个小的 <code>split_sizes</code> 将会导致许多微小的 <code>CUDA</code> 内核的启动，而使用较大的 <code>split_sizes</code>，则会导致较长的空闲时间。下面是一个搜索最佳 <code>split_sizes</code> 的实验。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">means = []</span><br><span class="line">stds = []</span><br><span class="line">split_sizes = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">8</span>, <span class="number">10</span>, <span class="number">12</span>, <span class="number">20</span>, <span class="number">40</span>, <span class="number">60</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> split_size <span class="keyword">in</span> split_sizes:</span><br><span class="line">    setup = <span class="string">"model = PipelineParallelResNet50(split_size=%d)"</span> % split_size</span><br><span class="line">    pp_run_times = timeit.repeat(</span><br><span class="line">        stmt, setup, number=<span class="number">1</span>, repeat=num_repeat, globals=globals())</span><br><span class="line">    means.append(np.mean(pp_run_times))</span><br><span class="line">    stds.append(np.std(pp_run_times))</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(split_sizes, means)</span><br><span class="line">ax.errorbar(split_sizes, means, yerr=stds, ecolor=<span class="string">'red'</span>, fmt=<span class="string">'ro'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'ResNet50 Execution Time (Second)'</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">'Pipeline Split Size'</span>)</span><br><span class="line">ax.set_xticks(split_sizes)</span><br><span class="line">ax.yaxis.grid(<span class="keyword">True</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.savefig(<span class="string">"split_size_tradeoff.png"</span>)</span><br><span class="line">plt.close(fig)</span><br></pre></td></tr></table></figure><p>实验结果如下所示：</p><p><img src="/2020/01/06/Pytorch之GPU程序/pytorch-学习/pipeline.jpg" alt=""></p><p>流水线输入分割份数</p><p>如上图所示，最佳的参数为 <code>12</code>，其将导致 <code>3.75/2.43-1=54%</code> 的加速。但这仍存在加速的可能。例如，所有在 <code>cuda:0</code> 上的操作放在默认的 <code>stream</code> 上。这意味着，在下一个 <code>split</code> 上的计算，不能与上一个 <code>split</code> 的 <code>copy</code> 操作进行重叠。然而，由于 <code>next_split</code> 和 <code>prev_plit</code> 是不同的 <code>tensor</code>，因此这不存在问题。</p><p>该实现需要在每个 <code>GPU</code> 上使用多个 <code>stream</code>，并且模型中不同的子网络需要使用不同的 <code>stream</code> 管理策略。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;介绍Pytorch的一些使用方法&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Deep Learning" scheme="http://yoursite.com/categories/Deep-Learning/"/>
    
    
      <category term="Pytorch" scheme="http://yoursite.com/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>Mxnet和Pytorch区别</title>
    <link href="http://yoursite.com/2019/12/29/Mxnet%E5%92%8CPytorch%E5%8C%BA%E5%88%AB/"/>
    <id>http://yoursite.com/2019/12/29/Mxnet和Pytorch区别/</id>
    <published>2019-12-29T09:05:01.000Z</published>
    <updated>2020-03-04T03:13:09.635Z</updated>
    
    <content type="html"><![CDATA[<p>平时主要使用mxnet和pytorch，下面记录下在代码中怎么使用GPU<br><a id="more"></a></p><!-- TOC --><ul><li><a href="#1-mxnet">1. mxnet</a><ul><li><a href="#11-%e5%8d%95gpu">1.1. 单GPU</a></li><li><a href="#12-%e5%a4%9agpu">1.2. 多GPU</a></li></ul></li><li><a href="#2-pytorch">2. pytorch</a><ul><li><a href="#21-%e5%8d%95gpu">2.1. 单GPU</a></li><li><a href="#22-%e5%a4%9agpu">2.2. 多GPU</a></li></ul></li><li><a href="#3-mxnet%e5%92%8cpytorch%e5%8c%ba%e5%88%ab">3. mxnet和pytorch区别</a><ul><li><a href="#31-ndarray%e5%92%8ctensor">3.1. NDArray和Tensor</a><ul><li><a href="#311-%e5%92%8cnumpy%e8%bd%ac%e6%8d%a2">3.1.1. 和numpy转换</a></li><li><a href="#312-%e8%bd%ac%e6%8d%a2%e4%b8%ba%e6%a0%87%e9%87%8f">3.1.2. 转换为标量</a></li><li><a href="#313-%e6%94%b9%e5%8f%98%e6%95%b0%e6%8d%ae%e5%bd%a2%e7%8a%b6">3.1.3. 改变数据形状</a></li><li><a href="#314-%e6%95%b0%e6%8d%ae%e8%bd%ac%e5%88%b0gpu%e4%b8%8a">3.1.4. 数据转到GPU上</a></li></ul></li><li><a href="#32-loss%e8%ae%a1%e7%ae%97">3.2. loss计算</a></li><li><a href="#33-rnn%e8%be%93%e5%85%a5%e7%bb%b4%e5%ba%a6">3.3. RNN输入维度</a></li><li><a href="#34-transformer%e8%be%93%e5%85%a5%e7%bb%b4%e5%ba%a6">3.4. Transformer输入维度</a></li><li><a href="#35-%e5%a4%9agpu%e8%bf%90%e8%a1%8c">3.5. 多GPU运行</a></li><li><a href="#36-%e5%b0%86%e7%bd%91%e7%bb%9c%e5%8a%a0%e5%85%a5list%e4%b8%ad">3.6. 将网络加入list中</a></li></ul></li></ul><!-- /TOC --><h1><span id="1-mxnet">1. mxnet</span></h1><h2><span id="11-单gpu">1.1. 单GPU</span></h2><p><a href="http://zh.gluon.ai/chapter_deep-learning-computation/use-gpu.html" target="_blank" rel="noopener">GPU计算</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment">#指定使用哪块GPU</span></span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"3"</span></span><br><span class="line"><span class="comment">#被指定的GPU编号默认为0</span></span><br><span class="line">ctx = mx.gpu(<span class="number">0</span>)</span><br><span class="line"><span class="comment">#模型、数据都需要拷贝到GPU中</span></span><br><span class="line">nd.array(data,ctx)</span><br><span class="line">data.as_in_context(ctx)</span><br></pre></td></tr></table></figure><h2><span id="12-多gpu">1.2. 多GPU</span></h2><p><a href="http://zh.gluon.ai/chapter_computational-performance/multiple-gpus-gluon.html" target="_blank" rel="noopener">多GPU计算</a><br><a href="http://mxnet.incubator.apache.org/api/faq/multi_device" target="_blank" rel="noopener">Run MXNet on Multiple CPU/GPUs with Data Parallelism</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">ctx_id = <span class="string">'1,2,3,4'</span></span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = ctx_id</span><br><span class="line">num_gpus = len(ctx_id.split(<span class="string">','</span>))</span><br><span class="line">ctx = [mx.gpu(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(num_gpus)]</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用split_and_load()将数据分配到多个GPU上</span></span><br></pre></td></tr></table></figure><h1><span id="2-pytorch">2. pytorch</span></h1><h2><span id="21-单gpu">2.1. 单GPU</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"1"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">"cuda:0"</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    device = torch.device(<span class="string">"cpu"</span>)</span><br><span class="line"><span class="comment">#使用to()将数据拷贝到GPU上</span></span><br><span class="line">train_feature.to(device)</span><br></pre></td></tr></table></figure><h2><span id="22-多gpu">2.2. 多GPU</span></h2><p><a href="https://github.com/dnddnjs/pytorch-multigpu/blob/master/data_parallel/train.py" target="_blank" rel="noopener">pytorch-multigpu</a></p><p><a href="https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html" target="_blank" rel="noopener">OPTIONAL: DATA PARALLELISM</a></p><p><a href="https://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html" target="_blank" rel="noopener">MULTI-GPU EXAMPLES</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"1,2,3"</span>  </span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">"cuda:0"</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    device = torch.device(<span class="string">"cpu"</span>)</span><br><span class="line"><span class="comment">#pytorch在使用多GPU时，需要先将数据和模型拷贝到GPU-0上，</span></span><br><span class="line"><span class="comment">#使用多GPU的关键代码</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.device_count() &gt; <span class="number">1</span>:</span><br><span class="line">    print(<span class="string">"Let's use"</span>, torch.cuda.device_count(), <span class="string">"GPUs!"</span>,flush=<span class="keyword">True</span>)</span><br><span class="line">    <span class="comment">#数据并行</span></span><br><span class="line">    model = nn.DataParallel(model)</span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> rand_loader:</span><br><span class="line">    input = data.to(device)</span><br><span class="line">    output = model(input)</span><br><span class="line">    print(<span class="string">"Outside: input size"</span>, input.size(),</span><br><span class="line">          <span class="string">"output_size"</span>, output.size())</span><br></pre></td></tr></table></figure><p><code>DataParallel</code>自动分割数据，并发送到多个GPU上，每个GPU上完成前向传播， <code>DataParallel</code>收集每个GPU上的结果。</p><hr><p>2020.2.11更新</p><h1><span id="3-mxnet和pytorch区别">3. mxnet和pytorch区别</span></h1><p>在写程序时，主要用到<code>mxnet和pytorch</code>框架，这里针对2者在代码上的不同做个总结，下面的不同都是我自己在写程序遇到的，仅仅是一部分，仅供参考。</p><h2><span id="31-ndarray和tensor">3.1. NDArray和Tensor</span></h2><h3><span id="311-和numpy转换">3.1.1. 和numpy转换</span></h3><ul><li><p>mxnet</p><ul><li><strong>Numpy—&gt;NDArray</strong><br><code>nd.array(a)</code></li><li><strong>NDArray—&gt;Numpy</strong><br><code>D.asnumpy()</code></li></ul></li><li><p>pytorch</p><ul><li><strong>Numpy—&gt;Tensor</strong><br><code>D = torch.from_numpy(a)</code></li><li><strong>Tensor—&gt;Numpy</strong><br><code>a = D.numpy()</code></li></ul></li></ul><h3><span id="312-转换为标量">3.1.2. 转换为标量</span></h3><ul><li>mxnet<br><code>asscalar()</code>将函数结果转换成Python的标量<br><code>X.sum().asscalar()</code></li><li>pytorch<br><code>item()</code>将函数结果转换成Python的标量<br><code>X.sum().item()</code></li></ul><h3><span id="313-改变数据形状">3.1.3. 改变数据形状</span></h3><ul><li><p>mxnet</p><ul><li><p><strong>reshape()</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = x.reshape((<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">X = x.reshape((<span class="number">-1</span>, <span class="number">4</span>))</span><br></pre></td></tr></table></figure></li></ul></li><li><p>pytorch</p><ul><li><p><strong>view()</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = x.view(<span class="number">15</span>)</span><br><span class="line">z = x.view(<span class="number">-1</span>, <span class="number">5</span>)  <span class="comment"># -1所指的维度可以根据其他维度的值推出来</span></span><br></pre></td></tr></table></figure></li></ul></li></ul><h3><span id="314-数据转到gpu上">3.1.4. 数据转到GPU上</span></h3><ul><li><p>mxnet<br>使用<code>as_in_context()</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在gpu上创建NDArray</span></span><br><span class="line">B = nd.random.uniform(shape=(<span class="number">2</span>, <span class="number">3</span>), ctx=mx.gpu(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">z = x.as_in_context(mx.gpu())</span><br></pre></td></tr></table></figure></li><li><p>pytorch<br>使用<code>to()</code>函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">"cuda"</span>) <span class="comment"># GPU</span></span><br><span class="line">y = torch.ones_like(x, device=device)  <span class="comment"># 直接创建一个在GPU上的Tensor</span></span><br><span class="line">x = x.to(device)</span><br></pre></td></tr></table></figure></li></ul><h2><span id="32-loss计算">3.2. loss计算</span></h2><ul><li>maxnet</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">loss = L2Loss()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>,num_epochs + <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> X,y <span class="keyword">in</span> data_iter:</span><br><span class="line">        <span class="keyword">with</span> autograd.record()：</span><br><span class="line">            <span class="comment">#l维度(batch_size,)</span></span><br><span class="line">            l = loss(net(X),y)</span><br><span class="line">        <span class="comment">#等价于l.sum().backward()</span></span><br><span class="line">        l.backward()</span><br><span class="line">        <span class="comment">#step对参数的梯度进行更新，传入batch_size是因为计算得到的梯度是一个batch样本的梯度和，需要除以batch_size得到梯度的平均值</span></span><br><span class="line">        trainer.step(batch_size)</span><br></pre></td></tr></table></figure><blockquote><p>注1：在使用<code>y.backward()</code>自动求梯度时，如果<code>y</code>不是一个标量，mxnet将默认先对<code>y</code>中元素求和得到新的变量，在求该变量关于<code>x</code>的梯度 </p><p>注2：mxnet的<code>L2Loss()</code>返回值维度<code>(batch_size,)</code>，即batch中每个样本的loss。需要在<code>step()</code>中传入<code>batch_size</code>参数</p></blockquote><ul><li>pytorch</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">loss = MSELoss()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>,num_epochs + <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> X,y <span class="keyword">in</span> data_iter:</span><br><span class="line">        <span class="comment">#l维度(1,)</span></span><br><span class="line">        l = loss(net(X),y)</span><br><span class="line">        optimizer.zero_grad() <span class="comment"># 梯度清零，等价于net.zero_grad()</span></span><br><span class="line">        l.backward()</span><br><span class="line">        <span class="comment">#step对参数的梯度进行更新，不需要传入batch_size参数</span></span><br><span class="line">        trainer.step()</span><br></pre></td></tr></table></figure><blockquote><p>注1：在<code>y.backward()</code>时，如果<code>y</code>是标量，则<code>backward()</code>不需要传入任何参数，否则，需要传入与<code>y</code>同形的Tensor</p><p>注2：grad在反向传播过程中是累加的，这意味着每一个batch运行反向传播，梯度都会累加之前batch的梯度，所以一般在反向传播传播之前需要把梯度清零。</p><p>注3：pytorch的<code>MSELoss()</code>返回值维度<code>(1,)</code>，Tensor中只有1个数，也称作<code>scalar:零维的张量</code>。因为<code>MSELoss()</code>返回值是batch中所有样本loss的平均值。所以在<code>step()</code>中不需要传入<code>batch_size</code>参数</p></blockquote><h2><span id="33-rnn输入维度">3.3. RNN输入维度</span></h2><p>RNN有2个数据：所有时间步的隐藏状态output、最后一个时间步的隐藏状态out_state</p><ul><li>mxnet<ul><li>输入数据维度默认<code>(T,batch_size,input_size)</code></li><li>output输出数据维度<code>(T,batch_size,hidden_size)</code></li></ul></li><li>pytorch<ul><li>输入数据维度默认<code>(T,batch_size,input_size)</code></li><li>output输出数据维度<code>(T,batch_size,hidden_size)</code></li></ul></li></ul><h2><span id="34-transformer输入维度">3.4. Transformer输入维度</span></h2><ul><li><p>mxnet<br>Mxnet中有一个NLP相关的包<code>gluonnlp</code>,里面封装了<code>Transformer</code>，这里只讨论<code>TransformerEncoder</code></p><ul><li>输入维度为<code>(batch_size, length, C_in)</code></li><li>输出维度为<code>(batch_size, length, C_out)</code></li></ul></li><li><p>pytorch<br>Pytorch中也封装了Transformer，<code>TransformerEncoder</code></p><ul><li>输入维度为<code>(length, batch_size, Embedding)</code></li><li>输出维度为<code>(length, batch_size, Embedding)</code><br><code>nn.TransformerEncoderLayer</code></li><li>输入维度为<code>(length, batch_size, Embedding)</code></li><li>输出维度为<code>(length, batch_size, Embedding)</code></li></ul></li></ul><p>【注意】Mxnet版的Tranformer中Dropout的p默认为0，Pytorch版的Transformer中Dropout的p默认为0.1</p><h2><span id="35-多gpu运行">3.5. 多GPU运行</span></h2><ul><li><p>mxnet</p><blockquote><p>mxnet.gluon.utils.split_and_load(data, ctx_list, batch_axis=0, even_split=True)</p></blockquote><p><code>split_and_load()</code>将一个batch中的数据划分为多个小batch到多个GPU上。<br><strong>【注意】默认batch_axis=0，也就是默认划分axis=0的维度，如果batch不在第0维，例如RNN中，输入的维度默认为TNC，batch在第1维，那就需要在split_and_load中指定batch_axis=1</strong><br><code>split_and_load()</code>返回值是list，里面每个元素是<code>NDArray</code>,经过<code>split_and_load()</code>对一个batch数据进行分割，得到的<code>X,y</code>的shape变成<code>(batch_size/n,*)</code>,经过模型输出得到的predicted维度也是<code>(batch_size/n,*)</code><br>计算得到的loss也是list类型，里面存储一个batch在多个GPU上计算的loss，对每个loss分别反向传播求梯度，然后再使用<code>step()</code>更新参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    <span class="keyword">for</span> X,y <span class="keyword">in</span> train_iter:</span><br><span class="line">        gpu_Xs = gutils.split_and_load(X,ctx)</span><br><span class="line">        gpu_ys = gutils.split_and_load(y,ctx)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> autograd.record():</span><br><span class="line">            <span class="comment">#ls是list，里面有n个NDArray，n是GPU的个数</span></span><br><span class="line">            ls = [loss(net(gpu_X),gpu_y <span class="keyword">for</span> gpu_X,gpu_y <span class="keyword">in</span> zip(gpu_Xs,gpu_ys)</span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> ls:</span><br><span class="line">            l.backward()</span><br><span class="line"></span><br><span class="line">        train.step(batch_size)</span><br></pre></td></tr></table></figure><p><img src="/2019/12/29/Mxnet和Pytorch区别/gpus-mxnet.png" alt=""></p></li><li><p>pytorch<br><a href="https://echohhhhhh.github.io/2019/01/31/%E8%BF%90%E8%A1%8CGPU%E7%A8%8B%E5%BA%8F/" target="_blank" rel="noopener">Pytorch学习</a>  </p><blockquote><p>CLASS torch.nn.DataParallel(module, device_ids=None, output_device=None, dim=0)</p></blockquote><p><strong><code>DataParallel</code>自动将batch进行划分，划分维度默认dim=0，如果batch在其他维度，通过dim指定</strong><br>pytorch使用<code>DataParallel()</code>来进行数据并行，不需要手动将数据划分到多个GPU上，即<code>train_feature</code>的维度是<code>(batch_size,*)</code>，经过模型输出的<code>predicted</code>的维度也是<code>(batch_size,*)</code>，这一点和<code>mxnet</code>不同</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用多GPU的关键代码</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.device_count() &gt; <span class="number">1</span>:</span><br><span class="line">    transformer_model = nn.DataParallel(transformer_model)<span class="comment">#默认全部GPU</span></span><br><span class="line">transformer_model.to(device0)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>,training_epoch+<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> train_feature,train_label <span class="keyword">in</span> train_loader:</span><br><span class="line">        train_feature = train_feature.to(device0)</span><br><span class="line">        train_label = train_label.to(device0)</span><br><span class="line">        <span class="comment">#train_label:(tabch_size,*)</span></span><br><span class="line">        predicted = transformer_model(train_feature)</span><br><span class="line">        l = loss(predicted,train_label)<span class="comment">#l的shape：(1,)</span></span><br><span class="line">        trainer.zero_grad()</span><br><span class="line">        l.backward()</span><br><span class="line">        trainer.step()</span><br></pre></td></tr></table></figure></li></ul><p>  <img src="/2019/12/29/Mxnet和Pytorch区别/gpus-pytorch.png" alt=""></p><blockquote><p>从这2个图中可以看出Mxnet和Pytorch多GPU运行的区别。<br>  <strong>Mxnet</strong>将batch数据和label都分配到每个GPU上，然后在每个GPU上都计算loss，然后再把loss聚合。<br>  <strong>Pytorch</strong>只把batch数据分配到每个GPU上，在每个GPU上得到输出，gather到主设备上，然后再和label计算loss。<br>  Mxnet会比Pytorch会一些，因为Mxnet的loss是在不同的GPU上计算的，但Pytorch的写法更简单。<br>  为了解决Pytorch在一张卡上计算loss的问题，有人提出了解决方案，参考<a href="https://liumin.blog.csdn.net/article/details/89437058" target="_blank" rel="noopener">基于PyTorch使用大batch训练神经网络</a>和<a href="https://blog.csdn.net/weixin_40087578/article/details/87186613?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">pytorch 多GPU训练总结（DataParallel的使用）</a></p></blockquote><h2><span id="36-将网络加入list中">3.6. 将网络加入list中</span></h2><ul><li><p>mxnet</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">self.submodules = []</span><br><span class="line">      <span class="keyword">with</span> self.name_scope():</span><br><span class="line">          <span class="keyword">for</span> backbones <span class="keyword">in</span> all_backbones:</span><br><span class="line">              self.submodules.append(</span><br><span class="line">                  ASTGCN_submodule(num_for_prediction, backbones))</span><br><span class="line">              self.register_child(self.submodules[<span class="number">-1</span>])</span><br></pre></td></tr></table></figure></li><li><p>pytorch<br>Pytorch中<code>nn.Module, nn.ModuleList, nn.Sequential</code>，统称为容器，因为我们可以添加模块module到它们中。但有时候容易混淆，我们主要讨论<code>nn.ModuleList, nn.Sequential</code>的使用。</p><p><strong>【nn.ModuleList】</strong><br><a href="https://zhuanlan.zhihu.com/p/64990232" target="_blank" rel="noopener">PyTorch 中的 ModuleList 和 Sequential: 区别和使用场景</a><br><a href="https://blog.csdn.net/qq_38863413/article/details/104118055" target="_blank" rel="noopener">Pytorch使用 nn.ModuleList() 和nn.Sequential()编写神经网络模型</a><br>ModuleList是一个类，可以将Module任意子类(Conv2d,Linear等)加入到list中，方法和Python自带的list一样，使用append或extend等操作。但不同于一般的list，<strong>加入到ModuleList里的module会自动注册到整个网络上，同时module的参数也会自动添加到整个网络中</strong>。</p></li></ul>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModel</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">      super(MyModel, self).__init__()</span><br><span class="line">      self.linears = nn.ModuleList([nn.linear <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)])</span><br><span class="line"></span><br><span class="line">  <span class="comment"># ModuleList can act as an iterable, or be indexed using ints</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">      <span class="keyword">for</span> i, l <span class="keyword">in</span> enumerate(self.linears):</span><br><span class="line">          x = self.linears[i // <span class="number">2</span>](x) + l(x)</span><br><span class="line">      <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;平时主要使用mxnet和pytorch，下面记录下在代码中怎么使用GPU&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Deep Learning" scheme="http://yoursite.com/categories/Deep-Learning/"/>
    
    
      <category term="Pytorch" scheme="http://yoursite.com/tags/Pytorch/"/>
    
      <category term="Mxnet" scheme="http://yoursite.com/tags/Mxnet/"/>
    
      <category term="GPU" scheme="http://yoursite.com/tags/GPU/"/>
    
  </entry>
  
  <entry>
    <title>leetcode踩坑</title>
    <link href="http://yoursite.com/2019/12/26/leecode-tirck/"/>
    <id>http://yoursite.com/2019/12/26/leecode-tirck/</id>
    <published>2019-12-26T11:25:57.000Z</published>
    <updated>2020-01-23T13:07:12.188Z</updated>
    
    <content type="html"><![CDATA[<p>&ensp;&ensp;&ensp;&ensp;最近开始刷Leecode，使用Python语言，踩了很多坑，在此记录。</p><a id="more"></a><!-- TOC --><ul><li><a href="#1-%e4%b8%80%e4%b8%aa%e8%90%9d%e5%8d%9c%e4%b8%80%e4%b8%aa%e5%9d%91">1. 一个萝卜一个坑</a><ul><li><a href="#11-int%e5%87%bd%e6%95%b0">1.1. int函数</a></li><li><a href="#12-bin%e5%87%bd%e6%95%b0">1.2. bin函数</a></li><li><a href="#13-zip%e5%87%bd%e6%95%b0">1.3. zip函数</a></li><li><a href="#14-%e4%ba%8c%e5%88%86%e6%b3%95%e8%ae%b2%e8%a7%a3">1.4. 二分法讲解</a></li></ul></li></ul><!-- /TOC --><h1><span id="1-一个萝卜一个坑">1. 一个萝卜一个坑</span></h1><h2><span id="11-int函数">1.1. int函数</span></h2><p>int()函数用于将一个字符串或数字转换为整型。<br><code>int(x,base=10)</code>:x—字符串或数字，base—进制数，默认十进制。 如果显示的指定base参数，x必须为str。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int(<span class="number">3</span>) = <span class="number">3</span></span><br><span class="line">int(<span class="number">3.6</span>) = <span class="number">3</span></span><br><span class="line">int(<span class="string">'12'</span>,<span class="number">16</span>) = <span class="number">18</span></span><br><span class="line">int(<span class="string">'11'</span>,<span class="number">2</span>) = <span class="number">3</span><span class="comment">#将字符串解析为2进制</span></span><br></pre></td></tr></table></figure><h2><span id="12-bin函数">1.2. bin函数</span></h2><p>bin()返回一个整数int的二进制表示，返回类型str<br><code>bin(x)</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#返回的结果前2个字符是固定的'0b'，后面才是真正的值。</span></span><br><span class="line">bin(<span class="number">10</span>) = <span class="string">'0b1010'</span></span><br><span class="line">bin(<span class="number">20</span>) = <span class="string">'0b10100'</span></span><br></pre></td></tr></table></figure><h2><span id="13-zip函数">1.3. zip函数</span></h2><p>zip()接受一系列(多个，个数不固定)可迭代对象(最常用list,tuple)作为参数，将多个对象中，对应位置的元素打包成一个个tuple，然后返回由这些tuple组成的list。若传入参数中长度不一样，则返回liist的长度和参数中最短的相同。  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">x = [<span class="string">'wang'</span>,<span class="string">'bei'</span>]</span><br><span class="line">y = [<span class="string">'lei'</span>,<span class="string">'xiao'</span>,<span class="string">'kang'</span>]</span><br><span class="line">list(zip(x,y))</span><br><span class="line">输出：[(<span class="string">'wang'</span>,<span class="string">'lei'</span>),(<span class="string">'bei'</span>,<span class="string">'xiao'</span>)]</span><br><span class="line"></span><br><span class="line">x = <span class="string">'wang'</span></span><br><span class="line">y = <span class="string">'lei'</span></span><br><span class="line">list(zip(x,y))</span><br><span class="line">输出：[(<span class="string">'w'</span>,<span class="string">'l'</span>),(<span class="string">'a'</span>,<span class="string">'e'</span>),(<span class="string">'n'</span>,<span class="string">'i'</span>)]  </span><br><span class="line"></span><br><span class="line"><span class="comment">#假设zip传入的参数是x，y，zip依次将(x[0],y[0]),(x[1],y[1])..</span></span><br><span class="line"><span class="comment">#以可迭代对象返回，可强制转换为list或tuple</span></span><br></pre></td></tr></table></figure><p>zip(<em>)传入的参数是zip()的返回值类型，从<zip\>类型中每一个tuple中，取出第0个元素组成一个list，再取出第1个元素组成一个list，即zip(\</zip\></em>)返回值是一个大list，里面有2个tuple</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line">b = [<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>]</span><br><span class="line">zipped = list(zip(a,b))</span><br><span class="line"><span class="comment">#zipped = [(1,'a'),(2,'b'),(3,'c')]</span></span><br><span class="line">c = list(zip(*zipped))</span><br><span class="line"><span class="comment">#c = [(1,2,3),('a','b','c')]</span></span><br></pre></td></tr></table></figure><h2><span id="14-二分法讲解">1.4. 二分法讲解</span></h2><p><a href="https://leetcode-cn.com/problems/search-insert-position/solution/te-bie-hao-yong-de-er-fen-cha-fa-fa-mo-ban-python-/" target="_blank" rel="noopener">参考资料</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;最近开始刷Leecode，使用Python语言，踩了很多坑，在此记录。&lt;/p&gt;
    
    </summary>
    
      <category term="算法" scheme="http://yoursite.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>nni</title>
    <link href="http://yoursite.com/2019/11/25/nni/"/>
    <id>http://yoursite.com/2019/11/25/nni/</id>
    <published>2019-11-25T06:23:50.000Z</published>
    <updated>2020-03-05T07:38:11.238Z</updated>
    
    <content type="html"><![CDATA[<p>NN是微软官方出的一个自动调参的第三方库。非常好用。但是用起来还是有一些需要注意的地方。这里记录一下。<br><a id="more"></a><br><!-- TOC --></p><ul><li><a href="#1-%e6%9c%af%e8%af%ad">1. 术语</a><ul><li><a href="#11-%e4%bd%bf%e7%94%a8%e6%ad%a5%e9%aa%a4">1.1. 使用步骤</a></li></ul></li><li><a href="#2-nni%e5%91%bd%e4%bb%a4">2. NNI命令</a></li></ul><!-- /TOC --><p><a href="https://nni.readthedocs.io/zh/latest/Tutorial/QuickStart.html" target="_blank" rel="noopener">NNi官方文档</a></p><h1><span id="1-术语">1. 术语</span></h1><p>主要有2个术语experiment和trial。<br>experiment：如果需要调整LSTM的超参数，则需要指定每个超参数的可选项，然后运行程序，让nni自动调参。运行的这个调参程序就是experiment。<br>trial：上面运行的程序中，有很多的参数组合，每一个超参数组合是trial。<br>每一个experiment有一个ID，experiment中的每一个trial也有一个ID。在网页中可以看到</p><p><img src="/2019/11/25/nni/experiment_id.png" alt=""></p><p><img src="/2019/11/25/nni/trial_id.png" alt=""></p><h2><span id="11-使用步骤">1.1. 使用步骤</span></h2><ol><li><p>创建搜索空间json文件<br>这里定义需要调整的超参数</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> <span class="attr">"num_layer"</span>:&#123;<span class="attr">"_type"</span>:<span class="string">"choice"</span>,<span class="attr">"_value"</span>:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]&#125;,</span><br><span class="line"> <span class="attr">"hidden_size"</span>:&#123;<span class="attr">"_type"</span>:<span class="string">"choice"</span>,<span class="attr">"_value"</span>:[<span class="number">64</span>,<span class="number">128</span>,<span class="number">256</span>,<span class="number">512</span>]&#125;,</span><br><span class="line"> <span class="attr">"batch_size"</span>: &#123;<span class="attr">"_type"</span>:<span class="string">"choice"</span>, <span class="attr">"_value"</span>: [<span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>,<span class="number">64</span>,<span class="number">128</span>,<span class="number">256</span>]&#125;,</span><br><span class="line"> <span class="attr">"learning_rate"</span>:&#123;<span class="attr">"_type"</span>:<span class="string">"uniform"</span>,<span class="attr">"_value"</span>:[<span class="number">0.0001</span>,<span class="number">0.001</span>]&#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></li><li><p>首先在程序中import nni </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nni  </span><br><span class="line"><span class="keyword">import</span> os  </span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"2"</span><span class="comment">#单GPU</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>,train_epoch):</span><br><span class="line">    每一个batch，在测试集上训练，并反向传播  </span><br><span class="line">    每一个epoch，计算验证集/测试集的loss</span><br><span class="line">    每一个epoch，计算验证集/测试集的评价指标(mae,rmse)</span><br><span class="line">    <span class="comment">#将验证集的评价指标加入到nni中</span></span><br><span class="line">    <span class="keyword">if</span> epoch &lt; train_epoch:</span><br><span class="line">         nni.report_intermediate_result(valid_mae)</span><br><span class="line">     <span class="keyword">else</span>:</span><br><span class="line">         nni.report_final_result(valid_mae)</span><br></pre></td></tr></table></figure><p>在下面的yml文件中，需要指定gpuNum,即需要使用多少张GPU卡。但是nni会自动申请gpu，你也不知道会申请到哪个gpu。为了解决这个问题，需要指定程序只能看见哪些卡，那么就会只申请看见的卡。<br>通过以下代码指定：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"2"</span><span class="comment">#单GPU</span></span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"1,2"</span><span class="comment">#多GPU</span></span><br></pre></td></tr></table></figure><p><strong>注意：如果只指定能看见第2张卡，但是程序中，会给第2张卡编号的为0，即通过ctx=mx.gpu(0)来获取。如果指定能看见1和2卡，那么程序中会分别编号0和1。</strong></p></li><li><p>nni的配置文件config.yml</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">authorName:</span> <span class="string">wangbeibei</span></span><br><span class="line"><span class="attr">experimentName:</span> <span class="string">gru_grid_experiment</span></span><br><span class="line"><span class="comment">#并发尝试任务的最大数量，有1张gpu卡就是1，有2张gpu卡就是2</span></span><br><span class="line"><span class="attr">trialConcurrency:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">maxExecDuration:</span> <span class="number">100</span><span class="string">h</span></span><br><span class="line"><span class="comment">#Trial 任务的最大数量，成功和失败的都计算在内</span></span><br><span class="line"><span class="attr">maxTrialNum:</span> <span class="number">10</span></span><br><span class="line"><span class="comment">#choice: local, remote, pai,在虚拟环境和docker运行时，都写local</span></span><br><span class="line"><span class="attr">trainingServicePlatform:</span> <span class="string">local</span></span><br><span class="line"><span class="comment">#在第一步创建的json文件的路径，这里需要写相对路径，因为当前的yml文件和json文件在同一文件夹下</span></span><br><span class="line"><span class="attr">searchSpacePath:</span> <span class="string">lstm_search_space.json</span></span><br><span class="line"><span class="comment">#choice: true, false</span></span><br><span class="line"><span class="attr">useAnnotation:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># 存储日志和数据的目录, 默认值是 /data/WangBeibei/nni/experiments</span></span><br><span class="line"><span class="comment">#如果在虚拟环境中运行该代码，logDir是服务器下的绝对路径，/data/WangBeibei/graduation/Code/nni_save_logs</span></span><br><span class="line"><span class="comment">#如果在docker下运行该代码，logDir是容器下的绝对路径，/root/Code/nni_save_logs/</span></span><br><span class="line"><span class="attr">logDir:</span> <span class="string">/root/Code/nni_save_logs/</span></span><br><span class="line"><span class="attr">tuner:</span></span><br><span class="line">    <span class="comment">#choice: TPE, Random, Anneal, Evolution, BatchTuner, MetisTuner, GPTuner</span></span><br><span class="line">    <span class="comment">#SMAC (SMAC should be installed through nnictl)</span></span><br><span class="line"><span class="attr">    builtinTunerName:</span> <span class="string">TPE</span></span><br><span class="line"><span class="attr">    classArgs:</span></span><br><span class="line">        <span class="comment">#choice: maximize, minimize</span></span><br><span class="line">        <span class="comment">#mae、rmse、mse都是最小化</span></span><br><span class="line"><span class="attr">        optimize_mode:</span> <span class="string">minimize</span></span><br><span class="line"><span class="attr">trial:</span></span><br><span class="line"><span class="comment"># 指定了运行 Trial 进程的命令行</span></span><br><span class="line"><span class="attr">command:</span> <span class="string">cd</span> <span class="string">baseline</span> <span class="string">&amp;&amp;</span> <span class="string">python3</span> <span class="string">lstm_baseline.py</span></span><br><span class="line"><span class="comment">#指定了 Trial 代码文件的目录</span></span><br><span class="line"><span class="comment">#首先从yml目录下，进入到代码的根目录下</span></span><br><span class="line"><span class="attr">codeDir:</span> <span class="string">../</span></span><br><span class="line"><span class="comment">#指定需要使用</span></span><br><span class="line"><span class="attr">gpuNum:</span> <span class="number">1</span></span><br></pre></td></tr></table></figure></li><li><p>启动容器<br>nni网页的默认端口是8080，所以需要和本地映射一下，</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker run -it -p 7000:8080 -v $PWD:/root --runtime=nvidia --rm -u 1018 --name wbbnni lin-ai-27:5000/wangbeibei/mxnet:cu_100  </span><br><span class="line"></span><br><span class="line">docker run -it -p 7000:8080 -v $PWD:/root --runtime=nvidia --rm -u 1018 --name wbbnni lin-ai-27:5000/wangbeibei/pytorch_nni</span><br></pre></td></tr></table></figure></li><li><p>启动一个nni的experiment<br>进入到yml所在的目录，使用以下命令，启动一个experiment实例，然后就可以在网页上查看<br>使用<code>nnictl create --config config.yml</code><br>出现以下提示，说明启动成功。</p><p><img src="/2019/11/25/nni/create.png" alt=""></p></li><li><p>在网页上访问<br>在网页上打开<code>服务器ip:7000</code></p><p><img src="/2019/11/25/nni/success.png" alt=""></p></li><li><p>错误日志<br>如果提交的任务都失败了，可以去看日志文件。日志文件的位置在下图中。在容器中进入到下面的目录中。</p><p><img src="/2019/11/25/nni/error1.png" alt=""></p><p><img src="/2019/11/25/nni/error2.png" alt=""></p><p>在容器中进入到日志目录中，找到对应id的文件夹。</p><p><img src="/2019/11/25/nni/log.png" alt=""></p></li><li><p>成功日志<br>如果trial成功运行，那么关于这次trial的</p><p><img src="/2019/11/25/nni/success1.png" alt=""></p></li></ol><h1><span id="2-nni命令">2. NNI命令</span></h1><p><a href="https://github.com/microsoft/nni/blob/master/docs/zh_CN/Tutorial/Nnictl.md" target="_blank" rel="noopener">NNI命令参考文档</a></p><ol><li>nnictl create<br>（1）在默认端口8080上创建一个新的Experiment<br><code>nnictl create --config nni/examples/trials/mnist/config.yml</code><br>（2）在指定的端口上8088创建新的Experiment<br><code>nnictl create --config nni/examples/trials/mnist/config.yml --port 8088</code></li><li>nnictl stop<br>停止正在运行的单个或多个Experiment<br>（1）没有指定id，停止所有正在运行的Experiment<br><code>nnictl stop</code><br>（2）停止指定id的Experiment<br><code>nnictl stop [experiment_id]</code></li><li>nnictl update<br>更新 Experiment 的搜索空间，其中<code>experiment_id</code>是可选的参数，后面的<code>--filename</code>是必填的参数。<br>先使用vscode修改搜索空间的json文件，然后再使用下面的命令来更新搜索空间文件。<br><code>nnictl update searchspace [experiment_id] --filename examples/trials/mnist/search_space.json</code></li><li><p>nnictl view<br>如果使用stop结束调参程序，以后还想看一下网页上的调参结果，使用该命令。这个命令只是在前端展示调参的结果，调参程序不会再次启动。  </p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nnictl <span class="keyword">view</span> [<span class="keyword">OPTIONS</span>]</span><br><span class="line">其中experiment_id是必填的，port是选填的</span><br><span class="line">nnictl <span class="keyword">view</span> [experiment_id] <span class="comment">--port 8088</span></span><br></pre></td></tr></table></figure></li><li><p>nnictl top<br>查看正在运行的Experiment</p></li><li>nnictl experiment show<br>显示Experiment的信息</li><li>nnictl experiment status<br>显示Experiment的状态</li><li>nnictl experiment list<br>显示正在运行的Experiment的信息</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;NN是微软官方出的一个自动调参的第三方库。非常好用。但是用起来还是有一些需要注意的地方。这里记录一下。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="工具" scheme="http://yoursite.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="Docker" scheme="http://yoursite.com/tags/Docker/"/>
    
      <category term="NNI" scheme="http://yoursite.com/tags/NNI/"/>
    
  </entry>
  
  <entry>
    <title>Deep Learning for Spatio-Temporal Data Mining: A Survey</title>
    <link href="http://yoursite.com/2019/11/08/Deep-Learning-for-Spatio-Temporal-Data-Mining-A-Survey/"/>
    <id>http://yoursite.com/2019/11/08/Deep-Learning-for-Spatio-Temporal-Data-Mining-A-Survey/</id>
    <published>2019-11-08T07:49:36.000Z</published>
    <updated>2020-01-23T13:06:45.571Z</updated>
    
    <content type="html"><![CDATA[<p>&ensp;&ensp;&ensp;&ensp;<a href="https://arxiv.org/pdf/1906.04928.pdf" target="_blank" rel="noopener">Deep Learning for Spatio-Temporal Data Mining: A Survey</a><br>这篇论文是时空领域的综述论文，介绍了近几年时空领域的发展。<br><a id="more"></a></p><p>一些比较好的GitHub<br><a href="https://github.com/xuehaouwa/Awesome-Trajectory-Prediction" target="_blank" rel="noopener">https://github.com/xuehaouwa/Awesome-Trajectory-Prediction</a></p><h1><span id="引言">引言</span></h1><p>时空领域的数据的应用很广泛，包括环境和气候预测（风预测，降雨预测等），公共安全预测（crime预测），智能交通预测（交通流量预测），人类活动（人类轨迹模式挖掘）。本文将时空数据的类型，和广泛应用的深度学习模型，以及现有的研究进展.</p><h1><span id="时空数据分类">时空数据分类</span></h1><ol><li>Even data<br>事件数据由离散的事件组成，有location和time信息，例如cirme事件和traffic accident事件，疾病爆发事件，社会事件。</li><li>Trajectory data<br>轨迹数据是一系列随着时间变化的经纬度序列组成。有人的轨迹和车的轨迹。  </li><li>Point reference data<br>一般都是气象数据，测量一个区域的温度，植被等。  </li><li>Raster data（栅格数据）<br>有固定的m个区域，每个区域有n个时间段，可以用一个$R^{m \times n}$来表示。例如traffic flow数据。</li><li>Vedio data<br>视频数据和时空数据类似，相邻的像素可以表示相似的RGB，在时间上，特征变化平缓。可以用三维张量表示。  </li></ol><p>以上的5类数据可以用下图的方式表示。</p><p><img src="/2019/11/08/Deep-Learning-for-Spatio-Temporal-Data-Mining-A-Survey/stdata.png" alt=""></p><p>(1)轨迹和时间序列都可以表示成序列的形式。<br>(2)有时轨迹也可以表示成2维矩阵，矩阵的行和列是网格的长和宽，矩阵的值表示轨迹走的网格。这个表示形式通常使用CNN模型。例如：<a href="https://arxiv.org/pdf/1705.09436.pdf" target="_blank" rel="noopener">（2017NIPS）Human Trajectory Prediction using Spatially aware Deep Attention Models</a><br>(3)空间地图可以表示为Graph和2维矩阵。至于使用图还是2D矩阵根据应用而定。例如在城市交通流预测，交通网络中的交通数据使用Graph表示，例如<a href="https://arxiv.org/pdf/1707.01926.pdf" target="_blank" rel="noopener">(2018ICLR)Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting</a><br>(4)网格数据，通常使用2D或3D张量表示，如果是2D矩阵，行和列分别表示区域和时间。如果是3D张量，分别表示区域的行和列，时间。</p><p><img src="/2019/11/08/Deep-Learning-for-Spatio-Temporal-Data-Mining-A-Survey/model.png" alt=""><br>未完待续。。。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;&lt;a href=&quot;https://arxiv.org/pdf/1906.04928.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Deep Learning for Spatio-Temporal Data Mining: A Survey&lt;/a&gt;&lt;br&gt;这篇论文是时空领域的综述论文，介绍了近几年时空领域的发展。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="时空领域" scheme="http://yoursite.com/tags/%E6%97%B6%E7%A9%BA%E9%A2%86%E5%9F%9F/"/>
    
  </entry>
  
  <entry>
    <title>Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting</title>
    <link href="http://yoursite.com/2019/11/05/Enhancing-the-Locality-and-Breaking-the-Memory-Bottleneck-of-Transformer-on-Time-Series-Forecasting/"/>
    <id>http://yoursite.com/2019/11/05/Enhancing-the-Locality-and-Breaking-the-Memory-Bottleneck-of-Transformer-on-Time-Series-Forecasting/</id>
    <published>2019-11-05T01:34:39.000Z</published>
    <updated>2020-01-23T13:07:00.196Z</updated>
    
    <content type="html"><![CDATA[<p>2019NIPS的一篇论文，<br><a href="https://arxiv.org/pdf/1907.00235.pdf" target="_blank" rel="noopener">论文地址</a><br><a id="more"></a><br><!-- TOC --></p><ul><li><a href="#1-introduction">1. Introduction</a></li><li><a href="#2-%e6%a8%a1%e5%9e%8b">2. 模型</a></li></ul><!-- /TOC --><h1><span id="1-introduction">1. Introduction</span></h1><p>本文说Transformer有2个缺点，（1）locality-agnostics：局部不可知性，原先只针对一个点，计算该点和其余所有点的相关性，没有考虑到子序列和子序列的attention。（2）memory bottleneck：内存瓶颈，空间复杂度和输入序列的长度L有关。对于捕获长时间序列不方便。</p><h1><span id="2-模型">2. 模型</span></h1><p>本文针对以上2个问题，提出2种解决方案，（1）传统Transformer—&gt;Conv Transformer,（2）使用LogSparse来减少内存的使用。</p><p><img src="/2019/11/05/Enhancing-the-Locality-and-Breaking-the-Memory-Bottleneck-of-Transformer-on-Time-Series-Forecasting/conv.png" alt=""></p><p>图b是传统的Transformer，在计算Attention时，计算的是一个点和其余所有点的Attention，在本文中使用一维卷积来生成query和key，在计算Attention时，使用的是子序列之间的Attention，捕获了local上下文信息。</p><p><img src="/2019/11/05/Enhancing-the-Locality-and-Breaking-the-Memory-Bottleneck-of-Transformer-on-Time-Series-Forecasting/log.png" alt=""></p><p>在传统Transformer在计算Atterntion时，使用的因果卷积，在第t步捕获前面所有历史时间步的信息，但是这样空间复杂度较大。所以本文提出了LogSparse，即在计算Attention时，对历史时间步的信息使用log函数进行抽样，然后多堆叠几层，也可以捕获前面所有时间步的信息。减少了空间复杂度，又可以捕获历史时间步的所有信息。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;2019NIPS的一篇论文，&lt;br&gt;&lt;a href=&quot;https://arxiv.org/pdf/1907.00235.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文地址&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
      <category term="Time Series" scheme="http://yoursite.com/tags/Time-Series/"/>
    
      <category term="Transformer" scheme="http://yoursite.com/tags/Transformer/"/>
    
  </entry>
  
  <entry>
    <title>DGL</title>
    <link href="http://yoursite.com/2019/11/04/DGL/"/>
    <id>http://yoursite.com/2019/11/04/DGL/</id>
    <published>2019-11-04T06:19:34.000Z</published>
    <updated>2020-01-23T13:06:52.671Z</updated>
    
    <content type="html"><![CDATA[<p>&ensp;&ensp;&ensp;&ensp;Deep Graph Library(DGL),一款面向图神经网络以及图机器学习的全新框架。DGL基于主流框架进行开发。用户可以使用他们偏爱的框架编写常见的CNN和注意力层，而当遇到图相关的计算时可以切换到DGL。用户和DGL的交互主要通过自定义函数UDF（user-defined function）。目前DGL支持Pytorch和MXNet/Gluon作为系统后端。<br><a id="more"></a><br><!-- TOC --></p><ul><li><a href="#1-dgl">1. DGL</a></li><li><a href="#2-%e5%87%bd%e6%95%b0%e4%bb%8b%e7%bb%8d">2. 函数介绍</a><ul><li><a href="#21-%e5%88%9b%e5%bb%ba%e5%9b%be">2.1. 创建图</a></li><li><a href="#22-%e8%8e%b7%e5%8f%96%e8%8a%82%e7%82%b9%e5%92%8c%e8%be%b9%e7%9a%84%e4%b8%aa%e6%95%b0">2.2. 获取节点和边的个数</a></li><li><a href="#23-%e5%88%86%e9%85%8d%e8%8a%82%e7%82%b9%e5%92%8c%e8%be%b9%e7%9a%84%e7%89%b9%e5%be%81">2.3. 分配节点和边的特征</a></li><li><a href="#24-%e5%88%a0%e9%99%a4%e8%8a%82%e7%82%b9%e5%92%8c%e8%be%b9%e7%89%b9%e5%be%81">2.4. 删除节点和边特征</a></li><li><a href="#25-%e8%87%aa%e5%ae%9a%e4%b9%89message%e5%87%bd%e6%95%b0">2.5. 自定义message函数</a></li><li><a href="#26-%e8%87%aa%e5%ae%9a%e4%b9%89reduce%e5%87%bd%e6%95%b0">2.6. 自定义reduce函数</a></li><li><a href="#27-%e6%b3%a8%e5%86%8cmessage%e5%92%8creduce%e5%87%bd%e6%95%b0">2.7. 注册message和reduce函数</a></li><li><a href="#28-updateall%e6%9b%b4%e6%96%b0%e8%8a%82%e7%82%b9%e7%89%b9%e5%be%81">2.8. update_all更新节点特征</a></li><li><a href="#29-%e9%ab%98%e7%ba%a7%e7%94%a8%e6%b3%95">2.9. 高级用法</a></li></ul></li></ul><!-- /TOC --><p><a href="https://archwalker.github.io/blog/2019/07/07/GNN-Framework-DGL-GCN.html" target="_blank" rel="noopener">GNN 教程：DGL框架-消息和GCN的实现</a>     </p><h1><span id="1-dgl">1. DGL</span></h1><p>DGL是基于<strong>消息传递message passing</strong>的编程模型。原因在于图上的计算往往可以表示为2步：</p><ol><li>发送节点：根据自身的特征计算需要向外分发的消息。</li><li>接收节点：对收到的消息进行累加并更新自身的特征。<br>用户需要自定义<strong>消息分发函数</strong>和<strong>消息聚合函数</strong>，来构造新的模型。</li></ol><ul><li>消息分发函数（message function）：将结点自身的消息传递传递给其邻居。因为对每条边来说，每个源节点将会将自身的Embedding(e.src.data)和边的Embedding(edge.data)传递给目的节点。对于每个目的节点来说，它可能会收到多个源节点传过来的消息，它会将这些消息存储在mailbox中。</li><li>消息聚合函数（reduce function）：聚合函数的目的是根据邻居传过来的消息更新自身节点Embedding，对每个节点来说，它先从邮箱(v.mailbox[‘m’])中汇聚消息函数所传递过来的消息(message)，并清空邮箱(v.mailbox[‘m’])内的消息；然后该节点结合汇聚后的结果和该节点原Embedding，更新节点Embedding。</li></ul><p><img src="/2019/11/04/DGL/dgl.png" alt=""></p><p>GCN的公式如下所示：</p><p><img src="/2019/11/04/DGL/gcn.png" alt=""></p><p>上面的数学描述可以利用<strong>消息传递</strong>的机制实现：<br>（1）在GCN中，每个节点都有属于自己的表示$h_i$<br>（2）根据消息传递（message passing），每个节点将会收到邻居节点发来的Embedding<br>（3）每个节点将聚合邻居节点的Embedding，得到中间表示$\hat{h_i}$<br>（4）对中间节点表示$\hat{h_i}$进行线性变换，然后利用非线性函数$f$进行计算：$h^{new}_u = f(W_u\hat{h}_u)$<br>（5）利用新的节点表示$h^{new}_u$对该节点的表示$h_u$进行更新。</p><h1><span id="2-函数介绍">2. 函数介绍</span></h1><p><a href="https://docs.dgl.ai/en/latest/api/python/graph.html" target="_blank" rel="noopener">官方文档</a><br><a href="https://docs.dgl.ai/en/latest/tutorials/basics/1_first.html" target="_blank" rel="noopener">实现GCN例子</a></p><h2><span id="21-创建图">2.1. 创建图</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line">g = dgl.DGLGraph()</span><br><span class="line"><span class="comment">#为图添加节点和边</span></span><br><span class="line">g.add_node(<span class="number">34</span>)<span class="comment">#添加34个节点</span></span><br><span class="line"><span class="comment">#一共有78条边</span></span><br><span class="line">edge_list = [(<span class="number">1</span>, <span class="number">0</span>), (<span class="number">2</span>, <span class="number">0</span>), (<span class="number">2</span>, <span class="number">1</span>), (<span class="number">3</span>, <span class="number">0</span>), (<span class="number">3</span>, <span class="number">1</span>), (<span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">        (<span class="number">4</span>, <span class="number">0</span>), (<span class="number">5</span>, <span class="number">0</span>), (<span class="number">6</span>, <span class="number">0</span>), (<span class="number">6</span>, <span class="number">4</span>), (<span class="number">6</span>, <span class="number">5</span>), (<span class="number">7</span>, <span class="number">0</span>), (<span class="number">7</span>, <span class="number">1</span>),</span><br><span class="line">        (<span class="number">7</span>, <span class="number">2</span>), (<span class="number">7</span>, <span class="number">3</span>), (<span class="number">8</span>, <span class="number">0</span>), (<span class="number">8</span>, <span class="number">2</span>), (<span class="number">9</span>, <span class="number">2</span>), (<span class="number">10</span>, <span class="number">0</span>), (<span class="number">10</span>, <span class="number">4</span>),</span><br><span class="line">        (<span class="number">10</span>, <span class="number">5</span>), (<span class="number">11</span>, <span class="number">0</span>), (<span class="number">12</span>, <span class="number">0</span>), (<span class="number">12</span>, <span class="number">3</span>), (<span class="number">13</span>, <span class="number">0</span>), (<span class="number">13</span>, <span class="number">1</span>), (<span class="number">13</span>, <span class="number">2</span>),</span><br><span class="line">        (<span class="number">13</span>, <span class="number">3</span>), (<span class="number">16</span>, <span class="number">5</span>), (<span class="number">16</span>, <span class="number">6</span>), (<span class="number">17</span>, <span class="number">0</span>), (<span class="number">17</span>, <span class="number">1</span>), (<span class="number">19</span>, <span class="number">0</span>), (<span class="number">19</span>, <span class="number">1</span>),</span><br><span class="line">        (<span class="number">21</span>, <span class="number">0</span>), (<span class="number">21</span>, <span class="number">1</span>), (<span class="number">25</span>, <span class="number">23</span>), (<span class="number">25</span>, <span class="number">24</span>), (<span class="number">27</span>, <span class="number">2</span>), (<span class="number">27</span>, <span class="number">23</span>),</span><br><span class="line">        (<span class="number">27</span>, <span class="number">24</span>), (<span class="number">28</span>, <span class="number">2</span>), (<span class="number">29</span>, <span class="number">23</span>), (<span class="number">29</span>, <span class="number">26</span>), (<span class="number">30</span>, <span class="number">1</span>), (<span class="number">30</span>, <span class="number">8</span>),</span><br><span class="line">        (<span class="number">31</span>, <span class="number">0</span>), (<span class="number">31</span>, <span class="number">24</span>), (<span class="number">31</span>, <span class="number">25</span>), (<span class="number">31</span>, <span class="number">28</span>), (<span class="number">32</span>, <span class="number">2</span>), (<span class="number">32</span>, <span class="number">8</span>),</span><br><span class="line">        (<span class="number">32</span>, <span class="number">14</span>), (<span class="number">32</span>, <span class="number">15</span>), (<span class="number">32</span>, <span class="number">18</span>), (<span class="number">32</span>, <span class="number">20</span>), (<span class="number">32</span>, <span class="number">22</span>), (<span class="number">32</span>, <span class="number">23</span>),</span><br><span class="line">        (<span class="number">32</span>, <span class="number">29</span>), (<span class="number">32</span>, <span class="number">30</span>), (<span class="number">32</span>, <span class="number">31</span>), (<span class="number">33</span>, <span class="number">8</span>), (<span class="number">33</span>, <span class="number">9</span>), (<span class="number">33</span>, <span class="number">13</span>),</span><br><span class="line">        (<span class="number">33</span>, <span class="number">14</span>), (<span class="number">33</span>, <span class="number">15</span>), (<span class="number">33</span>, <span class="number">18</span>), (<span class="number">33</span>, <span class="number">19</span>), (<span class="number">33</span>, <span class="number">20</span>), (<span class="number">33</span>, <span class="number">22</span>),</span><br><span class="line">        (<span class="number">33</span>, <span class="number">23</span>), (<span class="number">33</span>, <span class="number">26</span>), (<span class="number">33</span>, <span class="number">27</span>), (<span class="number">33</span>, <span class="number">28</span>), (<span class="number">33</span>, <span class="number">29</span>), (<span class="number">33</span>, <span class="number">30</span>),</span><br><span class="line">        (<span class="number">33</span>, <span class="number">31</span>), (<span class="number">33</span>, <span class="number">32</span>)]</span><br><span class="line"><span class="comment">#添加边的源节点和目的节点  </span></span><br><span class="line">drc,dst = tuple(zip(*edge_list))</span><br><span class="line">g.add_edges(src,dst)</span><br><span class="line"><span class="comment">#边是双向的</span></span><br><span class="line">g.add_edges(dst,src)</span><br></pre></td></tr></table></figure><h2><span id="22-获取节点和边的个数">2.2. 获取节点和边的个数</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看节点和边个数</span></span><br><span class="line">g.number_of_nodes()</span><br><span class="line">g.number_of_edges()  </span><br><span class="line"></span><br><span class="line"><span class="comment">#查看节点和边类型</span></span><br><span class="line">g.node_attr_schemes()</span><br></pre></td></tr></table></figure><h2><span id="23-分配节点和边的特征">2.3. 分配节点和边的特征</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch  </span><br><span class="line"><span class="comment">#分配节点特征</span></span><br><span class="line">g.ndata[<span class="string">'feature'</span>] = torch.eye(<span class="number">34</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取某个节点的特征  </span></span><br><span class="line">G.nodes[<span class="number">2</span>].data[<span class="string">'feature'</span>]</span><br><span class="line">G.nodes[[<span class="number">10</span>,<span class="number">11</span>]].data[<span class="string">'feature'</span>]  </span><br><span class="line"></span><br><span class="line"><span class="comment">#分配边特征,9条边，每条边特征有2个</span></span><br><span class="line">g.edata[<span class="string">'edge_feature'</span>] = torch.randn(<span class="number">9</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#单独为每条边赋值</span></span><br><span class="line">g.edata[<span class="number">1</span>].data[<span class="string">'edge_feature'</span>] = torch.randn(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">g.edata[[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]].data[<span class="string">'edge_feature'</span>] = torch.randn(<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line"><span class="comment">#同时指定起点和终点</span></span><br><span class="line">g.edata[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]].data[<span class="string">'edge_feature'</span>] = torch.randn(<span class="number">3</span>,<span class="number">2</span>)  </span><br><span class="line"></span><br><span class="line"><span class="comment">#查看图的节点特征和边特征</span></span><br><span class="line">g.ndata,g.edata</span><br></pre></td></tr></table></figure><h2><span id="24-删除节点和边特征">2.4. 删除节点和边特征</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">g.ndata.pop(<span class="string">'feature'</span>)</span><br><span class="line">g.edata.pop(<span class="string">'edge_feature'</span>)</span><br></pre></td></tr></table></figure><h2><span id="25-自定义message函数">2.5. 自定义message函数</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">message_func</span><span class="params">(edges)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    在该函数中，接收一个参数edges，edges有3个成员变量：</span></span><br><span class="line"><span class="string">    edges.src:获取源节点</span></span><br><span class="line"><span class="string">    edges.dst:获取目的节点</span></span><br><span class="line"><span class="string">    edges.data:获取边</span></span><br><span class="line"><span class="string">    主要是向目的节点传递消息，返回的格式是dict</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> &#123; <span class="string">'alpha'</span>: alpha, <span class="string">'state'</span>: edge.src[<span class="string">'state'</span>] &#125;</span><br></pre></td></tr></table></figure><h2><span id="26-自定义reduce函数">2.6. 自定义reduce函数</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduce_func</span><span class="params">(nodes)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    源节点通过message函数，将消息发送给目的节点，目的节点接收多个邻居发来的消息，并存储在mailbox中，reduce函数聚合多个邻居发来的消息,并以dict的形式返回。</span></span><br><span class="line"><span class="string">    reduce函数，接收一个参数nodes，nodes有2个成员变量</span></span><br><span class="line"><span class="string">    nodes.data:获取节点的特征</span></span><br><span class="line"><span class="string">    nodes.mailbox:获取message函数返回的值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    state = nodes.mailbox[<span class="string">'state'</span>]</span><br><span class="line">    alpha = nodes.mailbox[<span class="string">'alpha'</span>]</span><br><span class="line">    alpha = nd.softmax(alpha, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    new_state = nd.relu(nd.sum(alpha * state, axis=<span class="number">1</span>))  </span><br><span class="line">    <span class="keyword">return</span> &#123; <span class="string">'new_state'</span>: new_state &#125;</span><br></pre></td></tr></table></figure><h2><span id="27-注册message和reduce函数">2.7. 注册message和reduce函数</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#自定了message和reduce函数，在graph中注册，以便后续使用 </span></span><br><span class="line">g.register_message_func(message_func)</span><br><span class="line">g.register_reduce_func(reduce_func)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pagerank_batch</span><span class="params">(g)</span>:</span></span><br><span class="line">    g.send(g.edges())</span><br><span class="line">    g.recv(g.nodes())</span><br><span class="line"></span><br><span class="line">    <span class="comment">#如果没有将自定义的message和reduce函数注册，使用以下语句</span></span><br><span class="line">    g.send(g.edges(),message_func)</span><br><span class="line">    g.recv(g.nodes(),reduce_func)</span><br></pre></td></tr></table></figure><h2><span id="28-update_all更新节点特征">2.8. update_all更新节点特征</span></h2><p>该方法是上面方法的高级版本<br><code>DGLGraph.update_all(message_func=&#39;default&#39;, reduce_func=&#39;default&#39;, apply_node_func=&#39;default&#39;)</code><br>传入的参数是message函数名，reduce函数名，UDF函数名,如果不传入，使用默认值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pagerank_level2</span><span class="params">(g)</span>:</span></span><br><span class="line">    <span class="comment"># g.update_all()</span></span><br><span class="line">    g.update_all(self.message_func,self.reduce_func)</span><br></pre></td></tr></table></figure><h2><span id="29-高级用法">2.9. 高级用法</span></h2><p><a href="https://docs.dgl.ai/en/latest/tutorials/basics/3_pagerank.html" target="_blank" rel="noopener">PageRank实现</a></p><ul><li><p><code>dgl.function.copy_src(src, out)</code>:需要指定源节点的名称，和message的key值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line">message_func = dgl.function.copy_src(<span class="string">'feature'</span>, <span class="string">'state'</span>)</span><br><span class="line">等价于  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">message_func</span><span class="params">(edges)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'state'</span>: edges.src[<span class="string">'feature'</span>]&#125;</span><br></pre></td></tr></table></figure></li><li><p><code>dgl.function.sum(msg, out)</code>:用于对目的节点的mailbox进行求和，需要指定message的key值和输出的名称。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line">reduce_func = dgl.function.sum(<span class="string">'state'</span>, <span class="string">'new_state'</span>)</span><br><span class="line">等价于</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduce_func</span><span class="params">(nodes)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'new_state'</span>: torch.sum(nodes.mailbox[<span class="string">'state'</span>], dim=<span class="number">1</span>)&#125;</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl.function <span class="keyword">as</span> fn</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pagerank_builtin</span><span class="params">(g)</span>:</span></span><br><span class="line">    N = <span class="number">100</span>  <span class="comment"># number of nodes</span></span><br><span class="line">    DAMP = <span class="number">0.85</span>  <span class="comment"># damping factor</span></span><br><span class="line">    g.ndata[<span class="string">'pv'</span>] = g.ndata[<span class="string">'pv'</span>] / g.ndata[<span class="string">'deg'</span>]</span><br><span class="line">    g.update_all(message_func=fn.copy_src(src=<span class="string">'pv'</span>, out=<span class="string">'m'</span>,</span><br><span class="line">                reduce_func=fn.sum(msg=<span class="string">'m'</span>,out=<span class="string">'m_sum'</span>))</span><br><span class="line">    g.ndata[<span class="string">'pv'</span>] = (<span class="number">1</span> - DAMP) / N + DAMP * g.ndata[<span class="string">'m_sum'</span>]</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;Deep Graph Library(DGL),一款面向图神经网络以及图机器学习的全新框架。DGL基于主流框架进行开发。用户可以使用他们偏爱的框架编写常见的CNN和注意力层，而当遇到图相关的计算时可以切换到DGL。用户和DGL的交互主要通过自定义函数UDF（user-defined function）。目前DGL支持Pytorch和MXNet/Gluon作为系统后端。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Deep Learning" scheme="http://yoursite.com/categories/Deep-Learning/"/>
    
    
      <category term="GCN" scheme="http://yoursite.com/tags/GCN/"/>
    
      <category term="DGL" scheme="http://yoursite.com/tags/DGL/"/>
    
  </entry>
  
  <entry>
    <title>XGBoost</title>
    <link href="http://yoursite.com/2019/11/02/XGBoost/"/>
    <id>http://yoursite.com/2019/11/02/XGBoost/</id>
    <published>2019-11-02T07:28:18.000Z</published>
    <updated>2020-01-23T13:08:57.974Z</updated>
    
    <content type="html"><![CDATA[<p>&ensp;&ensp;&ensp;&ensp;最近使用XGBoost做一个二分类的任务。记录XGBoost的主要参数和调参过程。<br><a id="more"></a></p><!-- TOC --><ul><li><a href="#1-xgboost">1. XGBoost</a><ul><li><a href="#11-xgboost%e7%9a%84%e4%bc%98%e5%8a%bf">1.1. XGBoost的优势</a></li><li><a href="#12-%e5%8f%82%e6%95%b0">1.2. 参数</a></li><li><a href="#13-%e8%b0%83%e5%8f%82">1.3. 调参</a></li></ul></li></ul><!-- /TOC --><h1><span id="1-xgboost">1. XGBoost</span></h1><p>&ensp;&ensp;&ensp;&ensp;XGBoost是一种十分精致的算法，可以处理各种不规则的数据。<br>构造一个使用XGBoost的模型十分简单。但是，提高这个模型的表现就有些困难，因为涉及到很多参数。所以为了提高模型的表现，参数的调整十分必要。</p><h2><span id="11-xgboost的优势">1.1. XGBoost的优势</span></h2><ul><li>正则化<br>正则化防止过拟合，实际上，XGBoost以“正则化提升(regularized boosting)”技术而闻名。</li><li>缺失值处理<br>XGBoost内置处理缺失值的规则。XGBoost在不同节点遇到缺失值时采用不同的处理方法，并且会学习未来遇到缺失值的处理方法</li></ul><h2><span id="12-参数">1.2. 参数</span></h2><p>&ensp;&ensp;&ensp;&ensp;XGBoost实际上是很多CART树堆叠起来。传入的特征可以含有None值。XGBoost有很多参数，使用GridSearchCV进行网格搜索时比较耗时。  </p><p>使用pip install xgboost安装</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">XGBClassifier(</span><br><span class="line">        base_score=<span class="number">0.5</span>, </span><br><span class="line">        booster=<span class="string">'gbtree'</span>, </span><br><span class="line">        colsample_bylevel=<span class="number">1</span>,</span><br><span class="line">        colsample_bytree=<span class="number">1</span>, </span><br><span class="line">        gamma=<span class="number">0</span>, </span><br><span class="line">        learning_rate=<span class="number">1</span>, </span><br><span class="line">        max_delta_step=<span class="number">0</span>,</span><br><span class="line">        max_depth=<span class="number">2</span>, </span><br><span class="line">        min_child_weight=<span class="number">1</span>, </span><br><span class="line">        missing=<span class="keyword">None</span>, </span><br><span class="line">        n_estimators=<span class="number">2</span>,</span><br><span class="line">        n_jobs=<span class="number">1</span>, </span><br><span class="line">        nthread=<span class="keyword">None</span>, objective=<span class="string">'binary:logistic'</span>, random_state=<span class="number">0</span>,</span><br><span class="line">        reg_alpha=<span class="number">0</span>, </span><br><span class="line">        reg_lambda=<span class="number">1</span>, </span><br><span class="line">        scale_pos_weight=<span class="number">1</span>, </span><br><span class="line">        seed=<span class="keyword">None</span>,</span><br><span class="line">        silent=<span class="keyword">True</span>, </span><br><span class="line">        subsample=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>XGBoost参数有3类：<br><a href="https://www.cnblogs.com/wanglei5205/p/8579244.html" target="_blank" rel="noopener">https://www.cnblogs.com/wanglei5205/p/8579244.html</a><br>（1）通用类别：不需要调整，默认就好：</p><ul><li>booster：[默认gbtree]<br>选择每次迭代的模型，有两种选择：<br>gbtree：基于树的模型<br>gbliner：线性模型</li><li>silent[默认0]<br>当这个参数值为1时，静默模式开启，不会输出任何信息。<br>一般这个参数就保持默认的0，因为这样能帮我们更好地理解模型。</li><li>nthread[默认值为最大可能的线程数]<br>这个参数用来进行多线程控制，应当输入系统的核数。<br>如果你希望使用CPU全部的核，那就不要输入这个参数，算法会自动检测它。</li></ul><p>（2）学习目标参数：与任务有关</p><ul><li>objective:损失函数，支持分类/回归<br>[默认reg:linear]，这个参数定义需要被最小化的损失函数。最常用的值有：<br>binary:logistic 二分类的逻辑回归，返回预测的概率(不是类别)。<br>multi:softmax 使用softmax的多分类器，返回预测的类别(不是概率)。<br>在这种情况下，你还需要多设一个参数：num_class(类别数目)。<br>multi:softprob 和multi:softmax参数一样，但是返回的是每个数据属于各个类别的概率。</li><li><p>eval_metric：评价函数，对于回归问题，默认值是rmse，对于分类问题，默认值是error。<br>典型值有：<br>rmse 均方根误差<br>logloss 负对数似然函数值<br>error 二分类错误率(阈值为0.5)<br>merror 多分类错误率<br>mlogloss 多分类logloss损失函数<br>auc 曲线下面积</p></li><li><p>seed：随机数的种子，默认为0<br>设置它可以复现随机数据的结果，也可以用于调整参数</p></li></ul><p>（3）booster参数：弱学习器参数，需要仔细调整，会影响模型性能<br>学习率和n_estimators具有相反的关系，建议学习率设小，通过交叉验证确定n_estimators</p><ul><li>eta[默认0.3]，和GBM中的 learning rate 参数类似。 通过减少每一步的权重，可以提高模型的鲁棒性。 典型值为0.01-0.2。</li></ul><p><strong>和树有关的参数</strong></p><ul><li>min_child_weight[默认1]，最小样本权重的和，用于避免过拟合。但是如果这个值过高，会导致欠拟合。这个参数需要使用CV来调整。</li><li>max_depth[默认6]，树的最大深度。 用来避免过拟合的。max_depth越大，模型越复杂，学到更具体更局部的样本。 需要使用CV函数来进行调优。 典型值：3-10</li><li>gamma[默认0]，Gamma指定了节点分裂所需的最小损失函数下降值。这个参数的值越大，算法越保守。这个参数的值和损失函数息息相关，所以是需要调整的。   </li><li>subsample[默认1]<br>和GBM中的subsample参数一模一样。这个参数控制对于每棵树，随机采样的比例。减小这个参数的值，算法会更加保守，避免过拟合。但是，如果这个值设置得过小，它可能会导致欠拟合。<br>典型值：0.5-1  </li><li>colsample_bytree[默认1]<br>和GBM里面的max_features参数类似。用来控制每棵随机采样的列数的占比(每一列是一个特征)。<br>典型值：0.5-1  </li></ul><p><strong>和正则化有关的参数</strong></p><ul><li>lambda[默认1]<br>权重的L2正则化项。(和Ridge regression类似)。<br>这个参数是用来控制XGBoost的正则化部分的。虽然大部分数据科学家很少用到这个参数，但是这个参数在减少过拟合上还是可以挖掘出更多用处的。  </li><li><p>alpha[默认1]<br>权重的L1正则化项。(和Lasso regression类似)。<br>可以应用在很高维度的情况下，使得算法的速度更快。<br><strong>样本不均衡</strong></p></li><li><p>scale_pos_weight[默认1]<br>正样本占的比重，为1时表示正负样例比重是一样的。当正样本较少时，正样本:负样本=1:9，将scale_pos_weight设置为9，scale_pos_weight=负样本个数/正样本个数。在各类别样本十分不平衡时，把这个参数设定为一个正值，可以使算法更快收敛。</p></li></ul><h2><span id="13-调参">1.3. 调参</span></h2><ol><li>先给定一个较高的学习率(learning rate)，一般情况下，学习率为0.1，但是对于不同的问题，理想的学习率在0.05~0.3之间波动。先调节决策树的数量n_estimators</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display</span><br><span class="line"></span><br><span class="line">cv_params = &#123;<span class="string">'n_estimators'</span>: [<span class="number">20</span>,<span class="number">40</span>, <span class="number">60</span>, <span class="number">80</span>]&#125;</span><br><span class="line">other_params = &#123;<span class="string">'learning_rate'</span>: <span class="number">0.1</span>, <span class="string">'n_estimators'</span>: <span class="number">500</span>, <span class="string">'max_depth'</span>: <span class="number">5</span>, <span class="string">'min_child_weight'</span>: <span class="number">1</span>, </span><br><span class="line">                <span class="string">'seed'</span>: <span class="number">0</span>,<span class="string">'subsample'</span>: <span class="number">0.8</span>, <span class="string">'colsample_bytree'</span>: <span class="number">0.8</span>, <span class="string">'gamma'</span>: <span class="number">0</span>, <span class="string">'reg_alpha'</span>: <span class="number">0</span>,</span><br><span class="line">                <span class="string">'reg_lambda'</span>: <span class="number">1</span>,<span class="string">'scale_pos_weight'</span>:<span class="number">1</span>,<span class="string">'objective'</span>:<span class="string">'binary:logistic'</span>&#125;</span><br><span class="line">model = XGBClassifier(**other_params)</span><br><span class="line">optimized_GBM = GridSearchCV(estimator=model, param_grid=cv_params, scoring=<span class="string">'accuracy'</span>, cv=<span class="number">5</span>,verbose=<span class="number">1</span>, n_jobs=<span class="number">4</span>)</span><br><span class="line">optimized_GBM.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'参数的最佳取值：&#123;0&#125;'</span>.format(optimized_GBM.best_params_))</span><br><span class="line">print(<span class="string">'最佳模型得分:&#123;0&#125;'</span>.format(optimized_GBM.best_score_))</span><br><span class="line">display(pd.DataFrame(optimized_GBM.cv_results_).T)</span><br></pre></td></tr></table></figure><ol><li>在给定的learning rate和n_eatimators情况下，对决策树特定参数调优(max_depth,min_child_weight,gamma,subsample,colsample_bytree) </li><li>max_depth和min_child_weight参数调优</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cv_params = &#123;<span class="string">'max_depth'</span>: list(range(<span class="number">3</span>,<span class="number">10</span>,<span class="number">2</span>)), <span class="string">'min_child_weight'</span>: list(range(<span class="number">1</span>,<span class="number">7</span>,<span class="number">1</span>))&#125;</span><br><span class="line">other_params = &#123;<span class="string">'learning_rate'</span>: <span class="number">0.1</span>, <span class="string">'n_estimators'</span>: <span class="number">60</span>, <span class="string">'max_depth'</span>: <span class="number">5</span>, <span class="string">'min_child_weight'</span>: <span class="number">1</span>, </span><br><span class="line">                <span class="string">'seed'</span>: <span class="number">0</span>,<span class="string">'subsample'</span>: <span class="number">0.8</span>, <span class="string">'colsample_bytree'</span>: <span class="number">0.8</span>, <span class="string">'gamma'</span>: <span class="number">0</span>, <span class="string">'reg_alpha'</span>: <span class="number">0</span>,</span><br><span class="line">                <span class="string">'reg_lambda'</span>: <span class="number">1</span>,<span class="string">'scale_pos_weight'</span>:<span class="number">1</span>,<span class="string">'objective'</span>:<span class="string">'binary:logistic'</span>&#125;</span><br></pre></td></tr></table></figure><ol><li><p>gamma参数调优<br>Gamma参数取值范围可以很大，我这里把取值范围设置为5了。你其实也可以取更精确的gamma值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cv_params = &#123;<span class="string">'gamma'</span>: [<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.5</span>, <span class="number">0.6</span>]&#125;</span><br><span class="line">other_params = &#123;<span class="string">'learning_rate'</span>: <span class="number">0.1</span>, <span class="string">'n_estimators'</span>: <span class="number">350</span>, <span class="string">'max_depth'</span>: <span class="number">3</span>, <span class="string">'min_child_weight'</span>: <span class="number">5</span>, </span><br><span class="line">              <span class="string">'seed'</span>: <span class="number">0</span>,<span class="string">'subsample'</span>: <span class="number">0.8</span>, <span class="string">'colsample_bytree'</span>: <span class="number">0.8</span>, <span class="string">'gamma'</span>: <span class="number">0</span>, <span class="string">'reg_alpha'</span>: <span class="number">0</span>,</span><br><span class="line">              <span class="string">'reg_lambda'</span>: <span class="number">1</span>,<span class="string">'objective'</span>:<span class="string">'binary:logistic'</span>&#125;</span><br></pre></td></tr></table></figure></li><li><p>subsamplehe colsample_bytree参数,相当于每个树的样本和特征个数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> cv_params = &#123;  </span><br><span class="line">  <span class="string">'subsample'</span>: [i / <span class="number">10.0</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6</span>, <span class="number">10</span>)],  </span><br><span class="line">  <span class="string">'colsample_bytree'</span>: [i / <span class="number">10.0</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6</span>, <span class="number">10</span>)]  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>正则化参数调优<br>下一步应用正则化来降低过拟合。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv_params = &#123;<span class="string">'reg_alpha'</span>: [<span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], <span class="string">'reg_lambda'</span>: [<span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]&#125;</span><br></pre></td></tr></table></figure></li><li><p>学习率调优<br>最后使用较低的学习率</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;最近使用XGBoost做一个二分类的任务。记录XGBoost的主要参数和调参过程。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://yoursite.com/categories/Machine-Learning/"/>
    
    
      <category term="XGBoost" scheme="http://yoursite.com/tags/XGBoost/"/>
    
  </entry>
  
  <entry>
    <title>Transformer</title>
    <link href="http://yoursite.com/2019/11/02/Transformer/"/>
    <id>http://yoursite.com/2019/11/02/Transformer/</id>
    <published>2019-11-02T07:09:45.000Z</published>
    <updated>2020-03-03T07:40:53.105Z</updated>
    
    <content type="html"><![CDATA[<p>&ensp;&ensp;&ensp;&ensp;《Attention is all you need》是Google Brain在2017年发表在NIPS的一篇文章。虽然在这篇文章之前，也在用Attention，但在这篇文章中，正式提出了Attention的概念，从此Attention在各个领域得到了广泛的应用。</p><p><a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank" rel="noopener">论文地址</a>  </p><p><a href="https://zhuanlan.zhihu.com/p/102591791" target="_blank" rel="noopener">你应该知道的transformer</a></p><a id="more"></a><!-- TOC --><ul><li><a href="#1-transformer%e8%ae%b2%e8%a7%a31">1. Transformer讲解1</a><ul><li><a href="#11-%e4%bd%8d%e7%bd%ae%e5%b5%8c%e5%85%a5">1.1. 位置嵌入</a></li><li><a href="#12-self-attention">1.2. self-attention</a></li><li><a href="#13-%e6%ae%8b%e5%b7%ae%e8%bf%9e%e6%8e%a5%e5%92%8clayernorm">1.3. 残差连接和LayerNorm</a></li><li><a href="#14-transformer%e7%9a%84%e6%95%b4%e4%bd%93%e7%bb%93%e6%9e%84">1.4. transformer的整体结构</a></li></ul></li><li><a href="#2-tramsformer%e8%ae%b2%e8%a7%a32">2. Tramsformer讲解2</a><ul><li><a href="#21-multi-head">2.1. multi-head</a></li></ul></li><li><a href="#%e4%bc%98%e7%bc%ba%e7%82%b9">优缺点</a></li><li><a href="#pytorch%e7%89%88transformer">Pytorch版Transformer</a></li></ul><!-- /TOC --><p><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650411699&amp;idx=3&amp;sn=83286bfa620ebe7297759fb78c31286c&amp;chksm=becd94e989ba1dff4f933b69d5c74b6cc5c41026e3bed6e5067361a91863b7b6169335ff3326&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">参考资料</a></p><p>Latex公式在VSCode中显示还正常，博客上显示错乱。。。，凑合看吧</p><h1><span id="1-transformer讲解1">1. Transformer讲解1</span></h1><p><a href="https://spaces.ac.cn/archives/4765" target="_blank" rel="noopener">Attention is All You Need浅读（简介+代码）</a></p><p><a href="https://github.com/aespresso/a_journey_into_math_of_ml/blob/master/03_transformer_tutorial_1st_part/transformer_1.ipynb" target="_blank" rel="noopener">transformer教程</a></p><p><a href="https://www.bilibili.com/video/av58239477/" target="_blank" rel="noopener">transformer视频讲解</a></p><p>transformer和LSTM的最大区别是：LSTM是迭代的，是一个接一个字，当这个字过完LSTM单元，才可以进下一个字。Transformer的训练是并行的，就是所有的字是全部同时训练的，加快了训练效率。但是这样字之间的顺序是丢失的，transformer引入position embedding来捕获字与字之间的位置关系。<br>transformer的结构分为编码器和解码器：</p><p><img src="/2019/11/02/Transformer/transformer.png" alt=""></p><p>先把一个句子输入到编码器，得到一个隐藏层，把隐藏层输入到解码器，得到输出的序列。例如在机器翻译中，输入是why do you work？通过编码器得到一个隐藏层，输入到解码器中，先给解码器一个start符，开始翻译，解码器输出翻译的第一个字‘为’，将‘为’输入到解码器中，输出‘什’，然后再输入到解码器中，直到解码器输出‘结束符’停止。</p><p><img src="/2019/11/02/Transformer/transformer1.png" alt=""></p><p>Transformer的编码器分为4部分，分别是：</p><ol><li>位置嵌入</li><li>多头注意力机制</li><li>残差</li><li>Positionwise FFN</li></ol><p><img src="/2019/11/02/Transformer/transformer-all1.png" alt=""></p><h2><span id="11-位置嵌入">1.1. 位置嵌入</span></h2><p><img src="/2019/11/02/Transformer/PE.png" alt=""></p><p>其中<br>$pos$：字在句子中的位置，比如一句话有10个字，pos从0~9<br>$i$：embedding dimension的维度，比如一个字的字向量有256维，则$i$的取值为0~255。<br>$d_{model}$：总共字向量的维度，即256.<br>如果一句话中有10个字，pos从0至9，一个字向量维度是256，从0~255.则<br>第0个字的position embedding为$PE_{(0,0)},PE_{(0,1)},…,PE_{(0,254)},PE_{(0,255)}$.如果字向量维度的下标是偶数使用$sin$，为奇数使用$cos$。使用以上公式可以区分字与字之间的位置信息。<br>在输入的时候将每个字的词嵌入和位置嵌入相加，作为总体的输入。</p><h2><span id="12-self-attention">1.2. self-attention</span></h2><ol><li><p>经过Embedding-lookup查表得到字向量，和position embedding得到位置嵌入，两者相加，得到一个字的最终嵌入表示，输入的维度为$X \in R^{batch_size \quad <em> \quad seq_len \quad </em> \quad embedding_dim}$<br>比如一个batch中有32个句子，每个句子有10个单词，embedding_dim=100，则输入的维度为$X \in R^{32<em>10</em>100}$</p></li><li><p>然后将$X_{embedding}$进行3次线性变换，$W_QX_{embedding},W_KX_{embedding},W_VX_{embedding}$得到$Q,K,V$,维度都是$R^{batch_size \quad <em> \quad seq_len \quad </em> \quad embedding_dim}$  </p></li><li>对$Q,K,V$进行分割，即多头注意力机制，其中head的个数是一个超参数，注意：$embedding \quad dimension必须能够整除head$,即一个矩阵变成$h$个矩阵，分割之后$Q,K,V$的维度为$[batch_size,seq_len,h,embedding_dimension/h]$,之后把$Q,K,V$的$seq_len,h$的维度进行转置，为了方面后面的计算，转置之后的$Q,K,V$的维度为$[batch_size,h,seq_len,embedding_dimension/h]$  </li><li>拿出一个$head$，即$Q*K^T$,得到的维度是$[batch_size,h,seq_len,seq_len]$,每个字与每个字之间的注意力，每一行表示当前这个字和所有字的关系。如果2个字之间的意思越相近，得到的注意力也越大。对每一行做softmax归一化，即每一行的和为1，得到归一化之后的注意力矩阵。</li><li>将注意力矩阵给$V$加权，即让所有字的信息融入到当前字中，得到当前字的一个加权表示。最终让每一个字都融合所有字的信息。得到的$V$的维度为$[batch_size,h,seq_len,embedding_dimension/h]$.</li><li>在训练的时候，通常多句话进行计算，即形成一个mini-batch。mini-batch中的句子的长度不一样，找出句子的最大长度max_seq_len，将短的句子补成和最大句子一样的长度，使用0padding。假设max_seq_len=10，一个句子的长度为7，即得到的attention矩阵，下面3行和右边3列都是0。在对attention矩阵做softmax会出问题，因为softmax计算涉及到指数计算，$e^0=1$,即经过softmax计算attention不为0，让无效的部分参与了计算。为了解决这个问题，需要用一个mask让这些无效的区域不参与计算，一般给无效的区域加一个很大的负数的偏置，$Z_{illegal}$表示无效的区域，加上一个很大的负数，变成负数，即通过softmax指数计算结果还是0。  </li><li>不同的head得到的结果concat起来，才能恢复到原来的维度$[batch_size,seq_len,embedding_dimension]$。不同的head关注的点不一样，可能有的head关注的local的关系，有的head关注的是global的关系。  </li><li>最后一步是Position-wise FFN，其实就是2层全连接，对输出$[batch_size,seq_len,embedding_dimension]$，经过2次线性变换和一个Relu激活函数。$Relu=max(0,x)$</li></ol><p><img src="/2019/11/02/Transformer/FFN.png" alt=""></p><p><img src="/2019/11/02/Transformer/multi.png" alt=""></p><p><img src="/2019/11/02/Transformer/multi1.png" alt=""></p><p><img src="/2019/11/02/Transformer/multi2.png" alt=""></p><p>Attention的总体架构如下：给出Q，求Q和所有K的attention，然后使用attention和value加权求和，得到加权的value。</p><p><img src="/2019/11/02/Transformer/qkv.png" alt=""></p><h2><span id="13-残差连接和layernorm">1.3. 残差连接和LayerNorm</span></h2><p><img src="/2019/11/02/Transformer/res1.png" alt=""></p><h2><span id="14-transformer的整体结构">1.4. transformer的整体结构</span></h2><p><img src="/2019/11/02/Transformer/transformer-all.png" alt=""></p><h1><span id="2-tramsformer讲解2">2. Tramsformer讲解2</span></h1><p><a href="https://www.bilibili.com/video/av56239558?from=search&amp;seid=9460464372943296837" target="_blank" rel="noopener">李宏毅视频讲解</a></p><p>其中<br>$x1,x2,x3,x4表示4个词向量，组成一个sequence,$$每一个a分别乘上3个矩阵，得到q,k,v，然后使用每一个q对每个k做attention$。</p><p><img src="/2019/11/02/Transformer/a1.png" alt=""></p><p>将每一个q对k做attention，然后将结果进行softmax归一化，相加为1.</p><p><img src="/2019/11/02/Transformer/a2.png" alt=""></p><p>其中得到的$\hat{a}_{1,1},…\hat{a}_{1,4}$表示每个词对词1的attention，然后将attention和v做点积，再相加得到词1新的加权词向量b1，即b1包含了所有词对词1的影响，产生b1的时候已经看到了所有的词，即global attention，再远的词都可以看到。</p><p><img src="/2019/11/02/Transformer/a3.png" alt=""></p><p>同理可以算出b2</p><p><img src="/2019/11/02/Transformer/a4.png" alt=""></p><p>即一个序列a1…a4，通过一个self-attention layer得到一个新的序列b1…b4。此时b1…b4可以并行计算。</p><p><img src="/2019/11/02/Transformer/a5.png" alt=""></p><p>self-attention的输入看做矩阵$I$,经过self-attention layer变成矩阵$O$。</p><p><img src="/2019/11/02/Transformer/a6.png" alt=""></p><h2><span id="21-multi-head">2.1. multi-head</span></h2><p>如果head=2，生成2个$q,k,v$，维度也是原来的一半。经过self-attention操作得到$b^{i,1}和b^{i,2}$,将$b^{i,1}和b^{i,2}进行concat，得到b^i，或者concat之后乘上矩阵W得到b^i.$  </p><p><img src="/2019/11/02/Transformer/a7.png" alt=""></p><p><img src="/2019/11/02/Transformer/a8.png" alt="">   </p><h1><span id="优缺点">优缺点</span></h1><ul><li>【<strong>优点</strong>】<br>解释性好</li><li>【<strong>缺点</strong>】<ul><li>无法捕获位置信息，需要额外添加位置信息</li><li>空间消耗大，需要存储attention acore(N*N)的维度，所以序列长度N不能太长，易出现OOM问题。</li></ul></li></ul><h1><span id="pytorch版transformer">Pytorch版Transformer</span></h1><p><img src="/2019/11/02/Transformer/pytorch.png" alt="Pytorch版Tranformer结构"></p><p>Pytorch已经将Transformer封装好了，可以直接调用，但是这个Transformer中并没有位置嵌入层，所以需要自己来实现，在将数据输入到Transformer中，先经过位置嵌入层。<br><strong>【注】因为Transformer中有Dropout层，分训练模式和测试模式。训练是用<code>model.train()</code>，如果在测试或验证阶段使用<code>model.eval()</code></strong><br><a href="https://github.com/pytorch/examples/blob/master/word_language_model/main.py" target="_blank" rel="noopener">https://github.com/pytorch/examples/word_language_model</a><br><a href="https://www.cnblogs.com/shiwanghualuo/p/11789018.html" target="_blank" rel="noopener">PyTorch中，关于model.eval()和torch.no_grad()</a><br><a href="https://blog.csdn.net/ImDePanDa/article/details/99298006?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">Pytorch中net.eval与net.train</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;《Attention is all you need》是Google Brain在2017年发表在NIPS的一篇文章。虽然在这篇文章之前，也在用Attention，但在这篇文章中，正式提出了Attention的概念，从此Attention在各个领域得到了广泛的应用。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1706.03762.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文地址&lt;/a&gt;  &lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/102591791&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;你应该知道的transformer&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
      <category term="Transformer" scheme="http://yoursite.com/tags/Transformer/"/>
    
  </entry>
  
  <entry>
    <title>评价指标</title>
    <link href="http://yoursite.com/2019/10/18/metrics/"/>
    <id>http://yoursite.com/2019/10/18/metrics/</id>
    <published>2019-10-18T02:48:03.000Z</published>
    <updated>2020-01-23T13:23:08.271Z</updated>
    
    <content type="html"><![CDATA[<p>介绍在回归问题中的主要评价指标，以及各自的特点</p><a id="more"></a><!-- TOC --><ul><li><a href="#1-%e9%97%ae%e9%a2%98">1. 问题</a></li><li><a href="#2-%e5%9b%9e%e5%bd%92%e9%97%ae%e9%a2%98">2. 回归问题</a><ul><li><a href="#21-mae%e5%b9%b3%e5%9d%87%e7%bb%9d%e5%af%b9%e8%af%af%e5%b7%ae">2.1. MAE(平均绝对误差)</a></li><li><a href="#22-mse%e8%af%af%e5%b7%ae%e5%b9%b3%e6%96%b9%e5%b9%b3%e5%9d%87%e5%80%bc">2.2. MSE(误差平方平均值)</a></li><li><a href="#23-rmse%e5%9d%87%e6%96%b9%e6%a0%b9%e8%af%af%e5%b7%ae">2.3. RMSE(均方根误差)</a></li><li><a href="#24-mape%e5%b9%b3%e5%9d%87%e7%bb%9d%e5%af%b9%e7%99%be%e5%88%86%e6%af%94%e8%af%af%e5%b7%ae">2.4. MAPE(平均绝对百分比误差)</a></li><li><a href="#25-%e6%80%bb%e7%bb%93">2.5. 总结</a></li></ul></li><li><a href="#3-%e5%88%86%e7%b1%bb%e9%97%ae%e9%a2%98">3. 分类问题</a><ul><li><a href="#31-micro-f1">3.1. Micro-F1</a></li><li><a href="#32-macro-f1">3.2. Macro-F1</a></li></ul></li></ul><!-- /TOC --><h1><span id="1-问题">1. 问题</span></h1><p>在回归问题中，标签y的分布不均衡，范围在[1,88]，其中70%的值都在1左右。解决的方法：从损失函数入手，设计不同的评价指标，让其更关注一些大的y值。</p><h1><span id="2-回归问题">2. 回归问题</span></h1><p><a href="https://zhuanlan.zhihu.com/p/74627482" target="_blank" rel="noopener">Metircs参考资料</a></p><h2><span id="21-mae平均绝对误差">2.1. MAE(平均绝对误差)</span></h2><p><img src="/2019/10/18/metrics/mae.png" alt=""></p><p>绝对误差的平均值。</p><ol><li>范围在$[0,\infin]$</li><li>单看MAE并不能看出这个模型的好坏，因为不知道y的平均值。比如MAE=10,y的平均值为1000，则这个模型还不错，但是如果y的平均值为1，那这个模型就非常不好。</li><li>改进：$MAE/y_{mean}$</li></ol><h2><span id="22-mse误差平方平均值">2.2. MSE(误差平方平均值)</span></h2><p><img src="/2019/10/18/metrics/mse.png" alt=""></p><ol><li>范围在$[0,\infin]$,  </li><li>很多算法的loss函数都是基于MSE的，因为MSE计算速度快，比RMSE更容易操作。但是我们很少把MAE作为最终的评价指标。</li><li>更关注一些y比较大的值，但是它的代价是对异常点过于敏感。如果预测出的y很不合理，则它的误差比较大，从而对RMSE的值有很大的影响。</li></ol><h2><span id="23-rmse均方根误差">2.3. RMSE(均方根误差)</span></h2><p><img src="/2019/10/18/metrics/rmse.png" alt=""></p><p>在MSE上加了根号，误差的结果和数据是一个级别，在数量级上更直观，如果RMSE=10，可以认为回归问题效果与真实结果平均相差10。</p><ol><li>范围在$[0,\infin]$</li><li>RMSE把更大的注意力放在y更大的值上，只有更大的y值预测准确了，模型的效果才会好。</li></ol><h2><span id="24-mape平均绝对百分比误差">2.4. MAPE(平均绝对百分比误差)</span></h2><p><img src="/2019/10/18/metrics/mape.png" alt=""></p><ol><li>范围$[0,\infin]$，当MAPE=0%表示完美模型，MAPE大于100%表示劣质模型。</li><li>当真实值有数据等于0时，存在分母为0的情况，该公式不可用</li><li>比如将y1预测为1.5，和100预测为100.5，差值是一样的，。即1的MAPE比100的MAPE大很多。以MAPE作为loss函数时，更加关注y比较小的值。</li><li>单看MAPE的大小是没有意义的，因为MAPE是个相对值，而不是绝对值。MAPE只能用来对不同模型同一组数据的评估。比如对于同一组数据，模型A的MAPE比模型B小，可以说明模型A比模型B好。但是如果说MAPE=10%，并不能判断这个模型好还是不好</li></ol><h2><span id="25-总结">2.5. 总结</span></h2><p>综上，在选用评价指标时，需要考虑</p><ol><li><p>数据中是否有0，如果有0值就不能用MPE、MAPE之类的指标；</p></li><li><p>数据的分布如何，如果是长尾分布可以选择带对数变换的指标，中位数指标比平均数指标更好；</p></li><li><p>是否存在极端值，诸如MAE、MSE、RMSE之类容易受到极端值影响的指标就不要选用；</p></li><li><p>得到的指标是否依赖于量纲(即绝对度量，而不是相对度量)，如果指标依赖量纲那么不同模型之间可能因为量纲不同而无法比较；</p></li></ol><h1><span id="3-分类问题">3. 分类问题</span></h1><p>在二分类任务中，使用Precison，Recall和F1值来评价分类的效果。<br><img src="/2019/10/18/metrics/hun.png" alt=""></p><p><img src="/2019/10/18/metrics/f1.png" alt=""></p><p>F1是针对二分类的，对于多分类，有2个常用的指标，Marco-F1和Micro-F1.</p><h2><span id="31-micro-f1">3.1. Micro-F1</span></h2><p><img src="/2019/10/18/metrics/micro.png" alt=""></p><p>假设对于一个多分类问题，有三个类，分别是1，2，3</p><p>$TP_i$表示分类$i$的TP<br>$FP_i$表示分类$i$的FP<br>$TN_i$表示分类$i$的TN<br>$FN_i$表示分类$i$的FN<br>接下来，我们来计算Micro的Precison</p><p><img src="/2019/10/18/metrics/precison-mi.png" alt=""></p><p>以及Micro的Recall</p><p><img src="/2019/10/18/metrics/recall-mi.png" alt=""></p><p>然后计算Micro-F1</p><p><img src="/2019/10/18/metrics/f1-mi.png" alt=""></p><h2><span id="32-macro-f1">3.2. Macro-F1</span></h2><p>先计算每个类的Precison和Rcall，从而计算出每个类的F1，然后将所有类的F1值平均得到Macro-F1。<br>如果数据集中各个类的分布不均衡的话，建议使用Micro-F1。<br>Macro-F1平等的看待各个类别，它的值更容易受少类别的影响Micro则更容易受常见类别的影响。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;介绍在回归问题中的主要评价指标，以及各自的特点&lt;/p&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://yoursite.com/categories/Machine-Learning/"/>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>keras基础知识</title>
    <link href="http://yoursite.com/2019/09/07/keras%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    <id>http://yoursite.com/2019/09/07/keras基础知识/</id>
    <published>2019-09-07T08:21:04.000Z</published>
    <updated>2020-02-11T09:38:24.848Z</updated>
    
    <content type="html"><![CDATA[<p>最近看到keras容易上手，封装比较好，学习一下<br><a id="more"></a></p><h2><span id="11-基础层的介绍">1.1. 基础层的介绍</span></h2><h3><span id="111-flatten">1.1.1. Flatten</span></h3><p>&ensp;&ensp;&ensp;&ensp;Flatten用来将输入“压平”，把多维的输入变成一维。常用在从卷积层到全连接层的过渡，特征全都变成1维就可以输入到全连接层中。Flatten不影响batch的大小。<br>通过<code>keras.layers.Flatten</code>来引入。<br>比如通过卷积层的输出形状为(batch_size,output_channel,width,height),例如(16,64,32,32),通过<code>Flatten</code>层之后变换成(16,64<em>32\</em>32)=(16,65536)，不改变batch_size的大小。</p><h3><span id="112-dense">1.1.2. Dense</span></h3><p>Dense全连接层。<br>如果Dense是在第一层的话，需要指定output_dim和input_dim，即<code>Dense(output_dim=64,input_dim=44)</code>。在Dense中的API中，看到其实没有input_dim或者input_shape这个参数，查看源码看到，input_dim和input_shape是在**kwargs中，因为并不是所有的Dense层都需要传入输入的形状，只有第一层需要。可以输入<code>input_dim=44</code>,也可以是<code>input_shape=(44,)</code>。一般都是用input_shape</p><p><strong>注意：在input_shape中不包含batch的大小</strong></p><p><img src="/2019/09/07/keras基础知识/dense.png" alt=""></p><p>如果Dense不是在第一层，则只需要指定output_dim，而input_dim则默认为上一层的输出维度。即<code>Dense(output_dim=64)</code><br>如果需要激活函数，则需要再指定激活函数，例如<br><code>Dense(64,avtivation=&#39;relu&#39;)</code></p><h3><span id="113-embedding">1.1.3. Embedding</span></h3><p>Embedding只能作为模型的第一层。基本上用户自然语言处理方面，用来做词嵌入。</p><h3><span id="114-lstm">1.1.4. LSTM</span></h3><p>LSTM传入的参数<br><code>LSTM(batch_input_dim=(batch_size,time_steps,input_size),output_dim=cell_size,return_sequences=True,stateful=True)</code></p><p>其中</p><ul><li>input_dim是(batch_size，时间步的个数，每个时间步的特征个数)</li><li>output_dim是LSTM中隐藏层单元的个数  </li><li>return_sequences默认是False，表示一个时间步长为T的序列，只在最后一个时间步输出一个结果，True表示每个时间步都输出一个结果，保留起来。 </li><li>stateful默认是False，表示这个batch与batch之间是不是有联系的，表示这个batch和下一个batch的状态是不是要连起来。</li></ul><h3><span id="115-merge层">1.1.5. Merge层</span></h3><p>Merge层提供了用于融合<strong>两个层或两个张量</strong>的方法，如果方法以大写字母开头，例如<code>Add()</code>表示融合两个层，如果以小写字母开头，例如<code>add()</code>表示融合两个张量。<br>通过以下来调用<br><code>keras.layers.Add()或keras.layers.add()</code><br>例如</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"></span><br><span class="line">input1 = keras.layers.Input(shape=(<span class="number">16</span>,))</span><br><span class="line">x1 = keras.layers.Dense(<span class="number">8</span>, activation=<span class="string">'relu'</span>)(input1)</span><br><span class="line">input2 = keras.layers.Input(shape=(<span class="number">32</span>,))</span><br><span class="line">x2 = keras.layers.Dense(<span class="number">8</span>, activation=<span class="string">'relu'</span>)(input2)  </span><br><span class="line"><span class="comment"># 相当于added = keras.layers.add([x1, x2])</span></span><br><span class="line">added = keras.layers.Add()([x1, x2])  </span><br><span class="line"></span><br><span class="line">out = keras.layers.Dense(<span class="number">4</span>)(added)</span><br><span class="line">model = keras.models.Model(inputs=[input1, input2], outputs=out)</span><br></pre></td></tr></table></figure><h2><span id="12-训练">1.2. 训练</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add()</span><br><span class="line">....</span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,loss=<span class="string">'mean_squared_error'</span>,metric=[<span class="string">'mse'</span>])</span><br><span class="line"></span><br><span class="line">model.fit(train_x,train_y,epochs=<span class="number">1000</span>,batch_size=<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#对测试集进行验证loss或metric</span></span><br><span class="line">model.evaluate(test_x,test_y,batch_size=<span class="number">16</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#对测试集输出预测的结果。</span></span><br><span class="line">model.predict(test_x)</span><br></pre></td></tr></table></figure><p>在训练的时候，有以下3种方法：fit，train_on_batch,fit_gen</p><ol><li>fit()<br>当使用fit()函数时，首先要保证2个条件：（1）训练数据可以完成的放在内存中，（2）数据已经不需要再做任何处理了，可以直接训练。</li><li>train_on_batch()<br>train_on_batch()函数接收一个batch的输入和标签，然后反向传播，更新参数。大部分情况下都不需要用到train_on_batch()，例如<code>cost = train_on_batch(train_x,train_y)</code>,返回值是误差  </li></ol><h2><span id="13-模型构建">1.3. 模型构建</span></h2><p>在keras中，一些简单的组件可以直接使用def来实现，在这个输入是input，直接使用某些层，得到输出,不使用model。<br>在实现整个模型的框架时，使用<code>model = Model(input=input,output=output)</code>,然后<code>return model</code><br>对于有些层，这个层在<code>keras.layers</code>中没有，这时候就需要自己定义一个层，这个层中的参数需要自己定义。自定义层中的参数也是需要学习的。</p><h2><span id="14-callbacks">1.4. Callbacks</span></h2><p>传入fit()函数中的callbacks必须是一个list，里面是一个或多个callback实例。</p><h3><span id="141-modelcheckpoint">1.4.1. ModelCheckpoint</span></h3><p>回调函数<code>Callbacks</code>是一组在<strong>训练阶段</strong>被调用的函数集，使用回调函数来查看训练过程中网络内部的状态和统计信息。在模型上调用<code>fit()</code>函数时，可以将<code>ModelCheckpoint</code>传递给训练过程。<br>训练深度学习模型时，<code>Checkpoint</code>是模型的权重。<code>ModelCheckpoint</code>回调类运行定义检查模型权重的位置，文件应如何命名，</p><h3><span id="142-earlystopping">1.4.2. EarlyStopping</span></h3><p>EarlyStopping是Callbacks的一种，用于提前停止训练。停止训练的标准是当val_loss或者val_root_mean_square_error不再减少，或者val_acc不在增加。我们在训练模型时，主要目的是获得最好的泛化性能。模型的泛化能力通常使用验证集来评估。模型在训练的时候，模型在训练集上loss一直在变小，但是在验证集上的loss却是先变小后变大。说明出现了过拟合。解决过拟合的方法有2种方法：权重衰减和早停法。早停法就是模型在验证集上的表现开始下降时，停止训练。这样就可以避免过拟合的问题。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近看到keras容易上手，封装比较好，学习一下&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Deep Learning" scheme="http://yoursite.com/categories/Deep-Learning/"/>
    
    
      <category term="Keras" scheme="http://yoursite.com/tags/Keras/"/>
    
  </entry>
  
</feed>
