<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Echo&#39;s blog</title>
  
  <subtitle>远方到底有多远</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-10-21T03:18:16.294Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Echo</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>推荐系统冷启动问题</title>
    <link href="http://yoursite.com/2020/10/21/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%86%B7%E5%90%AF%E5%8A%A8%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2020/10/21/推荐系统冷启动问题/</id>
    <published>2020-10-21T01:47:04.000Z</published>
    <updated>2020-10-21T03:18:16.294Z</updated>
    
    <content type="html"><![CDATA[<p>推荐系统冷启动</p><ul><li>新用户。该怎么给新用户推荐，才能让用户满意</li><li>新物品。怎么将新物品推荐出去，才能推荐给喜欢的人</li><li>系统冷启动。新用户+新物品</li></ul><a id="more"></a><!-- TOC --><ul><li><a href="#1-用户冷启动">1. 用户冷启动</a></li><li><a href="#2-物品冷启动">2. 物品冷启动</a></li><li><a href="#3-系统冷启动">3. 系统冷启动</a></li><li><a href="#4-总结">4. 总结</a></li></ul><!-- /TOC --><h1><span id="1-用户冷启动">1. 用户冷启动</span></h1><ol><li>推荐热门产品或者必需品。这些物品往往是热点或购买最多的产品。</li><li>基于用户的信息来做推荐。比如年龄、性别等，但这需要提前知道用户的部分信息，可能比较难获取到</li><li>多样性和区分行，将库中的物品进行聚类，给新用户每个类中都推荐几个，总有一款是你喜欢的</li><li>当用户有很少的行为记录时，这时很多算法（例如协同过滤）等还无法给用户做推荐，可以采用基于内容的推荐算法</li><li>当产品在拓展过程中，比如原先只做长视频推荐，后来拓展到短视频，那么可以根据长视频的观看历史计算用户的相似度，然后根据用户相似度对新用户推荐短视频</li><li>当用户注册时，让用户选择自己的兴趣，可以做一些诙谐幽默的问题，让用户选择。</li><li>利用社交信息做冷启动，将好友喜欢的物品推荐给新用户</li><li>利用用户在其他地方已经沉淀的数组做冷启动。比如现在很多应用在注册的时候都会选择是否使用微信/QQ/微博等账号登录，通过该用户在其他应用上数据进行推荐</li></ol><h1><span id="2-物品冷启动">2. 物品冷启动</span></h1><ol><li>基于物品的属性推荐。一般新上线的物品都有些属性，根据这些属性找到与该物品最相似的物品，这些相似的物品被哪些用户消费过，可以把这个新物品推荐给消费过的用户</li></ol><h1><span id="3-系统冷启动">3. 系统冷启动</span></h1><ol><li>系统先收集一段时间的用户行为数据，先不调用推荐结果。</li><li>历史数据迁移。</li></ol><h1><span id="4-总结">4. 总结</span></h1><ul><li><strong>用户冷启动</strong>往往采用多样性和探索推荐的方式，融合实时受欢迎，热门，跨数据平台等多种方式。</li><li><strong>物品冷启动</strong>以语义相似推荐为主，通过时间权重干预的方式帮助新物品获得更多的曝光量</li><li><strong>系统冷启动</strong>可以先积累用户数据，或历史数据导入的方式将系统冷启动问题转化为用户冷启动或物品冷启动。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;推荐系统冷启动&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;新用户。该怎么给新用户推荐，才能让用户满意&lt;/li&gt;
&lt;li&gt;新物品。怎么将新物品推荐出去，才能推荐给喜欢的人&lt;/li&gt;
&lt;li&gt;系统冷启动。新用户+新物品&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="推荐系统" scheme="http://yoursite.com/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="推荐系统" scheme="http://yoursite.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>今日头条推荐算法原理介绍</title>
    <link href="http://yoursite.com/2020/10/20/%E4%BB%8A%E6%97%A5%E5%A4%B4%E6%9D%A1%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D/"/>
    <id>http://yoursite.com/2020/10/20/今日头条推荐算法原理介绍/</id>
    <published>2020-10-20T11:28:25.000Z</published>
    <updated>2020-10-27T11:23:18.084Z</updated>
    
    <content type="html"><![CDATA[<p>今天看到今日头条的推荐算法原理介绍，非常感兴趣，在此记录下。</p><a id="more"></a><!-- TOC --><ul><li><a href="#1-推荐系统概述">1. 推荐系统概述</a></li><li><a href="#2-评价指标">2. 评价指标</a></li><li><a href="#3-典型推荐算法">3. 典型推荐算法</a></li><li><a href="#4-典型的推荐特征">4. 典型的推荐特征</a></li><li><a href="#5-大规模模型训练">5. 大规模模型训练</a></li><li><a href="#6-内容分析">6. 内容分析</a></li><li><a href="#7-用户标签">7. 用户标签</a></li><li><a href="#8-评估分析">8. 评估分析</a></li></ul><!-- /TOC --><p>参考资料：<a href="https://36kr.com/p/1722189037569" target="_blank" rel="noopener">36氪首发 | 今日头条推荐算法原理全文详解</a></p><h1><span id="1-推荐系统概述">1. 推荐系统概述</span></h1><p>推荐系统就是需要去拟合一个用户对内容满意度的函数，这个函数需要输入三个维度的变量：</p><ol><li>内容维度。头条中有图片，视频，新闻等信息，每种内容都有自己的特征。</li><li>用户特征。包括用户的兴趣标签，职业，年龄，性别等，还有很多表示用户喜好的隐式特征</li><li>环境特征。用户随时随地移动，在工作场合，通勤，旅游三个不同的环境中，喜好会发生偏移。</li></ol><p>结合以上三个维度，模型会给出一个预估，在这个场景下用户对这个内容是否感兴趣。</p><h1><span id="2-评价指标">2. 评价指标</span></h1><p>推荐模型中，点击率，阅读时间，点赞（离散指标），评论等都是可以量化的目标，能够用模型进行预测。但当用户过多时，不能完全由指标进行评估，引入数据指标以外的要素也很重要。</p><h1><span id="3-典型推荐算法">3. 典型推荐算法</span></h1><p><img src="/2020/10/20/今日头条推荐算法原理介绍/推荐.jpg" alt=""></p><h1><span id="4-典型的推荐特征">4. 典型的推荐特征</span></h1><p>看完典型推荐模型，我们再看看典型的推荐模型中用到的特征，主要有4类特征。</p><p><img src="/2020/10/20/今日头条推荐算法原理介绍/特征.jpg" alt=""></p><ol><li>相关性特征。就是评估内容的属性和用户是否匹配。显性的匹配包括关键词匹配、来源匹配、分类匹配、主题匹配等。向FM模型中也有一些隐式匹配，从用户向量和物品向量的距离得出。</li><li>环境特征。地理位置和时间</li><li>热度特征。包括全局热度，分类热度，主题热度，以及关键词热度。其中内容热度信息在推荐系统冷启动问题非常有效。</li><li>协同特征。可以在部分程度上帮助解决算法越推越窄的问题。协同过滤并非考虑用户已有的历史，而是通过用户行为分析不同用户间的相似性，比如点击相似性，兴趣分类相似等，从而扩展模型的探索能力</li></ol><h1><span id="5-大规模模型训练">5. 大规模模型训练</span></h1><p>头条大部分推荐产品采用实时训练。实时训练省资源并且反馈快。用户的行为信息可以被模型快速捕捉并反馈给下一刷的推荐结果。头条线上目前基于storm集群实时处理样本数据，包括点击收藏等动作。</p><p>整体的训练过程是线上服务器记录实时特征，导入到kafka文件队列中，然后进一步导入storm集群消费kafka数据，客户端回传推荐的label构造训练样本，随后根据最新样本进行在线训练更新模型参数，最终线上模型得到更新。这个过程主要的延迟在用户的动作反馈延时，因为文章推荐后用户不一定马上看，不考虑这部分时间，整个系统几乎是实时的。</p><p><img src="/2020/10/20/今日头条推荐算法原理介绍/召回.jpg" alt=""></p><p>头条的内容量非常大，推荐系统不可能所有的内容全部由模型预测，所以需要设计一些召回策略，每次推荐时从海量内容中筛选出千级别的内容库。召回策略最重要的要求是性能要极致，一般超时不能超过50毫秒。</p><p><img src="/2020/10/20/今日头条推荐算法原理介绍/倒排.jpg" alt=""></p><p>召回策略有很多，头条采用的是倒排的思想。离线维护一个倒排，根据用户标签或topic，来源等，拉去对应的文章并对其排序。线上召回可以迅速的从倒排中根据用户兴趣标签对内容做截断，高效的从很大的内容库中筛选比较靠谱的一小部分内容。</p><h1><span id="6-内容分析">6. 内容分析</span></h1><p>内容分析包括文本分析、图片分析和视频分析。这里主要将文本分析，文本分析在推荐系统中很重要的作用是用户兴趣建模。没有内容和文本标签，无法得知用户兴趣标签。举个例子，只有知道文档标签是互联网，用户看了互联网标签的文章，才能知道用户有互联网标签。所以<strong>内容分析和用户标签是推荐系统的基石</strong>。</p><p>下面是今日头条一个实际文本的例子，可以看到这篇文章有分类，关键词，topic等文本特征。</p><p><img src="/2020/10/20/今日头条推荐算法原理介绍/文本特征.jpg" alt=""></p><p>今日头条推荐系统<strong>文本的特征</strong>主要有以下几类：</p><ul><li>语义标签类特征：显示为文章打上语义标签。这部分标签是人定义的特征，每个标签有明确的意义，标签体系是预定义的。</li><li>topic特征和关键词特征：隐式语义特征。其中topic特征描述词概率分布，无明确意义；关键词特征会基于一些统一的特征描述，无明确集合。</li></ul><p>下面是头条语义标签的特征和使用场景。他们之间层级不同，要求不同。</p><p>分层是为了每个层级粒度不同，要求也有区别。</p><ul><li>分类：要求覆盖全，希望每篇文章都有分类，精确性要求不高。</li><li>概念：表达比较精确，但又属于抽象概念的语义，也不要求覆盖全。</li><li>实体：不要求覆盖全，只要覆盖每个领域热门的人物、机构、作品即可。</li></ul><p><img src="/2020/10/20/今日头条推荐算法原理介绍/语义.jpg" alt=""></p><p>头条线上分类采用层次分类。最上面是root，下面第一层的分类像科技，体育，娱乐这样的大类，下面细分足球，篮球，网球等，足球再细分国际足球，中国足球，中国足球又分为中甲，中超，国家队等。相比单独的分类器，利用层次文本分类算法能更好地解决数据倾斜问题。</p><p>每个元分类器可以异构，像有些分类器SVM效果很好，有些要结合CNN，有些要结合RNN</p><p><img src="/2020/10/20/今日头条推荐算法原理介绍/分类.jpg" alt=""></p><h1><span id="7-用户标签">7. 用户标签</span></h1><p>用户分析和用户标签是推荐系统的两大基石。内容分析涉及到的机器学习多一些，相比而言，用户标签工程挑战更大。</p><p>用户标签包括：</p><ul><li><p>用户感兴趣的类别和主题、关键词、来源。基于兴趣的用户聚类和各种垂直兴趣特征</p></li><li><p>性别、年龄、地点等信息。性别信息通过用户第三方社交账号登录得到。年龄信息通常由模型预测，通过机型、阅读时间分布预估。常驻地来自用户授权访问位置信息，在位置信息的基础上通过传统聚类方法拿到常驻点，常驻点结合其他信息，可以推断用户的工作地点、出差地点、旅游地点。这些用户标签非常有助于推荐。</p></li></ul><p><img src="/2020/10/20/今日头条推荐算法原理介绍/用户.jpg" alt=""></p><p>最简单的用户标签是浏览过的内容标签，但这里涉及到一些数据处理的策略。主要包括:</p><ul><li>过滤噪声。通过停留时间短的点击，过滤标题党。</li><li>热点惩罚。对用户在一些热门文章上的动作做降权处理。理论上，传播范围较大的内容，置信度会下降。</li><li>时间衰减。用户兴趣会发生偏移，因此策略更偏向新的用户行为。因此，随着用户动作的增加，老的特征权重会随时间衰减，新动作贡献的权重会更大。</li><li>惩罚展现。如果一篇推荐给用户的文章没有被点击，相关特征（类别、关键词、来源）权重会被惩罚。</li></ul><p><img src="/2020/10/20/今日头条推荐算法原理介绍/用户1.jpg" alt=""></p><p>用户标签总体相对简单，主要还是工程上的挑战。头条用户标签第一版是批量计算框架，流程比较简单，每天抽取昨天的日活用户过去两个月的动作数据，在Hadoop集群上批量计算结果。</p><p>但随着用户增加，兴趣模型种类和其他批量处理任务都在增加，计算量太大，集群计算资源紧张，集中写入分布式存储系统的压力也开始增大，用户兴趣标签更新延迟越来越高。</p><p><img src="/2020/10/20/今日头条推荐算法原理介绍/工程挑战.jpg" alt=""></p><p>2014年，头条上线了用户标签storm集群流式计算系统，只要有用户动作更新，就更新标签，CPU代价较小，大大降低了计算资源开销，特征更新速度也很快</p><p><img src="/2020/10/20/今日头条推荐算法原理介绍/流式.jpg" alt=""></p><h1><span id="8-评估分析">8. 评估分析</span></h1><p>介绍了推荐系统的整体架构，怎么评估推荐效果好不好呢？</p><p>全面的评估推荐系统，需要完备的评估体系，并非单一的指标，不能只看点击率和停留时长，需要综合评估。</p><p><img src="/2020/10/20/今日头条推荐算法原理介绍/评估.jpg" alt=""></p><p>一个良好的评估体系需要遵循几个原则，首先是兼顾短期和长期指标，检录用户指标和生态指标。今日头条作为内容创作平台，既要为内容创作者提供价值，也有义务满足用户，这两者要平衡。还有广告主利益也要考虑，这是多方博弈和平衡的过程。</p><p><img src="/2020/10/20/今日头条推荐算法原理介绍/评估1.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天看到今日头条的推荐算法原理介绍，非常感兴趣，在此记录下。&lt;/p&gt;
    
    </summary>
    
      <category term="推荐系统" scheme="http://yoursite.com/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="推荐系统" scheme="http://yoursite.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>SVD++介绍Factorization meets the neighborhood: a multifaceted collaborative filtering model</title>
    <link href="http://yoursite.com/2020/10/08/Factorization-meets-the-neighborhood-a-multifaceted-collaborative-filtering-model/"/>
    <id>http://yoursite.com/2020/10/08/Factorization-meets-the-neighborhood-a-multifaceted-collaborative-filtering-model/</id>
    <published>2020-10-08T13:30:09.000Z</published>
    <updated>2020-10-20T09:39:51.998Z</updated>
    
    <content type="html"><![CDATA[<p>Yehuda Koren发表在2008KDD上的一篇论文。他也是Netflix Prize的冠军队成员，是推荐系统领域的大神级人物。他带领的团队在 Netflix Prize 比赛中拿到过两次进步奖（progress award），参与的团队拿到过 2009 年 Netflix Prize 比赛的百万美金大奖。当年比赛的题目是 netflix 电影评分预测，Yehuda Koren 所在团队提出的算法在测试集上的均方根误差为 0.8567，比比赛开始时的最高成绩提高了 10.06%。Yehuda Koren 等人当年做出的算法是基于矩阵分解的算法，优于传统的最近邻基础，已经成为现在几乎所有推荐系统的基础。</p><a id="more"></a><!-- TOC --><ul><li><a href="#1-引言">1. 引言</a></li><li><a href="#2-定义">2. 定义</a><ul><li><a href="#21-baseline">2.1. baseline</a></li><li><a href="#22-邻居方法">2.2. 邻居方法</a></li><li><a href="#23-潜在因子模型">2.3. 潜在因子模型</a></li><li><a href="#24-netflix数据集">2.4. Netflix数据集</a></li><li><a href="#25-隐式反馈">2.5. 隐式反馈</a></li></ul></li><li><a href="#3-邻居模型">3. 邻居模型</a></li><li><a href="#4-隐式因子模型">4. 隐式因子模型</a></li><li><a href="#5-整合模型">5. 整合模型</a></li><li><a href="#6-总结">6. 总结</a></li></ul><!-- /TOC --><p><a href="https://mp.weixin.qq.com/s/ks6Vvg7j35-uKgAncq63eQ" target="_blank" rel="noopener">推荐系统 | 一文带你了解协同过滤的前世今生</a></p><h1><span id="1-引言">1. 引言</span></h1><p>实现协同过滤CF的2个比较成功的方法：<strong>邻居模型</strong>（user-based和item-based）和<strong>潜在因子模型</strong>，本篇论文对以上两种方法进行融合。</p><p>邻居方法是计算item或user的相似性。</p><p>潜在因子模型，例如奇异值分解(SVD)，使用多个因素来表示item</p><p>这篇文章首次提出将邻居方法和潜在因子模型进行融合。</p><p>作者发现整合不同形式的输入到模型中是非常重要的，传统的方法一般输入的都是高质量的显示反馈，例如user-item评分矩阵，然后显示反馈有时无法获取到，一些隐式信息也能反映用户的喜好，隐式信息包括：购买历史，浏览记录，搜索模式，甚至鼠标移动。在本篇模型中，融合显示和隐式信息。</p><h1><span id="2-定义">2. 定义</span></h1><ul><li>用户$u,v$</li><li>物品$i,j$</li><li>评分$r_{ui}$，所有的评分$\mathcal<br>{K}=\{(u,i)|r_{ui}已知\}$</li><li>需要预测的值$\hat{r_{ui}}$</li></ul><p>在评分矩阵中，大部分的值缺失，为了避免过度拟合稀疏的数据，添加正则化</p><h2><span id="21-baseline">2.1. baseline</span></h2><p>普通的协同过滤方法CF，$b_{ui}$是基准推荐模型给出的评分：</p><script type="math/tex; mode=display">b_{ui}=\mu + b_u + b_i</script><p>其中$\mu$表示所有物品的平均评分，$b_u$表示用户$u$评分的偏差，$b_i$表示物品$i$评分的偏差。假设要对电影《泰坦尼克号》评分，所有电影的评分$\mu=3.7$，天威这个电影比较好，评分比一般的电影高$b_i=0.5$分，而用户$u$在电影上比较挑剔，评分比一般评分低$b_u=0.3$分，则《泰坦尼克号》的评分为$3.7-0.3+0.5=3.9$分。</p><p>为了求$b_i,b_u$，使用下面的目标函数</p><script type="math/tex; mode=display">\mathop{min} \limits_{b*} \sum_{(u,i) \in \mathcal{K}} (r_{ui}-\mu-b_i-b_u)^2+\lambda_1(\sum_\mu b_u^2 + \sum_{i}b_i^2)</script><h2><span id="22-邻居方法">2.2. 邻居方法</span></h2><p>基于邻居方法来实现协同过滤CF。先出现基于用户的CF，后提出基于物品的CF。在预测中，面向物品的CF更容易解释，因为我们更容易解释物品之间的相似性，而用户之间的相似性不容易解释。下面以面向物品的CF为例。</p><p>面向物品的CF核心是计算相似性。可以使用皮尔森系数，但由于评分矩阵非常系数，可以对皮尔森系数进行修正：</p><script type="math/tex; mode=display">s_{ij}=\frac{n_{ij}}{n_{ij}+\lambda_2}\rho_{ij}</script><p>其中$n_{ij}$表示同时给物品$i,j$都进行评分的用户个数，$\lambda_2$通常为100</p><p>为了求出用户$u$对未见过的物品$i$的评分$r_{ui}$，首先从用户$u$已经评分过的物品中找出与物品$i$最相似的$k$个物品，表示为$S^k(i;u)$，被预测的值$\hat{r}_{ui}$为这$k$个物品评分的加权平均</p><p><img src="/2020/10/08/Factorization-meets-the-neighborhood-a-multifaceted-collaborative-filtering-model/sim.jpg" alt=""> (3)</p><p>但是这种方法不能通过正式模型来证明，此外该相似性度量没有分析所有邻居间的相互作用，而权重和为1的事实导致该方法完全依赖邻居，即使在没有邻居的情况下。</p><p>为了解决以上问题，本文提出新的插值权重$\theta^u_{ij}$</p><script type="math/tex; mode=display">\hat{r}_{ui}=b_{ui}+\sum_{j \in S^k(i;u)}\theta^u_{ij}(r_{uj}-b_{uj})\quad \quad (4)</script><p>至于$\theta^u_{ij}$怎么得到的，参考《Scalable Collaborative Filtering with Jointly Derived Neighborhood Interpolation Weights》</p><h2><span id="23-潜在因子模型">2.3. 潜在因子模型</span></h2><p>潜在因子模型感觉就是矩阵分解MF，通常可以使用奇异值分解来实现，使用向量$p_u \in \mathbb{R}^f$表示用户$u$，使用向量$q_i \in \mathbb{R}^f$表示物品$i$。通过$\hat{r}_{ui}=b_{ui}+p_u^Tq_i$来进行预测。</p><p>在信息检索中，通常使用SVD进行矩阵分解，然而评分矩阵中通常比较稀疏，会造成过拟合的问题。早期的方法通过插值的方法来构造稠密矩阵，但这种代价太大。因此最近的额工作通常直接对评分矩阵进行建模，采用正则化来避免过拟合。</p><p><img src="/2020/10/08/Factorization-meets-the-neighborhood-a-multifaceted-collaborative-filtering-model/2.jpg" alt=""></p><p>Paterek提出使用NSVD，这种方法避免显式参数化每个用户，而是根据用户评价的物品对用户进行建模。对于每个物品，使用2个向量表示$q_i,x_i$，根据用户所评价的物品来表示用户向量，其中$R(u)$是用户评价的物品集合，用户向量为$(\sum_{j \in R(u)}x_j)/\sqrt{|R(u)|}$，最终的预测评分：</p><script type="math/tex; mode=display">\hat{r}_{ui}=b_{ui}+q_i^T (\sum_{j \in R(u)}x_j)/\sqrt{|R(u)|}</script><p>本篇论文在此基础上进行扩展。</p><h2><span id="24-netflix数据集">2.4. Netflix数据集</span></h2><p>使用Netfix电影评分数据，评价指标</p><p><img src="/2020/10/08/Factorization-meets-the-neighborhood-a-multifaceted-collaborative-filtering-model/rmse.jpg" alt=""></p><p>测试集中包含140万个最新电影评分，这里面包含较多的对电影评分不多的用户，很难预测，更符合实际情况。</p><p>Netflix数据集是现在Netflix Prize竞赛使用的数据集，该竞赛的基准是Netflix的专有系统，测试集的RMSE为0.9514，大奖将办法给将RMSE降低至0.8563以下(提升10%)的团队。本篇论文的RMSE为0.887</p><h2><span id="25-隐式反馈">2.5. 隐式反馈</span></h2><p>像Netflix这样的数据，隐式数据是用户的电影租赁记录，并不需要用户显示的评分，但是这样的数据并不能获取到，现在所能获取到的数据就是显示评分数据。</p><p>在本篇模型中，不限制使用隐式数据的类型，每个用户有2个向量表示，一个显式数据$R(u)$，例如用户$u$所评分的物品；一个隐式数据$N(u)$</p><h1><span id="3-邻居模型">3. 邻居模型</span></h1><p>在本篇论文中，我们引入了新的邻居模型，该模型不仅提升了准确率，并且整合了隐式信息。</p><p>之前的模型使用$\theta^u_{ij}$或$\frac{s_{ij}}{\sum_{j \in S^k(i;u)}s_{ij}}$将物品$i$和它的邻居$S^k(i;u)$联系起来.</p><p>为了促进全局优化，我们抛弃特定用户的权重，使用全局权重，该权重独立于特定的用户。从物品$j$到物品$i$的权重表示为$w_{ij}$，该权重通过优化学习得到，预测得分$\hat{r}_{ui}$公式如下：</p><script type="math/tex; mode=display">\hat{r}_{ui} = b_{ui}+\sum_{j \in R(u)}(r_{uj}-b_{uj})w_{ij} \quad \quad (6)</script><p>我们提出的公式6和公式4不同，公式6中的$w_{ij}$不是针对特定用户的。$R(u)$是用户评价的物品集合。公式6是对$R(u)$求和，公式4是对$S^k(i;u)$求和。用户$u$已经评分过的物品中找出与物品$i$最相似的$k$个物品，表示为$S^k(i;u)$</p><p>在邻居模型中，权重通常表示未知物品和已知物品的插值系数，也表示和baseline评估分数的偏差。残差$r_{uj}-b_{uj}$和这些偏差$w_{ij}$相乘。对于2个相关的物品$i,j$，希望$w_{ij}$越大越好。如果用户$u$对物品$j$评分高于期望值$(r_{uj}-b_{uj})$时，我们也希望增加用户$u$对物品$i$的评分，通过加上$(r_{uj}-b_{uj})\times w_{ij}$。我们的评估不会和baseline差太多。主要有以下2个原因：(1)如果用户$u$对物品$j$的评分和期望值差不不大，则$r_{uj}-b_{uj}$基本为0。(2)如果物品$j$对物品$i$来说是未知的，则$w_{ij}$基本为0。通过这种考虑对公式(6)进行改进。首先我们使用隐式反馈，通过这可学习用户偏好。最终，我们在后面添加一组权重来重写公式(6)</p><script type="math/tex; mode=display">\hat{r}_{ui} = b_{ui}+\sum_{j \in R(u)}(r_{uj}-b_{uj})w_{ij}+\sum_{j \in N(u)}c_{ij} \quad \quad (7)</script><p>$c_{ij}$和$w_{ij}$都是权重，对于物品$i$和物品$j$，用户$u$对物品$j$的隐式偏好会主导用户修改对物品$i$的评分$r_{ui}$,通过加上偏差$c_{ij}$。</p><p>上式中的权重是全局的偏差，而不是针对某个特定用户，这种方式强调了缺失值的影响。换句话说，用户的偏好不仅仅取决于他的评分，还取决于他没有评分的东西。例如要预测用户对“指环王3”的评分，如果用户对“指环王1和2”评分也比较高，则从指环王1和2到指环王3的权重就比较大，但是如果用户没有对指环王1和2进行评分，则对指环王3进行评分时，就需要进行惩罚。</p><p>下面给出更一般的公式</p><script type="math/tex; mode=display">\hat{r}_{ui} = \mu + b_i + b_u + \sum_{j \in R(u)}(r_{uj}-b_{uj})w_{ij}+\sum_{j \in N(u)}c_{ij} \quad \quad (7)</script><p>其中$\mu + b_i + b_u$是其他模型的预测值。</p><p>当前的方案中，对那些评分数据较多(具有高的$|R(u)|$)或隐式数据较多(具有高的$N(u)$)的的用户，鼓励生成较大偏差的评分结果，与baseline相比。也就是说对于那些输入数据较多的用户，我们更愿意预测更奇怪和不太常见的建议，对于那些少量输入数据的用户更希望给出接近baseline的估计值。但是，根据我们的经验可知，当前的模型在某种程度上过分强调了较多评分者和较少评分者之间的二分法，为了缓和这种情况，将预测规则修改如下：</p><p><img src="/2020/10/08/Factorization-meets-the-neighborhood-a-multifaceted-collaborative-filtering-model/3.jpg" alt=""></p><p>可以通过修剪与不太相关的项目来减少参数，使用$R^k(i;u)$表示在用户$u$评价的物品中，与物品$i$最相似的$k$个物品。$N^k(i;u)$表示在用户$u$隐式偏好的物品中，与物品$i$最相似的$k$个物品</p><p><img src="/2020/10/08/Factorization-meets-the-neighborhood-a-multifaceted-collaborative-filtering-model/4.jpg" alt=""></p><p>下面是我们提出方案的最终版，新的邻居模型的主要目标是利用有效的全局优化过程。在下面的优化过程中，加上正则项。</p><p><img src="/2020/10/08/Factorization-meets-the-neighborhood-a-multifaceted-collaborative-filtering-model/5.jpg" alt=""></p><h1><span id="4-隐式因子模型">4. 隐式因子模型</span></h1><p>隐式因子模型中较流行的是SVD，对评分矩阵进行分解，每个用户$u$使用向量$p_u \in \mathbb{R}^f$表示，每个物品$i$使用向量$q_i \in \mathbb{R}^f$，通过下式得到预测结果：</p><script type="math/tex; mode=display">\hat{r}_{ui}=b_{ui}+p^T_uq_i \quad \quad (12)</script><p>通过下面的公式进行优化求解：</p><p><img src="/2020/10/08/Factorization-meets-the-neighborhood-a-multifaceted-collaborative-filtering-model/2.jpg" alt=""></p><p>下面我们通过添加隐式信息对SVD进行扩展，预测公式如下所示：</p><p><img src="/2020/10/08/Factorization-meets-the-neighborhood-a-multifaceted-collaborative-filtering-model/6.jpg" alt=""></p><p>在上式中，每个物品$i$都有3个向量$q_i,x_i,y_i \in \mathbb{R}^f$。在这里我们并没有对用户$u$给出一个显示的向量表示，而是使用该用户过去评分的商品来表示用户$u$的喜好。使用下面的公式代替用户向量$p_i$</p><script type="math/tex; mode=display">|R(u)^{-\frac{1}{2}}|\sum_{j \in R(u)}(r_{uj}-b_{uj})x_j+|N(u)|^{-\frac{1}{2}}\sum_{j \in N(u)}y_j</script><p>带有正则项的损失函数就变成：</p><p><img src="/2020/10/08/Factorization-meets-the-neighborhood-a-multifaceted-collaborative-filtering-model/7.jpg" alt=""></p><p>本文提出的SVD被称为“<strong>非对称SVD</strong>”，主要有以下优点：</p><ol><li>更少的参数。通常用户的数量远大于商品的数量。因此使用物品参数代替用户参数降低模型复杂度</li><li>冷启动问题。因为非对称SVD中没有用户参数，只要用户在系统中有反馈，我们就可以处理新用户问题，并不需要重新训练模型。需要注意的是对于新的物品，我们需要学习新的参数。换句话说：系统对于新用户可以给出即时的推荐，对于新物品的推荐，需要等待一些时间。</li><li>可解释性。以前的SVD是通过对用户过去的行为进行抽象，抽象为用户向量，无法直接解释哪个历史行为对当前的预测结果更重要。非对称SVD算法没有对用户进行超互相，最终的预测结果是用户历史反馈的直接函数，所以可以直观的看出历史哪个行为对当前预测更重要，解释性更强。面向物品的协同过滤也有这个优点。</li><li>有效地整合隐式反馈。隐式反馈提供了额外的用户爱好，可能提升推荐准确率。在公式(13)中，当$|N(u)|$变大时，隐式反馈更重要。当$R(u)$变大时，显示反馈更重要。</li></ol><p>实际上，对隐式信息进行整合，我们可以通过更直接的方式来获取更准确的结果，公式如下：</p><script type="math/tex; mode=display">\hat{r}_{ui} = b_{ui}+q^T_i(p_u+|N(u)|^{-\frac{1}{2}}\sum_{j \in N(u)}y_j) \quad \quad (15)</script><p>以上面相比，在用户表示上添加$p_u$，其中$p_u$从用户显示评分数据中得到。使用$p_u+|N(u)|^{-\frac{1}{2}}\sum_{j \in N(u)}y_j$既有显示表示，又有隐式表示，我们称这种模型为<strong>SVD++</strong></p><p>SVD++虽然没有参数更少，解释性更强的优点，但在Netflix数据上效果更好。</p><p><img src="/2020/10/08/Factorization-meets-the-neighborhood-a-multifaceted-collaborative-filtering-model/SVD.jpg" alt=""></p><h1><span id="5-整合模型">5. 整合模型</span></h1><p>将邻居模型和SVD++融合</p><p>一种融合方式是将公式10和公式15的预测结果相加</p><p><img src="/2020/10/08/Factorization-meets-the-neighborhood-a-multifaceted-collaborative-filtering-model/8.jpg" alt=""></p><p>公式(16)提供了3层模型。</p><ul><li>第一层$\mu+b_i + b_u$描述了商品和用户的一般属性，不考虑任何的交互。例如电影《指环王》拍的很好，用户Joe对所有电影的评分都是平均水平。</li><li>第二层$q^T_i(p_u+|N(u)|^{-\frac{1}{2}}\sum_{j \in N(u)}y_j)$提供了用户和物品的交互。例如用户Joe对《指环王》的科幻电影里评分较高</li><li>第三层邻域层贡，对其进行细粒度的调整，这种调整很难描述，例如用户Joe在“励志”标签的电影中评分较低。</li></ul><p>模型参数通过梯度下降来更新。</p><p><img src="/2020/10/08/Factorization-meets-the-neighborhood-a-multifaceted-collaborative-filtering-model/9.jpg" alt=""></p><h1><span id="6-总结">6. 总结</span></h1><p>我们提出了新的邻居模型，该模型通过全局损失函数进行优化，具有可解释性强，并且可应对新用户，不用重新训练的问题。同时对SVD方法进行扩展，通过整合隐式反馈来提升准确率。</p><p>推荐系统的性能从不同的维度体现，例如准确率，多样性，推荐意想不到的物品的能力，可解释性，topK推荐，计算效率等。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Yehuda Koren发表在2008KDD上的一篇论文。他也是Netflix Prize的冠军队成员，是推荐系统领域的大神级人物。他带领的团队在 Netflix Prize 比赛中拿到过两次进步奖（progress award），参与的团队拿到过 2009 年 Netflix Prize 比赛的百万美金大奖。当年比赛的题目是 netflix 电影评分预测，Yehuda Koren 所在团队提出的算法在测试集上的均方根误差为 0.8567，比比赛开始时的最高成绩提高了 10.06%。Yehuda Koren 等人当年做出的算法是基于矩阵分解的算法，优于传统的最近邻基础，已经成为现在几乎所有推荐系统的基础。&lt;/p&gt;
    
    </summary>
    
      <category term="推荐系统" scheme="http://yoursite.com/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="推荐系统" scheme="http://yoursite.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>矩阵分解MF论文Matrix Factorization Techniques for Recommender Systems</title>
    <link href="http://yoursite.com/2020/10/07/Matrix-Factorization-Techniques-for-Recommender-Systems/"/>
    <id>http://yoursite.com/2020/10/07/Matrix-Factorization-Techniques-for-Recommender-Systems/</id>
    <published>2020-10-07T13:15:02.000Z</published>
    <updated>2020-10-20T10:27:05.854Z</updated>
    
    <content type="html"><![CDATA[<p>这个论文是推荐算法中的经典论文，介绍的是矩阵分解FM，雅虎团队提出来的，发表在IEEE2009的computer期刊上，算法有效但非常简单。</p><p>作者Yehuda Koren是Netflix Prize的冠军队成员，是推荐系统领域的大神级人物。他带领的团队在 Netflix Prize 比赛中拿到过两次进步奖（progress award），参与的团队拿到过 2009 年 Netflix Prize 比赛的百万美金大奖。当年比赛的题目是 netflix 电影评分预测，Yehuda Koren 所在团队提出的算法在测试集上的均方根误差为 0.8567，比比赛开始时的最高成绩提高了 10.06%。Yehuda Koren在这篇论文中提出基于矩阵分解的算法，优于传统的最近邻基础，已经成为现在几乎所有推荐系统的基础。</p><p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5197422" target="_blank" rel="noopener">论文地址</a></p><a id="more"></a><!-- TOC --><ul><li><a href="#1-推荐系统策略">1. 推荐系统策略</a></li><li><a href="#2-矩阵分解">2. 矩阵分解</a><ul><li><a href="#21-随机梯度下降">2.1. 随机梯度下降</a></li><li><a href="#22-交替最小二乘法als">2.2. 交替最小二乘法ALS</a></li><li><a href="#23-添加偏差">2.3. 添加偏差</a></li><li><a href="#24-丰富用户表示">2.4. 丰富用户表示</a></li><li><a href="#25-时间动态性">2.5. 时间动态性</a></li><li><a href="#26-带权正则矩阵分解">2.6. 带权正则矩阵分解</a></li></ul></li><li><a href="#3-矩阵分解的优点">3. 矩阵分解的优点</a></li></ul><!-- /TOC --><p>电子零售商给消费者提供了大量的商品供用户选择，造成信息过载，向用户推荐匹配的商品可以提升用户的满意度和忠诚度，零售商通过分析用户在商品的兴趣模式，提供个性化推荐。</p><h1><span id="1-推荐系统策略">1. 推荐系统策略</span></h1><p><img src="/2020/10/07/Matrix-Factorization-Techniques-for-Recommender-Systems/cf.jpg" alt=""></p><p><img src="/2020/10/07/Matrix-Factorization-Techniques-for-Recommender-Systems/优缺点.jpg" alt=""></p><p>广义上讲，推荐系统基于2个策略：</p><p><strong>1. 基于内容的策略</strong><br>   内容过滤策略给每个用户和商品创建一个画像表示其属性。例如电影画像包括主题，主演，票房等。用户画像包括人口统计信息或问卷调查信息。这些画像允许程序将用户和商品进行匹配。</p><p><strong>2. 协同过滤</strong><br>   协同过滤又分为邻居模型和潜在因子模型。邻居模型有user-based和item-based，潜在因子模型有矩阵分解，例如SVD，SVD++等。<br>   一种替代方法是基于用户的协同过滤，先找出用户-商品的评分矩阵，然后计算2个用户对商品的评分向量的相似性，而不是基于用户画像计算相似性。<br>   但是基于用户的协同过滤需要用户对商品的评分计算相似性，因此会遇到冷启动的问题。在这方面，基于内容的推荐更胜一筹。</p><p>   潜在因子模型根据评分模式推断出20~100个因子来表示商品或用户</p><p>   <img src="/2020/10/07/Matrix-Factorization-Techniques-for-Recommender-Systems/1.jpg" alt=""></p><h1><span id="2-矩阵分解">2. 矩阵分解</span></h1><p>Matrix Factorization矩阵分解通过<strong>对用户-物品评分矩阵进行分解，使用因子向量表示用户和物品</strong>。</p><p>矩阵分解使用的是用户-物品的评分矩阵，但这个矩阵是很稀疏的，因为一个用户可能只评价了一小部分物品。</p><p>矩阵分解MF的一个优点是可以使用额外的信息。有时候显示的评分没法获取到，但我们可以使用一些隐式的信息来表示用户的兴趣，例如用户的浏览，购买记录，鼠标停留时间等。</p><p>通过矩阵分解，分别使用向量表示用户和物品。对于商品使用向量表示，向量中每个元素表示该商品和这个因素的相关程度。对于用户使用向量表示，向量中每个元素表示用户对这个因素的感兴趣程度，<strong>计算用户$u$对商品$i$的感兴趣程度，使用2个向量的内积表示</strong></p><script type="math/tex; mode=display">\hat{r}_{ui}=q^T_ip_u</script><script type="math/tex; mode=display">q_i,p_u \in \mathbb{R}^f</script><p><strong>矩阵分解的关键是怎么获取到用户向量$p_u$和物品向量$q_i$</strong></p><p>矩阵分解模型有2种实现方法</p><ol><li>应用SVD对user-item评分矩阵进行分解，但有时user-item评分矩阵是很稀疏的。早期的系统会采用插值的方法使评分矩阵变得稠密，但这会增加工作量，另外不正确的插值会引入噪声。</li><li>最近的方法一般直接对评分矩阵进行建模，同时使用正则化避免过拟合，使用梯度下降进行优化</li></ol><script type="math/tex; mode=display">J(p_u,q_i)= \frac{1}{2}(\sum_{r_{ui} \neq0}(r_{ui}-q^T_ip_u)^2+\lambda(||q_i||^2+||p_u||^2))</script><p>优化的目标是$min J(p_u,q_i)$，即让$\hat{r}_{ui}=q^T_ip_u$和$r_{ui}$尽可能接近</p><p>其中$r_{ui}$是已知的</p><p>最小化上述公式有2种方法：随机梯度下降和交替最小二乘法ALS</p><h2><span id="21-随机梯度下降">2.1. 随机梯度下降</span></h2><p>$J(p_u,q_i)$对$p_u$求导得：</p><script type="math/tex; mode=display">\frac{\delta J(p_u,q_i)}{p_u}=(r_{ui}-q^T_ip_u)(-q^T_i)+\lambda p_u</script><p>这里令$e_{ui}=r_{ui}-q^T_ip_u$</p><p>所以</p><script type="math/tex; mode=display">\frac{\delta J(p_u,q_i)}{p_u}=-e_{ui}q^T_i+\lambda p_u</script><p>对$p_u$进行更新：</p><script type="math/tex; mode=display">p_u=p_u-\eta \cdot \frac{\delta J(p_u,q_i)}{p_u} = p_u + \eta \cdot (e_{ui} \cdot q_i - \lambda \cdot p_u)</script><p>同理</p><script type="math/tex; mode=display">q_i=q_i-\eta \cdot \frac{\delta J(p_u,q_i)}{q_i} = q_i + \eta \cdot (e_{ui} \cdot p_u - \lambda \cdot q_i)</script><h2><span id="22-交替最小二乘法als">2.2. 交替最小二乘法ALS</span></h2><p>矩阵分解中最常用的是ALS进行优化</p><p>因为$p_u,q_i$两个变量未知，因此损失函数不是凸函数，无法使用凸优化求解。<br>但是，如果固定$p_u$，那么损失函数就只是关于$q_i$的二次函数，直接解二次函数即可。</p><p>因此，可固定$p_u$，求解$q_i$；再固定$q_i$，求解$p_u$，这样迭代下去。</p><ul><li><p>固定$q_i$，求解$p_u$</p><script type="math/tex; mode=display">\frac{\delta J(p_u)}{p_u}=(r_{ui}-q^T_ip_u)(-q^T_i)+\lambda p_u=(q^T_iq_i+\lambda)p_u-r_{ui}q^T_i</script><p>令$\frac{\delta J(p_u)}{p_u}=0$，写成矩阵的形式：</p><script type="math/tex; mode=display">(QQ^T+\lambda E)P = R_jQ^T</script><p>$E$是全1矩阵<br>求解得到：</p><script type="math/tex; mode=display">P = (QQ^T+\lambda E)^{-1}R_j</script></li><li><p>固定$p_u$，求解$q_i$</p><p>同理求得：</p><script type="math/tex; mode=display">Q = (PP^T+\lambda E)^{-1}R_i</script></li></ul><p>通常随机梯度下降比ALS更快，但是在以下2种情况下，ALS更有利：</p><ol><li>并行化，在ALS中，系统独立于其他项目因素计算每个$q_i$和$p_u$</li><li>在以隐式数据为中心的系统中，训练集不是稀疏的，如果使用SGD，遍历每个训练样本是不切实际的，ALS可以处理这种情况</li></ol><h2><span id="23-添加偏差">2.3. 添加偏差</span></h2><p>在计算用户$u$对物品$i$的评分时，可以添加偏差。</p><script type="math/tex; mode=display">b_{ui}=\mu + b_i + b_u</script><p>其中$\mu$是所有电影的平均评分，$b_i$是物品$i$的偏差，$b_u$是用户$u$的偏差。最终的预测评分为：</p><script type="math/tex; mode=display">\hat{r}_{ui}=\mu + b_i + b_u + q^T_ip_u</script><p>假设现在你要预测Joe对《泰坦尼克号》的评分，令所有电影的评分$\mu=3.7$，而由于《泰坦尼克号》比一般电影好，评分高出$b_i=0.5$，而Joe对电影是一个挑剔的人，评分通常比平均低$b_u=0.3$分，则总的偏差为$3.7+0.5—.3=3.9$分</p><p>加上偏差，最终的损失函数为：</p><script type="math/tex; mode=display">J(p_u,q_i,b^*)= \frac{1}{2}(\sum_{r_{ui} \neq0}(r_{ui}-\mu-b_u-b_i-q^T_ip_u)^2+\lambda(||q_i||^2+||p_u||^2+b^2_u+b^2_i))</script><h2><span id="24-丰富用户表示">2.4. 丰富用户表示</span></h2><p>推荐系统需要解决冷启动问题，有些用户只有很少的评分，这样我们可以获取用户其他的隐式数据，例如浏览，购买记录等。</p><p>我们使用$N(u)$表示用户$u$显示了隐式喜好的物品集合，对于$N(u)$中的每个物品$i$使用$x_i \in \mathbb{R}^f$表示物品的特征，然后归一化：</p><script type="math/tex; mode=display">|N(u)|^{-0.5} \sum_{i \in N(u)}x_i</script><p>除了以上特征，还有用户$u$的个人属性特征$A(u)$，例如年龄，收入等，对于每一个特征$y_a \in \mathbb{R}^f$,总的表示为：</p><script type="math/tex; mode=display">\sum_{a \in A(u)}y_a</script><p>矩阵分解得到的预测得分变成下面式子：</p><script type="math/tex; mode=display">\hat{r}_{ui}=\mu + b_i + b_u + q^T_i (p_u+|N(u)|^{-0.5} \sum_{i \in N(u)}x_i+\sum_{a \in A(u)}y_a)</script><p>上面增强了用户表示，同样也可以丰富物品的表示。</p><h2><span id="25-时间动态性">2.5. 时间动态性</span></h2><p>现在为止，提出的模型都是静态的，实际上，用户的兴趣会随着时间变化。因此在考虑用户-物品的交互中需要考虑到时间动态性。</p><p>为了体现时间动态性，偏差都变成时间的函数，即物品偏差$b_i(t)$，用户偏差$b_u(t)$，用户偏好$p_u(t)$，不像人的喜好随时间变化，物品的特征一般是静态的，因此$q_i$不随着时间变化，现在用户$u$对物品$i$的评分变成：</p><script type="math/tex; mode=display">\hat{r}_{ui}(t)=\mu + b_i(t)+b_u(t)+q^T_ip_u(t)</script><h2><span id="26-带权正则矩阵分解">2.6. 带权正则矩阵分解</span></h2><p>并不是现在所有的评分都赋予相同的权重，例如大量的广告可能会影响对某个商品的打分，后者系统中有些商品被恶意打分或刷好评等。</p><p>在有些场景下，虽然没有得到用户具体的评分，但是能够得到一些类似于“置信度”的信息（也称为隐式反馈信息），例如用户的游戏时长、观看时长等数据。虽然时长信息不能直接体现用户的喜好，但是能够说明用户喜欢的概率更大。</p><p>“带权”就是根据置信度计算每条记录对应损失的权重，优化的目标函数如下：</p><p>当没有得到用户具体的评分，但是能够得到一些类似于隐式反馈信息时，就可使用带权正则矩阵分解</p><script type="math/tex; mode=display">J(p_u,q_i,b^*)= \frac{1}{2}(c_{ui}\sum_{r_{ui} \neq0}(r_{ui}-\mu-b_u-b_i-q^T_ip_u)^2+\lambda(||q_i||^2+||p_u||^2+b^2_u+b^2_i))</script><h1><span id="3-矩阵分解的优点">3. 矩阵分解的优点</span></h1><ol><li>泛化能力强，在一定程度上解决数据稀疏问题</li><li>空间复杂度低。不需要存储用户相似或物品相似矩阵，只需要存储用户和物品的隐向量。空间复杂度从$o(n^2)$降低到$o((n+m) \times k)$级别</li><li>更好的扩展性和灵活性。矩阵分解最后得到用户和物品隐向量，这其实和深度学习的嵌入类似，因此矩阵分解与其他特征进行组合和拼接很方便</li></ol><p>但矩阵分解也有一些局限。总的来说应该是整个协同过滤模型的局限，无法加入用户，物品属性，上下文信息，这丢失了很多有效信息。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这个论文是推荐算法中的经典论文，介绍的是矩阵分解FM，雅虎团队提出来的，发表在IEEE2009的computer期刊上，算法有效但非常简单。&lt;/p&gt;
&lt;p&gt;作者Yehuda Koren是Netflix Prize的冠军队成员，是推荐系统领域的大神级人物。他带领的团队在 Netflix Prize 比赛中拿到过两次进步奖（progress award），参与的团队拿到过 2009 年 Netflix Prize 比赛的百万美金大奖。当年比赛的题目是 netflix 电影评分预测，Yehuda Koren 所在团队提出的算法在测试集上的均方根误差为 0.8567，比比赛开始时的最高成绩提高了 10.06%。Yehuda Koren在这篇论文中提出基于矩阵分解的算法，优于传统的最近邻基础，已经成为现在几乎所有推荐系统的基础。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=5197422&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文地址&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="推荐系统" scheme="http://yoursite.com/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="推荐系统" scheme="http://yoursite.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统综述Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions</title>
    <link href="http://yoursite.com/2020/10/05/Toward-the-next-generation-of-recommender-systems-A-survey-of-the-state-of-the-art-and-possible-extensions/"/>
    <id>http://yoursite.com/2020/10/05/Toward-the-next-generation-of-recommender-systems-A-survey-of-the-state-of-the-art-and-possible-extensions/</id>
    <published>2020-10-05T12:11:10.000Z</published>
    <updated>2020-10-20T09:40:16.456Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=1423975" target="_blank" rel="noopener">论文地址</a></p><p>该论文发表于2005年IEEE TKDE，是推荐系统经典的综述论文。该论文主要对当时的技术进行总结。</p><a id="more"></a><!-- TOC --><ul><li><a href="#1-引言">1. 引言</a></li><li><a href="#2-推荐算法综述">2. 推荐算法综述</a><ul><li><a href="#21-基于内容的推荐">2.1. 基于内容的推荐</a><ul><li><a href="#211-介绍">2.1.1. 介绍</a></li><li><a href="#212-限制">2.1.2. 限制</a></li></ul></li><li><a href="#22-协同过滤cf">2.2. 协同过滤CF</a><ul><li><a href="#221-介绍">2.2.1. 介绍</a><ul><li><a href="#2211-基于内存的协同过滤">2.2.1.1. 基于内存的协同过滤</a></li><li><a href="#2212-基于模型的协同过滤">2.2.1.2. 基于模型的协同过滤</a></li></ul></li><li><a href="#222-限制">2.2.2. 限制</a></li></ul></li><li><a href="#23-混合方法">2.3. 混合方法</a></li></ul></li><li><a href="#3-推荐算法扩展">3. 推荐算法扩展</a></li></ul><!-- /TOC --><h1><span id="1-引言">1. 引言</span></h1><p>推荐系统可以帮助用户处理信息过载，提供个性化的推荐服务。<br>在下面的章节中，作者首先对当前的推荐算法进行总结，并列出他们的limitation。</p><h1><span id="2-推荐算法综述">2. 推荐算法综述</span></h1><p>推荐系统问题通常被定义为对用户未看到的东西进行排序。直观上，通常是基于用户对其他物品的评价或额外信息，来对这些未见过的东西进行排序，根据排序结果，我们就可以将排在前面的东西推荐给用户。</p><p>推荐系统的形式化定义：$C$表示用户集合，$S$表示被推荐的物品集合，集合$C,S$中元素个数可能会非常多。我们要学习一个效益函数$u$，$u:X \times S \rArr R$，$R$是有序集合，对于用户$c \in C$，我们想选出物品$s’ \in S$，使得用户的效益最大</p><script type="math/tex; mode=display">\forall c \in C, \quad s_{c}^{\prime}=\arg \max _{s \in S} u(c, s)</script><p>在推荐系统中，一个物品的效益通常用排名表示，表示这个用户喜欢这个物品的程度。</p><p>对于每个用户，可以使用年龄，性别，收入，婚姻状态等特征表描述用户，最简单的情况，可以仅适用用户ID来表示用户特征。类似，一个物品可以使用一些特征来描述。例如电影可以使用名字，导演，主演等特征。</p><p>推荐系统的中心问题是效益函数$u$通常不是定义在整个$C \times S$集合空间上，而是定义在它们的子集上，这意味着$u$需要外推到整个$C \times S$空间上。</p><p>根据推荐的方式，推荐算法被分为以下3类：</p><ol><li>基于内容的推荐：向用户推荐其以前偏好的物品</li><li>协同过滤：找和用户有相似喜好的人，向该用户推荐他们喜欢的物品</li><li>混合推荐：结合基于内容推荐和协同过滤</li></ol><h2><span id="21-基于内容的推荐">2.1. 基于内容的推荐</span></h2><h3><span id="211-介绍">2.1.1. 介绍</span></h3><p>$u(c,s)$用户$c$对物品$s$的喜爱程度，基于用户对与$s$相似的物品$s’$的喜爱程度来评估。例如电影推荐系统中，推荐算法会找出用户$c$以前看过的电影，对其评分高的那些电影间的共性（导演，演员，主题等），然后向用户推荐和这些电影相似的电影。</p><p>基于内容的推荐源自信息检索和信息过滤的研究。<strong>许多基于内容的推荐基本都是基于文本信息的推荐</strong>，例如文档，URL，或新闻等。</p><p>形式化定义：$Content(s)$表示物品$s$的特征，基于内容的推荐很多都是基于文本的推荐，所以物品的特征基本使用关键词表示。例如网页推荐中，通常推荐包含100个最重要单词的网页给用户。$w_{i,j}$表示单词$k_i$在文档$d_j$中的重要性，最常用的是使用$IT-IDF$来评估。</p><p>基于内容的推荐就是推荐与用户以前喜欢的物品相似的物品，因此我们需要评估候选物品和以前物品的相似性，然后推荐最匹配的物品给用户。</p><p>形式化定义：$ContentBasedProfile(c)$表示用户$c$过去的喜好，例如可以用关键词的权重来表示$ContentBasedProfile(c)=(w_{c1,,…,w_{ck}})$，$w_{ci}$表示关键词$k_i$对用户$c$的重要程度。计算用户$c$对物品$s$的喜爱程度为：</p><script type="math/tex; mode=display">u(c, s)= score ( ContentBasedProfile (c),  Content(s))</script><p>在文本信息中，可以分别使用TF-IDF计算词向量权重$\vec{w}_{c},\vec{w}_{s}$，然后计算这2个向量的相似性，使用cos函数：</p><script type="math/tex; mode=display">\begin{aligned}u(c, s) &=\cos \left(\vec{w}_{c}, \vec{w}_{s}\right)=\frac{\vec{w}_{c} \cdot \vec{w}_{s}}{\left\|\vec{w}_{c}\right\|_{2} \times\left\|\vec{w}_{s}\right\|_{2}} \\&=\frac{\sum_{i=1}^{K} w_{i, c} w_{i, s}}{\sqrt{\sum_{i=1}^{K} w_{i, c}^{2}} \sqrt{\sum_{i=1}^{K} w_{i, s}^{2}}}\end{aligned}</script><p>$K$表示字典中所有的关键词个数</p><p>除了使用cos计算相似度，还有一些其他方法，例如贝叶斯分类，深度神经网络也可以用来做基于内容的推荐。</p><h3><span id="212-限制">2.1.2. 限制</span></h3><ol><li><p>基于内容的推荐算法依赖于物品的特征，为了有足够的特征，通常使用特征自动或人工提取特征，但是有些领域特征提取困难，例如音频和视频。</p></li><li><p>另外一个问题是如果2个物品的使用同一组特征表示，则无法区分它们。基于文本的文档通常使用关键字表示，如果这2篇文档恰巧使用了相同的关键字，则无法区分这2个文档写的好坏。</p></li><li><p>当系统只向用户推荐他以前喜欢的物品时，这个系统就过度专业化，那些用户没看过的物品将永远不会被推荐。为了解决这个问题，系统通常会引入一定的随机性。在推荐的时候通常会推荐和以前物品相似的内容，但是如果2个物品太相似，例如在新闻系统中，用户看了一个新闻，如果有个新闻和这个新闻相似，讲的是同一件事，这时候也不建议推荐。所以在信息过滤的时候不仅要过滤那些和用户喜好完全不同的内容，还要过滤和用户以前看过的内容太相似的东西。</p></li><li><p><strong>冷启动问题</strong>：在推荐之前，用户必须要有对足够多的物品评分，如果一个用户对物品评分较少或者一个新用户，则推荐将会不准确</p></li></ol><p><strong>推荐系统的理想状态是多样性</strong>，为用户推荐一系列不同的内容，而不是全是同一系列的内容。</p><h2><span id="22-协同过滤cf">2.2. 协同过滤CF</span></h2><p>协同过滤Collaborative Filtering</p><h3><span id="221-介绍">2.2.1. 介绍</span></h3><p>协同过滤是根据与该用户相似用户的喜好物品来进行推荐。</p><p>形式化定义：效益函数$u(c,s)$基于$u(c_j,s)$，其中$c_j$表示和用户$c$相似的用户。</p><p>协同过滤算法可以分为2类：基于内存的、基于模型的。</p><h4><span id="2211-基于内存的协同过滤">2.2.1.1. 基于内存的协同过滤</span></h4><p>基于内存的表示用户$c$对物品$s$的喜爱程度$r_{c,s}$基于系统中以前其他用户$c’$对物品$s$的评分$r_{c’,s}$,$c’$通常是与$c$最相似的$N$个用户$\hat{C}$，$r_{c,s}$通常是$r_{c’,s}$的聚合函数。</p><script type="math/tex; mode=display">r_{c, s}=\underset{c^{\prime} \in \hat{C}}{\operatorname{aggr}} r_{c^{\prime}, s}</script><p>聚合函数主要有以下几种形式：</p><p>$($ a $) r_{c, s}=\frac{1}{N} \sum_{c^{\prime} \in \hat{C}} r_{c^{\prime}, s}$</p><p>$(\mathrm{b}) r_{c, s}=k \sum_{c^{\prime} \in \hat{C}} \operatorname{sim}\left(c, c^{\prime}\right) \times \mid r_{c^{\prime}, s}$</p><p>$(\mathrm{c}) r_{c, s}=\bar{r}_{c}+k \sum_{c^{\prime} \in \hat{C}} \operatorname{sim}\left(c, c^{\prime}\right) \times\left(r_{c^{\prime}, s}-\bar{r}_{c^{\prime}}\right)$</p><p>$\bar{r}_{c}$表示用户$c$的对物品的平均评分。</p><script type="math/tex; mode=display">\bar{r}_{c}=\left(1 /\left|S_{c}\right|\right) \sum_{s \in S_{c}} r_{c, s}, \text { where } S_{c}=\left\{s \in S \mid r_{c, s} \neq \oslash\right\}</script><p>其中权重聚合(b)最常用。对不同的用户评分赋予不同的权重，最相似的用户的评分权重最大。但是不同的用户在评分的时候量级可能不一样，需要归一化，于是出现了公式(c)，每个相似用户的评分需要先减去用户$c$的平均评分。</p><p>$sim(c,c’)$表示2个用户的相似性，相似性函数根据情况定义。通常情况下，相似性根据这2个用户对物品的评分来计算。其中<strong>最常用的2个相似性函数是皮尔森相关系数和余弦相似度</strong>：</p><ol><li><p>皮尔森相关系数<br>使用$S_{xy}$表示用户$x,y$都评分的物品集合。</p><p><img src="/2020/10/05/Toward-the-next-generation-of-recommender-systems-A-survey-of-the-state-of-the-art-and-possible-extensions/sim1.jpg" alt=""></p></li></ol><ol><li><p>余弦相似度<br> 余弦相似度使用2个m维向量表示2个用户，$m=|S_{xy}|$</p><p> <img src="/2020/10/05/Toward-the-next-generation-of-recommender-systems-A-survey-of-the-state-of-the-art-and-possible-extensions/sim2.jpg" alt=""></p></li></ol><p><strong>计算相似度的关键是找到2个用户都评价的物品交集</strong></p><p><strong>【注意】</strong><br>基于内容的推荐和协同过滤都使用了cos计算相似性，基于内容的推荐是计算2个物品的关键词TF-IDF权重的相似性，协同过滤计算2个用户对用户的评分的相似性。</p><h4><span id="2212-基于模型的协同过滤">2.2.1.2. 基于模型的协同过滤</span></h4><p>基于模型的协同过滤就是用收集的打分训练一个模型，然后模型预测出一个排名用于推荐。例如，一篇论文提出使用基于概率的协同过滤，其中打分函数为：</p><p><img src="/2020/10/05/Toward-the-next-generation-of-recommender-systems-A-survey-of-the-state-of-the-art-and-possible-extensions/r1.jpg" alt=""></p><p>假设打分的数组在0~n之间，概率表达式为：在给定之前给物品打分的情况下，用户$c$对物品$s$打分。有2种概率模型：聚类模型和贝叶斯网络。聚类模型是将兴趣相同的用户放在一类中。如果已经给定每类的用户，并且用户打分是独立的，则就变成朴素贝叶斯网络。每个节点的状态表示每个物品的可能的打分值，网络的结构和条件概率通过数据学到。这个方法的限制是一个用户只能被聚到一类，但实际情况下，一个用户可能同时属于多类，即一个用户可能有多个兴趣。</p><p>同时，协同过滤也可以使用机器学习框架，例如LR等。</p><h3><span id="222-限制">2.2.2. 限制</span></h3><p>协同过滤主要有以下3个问题：</p><ol><li>新用户问题（冷启动问题）对于一些新用户，没有评分数据，推荐往往不准。现在大部分使用混合推荐方法（基于内容推荐+协同过滤）</li><li>新物品问题：当系统中增加一些新物品，没有用户针对这个物品打分，通常也使用混合推荐解决</li><li>数据稀疏问题：用户对物品的打分矩阵是非常稀疏的，有些物品只被很少的用户打分，即使分数很高，这些物品也很少被推荐。解决这个问题的方法是计算用户相似度时，不仅仅使用打分数据，还可以使用用户的画像信息，例如性别，年龄，教育等信息。或者使用SVD进行降维。</li></ol><h2><span id="23-混合方法">2.3. 混合方法</span></h2><p>一些推荐系统使用混合方法，结合基于内容的推荐和协同过滤。在这2种方法的结合方式上有以下几种：</p><ol><li>分别使用这2种方法，然后把他们的预测结果结合在一起<br>使用线性组合或投票的方式将2个方法的输出结合在一起。</li><li>把基于内容的一些特征结合到协同过滤中<br>使用协同过滤进行推荐，但是保留用户画像信息，使用用户信息计算2个用户的相似性，而不是用历史打分来计算相似性。</li><li>把协同过滤的一些特征结合到基于内容的推荐中<br>在基于内容的用户画像上进行降维</li><li>构建一个综合模型，结合基于内容和协同过滤</li></ol><h1><span id="3-推荐算法扩展">3. 推荐算法扩展</span></h1><ol><li><p>丰富用户信息<br>以前的基于内容的推荐和协同过滤是基于用户和物品的画像信息，没有充分利用用户交易记录和其他有价值的信息，在推荐的时候应该使用更先进的用户画像技术。</p></li><li><p>多维度推荐</p><p>现在的推荐都是基于用户和物品的，不考虑上下文信息。然而很多时候，用户对某物品的喜爱程度很大程度上和时间有关，也可能取决与和谁一起消费。在这种情况下，仅仅就需要考虑上下文信息，例如时间，地点，公司等。</p></li><li><p>多规则打分<br>现在的推荐系统很多是单一规则打分。然而在一些应用中，比如餐厅推荐，用户可能喜欢这个餐厅的事物，环境，价格，服务等，因此需要从不同的规则来对这个餐厅进行打分。</p></li><li><p>评价指标<br>覆盖率，准确率，召回率，F1，ROC，MAE,MSE</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=1423975&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文地址&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;该论文发表于2005年IEEE TKDE，是推荐系统经典的综述论文。该论文主要对当时的技术进行总结。&lt;/p&gt;
    
    </summary>
    
      <category term="推荐系统" scheme="http://yoursite.com/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="推荐系统" scheme="http://yoursite.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Tucker分解</title>
    <link href="http://yoursite.com/2020/09/28/Tucker%E5%88%86%E8%A7%A3/"/>
    <id>http://yoursite.com/2020/09/28/Tucker分解/</id>
    <published>2020-09-28T12:26:34.000Z</published>
    <updated>2020-09-28T13:33:49.195Z</updated>
    
    <content type="html"><![CDATA[<p>最近读论文，发现在交通领域中可以使用Tucker进行数据补全和降维，于是在网上查了下，下面是对于该技术简单记录。</p><a id="more"></a><p>多维的矩阵叫做张量，张量中有多维，有称为模(mode)</p><p>假设一个矩阵$R$一共有$N$维，$R \in \mathbb{R}^{I_1 \times I_2 …\times I_N}$</p><ul><li>张量$n$-mode(沿第n模)展开是将N维张量$R$沿mode-n展开成一个二维矩阵$R_{(n)}$，其中$R_{(n)} \in \mathbb{R}^{I_n \times (I_1I_2…I_{n-1}I_{n+1}…I_{N})}$。假设三维张量$A \in \mathbb{R}^{I \times J \times K}$，展开后矩阵$A_{(1)} \in \mathbb{R}^{I \times (JK)}$，$A_{(2)} \in \mathbb{R}^{J \times (IK)}$，$A_{(3)} \in \mathbb{R}^{K \times (IJ)}$</li><li>张量与矩阵n-mode乘积。张量$R \in \mathbb{R}^{I_1 \times I_2 …\times I_N}$和矩阵$A \in \mathbb{R}^{J \times I_n}$的乘积$R \times A \in \mathbb{R}^{I_1 \times …\times I_{n-1} \times J \times I_{(n+1)} \times … \times I_N}$</li></ul><script type="math/tex; mode=display">\left(R \times_{n} A\right)_{i_{1} \cdots i_{n-1} j i_{n+1} \cdots i_{N}}=\sum_{i_{n}=1}^{I_{n}} r_{i_{1} i_{2} \cdots i_{n}} a_{j i_{n}}</script><p>张量分解是矩阵分解在高维数据中的扩展，典型的张量分解方法有CP分解和Tucker分解。下面只介绍Tucker分解。</p><p>Tucker分解将N维张量分解成一个核心张量G和N个因子矩阵沿各个mode的乘积</p><script type="math/tex; mode=display">\begin{aligned}\mathcal{R} \approx & G \times_{1} \boldsymbol{A}^{(1)} \times_{2} \boldsymbol{A}^{(2)} \times \cdots \times_{N} \boldsymbol{A}^{(N)}=\\& \sum_{i_{1}=1}^{J_{1}} \sum_{i_{2}=1}^{J_{2}} \ldots \sum_{i_{N}=1}^{J_{N}} G_{i_{i} i_{2} \cdots i_{N}} a_{i_{1}}^{(1)} \circ a_{i_{2}}^{(2)} \circ \cdots \circ a_{i_{N}}^{(N)}\end{aligned}</script><p>其中$\mathcal{R} \in \mathbb{R}^{I_1 \times I_2 …\times I_N}$是原始张量；核心张量$G \in \mathbb{R}^{J_1 \times J_2 …\times J_N}$；因子矩阵$\boldsymbol{A}^{(1)} \in \mathbb{R}^{I_1 \times J_1}$，$\boldsymbol{A}^{(2)} \in \mathbb{R}^{I_2 \times J_2}$，$\boldsymbol{A}^{(N)} \in \mathbb{R}^{I_N \times J_N}$。因子矩阵可以看做原始张量在每个mode上的主成分。</p><p>下面以3维张量做Tcuker分解为例：</p><p><img src="/2020/09/28/Tucker分解/tucker分解.jpg" alt=""></p><p><strong>【参考资料】</strong></p><p><a href="https://github.com/sysuits/tensor-computations-cookbook" target="_blank" rel="noopener">面向交通数据的张量计算技术</a></p><p><a href="https://blog.csdn.net/yixianfeng41/article/details/73009210" target="_blank" rel="noopener">浅析张量分解（Tensor Decomposition）</a></p><p><a href="https://www.microsoft.com/en-us/research/publication/travel-time-estimation-of-a-path-using-sparse-trajectories/?from=http%3A%2F%2Fresearch.microsoft.com%2Fapps%2Fpubs%2F%3Fid%3D217493" target="_blank" rel="noopener">Travel Time Estimation of a Path using Sparse Trajectories</a></p><p><a href="https://xueshu.baidu.com/usercenter/paper/show?paperid=698f76f981a87d8dc1643a0f7cd1989b" target="_blank" rel="noopener">基于位置聚类和张量分解的Web服务推荐研究与应用</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近读论文，发现在交通领域中可以使用Tucker进行数据补全和降维，于是在网上查了下，下面是对于该技术简单记录。&lt;/p&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://yoursite.com/categories/Machine-Learning/"/>
    
    
      <category term="时空领域" scheme="http://yoursite.com/tags/%E6%97%B6%E7%A9%BA%E9%A2%86%E5%9F%9F/"/>
    
  </entry>
  
  <entry>
    <title>GMAN: A Graph Multi-Attention Network for Traffic Prediction</title>
    <link href="http://yoursite.com/2020/09/18/GMAN-A-Graph-Multi-Attention-Network-for-Traffic-Prediction/"/>
    <id>http://yoursite.com/2020/09/18/GMAN-A-Graph-Multi-Attention-Network-for-Traffic-Prediction/</id>
    <published>2020-09-18T01:36:38.000Z</published>
    <updated>2020-09-19T14:36:37.200Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://people.eng.unimelb.edu.au/jianzhongq/papers/AAAI2020_GMAN.pdf" target="_blank" rel="noopener">GMAN: A Graph Multi-Attention Network for Traffic Prediction</a></p><p>厦门大学在2020AAAI发表的一篇文章</p><a id="more"></a><!-- TOC --><ul><li><a href="#1-介绍">1. 介绍</a></li><li><a href="#2-问题定义">2. 问题定义</a></li><li><a href="#3-gman">3. GMAN</a><ul><li><a href="#31-spatial-temporal-embedding">3.1. Spatial-Temporal Embedding</a></li><li><a href="#32-st-att-block">3.2. ST-Att Block</a><ul><li><a href="#321-spatial-att">3.2.1. Spatial-Att</a></li><li><a href="#322-temporal-att">3.2.2. Temporal-Att</a></li><li><a href="#323-门控融合">3.2.3. 门控融合</a></li></ul></li><li><a href="#33-transform-attention">3.3. Transform Attention</a></li><li><a href="#encoder-decoder">Encoder-Decoder</a></li></ul></li><li><a href="#loss">Loss</a></li></ul><!-- /TOC --><h1><span id="1-介绍">1. 介绍</span></h1><p>交通预测一般用来预测流量或速度。现在交通状态长期预测仍然存在以下挑战：</p><ol><li><p>复杂的时空相关性</p><p><img src="/2020/09/18/GMAN-A-Graph-Multi-Attention-Network-for-Traffic-Prediction/f1.jpg" alt=""></p></li><li>对错误传播敏感。</li></ol><p>为了解决以上2个挑战，提出了GMAN，</p><ul><li>GMAN是一个encoder-decoder架构，</li><li>其中encoder和decoder中包含多个时空attention块。ST-Att块包括空间Att和时间Att。然后门控fusion对空间Att和时间Att的输出进行融合。</li><li>在encoder和decoder中间有一个transform attention层，用来转换encoder的输出结果，来作为decoder的输入。</li></ul><h1><span id="2-问题定义">2. 问题定义</span></h1><p>$G=(V,E,A)，|V|=N，A \in \mathbb{R}^{N \times N}$,$A$中元素表示2个节点的距离。图信号矩阵$X_t \in \mathbb{R}^{N \times C}$。<br>给定历史$P$个时间段，预测未来$Q$个时间段</p><script type="math/tex; mode=display">\mathcal{X}=\left(X_{t_{1}}, X_{t_{2}}, \ldots, X_{t_{P}}\right) \in \mathbb{R}^{P \times N \times C}</script><script type="math/tex; mode=display">\hat{Y} = \left(\hat{X}_{t_{P+1}}, \hat{X}_{t_{P+2}}, \ldots, \hat{X}_{t_{P+Q}}\right) \in \mathbb{R}^{Q \times N \times C}</script><h1><span id="3-gman">3. GMAN</span></h1><ul><li>Encoder和Deocder都包含L个ST-Att block。</li><li>每个STAtt block包含空间att和时间att，通过门控进行融合。</li><li>在encoder和decoder之间有一个Transform att层</li><li></li></ul><p><img src="/2020/09/18/GMAN-A-Graph-Multi-Attention-Network-for-Traffic-Prediction/f2.jpg" alt=""></p><h2><span id="31-spatial-temporal-embedding">3.1. Spatial-Temporal Embedding</span></h2><p>包括空间embedding和时间embedding。</p><ul><li>空间embedding：使用node2vec来学习图中节点的嵌入，并且嵌入矩阵中保留图的结构信息，即相邻的2个节点学到的节点嵌入相似。节点$i$的空间嵌入为$e^S_{v_i} \in \mathbb{R}^D$</li><li>时间embedding：将每一个时间步编码成一个向量。一天有T个时间段，将每个时间段使用dayOfWeek(7维)和timeOfDay(T维)来表示，然后拼接成$\mathbb{R}^{(7+T)}$，然后使用2个FCN进行嵌入成$\mathbb{R}^{D}$，使用$e^T_{t_j} \in \mathbb{R}^D$表示</li></ul><p>然后将空间嵌入和时间嵌入融合，如图b所示。对于节点$v_i$在时间$t_j$，节点嵌入表示成$e_{v_i,t_j}=e^S_{v_i}+e^T_{t_j}$，则N个节点在$P+Q$个时间段的节点嵌入为$E \in \mathbb{R}^{(P+Q) \times N \times D}$</p><h2><span id="32-st-att-block">3.2. ST-Att Block</span></h2><p>时空注意力块如图c所示。包括空间att+时间att+门控融合。</p><ul><li>第$l$个时空注意力块的输入是$H^{(l-1)}$,输出为$H^{(l)}$</li><li>节点$v_i$在第$t_j$时间段的表示为$h^{(l-1)}_{v_i,t_j}$</li><li>在第$l$个块中空间att的输出表示为$H_S^{(l)}$，一个节点表示为$h_{S_{v_i,t_j}}^{(l)}$</li><li><p>在第$l$个块中时间att的输出表示为$H_T^{(l)}$,一个节点表示为$h_{T_{v_i,t_j}}^{(l)}$</p></li><li><p>提前定义非线性FC为：</p><script type="math/tex; mode=display">f(x)=\operatorname{ReLU}(x \mathbf{W}+\mathbf{b})</script></li></ul><h3><span id="321-spatial-att">3.2.1. Spatial-Att</span></h3><p>节点之间会相互影响，且随着时间变化。空间att对不同的节点分配不同的权重。</p><p><img src="/2020/09/18/GMAN-A-Graph-Multi-Attention-Network-for-Traffic-Prediction/f3.jpg" alt=""></p><script type="math/tex; mode=display">h s_{v_{i}, t_{j}}^{(l)}=\sum_{v \in \mathcal{V}} \alpha_{v_{i}, v} \cdot h_{v, t_{j}}^{(l-1)}</script><p>$\mathcal{V}$表示所有的节点，$\alpha_{v_{i}, v}$表示节点$v$对节点$v_i$的重要性。</p><p>下面介绍$\alpha_{v_{i}, v}$怎么计算的。在某个时间段，当前的交通状况和路网结构都会影响节点间的相关性。例如一条道路拥堵可能会影响到邻居节点的交通状况。基于此，我们考虑交通特征和图结构来学习attention分数。将上一层时空att块的输出$h^{(l-1)}$和时空嵌入$e$拼接，然后使用缩放的点积相乘计算节点$v_i$和$v$的相关性。</p><script type="math/tex; mode=display">s_{v_{i}, v}=\frac{\left\langle h_{v_{i}, t_{j}}^{(l-1)}\left\|e_{v_{i}, t_{j}}, h_{v, t_{j}}^{(l-1)}\right\| e_{v, t_{j}}\right\rangle}{\sqrt{2 D}}</script><p>然后再使用softmax归一化</p><script type="math/tex; mode=display">\alpha_{v_{i}, v}=\frac{\exp \left(s_{v_{i}, v}\right)}{\sum_{v_{r} \in \mathcal{V}} \exp \left(s_{v_{i}, v_{r}}\right)}</script><p>为了稳定学习过程，我们将学习注意力机制扩展为多头注意力机制,然后再将$K$个头的结果拼接在一起。</p><script type="math/tex; mode=display">\begin{array}{c}s_{v_{i}, v}^{(k)}=\frac{\left\langle f_{s, 1}^{(k)}\left(h_{v_{i}, t_{j}}^{(l-1)} \| e_{v_{i}, t_{j}}\right), f_{s, 2}^{(k)}\left(h_{v, t_{j}}^{(l-1)} \| e_{v, t_{j}}\right)\right\rangle}{\sqrt{d}} \\\\\alpha_{v_{i}, v}^{(k)}=\frac{\exp \left(s_{v_{i}, v}^{(k)}\right)}{\sum_{v_{r} \in \mathcal{V}} \exp \left(s_{v_{i}, v_{r}}^{(k)}\right)} \\\\h_{s_{v_{i}, t_{j}}}^{(l)}=\|_{k=1}^{K}\left\{\sum_{v \in \mathcal{V}} \alpha_{v_{i}, v}^{(k)} \cdot f_{s, 3}^{(k)}\left(h_{v, t_{j}}^{(l-1)}\right)\right\}\end{array}</script><p>$f^{(k)}_{s,1}(\cdot),f^{(k)}_{s,2}(\cdot),f^{(k)}_{s,3}(\cdot)$表示ReLU非线性变换。$d=\frac{D}{K}$</p><p>如果图中节点$N$非常大，计算attention时需要$N^2$的时间复杂度，为了解决这个问题，我们提出分组空间attention，包括组内空间attention和组间空间attention。</p><p>随机将$N$个节点分成$G$组，每个组内有$M=\frac{N}{G}$个节点。先使用上面的3个公式得到每个组组内（local）的attention，计算得到$h$。然后再进行最大池化，将多个节点变成一个节点的表示。然后再计算组间的空间attention，生成每个组的全局特征。将局部特征和全局特征相加得到最终的输出。</p><p><img src="/2020/09/18/GMAN-A-Graph-Multi-Attention-Network-for-Traffic-Prediction/f5.jpg" alt=""></p><h3><span id="322-temporal-att">3.2.2. Temporal-Att</span></h3><p>在一个区域的交通状况和它前面时间段的交通状态有关，并且这种相关性随着时间变化。通过时间attention来学习不同时间段的重要性。如图5所示，使用下面公式计算节点$v_i$中$t_j$和$t$的相关性：</p><p><img src="/2020/09/18/GMAN-A-Graph-Multi-Attention-Network-for-Traffic-Prediction/f4.jpg" alt=""></p><script type="math/tex; mode=display">\begin{array}{c}u_{t_{j}, t}^{(k)}=\frac{\left\langle f_{t, 1}^{(k)}\left(h_{v_{i}, t_{j}}^{(l-1)} \| e_{v_{i}, t_{j}}\right), f_{t, 2}^{(k)}\left(h_{v_{i}, t}^{(l-1)} \| e_{v_{i}, t}\right)\right\rangle}{\sqrt{d}} \\\\\beta_{t_{j}, t}^{(k)}=\frac{\exp \left(u_{t_{j}, t}^{(k)}\right)}{\sum_{t_{r} \in \mathcal{N}_{t_{j}}} \exp \left(u_{t_{j}, t_{r}}^{(k)}\right)}\\\\h_{t_{v_{i}, t_{j}}}^{(l)}=\|_{k=1}^{K}\left\{\sum_{t \in \mathcal{N}_{t_{j}}} \beta_{t_{j}, t}^{(k)} \cdot f_{t, 3}^{(k)}\left(h_{v_{i}, t}^{(l-1)}\right)\right\}\end{array}</script><p>$\mathcal{N}_{t_{j}}$表示$t_j$之前的时间段。</p><h3><span id="323-门控融合">3.2.3. 门控融合</span></h3><p>使用门控机制来融合空间和时间表示。在第$l$个时空att块中，空间att的输出为$H_S^{(l)}$，时间att的输出为$H_T^{(l)}$，在encoder中这2个输出的维度都是$\mathbb{R}^{P \times N \times D}$，在decoder中这2个输出的维度都是$\mathbb{R}^{Q \times N \times D}$</p><script type="math/tex; mode=display">H^{(l)}=z \odot H_{S}^{(l)}+(1-z) \odot H_{T}^{(l)}</script><script type="math/tex; mode=display">z=\sigma\left(H_{S}^{(l)} \mathbf{W}_{z, 1}+H_{T}^{(l)} \mathbf{W}_{z, 2}+\mathbf{b}_{z}\right)</script><p>其中$\mathbf{W}_{z, 1} \in \mathbb{R}^{D \times D},\mathbf{W}_{z, 2} \in \mathbb{R}^{D \times D},\mathbf{b}_{z} \in \mathbb{R}^D$,$z$是门控。</p><h2><span id="33-transform-attention">3.3. Transform Attention</span></h2><p>为了缓解预测时间步间的错误传播，我们在encoder和decoder之间添加了转换层，其建模了未来时间步和历史时间步的直接关系，对历史时间步的交通特征进行编码，生成未来的表示作为decoder的输入。</p><p><img src="/2020/09/18/GMAN-A-Graph-Multi-Attention-Network-for-Traffic-Prediction/f6.jpg" alt=""></p><p>如图6所示，对于节点$v_i$，被预测时间步$t_j$和历史时间步$t (t=t_1,…t_P)$的相关性通过下面的式子计算</p><ol><li>计算$t_j$和$t$的相关性<script type="math/tex; mode=display">\lambda_{t_{j}, t}^{(k)}=\frac{\left\langle f_{t r, 1}^{(k)}\left(e_{v_{i}, t_{j}}\right), f_{t r, 2}^{(k)}\left(e_{v_{i}, t}\right)\right\rangle}{\sqrt{d}}</script></li><li><p>将$t_j$与$t_1$~$t_P$的相关性归一化</p><script type="math/tex; mode=display">\gamma_{t_{j}, t}^{(k)}=\frac{\exp \left(\lambda_{t_{j}, t}^{(k)}\right)}{\sum_{t_{r}=t_{1}}^{t_{P}} \exp \left(\lambda_{t_{j}, t_{r}}^{(k)}\right)}</script></li><li><p>对$t_1$~$t_P$的输出进行融合，得到decoder的输入</p><script type="math/tex; mode=display">h_{v_{i}, t_{j}}^{(l)}=\|_{k=1}^{K}\left\{\sum_{t=t_{1}}^{t_{P}} \gamma_{t_{j}, t}^{(k)} \cdot f_{t r, 3}^{(k)}\left(h_{v_{i}, t}^{(l-1)}\right)\right\}</script></li></ol><h2><span id="encoder-decoder">Encoder-Decoder</span></h2><p>GMAN是一个encoder-decoder架构，</p><ul><li>输入数据是$X \in \mathbb{R}^{P \times N \times C}$，然后输入到FC中，生成$H^{(0)} \in \mathbb{R}^{P \times N \times D}$，同时STE生成时空嵌入$E \in \mathbb{R}^{(P+Q) \times N \times D}$。</li><li>$H^{(0)}$和$E$输入到L个时空注意力block中，输出$H^{(L)} \in \mathbb{R}^{P \times N \times D}$</li><li>然后转换层对$H^{(L)}$进行编码，生成未来序列表示$H^{(L+1)} \in \mathbb{R}^{Q \times N \times D}$</li><li>在decoder中堆叠L个时空注意力block，输出$H^{(2L+1)} \in \mathbb{R}^{Q \times N \times D}$</li><li>后跟一个FC，生成最终的结果$\hat{Y} \in \mathbb{R}^{Q \times N \times D}$</li></ul><p><img src="/2020/09/18/GMAN-A-Graph-Multi-Attention-Network-for-Traffic-Prediction/f2.jpg" alt=""></p><h1><span id="loss">Loss</span></h1><p>MAE损失函数</p><script type="math/tex; mode=display">\mathcal{L}(\Theta)=\frac{1}{Q} \sum_{t=t_{P+1}}^{t_{P+Q}}\left|Y_{t}-\hat{Y}_{t}\right|</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://people.eng.unimelb.edu.au/jianzhongq/papers/AAAI2020_GMAN.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GMAN: A Graph Multi-Attention Network for Traffic Prediction&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;厦门大学在2020AAAI发表的一篇文章&lt;/p&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="时空领域" scheme="http://yoursite.com/tags/%E6%97%B6%E7%A9%BA%E9%A2%86%E5%9F%9F/"/>
    
  </entry>
  
  <entry>
    <title>Multi-Range Attentive Bicomponent Graph Convolutional Network for Traffic Forecasting</title>
    <link href="http://yoursite.com/2020/09/17/Multi-Range-Attentive-Bicomponent-Graph-Convolutional-Network-for-Traffic-Forecasting/"/>
    <id>http://yoursite.com/2020/09/17/Multi-Range-Attentive-Bicomponent-Graph-Convolutional-Network-for-Traffic-Forecasting/</id>
    <published>2020-09-17T06:35:17.000Z</published>
    <updated>2020-09-18T02:03:55.671Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/ftp/arxiv/papers/1911/1911.12093.pdf" target="_blank" rel="noopener">Multi-Range Attentive Bicomponent Graph Convolutional Network for Traffic Forecasting</a></p><p>发表于AAAI2020</p><a id="more"></a><!-- TOC --><ul><li><a href="#1-介绍">1. 介绍</a></li><li><a href="#2-相关工作">2. 相关工作</a></li><li><a href="#3-问题定义">3. 问题定义</a></li><li><a href="#4-mra-bgcn">4. MRA-BGCN</a><ul><li><a href="#41-bicomponent-gcn">4.1. Bicomponent GCN</a></li><li><a href="#42-multi-range-attention">4.2. Multi-Range Attention</a></li><li><a href="#43-结合rnn">4.3. 结合RNN</a></li></ul></li></ul><!-- /TOC --><h1><span id="1-介绍">1. 介绍</span></h1><p>本文的任务是给定一个道路图历史的交通数据，预测未来的交通状况。该任务主要有以下2个挑战：</p><ol><li>不规则的路网导致交通数据间存在复杂时空依赖</li><li>各种各样不可预测的交通状况，使得交通数据具有不确定性</li></ol><p>以前的工作一般使用CNN来处理网格数据，使用GCN+RNN(DCRNN)或GCN+CNN(STGCN)来处理图数据。但是这些方法仍然忽略了以下2方面：</p><ol><li>原先的方法使用GCN都是基于一个固定的权重矩阵。如下图所示，图中有3个节点，其中节点1和3，节点2和3通过道路连接，现在的方法基本都是根据节点之间的距离来创建图，图的权重权重是不变的，但节点之间的权重并不是一成不变的，这种构图方法忽略了节点之间复杂的影响关系。</li></ol><p>   <img src="/2020/09/17/Multi-Range-Attentive-Bicomponent-Graph-Convolutional-Network-for-Traffic-Forecasting/f1.jpg" alt=""></p><ol><li>构建完图后，原先的方法一般使用GCN融合K跳邻居的信息进行聚合，但是却忽略了多个范围(multiple range)的信息。不同范围的信息反映了不同的交通属性。小范围的邻居揭示了局部依赖，大范围的邻居揭示了全局模式。并且不同范围的信息应该有不同的贡献。例如在一次交通事故中，目标区域主要受邻接区域的影响，所以模型也应该更关注这些区域，而不是对所有的K跳邻居都赋予相同的权重。</li></ol><p>为了解决以上2个问题，我们提出Multi-Range Attentive Bicomponent Graph Convolutional Network (MRA-BGCN),不仅考虑了节点信息，而且把边作为实体，考虑边之间的交互。如图1(C)所示。该文章的共享如下：</p><ol><li><p>提出MRA-BGCN，引入bicomponent图卷积，同时建模节点和边的相关性。节点图根据路网距离来构架，边图的构建考虑了2种模式：stream连通性、竞争关系。</p></li><li><p>为bicomponent图卷积提出多范围的attention机制，可以聚合不同范围的邻居信息并学到它们的权重</p></li><li>在METR-LA和PEMS-BAY这2个数据集上进行实验</li></ol><h1><span id="2-相关工作">2. 相关工作</span></h1><p>DCRNN和STGCN使用固定的图结构<br>Graph WaveNet通过学习自适应的邻接矩阵来解决这个问题，但是隐藏的空间依赖是以数据驱动的方式来学习的，缺乏领域知识的指导，可能会出现过拟合的问题。</p><p>现有的方法无法对边之间的交互进行建模。</p><h1><span id="3-问题定义">3. 问题定义</span></h1><p>$G=(V,E,A),|V|=N$，其中$A \in \mathbb{R}^{N \times N}$表示邻接矩阵，邻接矩阵通过路网的距离构建。图信号矩阵$X^{(t)} \in \mathbb{R}^{N \times P}$。预测任务是给定历史$T’$个时间段的图信号矩阵，预测未来$T$个时间段的图信号矩阵</p><script type="math/tex; mode=display">\left[X^{\left(t-T^{\prime}+1\right): t}, G\right] \stackrel{f}{\rightarrow}\left[X^{(t+1):(t+T)}\right]</script><p>$X^{\left(t-T^{\prime}+1\right): t} \in \mathbb{R}^{N \times P \times T’}$，$X^{(t+1):(t+T)} \in \mathbb{R}^{N \times P \times T}$</p><p>本文中用到的图卷积定义如下：</p><script type="math/tex; mode=display">\boldsymbol{\theta}_{\star G} \boldsymbol{X}=\rho\left(\tilde{\boldsymbol{D}}^{-1} \tilde{\boldsymbol{A}} \boldsymbol{X} \boldsymbol{\theta}\right)</script><h1><span id="4-mra-bgcn">4. MRA-BGCN</span></h1><p>该模型包括2部分：bicomponent图卷积模块、多范围attention模块。</p><ul><li>bicomponent图卷积模块包括节点图卷积、边图卷积，可以显式建模节点和边的相关性。</li><li>多范围attention层聚合不同范围的邻居信息，并学习它们的重要性权重。</li><li>除此之外，我们还将MRA-BGCN和RNN结合起来建模时间依赖。</li></ul><p><img src="/2020/09/17/Multi-Range-Attentive-Bicomponent-Graph-Convolutional-Network-for-Traffic-Forecasting/f2.jpg" alt=""></p><h2><span id="41-bicomponent-gcn">4.1. Bicomponent GCN</span></h2><p>首次创建2个图：节点图、边图</p><p>$G=(V,E,A)$表示<strong>节点图</strong>，$|V|=N$，每个节点表示sensor，边表示sensor之间的距离，邻接矩阵是权重邻接矩阵。</p><p>$G_e=(V_e,E_e,A_e)$表示<strong>边图</strong>,其中$|V_e|=|E|$，每个节点表示$E$中一条边。在邻接矩阵$A_e$中，有2种边的连接模式。</p><ul><li><p>上下游连接：如下图a所示，边(i,j)是边(j,k)的上游边，因此这2条边是相关的。如果点j有很多邻接，也就是说点j的度很大，则边(i,j)和边(j,k)的相关性就变得很弱。我们使用下面的公式计算这2条边的相关性。</p><script type="math/tex; mode=display">\begin{array}{c}A_{e,(i \rightarrow j),(j \rightarrow k)}=A_{e,(j \rightarrow k),(i \rightarrow j)}=\exp \left(-\frac{\left(\mathrm{deg}^{-}(j)+\mathrm{deg}^{+}(j)-2\right)^{2}}{\sigma^{2}}\right)\end{array}</script><p>其中$\mathrm{deg}^{-}(j)$和$\mathrm{deg}^{+}(j)$表示点j的入度和出度。$\sigma$表示节点度的标准差。</p></li><li><p>竞争连接：当2个节点共享一个源节点或目标节点，可能会争夺交通资源，使得这2条边产生竞争关系。如下图b所示。边(j,k)和边(i,k)共享目标节点k，如果源节点有很多邻居，则(j,k)和(i,k)的竞争连接就会变强。使用下面的公式计算这2条边的连接权重：</p><script type="math/tex; mode=display">\begin{array}{l}A_{e,(i \rightarrow k),(j \rightarrow k)}=A_{e,(j \rightarrow k),(i \rightarrow k)}= \exp \left(-\frac{\left(\mathrm{deg}^{+}(i)+\mathrm{deg}^{+}(j)-2\right)^{2}}{\sigma^{2}}\right)\end{array}</script></li></ul><p><img src="/2020/09/17/Multi-Range-Attentive-Bicomponent-Graph-Convolutional-Network-for-Traffic-Forecasting/f3.jpg" alt=""></p><p>根据上面2种连接，构建好边图$G_e$，如图2所示，bicomponent图卷积可以建模节点和边的相关性。</p><p>下面做bicomponent GCN的步骤是：</p><p>现在有节点图和边图，已知节点图的图信号矩阵$X$,但是不知道边图的图信号矩阵。</p><ol><li>根据节点图的图信号矩阵$X \in \mathbb{R}^{N \times P}$,和$M \in \mathbb{R}^{|V| \times |E|}$相乘得到边图的图信号矩阵$Z \in \mathbb{R}^{|E| \times P}$，然后再和$W_b$相乘做一个线性变换，得到$Z \in \mathbb{R}^{|E| \times P}$</li><li>然后对节点图$X$做GCN操作，得到下一层的输出$X^{(l)} \in \mathbb{R}^{N \times P}$</li><li>对边图$Z$做GCN操作，得到下一层的输出$Z^{(l)} \in \mathbb{R}^{|E| \times D}$ </li><li>然后将这2个图信号矩阵拼接，再做一次GCN操作，得到$X^{(l+1)}$</li></ol><ul><li>每个节点图的图信号矩阵$X^{(l+1)}$都是由$X^{(l)}$和$Z^{(l)}$计算得到</li><li>每个边图的图信号矩阵$Z^{(l+1)}$都是由自己的$Z^{(l)}$计算得到。</li></ul><p><img src="/2020/09/17/Multi-Range-Attentive-Bicomponent-Graph-Convolutional-Network-for-Traffic-Forecasting/f4.png" alt=""></p><p>$X^{(l-1)}$是第$l$层节点图卷积层的输入，$Z^{(l-1)}$是第$l$层边图卷积的输入。$M \in \mathbb{R}^{|V| \times |E|}$表示节点和边的关联矩阵。$M_{i,(i,j)}=M_{j,(i,j)}=1$，通过$MZ^{(\cdot)}$聚合每个节点的边的表示。$M^TX^{(\cdot)}$聚合每条边的节点表示。$W_b$是可学习的矩阵，从原始的节点输入$X^{(0)}$转换成边输入$Z^{(0)}$</p><h2><span id="42-multi-range-attention">4.2. Multi-Range Attention</span></h2><p>提出多范围attention机制来自动学习不同范围邻居的权重。</p><p>通过bicomponent图卷积，我们可以得到不同范围邻居的节点表示：$\boldsymbol{X}=\left\{\boldsymbol{X}^{(1)}, \boldsymbol{X}^{(2)}, \cdots, \boldsymbol{X}^{(k)}\right\}, \boldsymbol{X}^{(l)} \in \mathbb{R}^{|V| \times F}$。多范围attention层主要是就是不同范围的邻居信息，形成一个整合的节点表示。为了实现这个目标，首先一个共享的线性变换成$W_a \in \mathbb{R}^{F \times F’}$，作用在不同层的节点表示$X^{(l)}$上。</p><p>对于节点$i$，首先进行线性变换$W_aX^{(l)}_i$，$u$表示邻居上下文嵌入向量，是可学习参数。</p><script type="math/tex; mode=display">\begin{array}{c}e_{i}^{(l)}=\left(\boldsymbol{W}_{\mathrm{a}} \boldsymbol{X}_{i}^{(l)}\right)^{\mathrm{T}} \boldsymbol{u} \\\\a_{i}^{(l)}=\operatorname{SoftMax}_{l}\left(e_{i}^{(l)}\right)=\frac{\exp \left(e_{i}^{(l)}\right)}{\sum_{l=1}^{k} \exp \left(e_{i}^{(l)}\right)}\\\\\boldsymbol{h}_{i}=\sum_{l=1}^{k} a_{i}^{(l)} \boldsymbol{X}_{i}^{(l)}\end{array}</script><p>通过多范围Attention机制，对不同跳的邻居赋予不同的权重，得到最终的图信号矩阵。</p><h2><span id="43-结合rnn">4.3. 结合RNN</span></h2><p>参考DCRNN，把GRU中的全连接操作全都换成MRA-BGCN操作。</p><p><img src="/2020/09/17/Multi-Range-Attentive-Bicomponent-Graph-Convolutional-Network-for-Traffic-Forecasting/f5.jpg" alt=""></p><p><img src="/2020/09/17/Multi-Range-Attentive-Bicomponent-Graph-Convolutional-Network-for-Traffic-Forecasting/f4.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/ftp/arxiv/papers/1911/1911.12093.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Multi-Range Attentive Bicomponent Graph Convolutional Network for Traffic Forecasting&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;发表于AAAI2020&lt;/p&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="时空领域" scheme="http://yoursite.com/tags/%E6%97%B6%E7%A9%BA%E9%A2%86%E5%9F%9F/"/>
    
  </entry>
  
  <entry>
    <title>Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting</title>
    <link href="http://yoursite.com/2020/09/11/Diffusion-Convolutional-Recurrent-Neural-Network-Data-Driven-Traffic-Forecasting/"/>
    <id>http://yoursite.com/2020/09/11/Diffusion-Convolutional-Recurrent-Neural-Network-Data-Driven-Traffic-Forecasting/</id>
    <published>2020-09-11T07:10:53.000Z</published>
    <updated>2020-09-11T11:37:51.529Z</updated>
    
    <content type="html"><![CDATA[<p>2018ICLR的一篇论文：<a href="https://arxiv.org/abs/1707.01926" target="_blank" rel="noopener">Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting</a></p><a id="more"></a><p>时空预测主要有以下挑战：</p><ol><li>基于道路网络，存在复杂的空间依赖</li><li>交通状态会随着时间变化，存在动态性</li><li>long-term预测比较困难</li></ol><p>基于以上问题，本文根据交通流量的扩散过程，构建一个有向图，并且引入扩散卷积+RNN=DCRNN，融合时间和空间依赖，预测交通流量。DCRNN通过在图上进行双向随机游走来捕获空间依赖，使用encoder-decoder来捕获时间依赖。</p><!-- TOC --><ul><li><a href="#1-介绍">1. 介绍</a></li><li><a href="#2-问题定义">2. 问题定义</a></li><li><a href="#3-dcrnn">3. DCRNN</a><ul><li><a href="#31-空间依赖建模">3.1. 空间依赖建模</a></li><li><a href="#32-时间动态性建模">3.2. 时间动态性建模</a></li><li><a href="#33-encoder-deocder">3.3. Encoder-Deocder</a></li></ul></li><li><a href="#4-实验">4. 实验</a><ul><li><a href="#41-数据集">4.1. 数据集</a></li><li><a href="#42-实验结果">4.2. 实验结果</a></li></ul></li></ul><!-- /TOC --><h1><span id="1-介绍">1. 介绍</span></h1><p>本文研究的主要任务是：在道路图上进行交通速度预测。</p><p>下图中给出了3条路的交通速度，道路1和道路3虽然离得很近，但是速度模式却完全不同，说明<strong>交通速度的空间结构是非欧式且有向的</strong>。</p><p><img src="/2020/09/11/Diffusion-Convolutional-Recurrent-Neural-Network-Data-Driven-Traffic-Forecasting/road.jpg" alt=""></p><p><strong>DCRNN = 扩散卷积 + encoder-decoder + 采样技术</strong></p><h1><span id="2-问题定义">2. 问题定义</span></h1><p>首先构建一个有向图。</p><ul><li>节点：sensor线圈感知器，$N$个节点</li><li>边的权重：2个sensor在道路上的距离，$W \in \mathbb{R}^{N \times N}$表示图的权重邻接矩阵</li><li>图信号矩阵$X \in \mathbb{R}^{N \times P}$,表示每个节点的traffic flow，speed</li><li>给定历史$T’$个时间段，预测未来$T$个时间段</li></ul><script type="math/tex; mode=display">\left[\boldsymbol{X}^{\left(t-T^{\prime}+1\right)}, \cdots, \boldsymbol{X}^{(t)} ; \mathcal{G}\right] \stackrel{h(\cdot)}{\longrightarrow}\left[\boldsymbol{X}^{(t+1)}, \cdots, \boldsymbol{X}^{(t+T)}\right]</script><h1><span id="3-dcrnn">3. DCRNN</span></h1><h2><span id="31-空间依赖建模">3.1. 空间依赖建模</span></h2><p>在图上进行随机游走，重启概率是$\alpha \in [0,1]$，状态转移矩阵$D^{-1}_OW$.其中$D_O=diag(W \mathbf{1})表示图的出度$, $\mathbf{1}$表示全1的向量。经过很多次的随机游走，这样的马尔科夫过程逐渐收敛到一个静态的分布$\mathcal{P} \in \mathbb{R}^{N \times N}$，其中第$i$行$\mathcal{P}_{i,:} \in \mathbb{R}^N$表示从节点$i$到其他节点的扩散可能性大小。<br>下面是在图上无限次随机游走的转移矩阵</p><script type="math/tex; mode=display">\mathcal{P}=\sum_{k=0}^{\infty} \alpha(1-\alpha)^{k}\left(\boldsymbol{D}_{O}^{-1} \boldsymbol{W}\right)^{k}</script><p>其中$k$表示转移的次数，我们通常使用有限次的$K$步转移矩阵。</p><p><strong>扩散卷积</strong></p><p>下面给出扩散卷积的计算公式：</p><script type="math/tex; mode=display">\boldsymbol{X}_{:, p} \star_{\mathcal{G}} f_{\boldsymbol{\theta}}=\sum_{k=0}^{K-1}\left(\theta_{k, 1}\left(\boldsymbol{D}_{O}^{-1} \boldsymbol{W}\right)^{k}+\theta_{k, 2}\left(\boldsymbol{D}_{I}^{-1} \boldsymbol{W}^{\top}\right)^{k}\right) \boldsymbol{X}_{:, p} \quad \text { for } p \in\{1, \cdots, P\}</script><p>这是<strong>一个特征</strong>的扩散卷积操作。</p><p>其中$p$表示第$p$个特征，为每个特征计算一个扩散性。$\theta \in \mathbb{R}^{K \times 2}$是扩散卷积核参数，$\boldsymbol{D}_{O}^{-1} \boldsymbol{W}$和$\boldsymbol{D}_{I}^{-1} \boldsymbol{W}^{\top}$表示扩散过程中的转移矩阵和逆转移矩阵。</p><p><strong>扩散卷积层</strong></p><p>基于上面的扩散卷积操作，定义扩散卷积层，将每个节点$P$维特征映射成$Q$维特征。</p><script type="math/tex; mode=display">\boldsymbol{H}_{:, q}=\boldsymbol{a}\left(\sum_{p=1}^{P} \boldsymbol{X}_{:, p} \star_{\mathcal{G}}  f_{\boldsymbol{\Theta}_{q, p,:,:}}\right) \quad \text { for } q \in\{1, \cdots, Q\}</script><p>其中$\boldsymbol{\Theta} \in \mathbb{R}^{Q \times P \times K \times 2}$, $\boldsymbol{\Theta}_{q, p,:,:} \in \mathbb{R}^{K \times 2}$</p><p>$\boldsymbol{X} \in \mathbb{R}^{N \times P}$表示输入图信号矩阵，$\boldsymbol{H} \in \mathbb{R}^{N \times Q}$表示输出图信号矩阵。在扩散卷积层，假设每个节点有3个特征，则就有3个扩散表示，然后再把这3个扩散表示加起来。</p><p><strong>和谱图卷积的关系</strong></p><p>扩散卷积可以定义在有向图上或无向图上。当应用在无向图上，现在的谱图卷积，例如ChebNet就可以看做是扩散卷积的特例。</p><h2><span id="32-时间动态性建模">3.2. 时间动态性建模</span></h2><p>利用GRU来建模时间依赖。将GRU中矩阵相乘，全都变成扩散卷积操作。</p><p><img src="/2020/09/11/Diffusion-Convolutional-Recurrent-Neural-Network-Data-Driven-Traffic-Forecasting/scrnn.jpg" alt=""></p><h2><span id="33-encoder-deocder">3.3. Encoder-Deocder</span></h2><p>因为本文在时间上是多对多的预测，这里使用seq2seq架构。其中encoder和decoder都是DCGRU模型。<br>在训练阶段，将历史时间序列输入到encoder中，然后使用最后一个时间段的隐藏状态初始化decoder。</p><p><img src="/2020/09/11/Diffusion-Convolutional-Recurrent-Neural-Network-Data-Driven-Traffic-Forecasting/dcrnn.jpg" alt=""></p><p><strong>【注意】</strong></p><ul><li>在训练阶段，decoder使用上一个时间段的真值作为输入，进行预测</li><li>在测试阶段，由于获取不到真值，使用上一个时间段模型的预测值作为输入。</li></ul><p>但是上面这种训练方法会导致训练和测试的输入分布不同，导致预测性能下降，为了解决这个问题，本文在训练阶段，不全部使用真值作为decoder的输入，而是以概率$\epsilon_i$输入真值，以$1-\epsilon_i$输入上个时间段的预测值。这样可以保证训练和预测中，decoder的输入分布不会差别太多。</p><h1><span id="4-实验">4. 实验</span></h1><h2><span id="41-数据集">4.1. 数据集</span></h2><p>2个数据集</p><ul><li>METR-LA：洛杉矶高速公路的车辆速度，207个节点</li><li>PEMS-BAY：加州，325个节点</li></ul><p>下图是这2个数据集中节点的分布情况。</p><p><img src="/2020/09/11/Diffusion-Convolutional-Recurrent-Neural-Network-Data-Driven-Traffic-Forecasting/sensor.jpg" alt=""></p><p>这2个数据集，都是5min聚合一次，使用Z-score归一化。训练集:验证集:测试集=7:1:2。<br>根据任意2个节点的距离构建邻接矩阵，如果$\operatorname{dist}\left(v_{i}, v_{j}\right) &lt;= k$，则邻接矩阵中为0，否则为$W_{i j}$</p><script type="math/tex; mode=display">W_{i j}=\exp \left(-\frac{\operatorname{dist}\left(v_{i}, v_{j}\right)^{2}}{\sigma^{2}}\right)</script><h2><span id="42-实验结果">4.2. 实验结果</span></h2><p><img src="/2020/09/11/Diffusion-Convolutional-Recurrent-Neural-Network-Data-Driven-Traffic-Forecasting/result.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;2018ICLR的一篇论文：&lt;a href=&quot;https://arxiv.org/abs/1707.01926&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="时空领域" scheme="http://yoursite.com/tags/%E6%97%B6%E7%A9%BA%E9%A2%86%E5%9F%9F/"/>
    
  </entry>
  
  <entry>
    <title>Graph WaveNet for Deep Spatial-Temporal Graph Modeling</title>
    <link href="http://yoursite.com/2020/08/23/Graph-WaveNet-for-Deep-Spatial-Temporal-Graph-Modeling/"/>
    <id>http://yoursite.com/2020/08/23/Graph-WaveNet-for-Deep-Spatial-Temporal-Graph-Modeling/</id>
    <published>2020-08-23T08:54:35.000Z</published>
    <updated>2020-09-11T11:49:09.219Z</updated>
    
    <content type="html"><![CDATA[<p>论文地址：<a href="https://arxiv.org/pdf/1906.00121.pdf" target="_blank" rel="noopener">Graph WaveNet for Deep Spatial-Temporal Graph Modeling</a></p><a id="more"></a><!-- TOC --><ul><li><a href="#1-动机">1. 动机</a></li><li><a href="#2-问题定义">2. 问题定义</a></li><li><a href="#3-模型设计">3. 模型设计</a><ul><li><a href="#31-图卷积层">3.1. 图卷积层</a></li><li><a href="#32-时间卷积层">3.2. 时间卷积层</a></li></ul></li></ul><!-- /TOC --><h1><span id="1-动机">1. 动机</span></h1><p>现在的时空图建模都是在一个静态图上进行建模，即图的邻接矩阵不变，并且现有的方法一般使用RNN或CNN来捕获时间特征，不能捕获长期的时间依赖。为了解决这2个限制，提出Graph WaveNet，图的邻接矩阵随时间变化，在时间维度上使用1D空洞卷积来捕获长期依赖。</p><p>为了捕获时空数据，现在一般有2种方法：</p><ol><li>GCN+RNN</li><li>GCN+CNN</li></ol><p>但是这2种方法中2个节点的相互依赖都建立在连接的基础上，但有些节点不连接仍然存在相互依赖的关系；当前的这种方法没有很有效的学习到时间依赖，RNN耗时且存在梯度消失问题，CNN可以并行，但需要堆叠很多层。</p><h1><span id="2-问题定义">2. 问题定义</span></h1><p>定义图$G=(V,E)$,其中邻接矩阵$A$非0即1，在第$t$个时间步，图信号矩阵$X^{(t)}\in \mathbb{R}^{N \times D}$</p><p>给定图$G$和历史$S$个时间段的图信号矩阵，预测未来$T$个时间段的图信号矩阵。</p><p><img src="/2020/08/23/Graph-WaveNet-for-Deep-Spatial-Temporal-Graph-Modeling/问题定义.jpg" alt=""></p><h1><span id="3-模型设计">3. 模型设计</span></h1><p><img src="/2020/08/23/Graph-WaveNet-for-Deep-Spatial-Temporal-Graph-Modeling/模型图.jpg" alt=""></p><h2><span id="31-图卷积层">3.1. 图卷积层</span></h2><p>在介绍之前，我们先看一下DCRNN提出的扩散矩阵操作：</p><p><strong>1. 无向图</strong></p><script type="math/tex; mode=display">\mathbf{Z}=\sum_{k=0}^{K} \mathbf{P}^{k} \mathbf{X} \mathbf{W}_{\mathbf{k}}</script><p>其中$\mathbf{P}$是转移矩阵，如果是无向图的话，$\mathbf{P}=\mathbf{A} / \operatorname{rowsum}(\mathbf{A})$</p><p><strong>2. 有向图</strong></p><p>如果是有向图的话，需要计算入的方向和出的方向。<br>$\mathbf{P}_{f}=\mathbf{A} / \operatorname{rowsum}(\mathbf{A})$，$\mathbf{P}_{b}=\mathbf{A}^{\mathbf{T}} /$rowsum$\left(\mathbf{A}^{\mathbf{T}}\right)$</p><p>此时的图卷积操作就变成：</p><script type="math/tex; mode=display">\mathbf{Z}=\sum_{k=0}^{K} \mathbf{P}_{f}^{k} \mathbf{X} \mathbf{W}_{k 1}+\mathbf{P}_{b}^{k} \mathbf{X} \mathbf{W}_{k 2}</script><p>在本文中，提出一个<strong>自适应的邻接矩阵</strong>$\tilde{A}_{adp}$，即邻接矩阵是学出来的，并不是提前定义好的。</p><p>首先初始化2个节点嵌入矩阵$E_1,E_2 \in \mathbb{R}^{N \times c}$，</p><script type="math/tex; mode=display">\tilde{\mathbf{A}}_{a d p}=\operatorname{SoftMax}\left(\operatorname{ReLU}\left(\mathbf{E}_{1} \mathbf{E}_{2}^{T}\right)\right)</script><p>通过上面的式子，可以得到自适应的邻接矩阵$\tilde{A}_{adp}$，下面定义图卷积层的操作。</p><p><strong>1. 如果图的结构已知</strong><br>   参考DCRNN的扩散卷积的操作</p><ul><li><p>无向图</p><script type="math/tex; mode=display">\mathbf{Z}=\sum_{k=0}^{K} \mathbf{P}^{k} \mathbf{X} \mathbf{W}_{k 1}+\tilde{\mathbf{A}}_{a p t}^{k} \mathbf{X} \mathbf{W}_{k 3}</script></li><li><p>有向图</p><script type="math/tex; mode=display">\mathbf{Z}=\sum_{k=0}^{K} \mathbf{P}_{f}^{k} \mathbf{X} \mathbf{W}_{k 1}+\mathbf{P}_{b}^{k} \mathbf{X} \mathbf{W}_{k 2}+\tilde{\mathbf{A}}_{a p t}^{k} \mathbf{X} \mathbf{W}_{k 3}</script></li></ul><p><strong>2. 图的结构未知</strong></p><script type="math/tex; mode=display">\mathbf{Z}=\sum_{k=0}^{K} \tilde{\mathbf{A}}_{a p t}^{k} \mathbf{X} \mathbf{W}_{k}</script><p>通过自适应的图卷积得到图中节点嵌入</p><h2><span id="32-时间卷积层">3.2. 时间卷积层</span></h2><p>使用1D空洞卷积TCN来捕获长期的时间依赖，因为空洞卷积可以扩大感受野的范围，可以捕获到更长的时间。同时，这里使用了门控TCN，</p><script type="math/tex; mode=display">\mathbf{h}=g\left(\boldsymbol{\Theta}_{1} \star \mathcal{X}+\mathbf{b}\right) \odot \sigma\left(\boldsymbol{\Theta}_{2} \star \mathcal{X}+\mathbf{c}\right)</script><p>输入数据$\mathcal{X} \in \mathbb{R}^{N \times D \times S}$，$\star$表示1D空洞卷积操作。$g(\cdot)$使用Tanh激活函数。</p><p>下面介绍模型的步骤</p><p><img src="/2020/08/23/Graph-WaveNet-for-Deep-Spatial-Temporal-Graph-Modeling/模型图.jpg" alt=""></p><p>求自适应邻接矩阵—&gt;T-GCN—&gt;GCN</p><ol><li>首先模型的输入维度是(batch_size,D,N,T),首先经过$1*1$的2D卷积层，将节点特征D转换维度，变成(batch_size,D1,N,T)</li><li>计算自适应邻接矩阵，首先初始化2个可学习的节点嵌入矩阵$\mathbf{E}_1,\mathbf{E}_2$,维度都是$\mathbb{R}^{N \times 10}$,然后使用下面的式子计算$\mathbf{A}_{adp}=F.softmax(F.relu(torch.mm(E1, E2)), dim=1)$</li><li><p>将(batch_size,D1,N,T)输入到Gated-TCN中，首先输入到TCN-a（2D卷积当1D卷积用，卷积核中有1维为1）中，2D卷积的输入维度是D1，输出维度是D2，卷积核大小为(1,k)，然后再经过Tanh，输出维度(batch_size,D2,N,T)</p><script type="math/tex; mode=display">Tanh \left(\boldsymbol{\Theta}_{1} \star \mathcal{X}+\mathbf{b}\right)</script></li><li>将(batch_size,D1,N,T)输入到TCN-b（2D卷积当1D卷积用，卷积核中有1维为1）中，2D卷积的输入维度是D1，输出维度是D2，卷积核大小为(1,k)，然后再经过Sigmoid，输出维度(batch_size,D2,N,T)<script type="math/tex; mode=display">\sigma\left(\boldsymbol{\Theta}_{2} \star \mathcal{X}+\mathbf{c}\right)</script></li><li>将步骤3和步骤4的输出逐元素相乘<script type="math/tex; mode=display">\mathbf{h}=Tanh \left(\boldsymbol{\Theta}_{1} \star \mathcal{X}+\mathbf{b}\right) \odot \sigma\left(\boldsymbol{\Theta}_{2} \star \mathcal{X}+\mathbf{c}\right)</script></li><li>将步骤5的输出(batch_size,D2,N,T)，输入到skip-conv（1D卷积），改变通道维度为(batch_size,D3,N,T)存储在skip变量中，一共有K层，将K层G-TCN的输出加起来得到(batch_size,D3,N,T)</li><li><p>下面进行GCN操作，将步骤5的输出(batch_size,D2,N,T)=x，假设有2个邻接矩阵，一个是已知的邻接矩阵$\mathbf{P}$,一个是自适应邻接矩阵$\mathbf{A}_{a p t}$，先遍历第一个邻接矩阵，$\mathbf{P}X$保存取来，然后在$\mathbf{P}^2X$，直到$\mathbf{P}^kX$，然后再求$\mathbf{A}_{a p t}X,\mathbf{A}_{a p t}^2X,\mathbf{A}_{a p t}^kX$。一共有2个邻接矩阵，每个邻接矩阵都有K个值，将这2K个值在通道维上拼接，得到$(batch_size,2<em>K</em>D2,N,T)$，然后在经过一个全连接，将维度映射成D1，即(batch_size,D1,N,T)</p><script type="math/tex; mode=display">\mathbf{Z}=\sum_{k=0}^{K} \mathbf{P}^{k} \mathbf{X} \mathbf{W}_{k 1}+\tilde{\mathbf{A}}_{a p t}^{k} \mathbf{X} \mathbf{W}_{k 3}</script></li><li><p>将步骤7的输出和步骤1的输出做残差连接，直接相加，再经过一个BN层，完成一个block。接下来就再次经过G-TCN和GCN，重复步骤3-7</p></li><li>所有的block完成之后，输出维度(batch_size,D1,N,T),但我们并不是要GCN的输出，而是需要每个TGCN的输出保存在skip中，维度(batch_size,D3,N,T)，先使用ReLU激活，然后使用$1 \times 1$的2D卷积，变成维度(batch_size,D4,N,T),再ReLU，然后是$1 \times 1$卷积</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;论文地址：&lt;a href=&quot;https://arxiv.org/pdf/1906.00121.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Graph WaveNet for Deep Spatial-Temporal Graph Modeling&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="时空领域" scheme="http://yoursite.com/tags/%E6%97%B6%E7%A9%BA%E9%A2%86%E5%9F%9F/"/>
    
      <category term="GCN" scheme="http://yoursite.com/tags/GCN/"/>
    
  </entry>
  
  <entry>
    <title>稀疏数据处理</title>
    <link href="http://yoursite.com/2020/08/19/%E7%A8%80%E7%96%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    <id>http://yoursite.com/2020/08/19/稀疏数据处理/</id>
    <published>2020-08-19T03:34:45.000Z</published>
    <updated>2020-09-08T09:07:05.871Z</updated>
    
    <content type="html"><![CDATA[<p>在实际数据中，经常会遇到数据稀疏的问题，即数据中存在大量的0，且非零元素呈不规律分布。这就是稀疏矩阵。</p><a id="more"></a><p><img src="/2020/08/19/稀疏数据处理/系数矩阵.jpg" alt=""></p><h1><span id="1-稀疏矩阵处理">1. 稀疏矩阵处理</span></h1><p>通常，为了处理稀疏性矩阵，我们通常会压缩行和列；或者通过PCA/SVD进行降维。</p><p>矩阵压缩</p><p>降维</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在实际数据中，经常会遇到数据稀疏的问题，即数据中存在大量的0，且非零元素呈不规律分布。这就是稀疏矩阵。&lt;/p&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://yoursite.com/categories/Machine-Learning/"/>
    
    
      <category term="数据稀疏" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E7%A8%80%E7%96%8F/"/>
    
  </entry>
  
  <entry>
    <title>Excel转换为Latex</title>
    <link href="http://yoursite.com/2020/08/14/Excel%E8%BD%AC%E6%8D%A2%E4%B8%BALatex/"/>
    <id>http://yoursite.com/2020/08/14/Excel转换为Latex/</id>
    <published>2020-08-14T15:15:01.000Z</published>
    <updated>2020-08-21T15:20:17.278Z</updated>
    
    <content type="html"><![CDATA[<p>转载</p><p><a href="https://blog.csdn.net/Jiajikang_jjk/article/details/80788501" target="_blank" rel="noopener">使用Excel中导出latex代码的表格</a></p><a id="more"></a><p>使用Latex创建表格的一些语法</p><p><a href="https://cloud.tencent.com/developer/article/1635392" target="_blank" rel="noopener">Latex论文表格画法</a></p><ul><li><p>表格占2列或1列</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;table*&#125;[htb]</span><br><span class="line">  \centering</span><br><span class="line">  \caption&#123;Performance comparison of different approaches for traffic flow forecasting.&#125;</span><br><span class="line">  \resizebox&#123;0.95\textwidth&#125;&#123;!&#125;&#123; % If your table exceeds the column or page width, use this command to reduce it slightly</span><br><span class="line">  \begin&#123;tabular&#125;&#123;c|c|ccccccccc&#125;</span><br><span class="line">  .....</span><br><span class="line">  .....</span><br><span class="line">  \end&#123;tabular&#125;</span><br><span class="line">  &#125;</span><br><span class="line">  \label&#123;table2&#125;</span><br><span class="line">\end&#123;table*&#125;</span><br></pre></td></tr></table></figure><p><strong>其中<code>*</code>表示表格占2列</strong>,如果表格太宽，即使占了2列，表格还是溢出边界，<strong>使用<code>\resizebox</code>来调整表格的宽度</strong>，这里将表格变成原来的<code>0.95</code>倍，这样表格中的字体就会自动变小，表格左右宽度也会变窄。</p><p>在<strong>表格后面有<code>[htb]</code></strong>，完整的版本应该是<code>[htbp]</code>，表示表格的浮动</p><ul><li><code>[h]</code>:<code>here</code>表格放在当前位置</li><li><code>[t]</code>:<code>top</code>表格放在页面的首部</li><li><code>[b]</code>:<code>bottom</code>表格放在页面的底部</li><li><code>[p]</code>:将表格放在浮动对象的页面上</li></ul><p><strong>如果表格只占1列，不使用<code>*</code></strong>,同时表格的宽度可以变成<code>0.45</code>，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;table&#125;[htb]</span><br><span class="line">  \centering</span><br><span class="line">  \caption&#123;Performance comparison of different approaches for traffic flow forecasting.&#125;</span><br><span class="line">  \resizebox&#123;0.45\textwidth&#125;&#123;!&#125;&#123; % If your table exceeds the column or page width, use this command to reduce it slightly</span><br><span class="line">  \begin&#123;tabular&#125;&#123;c|c|ccccccccc&#125;</span><br><span class="line">  .....</span><br><span class="line">  .....</span><br><span class="line">  \end&#123;tabular&#125;</span><br><span class="line">  &#125;</span><br><span class="line">  \label&#123;table2&#125;</span><br><span class="line">\end&#123;table&#125;</span><br></pre></td></tr></table></figure></li><li><p>列设置<br><code>{c|c|ccccccccc}</code>其中1个<code>c</code>表示一列，格式为居中，这是列必选参数。下面是对齐方式：</p><ul><li><code>l</code>表示左对齐</li><li><code>c</code>表示居中对齐</li><li><code>r</code>表示右对齐</li></ul><p><code>|</code>表示是否需要绘制竖线，<code>||</code>表示画两条紧相邻的竖线。</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;转载&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/Jiajikang_jjk/article/details/80788501&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;使用Excel中导出latex代码的表格&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="工具" scheme="http://yoursite.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="Latex" scheme="http://yoursite.com/tags/Latex/"/>
    
  </entry>
  
  <entry>
    <title>latex安装与配置</title>
    <link href="http://yoursite.com/2020/07/27/latex%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/"/>
    <id>http://yoursite.com/2020/07/27/latex安装与配置/</id>
    <published>2020-07-27T03:46:01.000Z</published>
    <updated>2020-07-27T08:37:22.578Z</updated>
    
    <content type="html"><![CDATA[<p>最近开始使用Latex写论文，在此记录下Latex的安装和配置</p><a id="more"></a><!-- TOC --><ul><li><a href="#1-软件准备">1. 软件准备</a></li><li><a href="#2-安装texlive">2. 安装TexLive</a></li><li><a href="#3-配置latex-workshop">3. 配置LaTEX Workshop</a></li><li><a href="#4-vscode界面使用">4. VSCode界面使用</a><ul><li><a href="#41-编译latex">4.1. 编译latex</a></li><li><a href="#42-查看pdf">4.2. 查看pdf</a></li><li><a href="#43-查看日志">4.3. 查看日志</a></li><li><a href="#44-正向搜索">4.4. 正向搜索</a></li><li><a href="#45-latex符号搜索">4.5. latex符号搜索</a></li><li><a href="#46-查看参考文献">4.6. 查看参考文献</a></li></ul></li><li><a href="#5-快捷键">5. 快捷键</a></li><li><a href="#6-错误解决">6. 错误解决</a></li></ul><!-- /TOC --><h1><span id="1-软件准备">1. 软件准备</span></h1><ol><li>TexLive<br>Latex的编译器，安装之后，就可以打开记事本，然后写latex语句，然后使用TEXLive编译，但是这种方法不太友好</li><li>VSCode<br>为了更好的编辑Latex，使用宇宙第一编辑器VSCode</li><li>LaTEX Workshop<br>安装完VSCode之后，在VSCode中安装一个插件：LaTEX Workshop</li></ol><h1><span id="2-安装texlive">2. 安装TexLive</span></h1><ol><li>在<a href="https://mirrors.tuna.tsinghua.edu.cn/CTAN/systems/texlive/Images/" target="_blank" rel="noopener">清华源</a>上下载texlive.iso镜像，大约有3.7G，等呀等…..等呀等…..终于下完了。</li><li><p>安装<br>这个过程比较漫长，需要从网上下载需要的文件</p><p><img src="/2020/07/27/latex安装与配置/1.jpg" alt=""></p></li><li><p>验证是否安装成功<br>使用<code>Win+R</code>，输出<code>cmd</code>，然后使用下面的命令查看latex是否安装成功</p><p><img src="/2020/07/27/latex安装与配置/8.jpg" alt=""></p></li><li><p>查看环境变量<br>TexLive在安装的时候，会<code>Path</code>中自动写入环境变量的值，如果没有写入，需要自己手动添加。</p><p><img src="/2020/07/27/latex安装与配置/9.jpg" alt=""></p></li></ol><h1><span id="3-配置latex-workshop">3. 配置LaTEX Workshop</span></h1><ol><li>文件—&gt;首选项—&gt;配置</li><li>输入<code>latex-workshop.latex.recipes</code>进行搜索，编辑<code>settings.json</code></li><li><p>配置</p><ul><li><code>latex-workshop.latex.tools</code>:编译工具,”xelatex”,”pdflatex”,”bibtex”是三个常用的编译工具。如果安装路径中包括中文的话，可以将<code>&quot;latex-workshop.latex.tools&quot;</code>:中的<code>%DOC%</code>更改为<code>%DOCFILE%</code>。</li><li><code>latex-workshop.latex.recipes</code>:latex编译的方案。可以使用”xelatex”，也可以使用”pdflatex”，或”xe-&gt;bib-&gt;xe-&gt;xe”,”pdf-&gt;bib-&gt;pdf-&gt;pdf”连续多次编译。<strong>其中”pdf-&gt;bib-&gt;pdf-&gt;pdf”适合英文期刊模板</strong>，我使用的也是这个。默认使用<code>latexmk</code>。我们配置的这些在左边菜单栏的”build Latex project”中都可以看到<br><img src="/2020/07/27/latex安装与配置/2.jpg" alt=""> </li><li><code>&quot;latex-workshop.view.pdf.viewer&quot;: &quot;tab&quot;</code>表示使用vscode内嵌的pdf来查看编译后的pdf文件</li><li><code>&quot;latex-workshop.latex.autoBuild.run&quot;: &quot;onFileChange&quot;或&quot;never&quot;</code>，表示在保存tex文件时是否自动编译</li><li><code>&quot;latex-workshop.latex.autoClean.run&quot;: &quot;onBuilt&quot;</code>表示在生成pdf后自动清除辅助文件</li></ul><pre><code class="lang-json">{ &quot;remote.SSH.remotePlatform&quot;: {     &quot;gpu27&quot;: &quot;linux&quot;,     &quot;gpu28&quot;: &quot;linux&quot;,     &quot;gpu-test&quot;: &quot;linux&quot;,     &quot;gpu29&quot;: &quot;linux&quot; }, &quot;editor.fontSize&quot;: 18, &quot;editor.suggestSelection&quot;: &quot;first&quot;, &quot;vsintellicode.modify.editor.suggestSelection&quot;: &quot;automaticallyOverrodeDefaultValue&quot;, &quot;python.jediEnabled&quot;: false, &quot;files.eol&quot;: &quot;\n&quot;, &quot;files.autoSave&quot;: &quot;afterDelay&quot;, &quot;python.languageServer&quot;: &quot;Microsoft&quot;, &quot;latex-workshop.view.pdf.viewer&quot;: &quot;tab&quot;, &quot;latex-workshop.latex.autoBuild.run&quot;: &quot;never&quot;, &quot;latex-workshop.latex.autoClean.run&quot;: &quot;onBuilt&quot;, &quot;latex-workshop.latex.clean.fileTypes&quot;: [     &quot;*.aux&quot;,     &quot;*.bbl&quot;,     &quot;*.blg&quot;,     &quot;*.idx&quot;,     &quot;*.ind&quot;,     &quot;*.lof&quot;,     &quot;*.lot&quot;,     &quot;*.out&quot;,     &quot;*.toc&quot;,     &quot;*.acn&quot;,     &quot;*.acr&quot;,     &quot;*.alg&quot;,     &quot;*.glg&quot;,     &quot;*.glo&quot;,     &quot;*.gls&quot;,     &quot;*.ist&quot;,     &quot;*.fls&quot;,     &quot;*.log&quot;,     &quot;*.fdb_latexmk&quot;     ], &quot;latex-workshop.latex.recipes&quot;: [     {         &quot;name&quot;: &quot;pdflatex-&gt;bibtex-&gt;pdflatex × 2&quot;,         &quot;tools&quot;: [             &quot;pdflatex&quot;,             &quot;bibtex&quot;,             &quot;pdflatex&quot;,             &quot;pdflatex&quot;         ]     },     {         &quot;name&quot;: &quot;xelatex&quot;,         &quot;tools&quot;: [             &quot;xelatex&quot;         ],     },     {         &quot;name&quot;: &quot;latexmk&quot;,         &quot;tools&quot;: [             &quot;latexmk&quot;         ]     },     {         &quot;name&quot;: &quot;pdflatex&quot;,         &quot;tools&quot;: [             &quot;pdflatex&quot;         ]     },     {         &quot;name&quot;: &quot;xe-&gt;bib-&gt;xe-&gt;xe&quot;,         &quot;tools&quot;: [             &quot;xelatex&quot;,             &quot;bibtex&quot;,             &quot;xelatex&quot;,             &quot;xelatex&quot;         ]     },     {         &quot;name&quot;: &quot;Compile Rnw files&quot;,         &quot;tools&quot;: [             &quot;rnw2tex&quot;,             &quot;latexmk&quot;         ]     },     {         &quot;name&quot;: &quot;Compile Jnw files&quot;,         &quot;tools&quot;: [             &quot;jnw2tex&quot;,             &quot;latexmk&quot;         ]     } ], &quot;latex-workshop.latex.tools&quot;: [     {         &quot;name&quot;: &quot;xelatex&quot;,         &quot;command&quot;: &quot;xelatex&quot;,         &quot;args&quot;: [             &quot;-synctex=1&quot;,             &quot;-interaction=nonstopmode&quot;,             &quot;-file-line-error&quot;,             &quot;%DOC%&quot;         ]     },     {       &quot;name&quot;: &quot;latexmk&quot;,       &quot;command&quot;: &quot;latexmk&quot;,       &quot;args&quot;: [         &quot;-synctex=1&quot;,         &quot;-interaction=nonstopmode&quot;,         &quot;-file-line-error&quot;,         &quot;-pdf&quot;,         &quot;%DOC%&quot;       ]     },     {       &quot;name&quot;: &quot;pdflatex&quot;,       &quot;command&quot;: &quot;pdflatex&quot;,       &quot;args&quot;: [         &quot;-synctex=1&quot;,         &quot;-interaction=nonstopmode&quot;,         &quot;-file-line-error&quot;,         &quot;%DOC%&quot;       ]     },     {       &quot;name&quot;: &quot;bibtex&quot;,       &quot;command&quot;: &quot;bibtex&quot;,       &quot;args&quot;: [         &quot;%DOCFILE%&quot;       ]     }   ], &quot;tabnine.experimentalAutoImports&quot;: true}</code></pre></li></ol><h1><span id="4-vscode界面使用">4. VSCode界面使用</span></h1><p>安装了LaTEX Workshop,左下角就会出现<code>TEX</code>这个菜单。我们点进去，就可以看到右边的这些功能。其中前三个是比较常用的功能。<br>第一个是编译latex，称为pdf<br>第二个是展示pdf<br>第三个是打开日志查错</p><h2><span id="41-编译latex">4.1. 编译latex</span></h2><p><img src="/2020/07/27/latex安装与配置/4.jpg" alt=""></p><p>如果直接点击<code>Build LaTex project</code>，而不是点”下三角”展开，会默认执行离行首最近的第一条相关命令，这里是<code>latexmk</code>编译（现在还没有配置，默认是pdflatex编译文件）</p><p><img src="/2020/07/27/latex安装与配置/5.jpg" alt=""></p><h2><span id="42-查看pdf">4.2. 查看pdf</span></h2><p>在编译成功后，会生成pdf文件，我们可以在VSCode内部来查看生成的pdf，点击左侧的<code>view in vscode tab</code>，就会生成左右2个窗口。也可以在用一些外部的pdf查看器来查看，这样就不是在vscode内部查看了，通常用<code>SumatraPDF</code>来查看，这个软件需要单独下载。这里就不介绍这种方式了<br><img src="/2020/07/27/latex安装与配置/6.jpg" alt=""></p><h2><span id="43-查看日志">4.3. 查看日志</span></h2><p>当编译latex出错时，我们可以点击左侧的<code>view latex compilier log</code>来查看日志。</p><p><img src="/2020/07/27/latex安装与配置/7.jpg" alt=""></p><h2><span id="44-正向搜索">4.4. 正向搜索</span></h2><p>点击<code>syntex from cursor</code>可以进行正向搜索。在tex文件中，鼠标的游标停留在某个位置，然后点击<code>syntex from cursor</code>，在右侧的pdf中会定位到鼠标所有在位置。</p><p><img src="/2020/07/27/latex安装与配置/11.jpg" alt=""></p><h2><span id="45-latex符号搜索">4.5. latex符号搜索</span></h2><p>有一些公式涉及到复杂的符号，可以点击左侧的<code>snippet panel</code>，在右侧会出现常用的符号，点击某一个符号，就会在tex文件中插入相应的latex表示。</p><p><img src="/2020/07/27/latex安装与配置/12.jpg" alt=""></p><h2><span id="46-查看参考文献">4.6. 查看参考文献</span></h2><p>在文件中提前写好<code>bib</code>参考文件，然后点击<code>open citation browser</code>,就会出现bib文件中所有的参考文献，然后点击某个参考文献，就可以在tex文件中插入参考文献。</p><p><img src="/2020/07/27/latex安装与配置/13.jpg" alt=""></p><h1><span id="5-快捷键">5. 快捷键</span></h1><ol><li><code>Ctrl+Alt+B</code>对tex进行编译,然后在VSCode的左下角就可以看到编译的状态。<br><img src="/2020/07/27/latex安装与配置/3.jpg" alt=""></li><li>在编译完之后，按<code>Ctrl+Alt+V</code>预览生成的pdf文件</li></ol><h1><span id="6-错误解决">6. 错误解决</span></h1><p>在完成上面的操作时，将一个AAAI的tex文件进行编译，然后报错<code>aaai2020.sty not found</code>，去AAAI的官网上下载论文latex模板，其中模板文件夹中有<code>aaai.bst,aaai20.sty</code>这2个文件，把这2个文件拷贝到tex所在的文件夹中，重新编译就成功啦。</p><p><img src="/2020/07/27/latex安装与配置/10.jpg" alt=""></p><p>参考资料</p><p><a href="https://blog.csdn.net/aiwei169/article/details/81431363" target="_blank" rel="noopener">TeX Live安装教程</a><br><a href="https://blog.csdn.net/qq280929090/article/details/104357697?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param" target="_blank" rel="noopener">基于Visual Studio Code的 LaTeX环境配置及使用示例</a><br><a href="https://blog.csdn.net/david394/article/details/107165422" target="_blank" rel="noopener">在VSCode中配置Latex编译环境</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近开始使用Latex写论文，在此记录下Latex的安装和配置&lt;/p&gt;
    
    </summary>
    
      <category term="工具" scheme="http://yoursite.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="Latex" scheme="http://yoursite.com/tags/Latex/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统学习</title>
    <link href="http://yoursite.com/2020/07/25/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0/"/>
    <id>http://yoursite.com/2020/07/25/推荐系统学习/</id>
    <published>2020-07-25T04:38:22.000Z</published>
    <updated>2020-10-20T11:08:39.058Z</updated>
    
    <content type="html"><![CDATA[<p>开始学习推荐系统的相关内容</p><a id="more"></a><!-- TOC --><ul><li><a href="#1-推荐系统和搜索的区别">1. 推荐系统和搜索的区别</a></li><li><a href="#2-推荐系统lambda架构">2. 推荐系统Lambda架构</a></li><li><a href="#3-推荐算法模型历程">3. 推荐算法模型历程</a></li><li><a href="#4-推荐算法流程">4. 推荐算法流程</a><ul><li><a href="#41-长尾效应和推荐系统">4.1. 长尾效应和推荐系统</a></li><li><a href="#42-召回">4.2. 召回</a></li><li><a href="#43-排序">4.3. 排序</a><ul><li><a href="#431-lr">4.3.1. LR</a></li></ul></li></ul></li><li><a href="#5-推荐模型的构建流程">5. 推荐模型的构建流程</a></li><li><a href="#6-相似度计算">6. 相似度计算</a><ul><li><a href="#61-余弦相似度">6.1. 余弦相似度</a></li><li><a href="#62-皮尔逊相关系数">6.2. 皮尔逊相关系数</a></li><li><a href="#63-杰卡德jaccard相似度">6.3. 杰卡德Jaccard相似度</a></li></ul></li><li><a href="#7-召回算法">7. 召回算法</a><ul><li><a href="#71-基于内容的召回算法">7.1. 基于内容的召回算法</a></li><li><a href="#72-协同过滤cf">7.2. 协同过滤CF</a><ul><li><a href="#721-基于用户的协同过滤">7.2.1. 基于用户的协同过滤</a></li><li><a href="#722-基于物品的协同过滤">7.2.2. 基于物品的协同过滤</a></li><li><a href="#723-基于模型的协同过滤">7.2.3. 基于模型的协同过滤</a><ul><li><a href="#7231-矩阵分解mf">7.2.3.1. 矩阵分解MF</a></li></ul></li></ul></li><li><a href="#73-基于内容推荐和协同过滤的区别">7.3. 基于内容推荐和协同过滤的区别</a></li></ul></li><li><a href="#8-排序算法">8. 排序算法</a><ul><li><a href="#81-逻辑回归lr">8.1. 逻辑回归LR</a></li><li><a href="#82-fm">8.2. FM</a></li></ul></li><li><a href="#9-推荐系统的评价">9. 推荐系统的评价</a></li></ul><!-- /TOC --><h1><span id="1-推荐系统和搜索的区别">1. 推荐系统和搜索的区别</span></h1><ul><li>推荐系统个性化强，用户被动的接受，希望能提供持续的服务，推荐主要是信息过滤系统。</li><li>搜索个性化弱，用户主动搜索，快速满足用户的需求。主要是构建稳定的信息流通通道</li></ul><p>什么时候才需要推荐：</p><ol><li>信息过载</li><li>需求不明确</li></ol><h1><span id="2-推荐系统lambda架构">2. 推荐系统Lambda架构</span></h1><p>推荐系统要素：</p><ol><li>前段界面</li><li>数据（Lambda架构）</li><li>业务知识</li><li>推荐算法</li></ol><ul><li><p><strong>推荐系统整体架构</strong></p><p><img src="/2020/07/25/推荐系统学习/推荐系统整体架构.jpg" alt=""></p></li></ul><p>下面介绍<strong>大数据Labmda架构</strong></p><ul><li>Lambda架构结合实时数据和Hadoop平台，提供实时的数据视图。简单说将离线计算和实时计算结合起来。</li><li><p>实时和离线的分层操作</p><ul><li><p>离线：</p><ul><li>分布式计算：Hadoop MapReduce、Spark</li><li>数据存储：HBase、Redis、MySQL</li></ul></li><li><p>实时</p><ul><li>流式处理数据</li><li>实时数据收集：Flume、Kafka</li><li>实时数据分析：Spark Streaming / storm、flink</li></ul></li></ul></li></ul><p>下面是Lambda的架构图。首先数据源从flume中得到。一部分做批处理，一部分做实时处理。批处理把数据放在数据库上，然后经过MapReduce算出一个阶段，缓存起来。然后实时这部分也会做实时计算，然后将这2部分的计算结果汇总，为推荐系统提供服务。</p><p>这2部分的相辅相成。离线服务算的时间比较长，比如10分钟得出一次结果，那在前端用户看到的结果10分钟都不会变。然后实时计算是基于离线计算的结果做一些微调。这样用户看到的推荐结果就会实时变化。</p><p><img src="/2020/07/25/推荐系统学习/lambda.jpg" alt=""></p><h1><span id="3-推荐算法模型历程">3. 推荐算法模型历程</span></h1><p><a href="https://mp.weixin.qq.com/s/-e9M_rGaE2oGcxE-p1U5Tw" target="_blank" rel="noopener">推荐系统-传统推荐模型之协同过滤</a></p><p><img src="/2020/07/25/推荐系统学习/流程.png" alt=""></p><h1><span id="4-推荐算法流程">4. 推荐算法流程</span></h1><p>上面讲了整个推荐系统的架构，下面我们只关注推荐算法。推荐算法只有3个阶段：</p><ol><li>召回阶段<ul><li>这里的召回不要和分类问题的召回率混淆，这2者是不同的概念。推荐算法的召回是海选，就是先从很多内容中选出一些内容，作为接下来推荐的候选人。也就是说我们后面推荐的结果都是从这些候选内容中选的。所以召回阶段决定了最终推荐结果的天花板</li><li>召回阶段常用算法<ul><li>协同过滤 CF（基于物品和基于用户）</li><li>基于内容（根据用户的行为总结出用户的喜好，根据文本挖掘技术找到相似的商品）</li><li>基于隐语义</li></ul></li></ul></li><li>排序阶段<ul><li>对召回阶段找到候选内容进行排序</li><li>CTR估计(点击率估计)，可以使用逻辑回归，输出用户对某个物品点击的概率，然后将概率进行排序，选出topK的物品做为最终的推荐结果</li></ul></li><li>策略调整<ul><li>新用户数据少采取补充策略（冷启动）</li><li>地域热门：根据用户当前的定位，统计附近的热门帖子</li><li>全局热门：对某个时间段的帖子进行热门排序</li></ul></li></ol><p><img src="/2020/07/25/推荐系统学习/推荐算法.jpg" alt=""></p><p><img src="/2020/07/25/推荐系统学习/推荐算法2.jpg" alt=""></p><p>如果比较细致的看推荐系统，分为4个阶段：召回+粗排+精排+ReRanker</p><p><img src="/2020/07/25/推荐系统学习/推荐算法3.jpg" alt=""></p><p>召回目的如上所述；有时候因为每个用户召回环节返回的物品数量还是太多，怕排序环节速度跟不上，所以可以在召回和精排之间加入一个粗排环节，通过少量用户和物品特征，简单模型，来对召回的结果进行个粗略的排序，在保证一定精准的前提下，进一步减少往后传送的物品数量，粗排往往是可选的，可用可不同，跟场景有关。之后，是精排环节，使用你能想到的任何特征，可以上你能承受速度极限的复杂模型，尽量精准地对物品进行个性化排序。排序完成后，传给重排环节，传统地看，这里往往会上各种技术及业务策略，比如去已读、去重、打散、多样性保证、固定类型物品插入等等，主要是技术产品策略主导或者为了改进用户体验的。</p><p><img src="/2020/07/25/推荐系统学习/推荐系统.jpg" alt=""></p><h2><span id="41-长尾效应和推荐系统">4.1. 长尾效应和推荐系统</span></h2><p><a href="https://cloud.tencent.com/developer/ask/68639" target="_blank" rel="noopener">长尾效应与推荐系统的关系？</a></p><p><strong>长尾效应</strong>往往用来解释现实生活中的商业理论，将所有非流行的市场累加起来就会形成一个比流行市场还要大的市场。</p><p><strong>长尾效应和推荐系统的关系：</strong><br>目前的推荐系统或推荐算法，很难发现用户的隐性需求，也是目前推荐算法所追求的。目前而言，现在的推荐系统只能发现你的主观需求，比如你在B站上搜索一个关键词后，系统往往会推荐和这个关键词有关的内容，但是却很难发现你目前不知道，但是心里感兴趣的东西。所以这是一个很大的难点。</p><p>在推荐系统中，可以把长尾效应看做是一种目标，即向用户推荐他喜欢，但是不会自己发现的物品。由于长尾中的物品比较肺腑，推荐系统可能会有很大的收益。</p><h2><span id="42-召回">4.2. 召回</span></h2><p>召回是推荐系统的第一步，根据用户和商品的部分特征，从海量的物品中找出用户潜在感兴趣的物品，交给排序阶段。<strong>召回阶段需要快，所以模型不能太复杂</strong>。</p><p>现在召回环节一般采用多路召回，随便想到一个策略就可以做一路召回。</p><p><img src="/2020/07/25/推荐系统学习/召回.jpg" alt=""></p><p><strong>传统的召回思路：</strong></p><p>先离线计算好商品的Embedding和用户的Embedding，然后在线上召回的时候，根据用户的Embedding和所有商品的Embedding内积，找出TopN。</p><ol><li>根据用户行为召回<br>将用户一系列的行为，使用GRU/Transformer来聚合用户行为，生成1个用户兴趣嵌入。有监督学习，标签可以是next iterm prediction</li><li>用户多兴趣拆分<br>上面根据用户行为生成1个用户兴趣嵌入，但是用户的兴趣可以有很多类，例如体育，购物等。用户多兴趣拆分的输入和上面一样，还是用户历史行为序列，但是输出的是用户多个兴趣嵌入，可以进行多兴趣点召回，避免单兴趣嵌入召回头部问题。可以看做是聚类问题，就是把不同的item聚到不同的兴趣类别中。</li><li>和知识图谱融合<br>首先构建一个用户和商品的行为图，如果用户对商品有行为产生，则建立一条边，这样就建立了用户-商品交互的二部图。这里面还隐藏这物品之间的一些知识。比如说用户点击过电影“泰坦尼克号”，这部电影是小李子主演的，我们就可以利用电影领域的知识图谱数据，来推荐小李子主演的其他电影给用户。</li><li>图神经网络模型召回<br>上面知识图谱是图神经网络的一个特例，但是知识图谱因为编码的是静态知识，而不是用户比较直接的行为数据，和具体应用距离较远。图中的节点是用户和商品，通过用户行为来建立边，边还可以带上权重，然后使用图神经网络，例如GraphSAGE来获取节点的嵌入。</li></ol><p><img src="/2020/07/25/推荐系统学习/召回模型.jpg" alt=""></p><h2><span id="43-排序">4.3. 排序</span></h2><h3><span id="431-lr">4.3.1. LR</span></h3><p>LR最早可以用在点击率预测中，LR是一个二分类，输出的概率表示用户点击的概率。</p><p>步骤如下：</p><ol><li><p>构造特征<br>将所有特征进行离散化,变成one-hot输入</p><p><img src="/2020/07/25/推荐系统学习/lr.jpg" alt=""></p></li><li>模型训练<br>根据输入的特征和label（用户点击1或者不点击0）来训练LR分类器</li><li>模型推荐<br>给定一个用户u，以及一批候选商品，对用户u如何推荐商品。通过上述方法计算用户u对候选商品中每个商品的点击点击得分，然后按照得分从大大小排序，推荐前N个物品。</li></ol><h1><span id="5-推荐模型的构建流程">5. 推荐模型的构建流程</span></h1><p><img src="/2020/07/25/推荐系统学习/推荐算法1.jpg" alt=""></p><ol><li>数据清洗阶段<ul><li>数据来源<ul><li>显性数据：打分，评论</li><li>隐性数据：历史订单、加购物车、页面浏览</li></ul></li></ul></li><li>特征工程<ul><li>user-item的评分矩阵</li><li>如果没有显式的评分矩阵，可以用一些用户的行为，比如加入购物车，单曲循环，页面停留时间等。</li></ul></li><li>算法<ul><li>协同过滤：计算相似度</li><li>矩阵分解</li></ul></li><li>产生推荐结果<ul><li>交叉推荐：买了手机，推荐手机壳</li><li>向上推荐：买了自行车，推荐跑车</li></ul></li></ol><h1><span id="6-相似度计算">6. 相似度计算</span></h1><p>相似度计算根据数据来选择。</p><ul><li>数据是实数值，评分情况</li><li>数据是布尔值，是否消费</li></ul><h2><span id="61-余弦相似度">6.1. 余弦相似度</span></h2><p>余弦相似度就是看2个向量夹角的cos值。余弦相似度范围[-1,1]，从负相关到正相关。</p><p>缺点：只和夹角有关，不关心向量长度。可能会有误差。对2个电影打分，一个人打分向量(5,8)，另一个人打分向量(0.5,1)，这2个向量虽然夹角很小，但是长度差别很大。</p><p><img src="/2020/07/25/推荐系统学习/余弦相似度.jpg" alt=""></p><h2><span id="62-皮尔逊相关系数">6.2. 皮尔逊相关系数</span></h2><p>对余弦相似度的优化，对向量做中心化，将向量a和b减去向量均值，在计算余弦相似度</p><p><img src="/2020/07/25/推荐系统学习/皮尔逊.jpg" alt=""></p><p><img src="/2020/07/25/推荐系统学习/相似性.png" alt=""></p><h2><span id="63-杰卡德jaccard相似度">6.3. 杰卡德Jaccard相似度</span></h2><p>Jaccard = 交集/并集</p><p>比如用户2喜欢物品(2,7,10),用户4喜欢物品(2,5,7,9)，2个用户的交集是物品(2,7)，所以交集个数为2，2个用户喜欢用品的并集是(2,5,7,9,10)，所以并集个数为5.则这2个用户的jaccard相似度=0.4</p><p><img src="/2020/07/25/推荐系统学习/杰卡德.jpg" alt=""></p><p>杰卡德相似度适合评分是0/1的情况</p><p>问题：无法反映具体用户的评分喜好信息，所以经常用来评估用户是否会对某商品进行打分，而不是预估用户对某商品打多少分。</p><h1><span id="7-召回算法">7. 召回算法</span></h1><h2><span id="71-基于内容的召回算法">7.1. 基于内容的召回算法</span></h2><p>基于内容的推荐一般是文本类型的特征，需要提取关键词，计算关键词的权重。</p><p>一般步骤是：</p><ol><li>先分词，</li><li>然后计算词的权重(TF-IDF)，即提取关键字</li><li>然后使用word2vec得到词向量，从词向量构建物品向量</li></ol><h2><span id="72-协同过滤cf">7.2. 协同过滤CF</span></h2><p><strong>协同过滤(Collaborative Filtering)的算法思想：物以类聚，人以群分</strong></p><p>协同过滤推荐算法分为2类：</p><ul><li><strong>基于用户的协同过滤</strong>user-based CF：和你喜好相似的人，那他喜欢的东西你也可能喜欢</li><li><strong>基于物品的协同过滤</strong>item-based CF：和你喜欢的东西相似的东西，你也可能喜欢</li><li><strong>基于模型的协同过滤</strong>，现在最主流的协同过滤类型，包含矩阵分解，聚类算法，深度学习，图模型等。</li></ul><p><strong>缺点：</strong></p><p>召回结果的候选item限定在用户的历史行为类目中，导致推荐结果越推越窄，难以发现长尾商品。</p><h3><span id="721-基于用户的协同过滤">7.2.1. 基于用户的协同过滤</span></h3><p>实现协同过滤的步骤：</p><ol><li>首先计算<strong>用户与用户的相似程度</strong><br>比如下图中，我们计算出用户1和用户2，3最相似</li><li>根据相似的人产生推荐结果<br>然后我们根据用户2，3的内容给用户1来推荐，用户3喜欢物品AC，用户2喜欢ADE，则向用户1初始推荐AC+ADE，而用户1已经消费过ACD，过滤掉用户1已经消费过的商品，最终推荐商品E</li></ol><p><img src="/2020/07/25/推荐系统学习/基于用户.jpg" alt=""></p><h3><span id="722-基于物品的协同过滤">7.2.2. 基于物品的协同过滤</span></h3><ol><li>首先计算<strong>物品与物品的相似程度</strong><br>比如物品A和物品B相似</li><li><p>根据相似的物品产生推荐结果<br>用户A原先买过物品A，然后就给推荐物品B</p><p>物品A被4个用户消费过，物品B被2个用户消费过，其中用户5是2个物品共同的消费用户，对物品B来说这个用户5占所有用户的0.5，对物品A来说这个用户5占所有用户的0.25，所以物品A和B之间的相似度为0.5*0.25。按照这样方式计算所有物品之间的相似度，发现物品A和物品C</p><p><img src="/2020/07/25/推荐系统学习/基于物品.jpg" alt=""></p></li></ol><h3><span id="723-基于模型的协同过滤">7.2.3. 基于模型的协同过滤</span></h3><h4><span id="7231-矩阵分解mf">7.2.3.1. 矩阵分解MF</span></h4><p>MF（Matrix Factorization，矩阵分解）是一个简单的Embedding模型。给定用户和物品矩阵$A \in \mathbb{R}^{m \times n}$,然后对其进行分解成用户嵌入矩阵$U \in \mathcal{R}^{m \times d}$和商品矩阵$V \in \mathcal{R}^{n \times d}$。$d &lt;&lt; m和n$</p><p>矩阵分解的目标就是让$UV^T$的结果和$A$尽可能的相似。</p><p><img src="/2020/07/25/推荐系统学习/矩阵分解1.jpg" alt=""></p><p>在上面的目标函数中，只对观察到的obs的对$(i,j)$进行误差求和。即只对下图中为1的元素求误差，但是这并不能很好的推荐，泛化性能差。</p><p><img src="/2020/07/25/推荐系统学习/矩阵分解2.jpg" alt=""></p><p>因为我们需要对所有的值进行求误差，目标函数就变成下面这样：</p><p><img src="/2020/07/25/推荐系统学习/矩阵分解3.jpg" alt=""></p><p>最小化目标函数的方法包括：</p><ol><li>随机梯度下降SGD</li><li>加权交替最小二乘法WALS<br>在2个矩阵U和V中，对U和V进行交替更新。（1）固定U求解V，（2）固定V求解U</li></ol><h2><span id="73-基于内容推荐和协同过滤的区别">7.3. 基于内容推荐和协同过滤的区别</span></h2><p>基于内容的推荐和用户协同过滤都是计算用户的相似度，但用到的特征却不同。</p><ol><li>基于内容的推荐使用用户画像特征，即用户的个人信息，例如年龄，性别，教育程度等</li><li>基于用户的协同过滤用的是用户对物品的评分特征，通过计算2个用户对商品的评分向量来计算相似性。</li></ol><p>基于用户的协同过滤需要用到用户对商品的评分来计算相似性，当一个新用户没有对任何商品评分，因此会出现“冷启动”的问题，基于内容的推荐就没有这个问题。</p><h1><span id="8-排序算法">8. 排序算法</span></h1><h2><span id="81-逻辑回归lr">8.1. 逻辑回归LR</span></h2><p>LR最早可以用在点击率预测中，LR是一个二分类，输出的概率表示用户点击的概率。</p><p>步骤如下：</p><ol><li><p>构造特征<br>将所有特征进行离散化,变成one-hot输入</p><p><img src="/2020/07/25/推荐系统学习/lr.jpg" alt=""></p></li><li>模型训练<br>根据输入的特征和label（用户点击1或者不点击0）来训练LR分类器</li><li>模型推荐<br>给定一个用户u，以及一批候选商品，对用户u如何推荐商品。通过上述方法计算用户u对候选商品中每个商品的点击点击得分，然后按照得分从大大小排序，推荐前N个物品。</li></ol><p>LR模型最大的缺陷就是人工特征工程，耗时费力费人力资源，能否将特征组合的能力体现在模型层面呢？就不用人工再去组合特征了。</p><h2><span id="82-fm">8.2. FM</span></h2><p>FM英文全称是“Factorization Machine”，简称FM模型，中文名“因子分解机”。</p><p>FM在2010年提出，核心在于特征组合，以此减少人工参与特征组合工作。FM的优势：</p><ol><li>FM能处理高维稀疏场景</li><li>FM具有线性的计算复杂度</li></ol><p><img src="/2020/07/25/推荐系统学习/FM.jpg" alt=""></p><p>FM在LR的基础上，引入任意2个特征的二阶特征组合，为每个特征，学习一个大小为k的一维向量。于是2个特征$x_i,x_j$的特征组合的权重值，通过特征对应的向量$v_i,v_j$的内积$<v_i,v_j>$来表示。</v_i,v_j></p><h1><span id="9-推荐系统的评价">9. 推荐系统的评价</span></h1><ol><li><p>准确率</p><ul><li>学术角度：RMSE,MAE,点击预估</li><li>工程角度：A/B test对比不同的算法，在线上运行对关键指标的影响</li></ul></li><li><p>覆盖率<br>尽量照顾到大部分的产品</p></li><li>探索和利用<ul><li>利用：利用用户的历史行为，只给他推荐他曾经消费过的相似物品</li><li>探索：发现用户的新兴趣</li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;开始学习推荐系统的相关内容&lt;/p&gt;
    
    </summary>
    
      <category term="推荐系统" scheme="http://yoursite.com/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="推荐系统" scheme="http://yoursite.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>AUC在推荐系统中的应用</title>
    <link href="http://yoursite.com/2020/07/21/AUC%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/"/>
    <id>http://yoursite.com/2020/07/21/AUC在推荐系统中的应用/</id>
    <published>2020-07-21T14:41:26.000Z</published>
    <updated>2020-09-09T14:41:08.878Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/uVZOfFayOzba5mALR5lHRQ" target="_blank" rel="noopener">参考资料</a></p><p>在推荐、广告系统中AUC是一个常见的指标。</p><a id="more"></a><!-- TOC --><ul><li><a href="#1-介绍auc">1. 介绍AUC</a></li><li><a href="#2-排序问题中的auc">2. 排序问题中的AUC</a></li><li><a href="#3-auc的计算">3. AUC的计算</a></li></ul><!-- /TOC --><h1><span id="1-介绍auc">1. 介绍AUC</span></h1><p><a href="https://tracholar.github.io/machine-learning/2018/01/26/auc.html" target="_blank" rel="noopener">深入理解AUC</a></p><p>关于AUC，通常说是ROC线下面积。ROC横坐标假阳率，纵坐标真阳率。<br>如下图中AUC=0.5，表示不论样本真实label是0还是1，模型将以0.5的概率将其预测为正样本。这就和抛硬币没区别，这说明模型对正负样本没有区分能力。<br>我们训练的目标是让AUC越大越好。</p><p>在统计和机器学习中，常用AUC来评估二分类模型的性能。AUC全称是Area Under the Curve。</p><p><img src="/2020/07/21/AUC在推荐系统中的应用/roc.jpg" alt=""></p><p>AUC同时考虑了分类器对正例和负例的分类能力，在样本不均衡时，分类器依然能做出合理的评价。</p><p>另一种解释是：基于概率的解释，评估模型的排序能力。</p><h1><span id="2-排序问题中的auc">2. 排序问题中的AUC</span></h1><p>假如AUC=0.7，表示给定一个正样本和一个负样本，在70%的情况下，模型对正样本的打分高于负样本的打分。可以看出，我们只关心正负样本之间的分数高低，并不在乎具体的概率值。</p><p>对于Precision，Recall等指标，AUC只关注排序结果，不关注模型输出的概率值，所以适合排序业务。<br>正负样本被预测的gap越大，AUC越大。</p><h1><span id="3-auc的计算">3. AUC的计算</span></h1><p>将测试样本得到的概率从小到大排序，对于<strong>第$j$个正样本</strong>，假设它的排名是$r_j$，那就说明在这个正样本之前有$r_j-1$个样本，其中正样本个数为$j-1$个（因为这个正样本在所有正样本中排第j），那排在第j个正样本前面的负样本个数有$(r_j-1-(j-1))=r_j-j$个，也就是说，低于第$j$个正样本来说，其得分比随机取的一个负样本大（正样本的排名靠后）的概率是$\frac{r_j-j}{N_-}$,其中$N_-$是标签中负样本的个数，所以平均下来，随机取的正样本得到比负样本大的概率为：</p><script type="math/tex; mode=display">AUC=\frac{1}{N_+}\sum_{j=1}^{N_+}\frac{r_j-j}{N_-}=\frac{\sum_{j=1}^{N_+}r_j-N_+(N_++1)/2}{N_+N_-}</script><p>即需要求出以下3个值：</p><ol><li>所有正样本的排名，排名相加$\sum_{j=1}^{N_+}r_j$</li><li>label中正样本个数$N_+$</li><li>label中负样本个数$N_-$</li></ol><p>$prob=[0.4,0.5,0.2,0.8,0.7,0.9,0.6]$<br>$label=[0^{0.4},0^{0.5},1^{0.2},1^{0.8},1^{0.7},0^{0.9},1^{0.6}]$</p><p>首先对prob从小到大排序，并同时调整prob的顺序<br>$prob=[0.2,0.4,0.5,0.6,0.7,0.8,0.9,]$<br>$label=[1^{0.2},0^{0.4},0^{0.5},1^{0.6},1^{0.7},1^{0.8},0^{0.9}]$</p><p>其中正样本的排名分别是1,4,5,6，排名相加是16。<br>label正样本个数有4个，负样本个数有3个，</p><p>$AUC=\frac{16-4<em>5/2}{4</em>3}=0.5$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calAUC</span><span class="params">(prob,labels)</span>:</span></span><br><span class="line">    f = list(zip(prob,labels))</span><br><span class="line">    <span class="comment">#按照prob从小到大排序，对labels进行排序</span></span><br><span class="line">    rank = [cur_label <span class="keyword">for</span> cur_pro,cur_label <span class="keyword">in</span> sorted(f,key=<span class="keyword">lambda</span> x:x[<span class="number">0</span>])]</span><br><span class="line">    <span class="comment">#找出正样本在排名</span></span><br><span class="line">    rankList = [i+<span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(len(rank)) <span class="keyword">if</span> rank[i]==<span class="number">1</span>]</span><br><span class="line">    posNum = <span class="number">0</span><span class="comment">#正样本的个数</span></span><br><span class="line">    negNum = <span class="number">0</span><span class="comment">#负样本的个数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(labels)):</span><br><span class="line">        <span class="keyword">if</span>(labels[i]==<span class="number">1</span>):</span><br><span class="line">            posNum+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            negNum+=<span class="number">1</span></span><br><span class="line">    auc = <span class="number">0</span></span><br><span class="line">    auc = (sum(rankList)- (posNum*(posNum+<span class="number">1</span>))/<span class="number">2</span>)/(posNum*negNum)</span><br><span class="line">    print(auc)</span><br><span class="line">    <span class="keyword">return</span> auc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    prob=[<span class="number">0.4</span>,<span class="number">0.5</span>,<span class="number">0.2</span>,<span class="number">0.8</span>,<span class="number">0.7</span>,<span class="number">0.9</span>,<span class="number">0.6</span>]</span><br><span class="line">    label=[<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">    calAUC(prob,label)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/uVZOfFayOzba5mALR5lHRQ&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;参考资料&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在推荐、广告系统中AUC是一个常见的指标。&lt;/p&gt;
    
    </summary>
    
      <category term="Deep Learning" scheme="http://yoursite.com/categories/Deep-Learning/"/>
    
    
      <category term="AUC" scheme="http://yoursite.com/tags/AUC/"/>
    
  </entry>
  
  <entry>
    <title>python输入怎么写</title>
    <link href="http://yoursite.com/2020/06/21/python%E8%BE%93%E5%85%A5%E6%80%8E%E4%B9%88%E5%86%99/"/>
    <id>http://yoursite.com/2020/06/21/python输入怎么写/</id>
    <published>2020-06-21T09:35:43.000Z</published>
    <updated>2020-06-21T09:47:14.170Z</updated>
    
    <content type="html"><![CDATA[<p>Leetcode刷多了不太记得python的输入怎么写了。在实际笔试或面试时，需要自己写输入和输出函数，所以在此记录下怎么使用Python读取数据。<br><a id="more"></a></p><p>在面试的时候，面试官只给你一个白板，最多给你定义好的函数名，其余都要自己写。给定的题目一般先读取数据，然后使用<code>print</code>输出最终的结果。</p><ul><li><code>print</code>可以写在<code>test</code>函数中</li><li>也可以将要输出的内容保存下来，作为<code>test</code>的<code>return</code>，然后在<code>main</code>中输出<br>下面是写程序的模板：</li><li><code>main</code>只关注输入和输出</li><li>其余的功能单独封装成函数，在<code>main</code>中调用</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(param1,param2)</span>:</span></span><br><span class="line">    <span class="comment">#do something</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">"xx"</span>)</span><br><span class="line">    <span class="comment">#或者return</span></span><br><span class="line">    <span class="keyword">return</span> xx</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment">#使用input读取数据</span></span><br><span class="line">    m = input()</span><br><span class="line">    n = list(map(int,input.split()))</span><br><span class="line"></span><br><span class="line">    test(m,n)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"xx"</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Leetcode刷多了不太记得python的输入怎么写了。在实际笔试或面试时，需要自己写输入和输出函数，所以在此记录下怎么使用Python读取数据。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="算法" scheme="http://yoursite.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>How to Build a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey</title>
    <link href="http://yoursite.com/2020/06/02/How-to-Build-a-Graph-Based-Deep-Learning-Architecture-in-Traffic-Domain-A-Survey/"/>
    <id>http://yoursite.com/2020/06/02/How-to-Build-a-Graph-Based-Deep-Learning-Architecture-in-Traffic-Domain-A-Survey/</id>
    <published>2020-06-02T01:41:59.000Z</published>
    <updated>2020-06-18T02:33:30.602Z</updated>
    
    <content type="html"><![CDATA[<p>这篇综述性论文介绍图神经网络在交通领域的应用。</p><a id="more"></a><!-- TOC --><ul><li><a href="#1-摘要">1. 摘要</a></li><li><a href="#2-前言">2. 前言</a></li><li><a href="#3-研究方向">3. 研究方向</a></li><li><a href="#4-问题定义">4. 问题定义</a><ul><li><a href="#41-构建图">4.1. 构建图</a></li><li><a href="#42-构造邻接矩阵">4.2. 构造邻接矩阵</a></li></ul></li><li><a href="#5-前人的模型">5. 前人的模型</a><ul><li><a href="#51-gnn">5.1. GNN</a></li><li><a href="#52-rnn">5.2. RNN</a></li><li><a href="#53-tcn">5.3. TCN</a></li><li><a href="#54-seq2seq">5.4. Seq2Seq</a></li><li><a href="#55-gan">5.5. GAN</a></li></ul></li><li><a href="#6-挑战">6. 挑战</a><ul><li><a href="#61-空间依赖">6.1. 空间依赖</a></li><li><a href="#62-时间依赖">6.2. 时间依赖</a></li><li><a href="#63-时空依赖">6.3. 时空依赖</a></li><li><a href="#64-外部因素">6.4. 外部因素</a></li></ul></li><li><a href="#7-未来方向">7. 未来方向</a></li></ul><!-- /TOC --><h1><span id="1-摘要">1. 摘要</span></h1><p>在交通数据中，有很多数据以图的形式存在，为了充分利用其中的空间信息，很多模型使用图神经网络来处理交通图数据。本文针对交通领域的图网络模型进行总结。</p><h1><span id="2-前言">2. 前言</span></h1><p>在交通预测领域，（1）早期采用的方法有：ARIMA,VAR,Kalman过滤器等，然而，这些方法通常需要一些前提假设，例如数据是静态且线性相关，不能应用在实际数据中。（2）机器学习方法例如SVM，K近邻可以建模交通数据中的非线性相关性，但是模型结构较浅，且需要人工构造和选择特征，不能满足大量交通数据的应用需求。（3）深度学习方法，例如RNN无法捕获空间相关性，CNN无法应用在图数据中，并且CNN更关注local相关性，忽略了global相关性。（4）图神经网络，使用图神经网络来解决交通领域的预测问题。<br>贡献总结如下：</p><ul><li>第一篇介绍图神经网络在交通领域应用的综述</li><li>系统地列出交通领域的研究方向和挑战</li><li>针对4种交通领域数据，介绍如何构建图</li><li>分析了5种应用在图交通领域的技术，介绍了它们的优缺点，以及变体</li><li>讨论了基于图网络的交通任务中4种常见的挑战，并总结对应的解决方案</li><li>收集数据集，开源代码</li></ul><h1><span id="3-研究方向">3. 研究方向</span></h1><p>给出了交通领域的一些研究问题<br><img src="/2020/06/02/How-to-Build-a-Graph-Based-Deep-Learning-Architecture-in-Traffic-Domain-A-Survey/1.png" alt=""></p><ol><li>交通拥堵</li><li>交通需求<br>出租车、自行车、公共交通的需求预测，像滴滴，Uber等线上打车平台经常做这一类问题。</li><li>交通安全<br>预测交通事故的风险，严重程度</li><li>交通监控<br>主要通过监控的图像和视频检测车辆，行人检测。</li><li>自动驾驶<br>自动驾驶要求检测树木，道路，行人，一般和CV领域相关。</li></ol><p>图神经网络在交通领域的应用</p><ol><li>交通状态预测<br>交通状态：交通流量、速度、时间ETA、密度等。</li><li>交通需求预测<br>预测将来用户对出租车、自行车的需求</li><li>交通信号预测<br>减低用户在交叉路口的等待时间，避免交通拥堵</li><li>司机行为分类</li></ol><p>交通事故预测还没有用到图模型。</p><h1><span id="4-问题定义">4. 问题定义</span></h1><p>基于图的交通预测问题，首先需要构件图G。</p><ul><li>图：无权图，有权图，无向图，有向图，取决于具体的任务。</li><li>节点：传感器sensor，路段，道路交叉口，GPS交叉点。</li><li>邻接矩阵A：非0即1，浮点数（表示2个节点的关系，例如相似性，距离）</li></ul><p>给定历史P个时间段所有节点的信息，维度是$\left[\mathcal{X}_{1}, \cdots, \mathcal{X}_{i}, \cdots, \mathcal{X}_{\mathbf{P}}\right] \in \mathbb{R}^{\mathbf{P} \times \mathbf{N} \times \mathbf{F}_{1}}$预测未来Q个时间段的$\mathcal{Y}=\left[\mathcal{Y}_{1}, \cdots, \mathcal{Y}_{j}, \cdots, \mathcal{Y}_{\mathrm{Q}}\right] \in \mathbb{R}^{\mathbf{Q} \times \mathbf{N} \times \mathrm{F}_{\mathrm{O}}}$</p><ul><li>预测的特征只有1个，即$F_O=1$，预测特征有多个，即$F_O&gt;1$</li><li>预测未来时间段只有1个，单步预测，即$Q=1$，预测未来时间段有多个，多步预测，即$Q&gt;1$</li><li>多步预测问题中，一般使用FC（将输出reshape成需要的维度，ASTGCN,T-GCN,），Seq2Seq（使用RNN循环输出预测结果,DCRNN,GMAN），空洞技术（WaveNet）</li></ul><h2><span id="41-构建图">4.1. 构建图</span></h2><p>在构建图时，一般使用3类数据：传感器，GPS轨迹，打车订单数据，</p><ol><li>传感器数据<br>最常用的加州PEMS数据，图中的每个节点表示一个传感器，同一条路上的传感器有边相连。</li><li>GPS数据<br>GPS轨迹数据，需要将GPS匹配到最近的路段上，以路段为节点创建图，或者以交叉路口为节点创建图。这里的图可以是有向，也可以无向。</li></ol><p><img src="/2020/06/02/How-to-Build-a-Graph-Based-Deep-Learning-Architecture-in-Traffic-Domain-A-Survey/3.png" alt="">  </p><ol><li>订单数据<br>将城市划分为网格，每个节点表示一个网格，边表示连通性。可以根据不同的特征来构件图，例如下图使用邻近区域、道路连通性、功能相似区域分别构建3个图。</li></ol><p><img src="/2020/06/02/How-to-Build-a-Graph-Based-Deep-Learning-Architecture-in-Traffic-Domain-A-Survey/4.png" alt="">  </p><ol><li>公共交通数据<ul><li>地铁图：每个地铁站表示一个节点，如果一条线上的2个地铁站相邻则有边。图信号矩阵是inflow和outflow</li><li>公交车图：每个公交站是一个节点，如果一条线上的2个公交站相邻则有边。图信号矩阵进站记录</li></ul></li></ol><h2><span id="42-构造邻接矩阵">4.2. 构造邻接矩阵</span></h2><ol><li>静态邻接矩阵<br>邻接矩阵不会随着时间变化。可以根据节点之间的特征构建多个邻接矩阵，例如功能相似，道路相通，时间相似。邻接矩阵中的值可以是非0即1，也可以表示节点间距离或者相似性。一般通过阈值来定义邻接矩阵，通过调整阈值来控制邻接矩阵的稀疏性。<script type="math/tex; mode=display">\mathbf{a}_{i j}=\left\{\begin{array}{l}\exp \left(-\frac{\mathbf{d}_{i j}^{2}}{\sigma^{2}}\right), i \neq j \text { and } \mathbf{d}_{i j} \geq \epsilon \\0 \quad, i=j \text { or } \mathbf{d}_{i j}<\epsilon\end{array}\right.</script></li></ol><ol><li>动态邻接矩阵<br>有2种情况：1. 邻接矩阵不随着时间变化，但是邻接矩阵不是预先定义好的，而是模型先动态学习节点嵌入，然后根据学习到的节点嵌入构造邻接矩阵。2. 邻接矩阵随着时间变化。</li></ol><h1><span id="5-前人的模型">5. 前人的模型</span></h1><p>分析图神经网络在交通领域的应用，发现GNN通常和其他组件一起用，类似RNN,Seq2Seq，TCN等。</p><h2><span id="51-gnn">5.1. GNN</span></h2><p>GNN在交通领域的应用主要有3个：谱图卷积for无向图，扩散卷积for有向图。</p><ol><li><p>谱图卷积</p><script type="math/tex; mode=display">\begin{aligned}Y_{j} &=\rho\left(\Theta_{j} *_{\mathcal{G}} X\right) \\&=\rho\left(\sum_{i=1}^{\mathbf{F}_{\mathrm{I}}} \theta_{i, j} \tilde{\mathbf{D}}^{-\frac{1}{2}} \tilde{\mathbf{A}} \tilde{\mathbf{D}}^{-\frac{1}{2}} X_{i}\right), 1 \leq j \leq \mathbf{F}_{\mathbf{O}} \\Y &=\rho\left(\tilde{\mathbf{D}}^{-\frac{1}{2}} \tilde{\mathbf{A}} \tilde{\mathbf{D}}^{-\frac{1}{2}} X W\right)\end{aligned}</script><p>谱图卷积要求对称的拉普拉斯矩阵，来实现特征值分解。</p></li><li><p>扩散卷积<br>谱图卷积要求对称的拉普拉斯矩阵，来实现特征值分解。但是对于有向图来说，拉普拉斯矩阵不是对称的。扩散卷积对图的结构，邻接矩阵，拉普拉斯矩阵没有任何限制。扩散卷积可以看做是转移矩阵的幂次，表示从节点i到节点j的转移概率。</p><script type="math/tex; mode=display">y=\Theta *_{\mathcal{G}} x=\sum_{k=0}^{\mathrm{K}-1}\left(\theta_{k, 1}\left(\mathrm{D}_{\mathrm{O}}^{-1} \mathrm{A}\right)^{k}+\theta_{k, 2}\left(\mathrm{D}_{\mathrm{I}}^{-1} \mathrm{A}^{T}\right)^{k}\right) x</script></li></ol><p>总结：谱图卷积和扩散卷积的不同：谱图卷积的邻接矩阵揭示中心节点和它直接邻近的节点更相关。而扩散卷积揭示空间依赖是随机且动态的。扩散卷积比谱图卷积更复杂。扩散卷积可以适用在任何交通网络上，而谱图卷积只能用在对称的图上，即无向图中。</p><p>有些工作在使用SGC和DGC使用以下tricks</p><ul><li>使用SGC时，引入attention机制<br>S表示图信号矩阵，使用切比雪夫多项式计算图卷积时，对S求attention，计算节点之间的影响程度。</li></ul><script type="math/tex; mode=display">\Theta *_{\mathcal{G}} x \approx \sum_{k=0}^{K-1} \theta_{k}\left(T_{k}(\tilde{\mathbf{L}}) \odot \mathbf{S}\right) x$$ $$\mathbf{S} = W_{1} \odot \rho\left(\left(X W_{2}\right) W_{3}(W_{4} X)^{T}+b\right) \in \mathbb{R}^{N \times N}</script><ul><li><p>直接使用邻接矩阵，FFR表示道路特征</p><script type="math/tex; mode=display">\Theta *_{\mathcal{G}} x=\left(W \odot \tilde{\mathbf{A}}^{\mathrm{K}} \odot \mathcal{F} \mathcal{F} \mathcal{R}\right) x</script></li><li><p>在邻接矩阵中引入地理位置信息</p><script type="math/tex; mode=display">\mathbf{S}=\mathbf{A} \odot \omega$$$$Y=\rho\left(\tilde{\mathbf{Q}}^{-\frac{1}{2}} \tilde{\mathbf{S}} \tilde{\mathbf{Q}}^{-\frac{1}{2}} X W\right)</script></li></ul><h2><span id="52-rnn">5.2. RNN</span></h2><p>交通任务预测中很多都是时间序列数据，适用RNN来捕获时间相关性。这里包括三类：RNN,LSTM,GRU</p><ul><li>RNN：输入层，隐藏层，输出层</li><li>LSTM：为了解决RNN的梯度消失和梯度爆炸问题，引入输入门，遗忘门，输出门。</li><li>GRU：LSTM结构复杂，参数更多，用更简单的GRU来代替，只有2个门：重置门</li></ul><p>在交通预测领域中，很少用RNN，大部分都是用GRU，少数用LSTM。在用GRU或LSTM时，有很多小tricks，例如attention，门控机制，残差机制。<br>在使用RNN所用到的tricks</p><ul><li>在RNN中引入空间信息<script type="math/tex; mode=display">\mathbf{H}_{t} = R N N\left(\left[\mathbf{H}_{t-1}, \mathbf{X}_{t}\right] \odot S\right)</script></li><li>引入外部因素<script type="math/tex; mode=display">\mathbf{H}_{t}=G R U\left(\left[\mathbf{H}_{t-1}, \mathbf{X}_{t}\right], \mathbf{E}_{t}\right)+\mathbf{H}_{t-1} W</script></li><li>使用空洞RNN<script type="math/tex; mode=display">\mathbf{H}_{t}=G R U\left(\mathbf{H}_{t-s}, \mathbf{X}_{t}\right)</script></li><li>RNN和图卷积结合<script type="math/tex; mode=display">\begin{aligned}r_{t} &=\sigma\left(\left[\mathbf{H}_{t-1}, \mathbf{X}_{t}\right] *_{\mathcal{G}} W_{r}+b_{r}\right) \\u_{t} &=\boldsymbol{\sigma}\left(\left[\mathbf{H}_{t-1}, \mathbf{X}_{t}\right] *_{\mathcal{G}} W_{u}+b_{u}\right) \\\tilde{\mathbf{H}}_{t} &=\tanh \left(r_{t} \odot\left[\mathbf{H}_{t-1}, \mathbf{X}_{t}\right] *_{\mathcal{G}} W_{h}+b_{h}\right) \\\mathbf{H}_{t} &=u_{t} \odot \mathbf{H}_{t-1}+\left(1-u_{t}\right) \odot \tilde{\mathbf{H}}_{t}\end{aligned}</script></li></ul><h2><span id="53-tcn">5.3. TCN</span></h2><p>虽然RNN可以捕获时间的相关性，但是其不能并行计算，耗时。与之对比，1D卷积运行更快，同样也可以捕获时间相关性。然后1D卷积与RNN相比应用更少，由于1D卷积缺少长期建模的memory机制。后来提出空洞卷积，在长期时间建模上，比RNN效果更好。之后，TCN被广泛应用在时间建模上。</p><p><img src="/2020/06/02/How-to-Build-a-Graph-Based-Deep-Learning-Architecture-in-Traffic-Domain-A-Survey/5.png" alt=""> </p><p>在使用TCN时，有一些小traick</p><ul><li><p>堆叠不同的TCN层，每层使用不同的dilation rate</p><script type="math/tex; mode=display">\mathcal{Y}^{(l+1)}=\sigma\left(\Theta^{l} *_{\mathcal{T} \mathrm{d}^{l}} \mathcal{Y}^{(l)}\right)</script></li><li><p>残差，原始输入+TCN的输出</p><script type="math/tex; mode=display">\mathcal{Y}^{(l+1)}=\mathcal{Y}^{(l)}+\boldsymbol{\operatorname { R e }} \boldsymbol{L} \boldsymbol{U}\left(\Theta_{1}^{l} *_{\mathcal{T}^{\mathrm{d}}}\left(\boldsymbol{\operatorname { R e }} \boldsymbol{L} \boldsymbol{U}\left(\Theta_{0}^{l} *_{\mathcal{T}^{\mathrm{d}}} \mathcal{Y}^{(l)}\right)\right)\right)</script></li><li><p>使用门控机制</p><script type="math/tex; mode=display">\mathcal{Y}=\rho\left(\Theta_{1} *_{\mathcal{T}^{\mathrm{d}}} \mathcal{X}+b_{1}\right) \odot \sigma\left(\Theta_{2} *_{\mathcal{T}^{\mathrm{d}}} \mathcal{X}+b_{2}\right)</script></li></ul><h2><span id="54-seq2seq">5.4. Seq2Seq</span></h2><p>原始的Seq2Seq模型为对输入进行建模，得到一个隐变量$C$,然后将$C$输入到解码器中，进行预测。</p><p><img src="/2020/06/02/How-to-Build-a-Graph-Based-Deep-Learning-Architecture-in-Traffic-Domain-A-Survey/6.png" alt=""> </p><p>对Seq2Seq的改进主要有2点：</p><ul><li><p>改变隐变量C<br>原先输入到decoder的C是固定的，对decoder中所有的时间步来说都一样，然后输入中的值对不同的输出影响程度不同，这里引入attention机制，动态改变C</p><script type="math/tex; mode=display">\begin{array}{l}\mathbf{H}_{i}=\operatorname{Encoder}\left(\mathbf{X}_{i}, \mathbf{H}_{i-1}\right) \\\mathbf{C}_{j}=\sum_{i=1}^{\mathbf{P}}\left(\theta_{j i} \mathbf{H}_{i}\right), \mathbf{S}_{0}=\mathbf{H}_{\mathbf{P}} \\\mathbf{S}_{j}=\operatorname{Decoder}\left(\mathbf{C}_{j}, \mathbf{Y}_{j-1}, \mathbf{S}_{j-1}\right) \\\mathbf{Y}_{j}=\mathbf{S}_{j} W\end{array}</script></li><li><p>采样<br>在decoder在训练阶段和测试阶段的输入是不同的。在训练阶段，decoder的不同时间步输入的真实的label，而在测试阶段，因为不知道label，输入的是上一个时间步预测的结果，这样可能会造成错误累积的问题。为了解决这个问题，可以在训练阶段进行采样，即并不总是输入真实的label，以$\epsilon_{j}$输入真实babel，以$1-\epsilon_{j}$输入上个时间步的预测结果。</p></li></ul><p>交通领域中的多步预测通常采用Seq2Seq架构。Seq2Seq中的encoder和decoder架构通常采用RNN，但是也不一定相同。</p><h2><span id="55-gan">5.5. GAN</span></h2><p>这一模块看的论文较少，以后补充</p><h1><span id="6-挑战">6. 挑战</span></h1><p>尽管交通领域有很多研究方向，但它们都有一些共同的挑战，如下所示，主要分为三类：空间依赖，时间依赖，外部因素。</p><p><img src="/2020/06/02/How-to-Build-a-Graph-Based-Deep-Learning-Architecture-in-Traffic-Domain-A-Survey/2.png" alt=""> </p><h2><span id="61-空间依赖">6.1. 空间依赖</span></h2><p>在一个双向的道路中，R1只受R2的影响，R3对R1的影响较小。如果采用网格的形式，R3和R2对R1的影响相同，这不符合实际。如果采用图的形式，R2对R1的影响较大，R3对R1的影响较小，符合实际。</p><p><img src="/2020/06/02/How-to-Build-a-Graph-Based-Deep-Learning-Architecture-in-Traffic-Domain-A-Survey/7.png" alt=""> </p><p>交通网络中空间依赖十分复杂，可以分成三类：空间局部性，多元关系，全局连通性。</p><ol><li>空间局部性<br>空间局部性表示邻近区域比较远的区域更相关。K阶局部谱图卷积SGCN可以聚合0~K-1跳的邻居信息。还有一些其他工作可以捕获空间局部相关性。比如动态计算邻接矩阵</li><li>多元关系<br>目标区域也可能与距离较远的区域相关。例如功能相似的区域，交通连通的区域。根据这些不同的相似性来创建不同的图。</li><li>全局连通性<br>以上2点更关注网络部分，而忽略了整体的结构。全局连通性表示不同区域的交通情况在整个网络上互相影响。使用扩散卷积、pooling层、self-adaptive邻接矩阵可以捕获到这种全局连通性。</li></ol><h2><span id="62-时间依赖">6.2. 时间依赖</span></h2><p>使用RNN或TCN来捕获时间依赖</p><ol><li>多粒度<br>时间有不同的周期性，例如recent，daily，weekly。</li><li>不同的权重<br>历史信息对目标时间段的影响权重不同。使用Attention机制计算权重分数。</li></ol><h2><span id="63-时空依赖">6.3. 时空依赖</span></h2><p>以上对时间和空间依赖分别建模，如果对时空依赖同时建模，预测效果可能会更好。例如STSGCN</p><h2><span id="64-外部因素">6.4. 外部因素</span></h2><p>天气（雨/温度/空气质量），时间（节假日/周几/几点），特殊时间，POI等信息都会影响交通预测。<br>对于外部因素的处理通常有2种方法：</p><ol><li>和其他因素拼接，输入到模型中</li><li>设计外部因素处理模块，对外部因素单独处理。通常是2个FCN，第一个FCN提取重要信息，第二个FCN从低维特征映射到高维特征</li></ol><h1><span id="7-未来方向">7. 未来方向</span></h1><ol><li>在司机行为分类，车辆/人们轨迹预测，交通事故预测使用图模型。</li><li>大多使用SGCN和DGCN，很少使用GAT,GAE,RNN+GCN，可以使用以上模型解决交通问题</li><li>交通问题大多是回归问题，很少有分类问题，可以使用图模型研究分类问题</li><li>现有模型对外部因素处理比较简单，可以设计更复杂的模型捕获外部因素信息。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇综述性论文介绍图神经网络在交通领域的应用。&lt;/p&gt;
    
    </summary>
    
      <category term="论文阅读笔记" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="时空领域" scheme="http://yoursite.com/tags/%E6%97%B6%E7%A9%BA%E9%A2%86%E5%9F%9F/"/>
    
  </entry>
  
  <entry>
    <title>图神经网络研讨会</title>
    <link href="http://yoursite.com/2020/03/29/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%A0%94%E8%AE%A8%E4%BC%9A/"/>
    <id>http://yoursite.com/2020/03/29/图神经网络研讨会/</id>
    <published>2020-03-29T05:40:52.000Z</published>
    <updated>2020-03-31T15:15:44.158Z</updated>
    
    <content type="html"><![CDATA[<p>在线图神经网络研讨会<br><a id="more"></a><br><img src="/2020/03/29/图神经网络研讨会/intro.png" alt=""></p><h1><span id="网络表示学习">网络表示学习</span></h1><ul><li>网络表示的关键问题：<br>如何定义图中节点的相似性</li></ul><h1><span id="图神经网络及认知推理">图神经网络及认知推理</span></h1><p><strong>网络上的学习任务：</strong></p><ul><li>节点分类：给定一个点，预测其类别</li><li>链接预测：给2个点，预测这2个点是否相连</li><li>community detection：找子图</li><li>网络相似度：2个网络或子网络的相似度</li></ul><h2><span id="回顾网络表示学习">回顾网络表示学习</span></h2><p>给定一个网络，学习节点的低维表示，如果2个节点距离很近，那这2个节点的表示也要相似。<br><strong>挑战：</strong></p><ol><li>CNN只适用于网格(二维)，但是网络是一个拓扑机构</li><li>RNN适用于文本/序列，这种都有先后关系，但是网络没有先后关系</li><li>网络是动态的，节点有属性，并且网络还有结构属性</li></ol><p><strong>网络表示学习发展：</strong></p><ol><li>使用word2vec来做网络表示学习，即DeepWalk</li><li>根据DeepWalk进行扩展：<ul><li>LINE：一阶和二阶相似性</li><li>PTE：异构网络</li><li>Node2vec：biased random walk</li></ul></li></ol><p><strong>网络表示学习的本质：</strong><br>都是在做矩阵分解，SVD分解，只是分解的形式不一样。<br>图表示学习结合的是context信息，用上下文信息来做网络表示学习。</p><p><img src="/2020/03/29/图神经网络研讨会/1.png" alt=""></p><p><strong>问题：</strong></p><h2><span id="gnn">GNN</span></h2><p><img src="/2020/03/29/图神经网络研讨会/2.png" alt=""></p><p><img src="/2020/03/29/图神经网络研讨会/3.png" alt=""></p><h2><span id="异质图">异质图</span></h2><p>同质网络：网络中只有一种类型的节点或边<br>异质网络：网络中有多类节点或边</p><p>首先分解出网络中的对象，以及对象之间的关系。<br>例如：作者-论文-会议，一个网络中有3类节点。<br>其中对象之间的关系（Meta path）有：</p><ul><li>作者1-论文-作者2（2个作者共同合作一篇论文）</li><li>作者1-论文-引用论文1，作者1写论文，引用了其他论文</li><li>……</li></ul><h3><span id="模型">模型</span></h3><ol><li>Metapath2Vec<br>基于meta path的随机游走，</li><li>HERec<br>解决异质图中节点的表示，将异质图变成同质图，在同质图中用DeepWalk或LINE学习节点表示</li><li>HIN2Vec<br>随机游走抽取出点边序列</li><li>MCRec</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在线图神经网络研讨会&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Deep Learning" scheme="http://yoursite.com/categories/Deep-Learning/"/>
    
    
      <category term="Graph" scheme="http://yoursite.com/tags/Graph/"/>
    
  </entry>
  
  <entry>
    <title>argparse不支持bool类型</title>
    <link href="http://yoursite.com/2020/03/09/argparse%E4%B8%8D%E6%94%AF%E6%8C%81bool%E7%B1%BB%E5%9E%8B/"/>
    <id>http://yoursite.com/2020/03/09/argparse不支持bool类型/</id>
    <published>2020-03-09T08:28:29.000Z</published>
    <updated>2020-03-09T08:57:46.605Z</updated>
    
    <content type="html"><![CDATA[<p>在Python中通过下列方式向程序传递bool参数时，其中<code>neg</code>参数指定类型为bool，但是无论传入的值是什么，<code>neg</code>始终为<code>True</code></p><p>解决方法：<br><a href="https://blog.csdn.net/yaokai_assultmaster/article/details/77928629" target="_blank" rel="noopener">使用Python中的argparse从命令行接收boolean类型的参数</a><br><a id="more"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">"--config"</span>, type=str, help=<span class="string">'configuration file'</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--gpus"</span>, type=str,help=<span class="string">"test program"</span>)<span class="comment">#如果</span></span><br><span class="line">parser.add_argument(<span class="string">"--neg"</span>, type=bool, help=<span class="string">"test program"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--test"</span>, action=<span class="string">"store_true"</span>, help=<span class="string">"test program"</span>)</span><br></pre></td></tr></table></figure><p>【注意】类似于上文中<code>gpus</code>这种参数，指定也可以，不指定也可以</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在Python中通过下列方式向程序传递bool参数时，其中&lt;code&gt;neg&lt;/code&gt;参数指定类型为bool，但是无论传入的值是什么，&lt;code&gt;neg&lt;/code&gt;始终为&lt;code&gt;True&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;解决方法：&lt;br&gt;&lt;a href=&quot;https://blog.csdn.net/yaokai_assultmaster/article/details/77928629&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;使用Python中的argparse从命令行接收boolean类型的参数&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="http://yoursite.com/categories/Python/"/>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>深度学习优秀代码示例</title>
    <link href="http://yoursite.com/2020/03/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BC%98%E7%A7%80%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B/"/>
    <id>http://yoursite.com/2020/03/03/深度学习优秀代码示例/</id>
    <published>2020-03-03T03:30:18.000Z</published>
    <updated>2020-03-07T05:14:24.731Z</updated>
    
    <content type="html"><![CDATA[<p>&ensp;&ensp;&ensp;&ensp;曾经一段时间很苦恼，对于深度学习算法不知道怎么上手，看了很多深度学习教程，依然不会写。后来就看论文公开的源代码，对照着论文模型，一点点看，多看几篇代码，逐渐有种开窍的感觉。其次是看Mxnet和Pytorch的源代码(我主要用这2个框架)，Mxnet和Pytorch的Github上给了很多示例代码，写的非常规范，从中可以学到用法，从而也可以规范自己的代码。<br>&ensp;&ensp;&ensp;&ensp;下面整理一下，在我学习过程中，对我帮助很大的教程和代码。</p><a id="more"></a><ol><li><a href="http://zh.gluon.ai/" target="_blank" rel="noopener">《动手学深度学习》Mxnet版</a><br>Mxnet的入门教程，沐神写的，来来回回看了2~3遍，每次看都有新的收货</li><li><a href="https://tangshusen.me/Dive-into-DL-PyTorch/#/" target="_blank" rel="noopener">《动手学深度学习》Pytorch版</a><br>将Mxnet改写为Pytorch版本，非常好的Pytorch入门教程</li><li><a href="https://github.com/Davidham3/ASTGCN" target="_blank" rel="noopener">ASTGCN</a><br>AAAI2019论文公开代码，用Mxnet写的</li><li><a href="https://yjucho1.github.io/spatio-temporal%20data/deep%20learning%20paper/ST-resnet/" target="_blank" rel="noopener">ST-ResNet</a><br>AAAI2017论文公开代码，用Keras，看这篇代码主要是学习模型架构，然后自己用mxnet复现了一下</li><li><a href="https://github.com/panzheyi/ST-MetaNet" target="_blank" rel="noopener">ST-MetaNet</a><br>KDD2019论文公开代码，用Mxnet写的，学到了很多高级用法，例如EarlyStopping，Encoder和Decoder，getattr，DGL</li><li><p><a href="https://github.com/pytorch/examples/tree/master/word_language_model" target="_blank" rel="noopener">Pytorch Transformer</a><br>学习怎么使用Transformer，Dropout和BN在训练和测试的不同，PositionEmbedding，getattr等用法。学习Transformer最好去看Pytorch关于Tranformer的源代码。</p></li><li><p><a href="https://github.com/pytorch/examples" target="_blank" rel="noopener">Pytorch示例代码</a><br>Pytorch Github中的示例代码</p></li><li><a href="https://github.com/apache/incubator-mxnet/tree/master/example" target="_blank" rel="noopener">Mxnet示例代码</a><br>Mxnet Github中的示例代码</li></ol><p>觉得自己最大的变化是喜欢去读源代码了，遇到问题去官网看教程，读源码，帮助很大。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;曾经一段时间很苦恼，对于深度学习算法不知道怎么上手，看了很多深度学习教程，依然不会写。后来就看论文公开的源代码，对照着论文模型，一点点看，多看几篇代码，逐渐有种开窍的感觉。其次是看Mxnet和Pytorch的源代码(我主要用这2个框架)，Mxnet和Pytorch的Github上给了很多示例代码，写的非常规范，从中可以学到用法，从而也可以规范自己的代码。&lt;br&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;下面整理一下，在我学习过程中，对我帮助很大的教程和代码。&lt;/p&gt;
    
    </summary>
    
      <category term="Deep Learning" scheme="http://yoursite.com/categories/Deep-Learning/"/>
    
    
      <category term="Mxnet" scheme="http://yoursite.com/tags/Mxnet/"/>
    
      <category term="Pyotrch" scheme="http://yoursite.com/tags/Pyotrch/"/>
    
  </entry>
  
</feed>
